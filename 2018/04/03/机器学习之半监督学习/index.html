<!DOCTYPE html>
<html>
<meta  lang="zh-CN" >
<head>
  <meta charset="UTF-8">
  <meta name="viewport"
    content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <meta name="theme-color" content="#fff" id="theme-color">
  <link rel="icon" href="/img/logo.jpg">
  <title>Tan Qing Bo's Blog</title>
  
  
  <meta property="og:title" content="机器学习之半监督学习（Semi-supervised learning）">
  
  
  <meta property="og:url" content="http://tanqingbo.cn/2018/04/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/index.html">
  
  
  <meta property="og:img" content="/img/logo.jpg">
  
  
  <meta property="og:img" content="学习总结  思考感悟  知识管理">
  
  
  <meta property="og:type" content="article">
  <meta property="og:article:published_time" content="2018-04-03">
  <meta property="og:article:modified_time" content="2018-04-04">
  <meta property="og:article:author" content="Tan Qing Bo">
  
  
  
  
  
  
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-178024758-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-178024758-1');
</script>
  
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?d87293651eefff721c898f38338ea3a8";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

  
  <script>
    // control reverse button
    var reverseDarkList = {
      dark: 'light',
      light: 'dark'
    };
    var themeColor = {
      dark: '#1c1c1e',
      light: '#fff'
    }
    // get the data of css prefers-color-scheme
    var getCssMediaQuery = function() {
      return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
    };
    // reverse current darkmode setting function
    var reverseDarkModeSetting = function() {
      var setting = localStorage.getItem('user-color-scheme');
      if(reverseDarkList[setting]) {
        setting = reverseDarkList[setting];
      } else if(setting === null) {
        setting = reverseDarkList[getCssMediaQuery()];
      } else {
        return;
      }
      localStorage.setItem('user-color-scheme', setting);
      return setting;
    };
    // apply current darkmode setting
    var setDarkmode = function(mode) {
      var setting = mode || localStorage.getItem('user-color-scheme');
      if(setting === getCssMediaQuery()) {
        document.documentElement.removeAttribute('data-user-color-scheme');
        localStorage.removeItem('user-color-scheme');
        document.getElementById('theme-color').content = themeColor[setting];
      } else if(reverseDarkList[setting]) {
        document.documentElement.setAttribute('data-user-color-scheme', setting);
        document.getElementById('theme-color').content = themeColor[setting];
      } else {
        document.documentElement.removeAttribute('data-user-color-scheme');
        localStorage.removeItem('user-color-scheme');
        document.getElementById('theme-color').content = themeColor[getCssMediaQuery()];
      }
    };
    setDarkmode();
  </script>
  <script>
    function loadScript(url, cb) {
      var script = document.createElement('script');
      script.src = url;
      if (cb) script.onload = cb;
      script.async = true;
      document.body.appendChild(script);
    }
  </script>
  
  <link rel="preload" href="//at.alicdn.com/t/font_1946621_f7g5jnuftcf.css" as="style" >
  <link rel="preload" href="//at.alicdn.com/t/font_1952792_89b4ac4k4up.css" as="style" >
  
  <link rel="preload" href="//cdn.jsdelivr.net/npm/fslightbox@3.1.0/index.min.js" as="script">
  
  
  <link rel="preload" href="/js/lib/lozad.min.js" as="script">
  
  
  
  
  
  <link rel="prefetch" href="//cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-svg.js" as="script">
  
  
  
  
  
<link rel="stylesheet" href="/css/main.css">

  
  
<link rel="stylesheet" href="//at.alicdn.com/t/font_1946621_f7g5jnuftcf.css">

  
  
<link rel="stylesheet" href="//at.alicdn.com/t/font_1952792_89b4ac4k4up.css">

  
  
  
<meta name="generator" content="Hexo 5.1.1"></head>


<body>
  <div class="wrapper">
    
    <nav class="navbar">
  <div class="navbar-logo">
    <span class="navbar-logo-main">
      
      <img class="navbar-logo-img" src="/img/logo.jpg">
      
      <span class="navbar-logo-dsc">Tan Qing Bo's Blog</span>
    </span>
  </div>
  <div class="navbar-menu">
    
    <a href="/" class="navbar-menu-item">
    
    首页
    
    </a>
    
    <a href="/archives" class="navbar-menu-item">
    
    归档
    
    </a>
    
    <a href="/tags" class="navbar-menu-item">
    
    标签
    
    </a>
    
    <a href="/categories" class="navbar-menu-item">
    
    分类
    
    </a>
    
    <a href="/about" class="navbar-menu-item">
    
    关于
    
    </a>
    
    <a href="/links" class="navbar-menu-item">
    
    友链
    
    </a>
    
    <a class="navbar-menu-item darknavbar" id="dark"><i class="iconfont icon-weather"></i></a>
    <a class="navbar-menu-item searchnavbar" id="search"><i class="iconfont icon-search" style="font-size: 1.2rem; font-weight: 400;"></i></a>
  </div>
</nav>
    
    <div id="local-search" style="display: none;">
      <input class="navbar-menu-item" id="search-input" placeholder="请输入搜索内容...">
      <div id="search-content"></div>
    </div>
    
    <div class="section-wrap">
      <div class="container">
        <div class="columns">
          <main class="main-column">
<article class="card card-content">
  <header>
    <h1 class="post-title">
      机器学习之半监督学习（Semi-supervised learning）
    </h1>
  </header>
  <div class="post-meta post-show-meta">
    <time datetime="2018-04-03T06:23:18.000Z" style="display: flex; align-items: center;">
      <i class="iconfont icon-calendar" style="margin-right: 2px;"></i>
      <span>2018-04-03</span>
    </time>
    
    <span class="dot"></span>
    
    <a href="/categories/机器学习/" class="post-meta-link">机器学习</a>
    
    
    
    <span class="dot"></span>
    <span>1.3k 字</span>
    
  </div>
  
  </header>
  <div id="section" class="post-content">
    <h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><ul>
<li><strong>什么是半监督学习？</strong>既有有标记数据 xr，又有无标记数据 xu，一般无标记数据的数量远大于有标记数据。半监督学习又可以分为两种：<ul>
<li>**Transductive learning:**无标记数据就是<code>Testing data</code>.</li>
<li>**Inductive learning:**无标记数据不是 testing data，假设在训练时不知道 testing set.</li>
</ul>
</li>
<li><strong>为什么要用半监督学习（Semi-supervised learning）？</strong><ul>
<li>因为收集数据比较容易，但是收集<code>label</code>数据的代价却很昂贵。<h2 id="半监督学习下的-generative-model"><a href="#半监督学习下的-generative-model" class="headerlink" title="半监督学习下的 generative model"></a>半监督学习下的 generative model</h2></li>
</ul>
</li>
<li>为了更直观的了解半监督学习下的生成模型，我们先介绍一下全监督学习下的生成模型，好让大家有个对比。</li>
</ul>
<h3 id="全监督学习下的生成模型"><a href="#全监督学习下的生成模型" class="headerlink" title="全监督学习下的生成模型"></a>全监督学习下的生成模型</h3><ul>
<li>首先，估计 prior probability P(Ci)，再估计出每一类有标记数据的分布 P(x|Ci)，假设数据的分布为共用协方差矩阵的高斯分布，因此只需要估计出<img src="https://i.imgur.com/KqKsRiu.png" / srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20300%20300'%3E%3C/svg%3E" data-src="https://i.imgur.com/KqKsRiu.png" class="lozad post-image">就行，之后就可以估计某个数据属于某一类的概率了，计算公式如下：</li>
</ul>
<center>
![](https://i.imgur.com/pEZpzZL.png)
</center>

<h3 id="半监督学习下的生成模型"><a href="#半监督学习下的生成模型" class="headerlink" title="半监督学习下的生成模型"></a>半监督学习下的生成模型</h3><ul>
<li>前面部分与监督学习的操作一样，先使用有监督的数据估计出 P(Ci)、μi 和 Σ，接下来使用未标记的数据 xu 来对这些参数重新估计，以二分类问题为例，估计过程主要分为如下两个步骤：<ul>
<li><strong>初始化</strong> θ={P(C1),P(C2),μ1,μ2,Σ}，（可以随机初始化，也可以根据已有的标记数据估计出来）。</li>
<li><strong>step1</strong>：根据初始化的参数计算无标记数据的后验概率Pθ(C1|xu) 。</li>
<li><strong>step2</strong>：更新模型参数：</li>
</ul>
</li>
</ul>
<center>
![](https://i.imgur.com/esLORLP.png)
</center>

<ul>
<li>接着再返回<code>step1</code>，直到参数收敛为止。</li>
<li>其实上面这个过程，我们用到了再机器学习领域一个超级NB的算法的思想，它就是EM(Expectation-maximization),<strong>step1</strong>就是 E，<strong>step2</strong>就是 M. 这样反复下去，在最终一定会收敛.</li>
</ul>
<h2 id="半监督学习之低密度分离假设（Low-density-Separation）"><a href="#半监督学习之低密度分离假设（Low-density-Separation）" class="headerlink" title="半监督学习之低密度分离假设（Low-density Separation）"></a>半监督学习之低密度分离假设（Low-density Separation）</h2><ul>
<li>在用这个假设的时候，需要假设有一个很明显的区域(Low-density),能够把数据分开。<h3 id="Self-training"><a href="#Self-training" class="headerlink" title="Self-training"></a>Self-training</h3></li>
<li>先对有标记数据训练出一个模型f*,这个可以模型可以用任何方法训练。</li>
<li>用这个 f∗ 来预测无标记的数据，预测出的就叫 pseudo label.</li>
<li>接下来，就用无标记数据中拿出一部分数据，放到有标记数据中，怎么选出这部分是自己定的，也可以对每一个数据提供一个权重。新加入了这些数据之后，就可以再重新训练一个 f∗，往复进行。 </li>
<li>这招用在 regression 中，是没有用的，因为用预测出来的数字重新用来做训练，并不会影响模型的参数。</li>
<li>在做 self-training 时，其实就是把某个未标记数据指定一个分类，而在 generative model 中，其实就是把未标记数据对应于各个分类的概率计算出来。</li>
</ul>
<h2 id="基于熵的正则化-Entropy-based-Regularization"><a href="#基于熵的正则化-Entropy-based-Regularization" class="headerlink" title="基于熵的正则化(Entropy-based Regularization)"></a>基于熵的正则化(Entropy-based Regularization)</h2><ul>
<li>假如未标记数据数据 xu 经过某一组参数估计后属于某一类的概率如下：</li>
</ul>
<center>
![](https://i.imgur.com/cdqFgMG.png)
</center>

<ul>
<li>又边红圈中的公式为熵的计算公式。由上图可知 xu 属于某一类的概率越大，熵的值E就越小，因此重新定义损失函数<img src="https://i.imgur.com/qmJrm7t.png" / srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20300%20300'%3E%3C/svg%3E" data-src="https://i.imgur.com/qmJrm7t.png" class="lozad post-image">，其中E(yu)可以微分，我们可以直接用梯度下降法来求解。</li>
</ul>
<h2 id="Semi-supervised-SVM"><a href="#Semi-supervised-SVM" class="headerlink" title="Semi-supervised SVM"></a>Semi-supervised SVM</h2><ul>
<li>将未标记数据穷举所有的分法，然后对每一种分法都进行 SVM，具有最大的间隔和最小误差的那一种。<br>但是，如果有 10000 个未标记数据，那么就会有 210000 种分法来穷举，<a target="_blank" rel="noopener" href="https://www.cs.cornell.edu/people/tj/publications/joachims_99c.pdf">Transductive Inference for Text Classification using Support Vector Machines</a> 中提出的解决办法是，每次只改一个数据，看一下能否让间距变大，变大了就改。</li>
</ul>
<h2 id="平滑假设-smoothness-assumption"><a href="#平滑假设-smoothness-assumption" class="headerlink" title="平滑假设(smoothness assumption)"></a>平滑假设(smoothness assumption)</h2><ul>
<li>做出如下假设：<ul>
<li>x的分布不均匀，在有些地方集中，有些地方分散，若x1和x2在一个<code>high density region</code>内很接近，那么 y^1 就与 y^2 相同，那么什么是<code>high density region</code>呢？请看下图：</li>
</ul>
</li>
</ul>
<center>
![](https://i.imgur.com/zYSZZGN.png)
</center>

<ul>
<li>在图中，虽然x2与x3比较接近，但是x1与x2在同一块<code>high density region</code>，所以 y^1 与 y^2 相同,y^2 与 y32 不相同。</li>
</ul>
<h2 id="基于图的方法-Graph-based-Approach"><a href="#基于图的方法-Graph-based-Approach" class="headerlink" title="基于图的方法(Graph-based Approach)"></a>基于图的方法(Graph-based Approach)</h2><ul>
<li>首先需要定义相似度，一般可以用 <code>Gaussian Radial Basis Function (RBF)</code> 来定义：<img src="https://i.imgur.com/yWf68TM.png" / srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20300%20300'%3E%3C/svg%3E" data-src="https://i.imgur.com/yWf68TM.png" class="lozad post-image">，这个函数可以让相似度随着距离的增加而迅速减小。 </li>
<li>定义完相似度之后，就可以逐渐把数据点之间相连的边加上去，加边可以用 kNN 或者 e-Neighborhood 的方法来做。然后设置边的权重，和 s(xi,xj) 成比例。 </li>
<li>然后，定义在图上的标记的<strong>平滑因子(smoothness)S:</strong><img src="https://i.imgur.com/e6sc9mT.png" / srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20300%20300'%3E%3C/svg%3E" data-src="https://i.imgur.com/e6sc9mT.png" class="lozad post-image">，该式可以写成 <img src="https://i.imgur.com/rEsFVDD.png" / srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20300%20300'%3E%3C/svg%3E" data-src="https://i.imgur.com/rEsFVDD.png" class="lozad post-image">，y 是 R+U 维的向量（所有的有标记和无标记数据），L=D−W，W 是所有数据之间两两的连接权重，D 是对角矩阵，对角线上的值是每个数据点所有的连接的权重之和。之后，就可以定义出 loss function:<center>
![](https://i.imgur.com/oS2nken.png)
</center></li>
</ul>

  </div>
  <div>
  
  <div class="post-note note-warning copyright" style="margin-top: 42px">
    <p><span style="font-weight: bold;">作者：</span><a target="_blank" rel="nofollow noopener noreferrer" href="http://tanqingbo.cn/about">谭庆波</a></p>
    <p><span style="font-weight: bold;">文章链接：</span><a target="_blank" rel="nofollow noopener noreferrer" href="http://tanqingbo.cn/2018/04/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">http://tanqingbo.cn/2018/04/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/</a></p>
    <p><span style="font-weight: bold;">版权声明：</span>本博客所有文章除特别声明外，均采用<a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">CC BY-NC-SA 4.0 协议</a>。转载请注明出处！</p>
  </div>
  
  </div>
</article>
<div class="nav">
  
  <div class="nav-item-prev">
    <a href="/2018/04/04/【无监督学习】Unsupervised Learning-Linear Dimension Reduction/" class="nav-link">
      <i class="iconfont icon-left nav-prev-icon"></i>
      <div>
        <div class="nav-label">上一篇</div>
        
        <div class="nav-title">【无监督学习之线性降维】Unsupervised Learning-Linear Dimension Reduction </div>
        
      </div>
    </a>
  </div>
  
  
  <div class="nav-item-next">
    <a href="/2018/03/30/廖雪峰历时3个月打磨出价值1980的数据分析教程，终终终于免费啦！/" class="nav-link">
      <div>
        <div class="nav-label">下一篇</div>
        
        <div class="nav-title">廖雪峰历时3个月打磨出价值1980的数据分析教程，终终终于免费啦！ </div>
        
      </div>
      <i class="iconfont icon-right nav-next-icon"></i>
    </a>
  </div>
  
</div>

<div class="card card-content toc-card" id="mobiletoc">
  <div class="toc-header"><i class="iconfont icon-menu" style="padding-right: 2px;"></i>目录</div>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B8%8B%E7%9A%84-generative-model"><span class="toc-text">半监督学习下的 generative model</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%A8%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B8%8B%E7%9A%84%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B"><span class="toc-text">全监督学习下的生成模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B8%8B%E7%9A%84%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B"><span class="toc-text">半监督学习下的生成模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B9%8B%E4%BD%8E%E5%AF%86%E5%BA%A6%E5%88%86%E7%A6%BB%E5%81%87%E8%AE%BE%EF%BC%88Low-density-Separation%EF%BC%89"><span class="toc-text">半监督学习之低密度分离假设（Low-density Separation）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Self-training"><span class="toc-text">Self-training</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E7%86%B5%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%96-Entropy-based-Regularization"><span class="toc-text">基于熵的正则化(Entropy-based Regularization)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Semi-supervised-SVM"><span class="toc-text">Semi-supervised SVM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B9%B3%E6%BB%91%E5%81%87%E8%AE%BE-smoothness-assumption"><span class="toc-text">平滑假设(smoothness assumption)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%9A%84%E6%96%B9%E6%B3%95-Graph-based-Approach"><span class="toc-text">基于图的方法(Graph-based Approach)</span></a></li></ol>
</div></main>
          <aside class="left-column">
            
            <div class="card card-author">
              
<img src="/img/logo.jpg" class="author-img">

<p class="author-name">Tan Qing Bo</p>
<p class="author-description">designed by Tan Qing Bo</p>
<div class="author-message">
  <a class="author-posts-count" href="/archives">
    <span>318</span>
    <span>文章</span>
  </a>
  <a class="author-categories-count" href="/categories">
    <span>14</span>
    <span>分类</span>
  </a>
  <a class="author-tags-count" href="/tags">
    <span>34</span>
    <span>标签</span>
  </a>
</div>

            </div>
            
            <div class="sticky-tablet">
  
  
  <article class="display-when-two-columns spacer">
    <div class="card card-content toc-card">
      <div class="toc-header"><i class="iconfont icon-menu" style="padding-right: 2px;"></i>目录</div>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B8%8B%E7%9A%84-generative-model"><span class="toc-text">半监督学习下的 generative model</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%A8%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B8%8B%E7%9A%84%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B"><span class="toc-text">全监督学习下的生成模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B8%8B%E7%9A%84%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B"><span class="toc-text">半监督学习下的生成模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B9%8B%E4%BD%8E%E5%AF%86%E5%BA%A6%E5%88%86%E7%A6%BB%E5%81%87%E8%AE%BE%EF%BC%88Low-density-Separation%EF%BC%89"><span class="toc-text">半监督学习之低密度分离假设（Low-density Separation）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Self-training"><span class="toc-text">Self-training</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E7%86%B5%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%96-Entropy-based-Regularization"><span class="toc-text">基于熵的正则化(Entropy-based Regularization)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Semi-supervised-SVM"><span class="toc-text">Semi-supervised SVM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B9%B3%E6%BB%91%E5%81%87%E8%AE%BE-smoothness-assumption"><span class="toc-text">平滑假设(smoothness assumption)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%9A%84%E6%96%B9%E6%B3%95-Graph-based-Approach"><span class="toc-text">基于图的方法(Graph-based Approach)</span></a></li></ol>
    </div>
  </article>
  
  
  <article class="card card-content categories-widget">
    <div class="categories-card">
  <div class="categories-header"><i class="iconfont icon-fenlei" style="padding-right: 2px;"></i>分类</div>
  <div class="categories-list">
    
      <a href="/categories/转载">
        <div class="categories-list-item">
          转载
          <span class="categories-list-item-badge">117</span>
        </div>
      </a>
    
      <a href="/categories/漂来漂去">
        <div class="categories-list-item">
          漂来漂去
          <span class="categories-list-item-badge">40</span>
        </div>
      </a>
    
      <a href="/categories/机器学习">
        <div class="categories-list-item">
          机器学习
          <span class="categories-list-item-badge">37</span>
        </div>
      </a>
    
      <a href="/categories/C语言">
        <div class="categories-list-item">
          C语言
          <span class="categories-list-item-badge">4</span>
        </div>
      </a>
    
      <a href="/categories/资源分享">
        <div class="categories-list-item">
          资源分享
          <span class="categories-list-item-badge">17</span>
        </div>
      </a>
    
      <a href="/categories/图像处理">
        <div class="categories-list-item">
          图像处理
          <span class="categories-list-item-badge">15</span>
        </div>
      </a>
    
      <a href="/categories/技术博客">
        <div class="categories-list-item">
          技术博客
          <span class="categories-list-item-badge">38</span>
        </div>
      </a>
    
      <a href="/categories/Linux">
        <div class="categories-list-item">
          Linux
          <span class="categories-list-item-badge">5</span>
        </div>
      </a>
    
      <a href="/categories/Java">
        <div class="categories-list-item">
          Java
          <span class="categories-list-item-badge">23</span>
        </div>
      </a>
    
      <a href="/categories/大话设计模式">
        <div class="categories-list-item">
          大话设计模式
          <span class="categories-list-item-badge">5</span>
        </div>
      </a>
    
      <a href="/categories/东搞西搞">
        <div class="categories-list-item">
          东搞西搞
          <span class="categories-list-item-badge">10</span>
        </div>
      </a>
    
      <a href="/categories/网络原理">
        <div class="categories-list-item">
          网络原理
          <span class="categories-list-item-badge">4</span>
        </div>
      </a>
    
      <a href="/categories/操作系统">
        <div class="categories-list-item">
          操作系统
          <span class="categories-list-item-badge">2</span>
        </div>
      </a>
    
      <a href="/categories/设计模式">
        <div class="categories-list-item">
          设计模式
          <span class="categories-list-item-badge">1</span>
        </div>
      </a>
    
  </div>
</div>
  </article>
  
  <article class="card card-content tags-widget">
    <div class="tags-card">
  <div class="tags-header"><i class="iconfont icon-biaoqian" style="padding-right: 2px;"></i>热门标签</div>
  <div class="tags-list">
    
    <a href="\tags\技术" title="技术"><div class="tags-list-item">技术</div></a>
    
    <a href="\tags\VS" title="VS"><div class="tags-list-item">VS</div></a>
    
    <a href="\tags\JVM" title="JVM"><div class="tags-list-item">JVM</div></a>
    
    <a href="\tags\Java" title="Java"><div class="tags-list-item">Java</div></a>
    
    <a href="\tags\面试" title="面试"><div class="tags-list-item">面试</div></a>
    
    <a href="\tags\Linux" title="Linux"><div class="tags-list-item">Linux</div></a>
    
    <a href="\tags\C语言" title="C语言"><div class="tags-list-item">C语言</div></a>
    
    <a href="\tags\数据结构，Map" title="数据结构，Map"><div class="tags-list-item">数据结构，Map</div></a>
    
    <a href="\tags\数据库" title="数据库"><div class="tags-list-item">数据库</div></a>
    
    <a href="\tags\MYSQL" title="MYSQL"><div class="tags-list-item">MYSQL</div></a>
    
    <a href="\tags\Python" title="Python"><div class="tags-list-item">Python</div></a>
    
    <a href="\tags\算法" title="算法"><div class="tags-list-item">算法</div></a>
    
    <a href="\tags\博客" title="博客"><div class="tags-list-item">博客</div></a>
    
    <a href="\tags\Servlet" title="Servlet"><div class="tags-list-item">Servlet</div></a>
    
    <a href="\tags\数据结构" title="数据结构"><div class="tags-list-item">数据结构</div></a>
    
    <a href="\tags\Sping" title="Sping"><div class="tags-list-item">Sping</div></a>
    
  </div>
</div>
  </article>
  
  
</div>
          </aside>
          <aside class="right-column">
            <div class="sticky-widescreen">
  
  
  <article class="card card-content toc-card">
    <div class="toc-header"><i class="iconfont icon-menu" style="padding-right: 2px;"></i>目录</div>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B8%8B%E7%9A%84-generative-model"><span class="toc-text">半监督学习下的 generative model</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%A8%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B8%8B%E7%9A%84%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B"><span class="toc-text">全监督学习下的生成模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B8%8B%E7%9A%84%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B"><span class="toc-text">半监督学习下的生成模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B9%8B%E4%BD%8E%E5%AF%86%E5%BA%A6%E5%88%86%E7%A6%BB%E5%81%87%E8%AE%BE%EF%BC%88Low-density-Separation%EF%BC%89"><span class="toc-text">半监督学习之低密度分离假设（Low-density Separation）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Self-training"><span class="toc-text">Self-training</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E7%86%B5%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%96-Entropy-based-Regularization"><span class="toc-text">基于熵的正则化(Entropy-based Regularization)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Semi-supervised-SVM"><span class="toc-text">Semi-supervised SVM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B9%B3%E6%BB%91%E5%81%87%E8%AE%BE-smoothness-assumption"><span class="toc-text">平滑假设(smoothness assumption)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%9A%84%E6%96%B9%E6%B3%95-Graph-based-Approach"><span class="toc-text">基于图的方法(Graph-based Approach)</span></a></li></ol>
  </article>
  
  
  <article class="card card-content">
    <div class="recent-posts-card">
  <div class="recent-posts-header"><i class="iconfont icon-wenzhang_huaban" style="padding-right: 2px;"></i>最近文章</div>
  <div class="recent-posts-list">
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2020-10-29</div>
        <a href="/2020/10/29/历年微软面试中出现的leetcode算法题/"><div class="recent-posts-item-content">历年微软面试中出现的leetcode算法题</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2020-10-22</div>
        <a href="/2020/10/22/推荐两本书/"><div class="recent-posts-item-content">推荐两本书</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2020-10-14</div>
        <a href="/2020/10/14/如何学习大数据模式？/"><div class="recent-posts-item-content">如何学习设计模式？</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2020-09-29</div>
        <a href="/2020/09/29/程序员绕不去的槛，Linux！！！/"><div class="recent-posts-item-content">想学Linux，这一本书就够了！</div></a>
      </div>
    
  </div>
</div>
  </article>
  
  
</div>
          </aside>
        </div>
      </div>
    </div>
  </div>
  
  <footer class="footer">
  <div class="footer-container">
    <div>
      <div class="footer-dsc">
        <span>Copyright ©
          
          2020 -
          
          2020
        </span>
        &nbsp;
        <a href="/" class="footer-link">Tan Qing Bo's Blog </a>
      </div>
    </div>

    
    <div class="footer-dsc">
      
      Powered by
      <a href="https://hexo.io/" class="footer-link" target="_blank" rel="nofollow noopener noreferrer">&nbsp;Hexo </a>
      
      
      <span>&nbsp;|&nbsp;</span>
      
      
      Theme -
      <a href="https://github.com/theme-kaze" class="footer-link" target="_blank"
        rel="nofollow noopener noreferrer">&nbsp;Kaze</a>
      
    </div>
    
    
    
    
      <div class="footer-dsc">
        
        本站总访问量<span id="busuanzi_value_site_pv"></span>次
        
        
        <span>&nbsp;|&nbsp;</span>
        
        
        本站总访客数<span id="busuanzi_value_site_uv"></span>次
        
      </div>
      
    
</footer>
  <a role="button" id="scrollbutton" class="basebutton" >
  <i class="iconfont icon-arrowleft button-icon"></i>
</a>
<a role="button" id="menubutton" class="basebutton">
  <i class="iconfont icon-menu button-icon"></i>
</a>
<a role="button" id="popbutton" class="basebutton">
  <i class="iconfont icon-expand button-icon"></i>
</a>
<a role="button" id="darkbutton" class="basebutton darkwidget">
  <i class="iconfont icon-weather button-icon"></i>
</a>
<a role="button" id="searchbutton" class="basebutton searchwidget">
  <i class="iconfont icon-search button-icon"></i>
</a>

  
  
  

  
  
  <script>
  var addImgLayout = function () {
    var img = document.querySelectorAll('.post-content img');
    var i;
    for (i = 0; i < img.length; i++) {
      var wrapper = document.createElement('a');
      wrapper.setAttribute('data-fslightbox', 'gallery');
      wrapper.setAttribute('href', img[i].getAttribute('data-src'));
      wrapper.style.cssText = 'width: 100%; display: flex; justify-content: center;';
      img[i].before(wrapper);
      wrapper.append(img[i]);
    }
    refreshFsLightbox();
  }
</script>
<script>loadScript("//cdn.jsdelivr.net/npm/fslightbox@3.1.0/index.min.js", addImgLayout)</script>
  
  
  
<script src="/js/main.js"></script>

  
  <script>loadScript("/js/lib/busuanzi.min.js")</script>
  
  
  <script>
    var addLazyload = function () {
      var observer = lozad('.lozad', {
        load: function (el) {
          el.srcset = el.getAttribute('data-src');
        },
        loaded: function (el) {
          el.classList.add('loaded');
        }
      });
      observer.observe();
    }
  </script>
  <script>loadScript("/js/lib/lozad.min.js", addLazyload)</script>
  
  
  <script>
    var googleAnalytics = function() {
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-178024758-1');
    }
  </script>
  <script>loadScript("https://www.googletagmanager.com/gtag/js?id=" + "UA-178024758-1", googleAnalytics)</script>
  
</body>

</html>