<!DOCTYPE html>
<html>
<meta  lang="zh-CN" >
<head>
  <meta charset="UTF-8">
  <meta name="viewport"
    content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <meta name="theme-color" content="#fff" id="theme-color">
  <link rel="icon" href="/img/logo.jpg">
  <title>Tan Qing Bo's Blog</title>
  
  
  <meta property="og:title" content="【无监督学习之线性降维】Unsupervised Learning-Linear Dimension Reduction">
  
  
  <meta property="og:url" content="http://tanqingbo.cn/2018/04/04/%E3%80%90%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E3%80%91Unsupervised%20Learning-Linear%20Dimension%20Reduction/index.html">
  
  
  <meta property="og:img" content="/img/logo.jpg">
  
  
  <meta property="og:img" content="学习总结  思考感悟  知识管理">
  
  
  <meta property="og:type" content="article">
  <meta property="og:article:published_time" content="2018-04-04">
  <meta property="og:article:modified_time" content="2018-04-04">
  <meta property="og:article:author" content="Tan Qing Bo">
  
  
  
  
  
  
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-178024758-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-178024758-1');
</script>
  
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?d87293651eefff721c898f38338ea3a8";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

  
  <script>
    // control reverse button
    var reverseDarkList = {
      dark: 'light',
      light: 'dark'
    };
    var themeColor = {
      dark: '#1c1c1e',
      light: '#fff'
    }
    // get the data of css prefers-color-scheme
    var getCssMediaQuery = function() {
      return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
    };
    // reverse current darkmode setting function
    var reverseDarkModeSetting = function() {
      var setting = localStorage.getItem('user-color-scheme');
      if(reverseDarkList[setting]) {
        setting = reverseDarkList[setting];
      } else if(setting === null) {
        setting = reverseDarkList[getCssMediaQuery()];
      } else {
        return;
      }
      localStorage.setItem('user-color-scheme', setting);
      return setting;
    };
    // apply current darkmode setting
    var setDarkmode = function(mode) {
      var setting = mode || localStorage.getItem('user-color-scheme');
      if(setting === getCssMediaQuery()) {
        document.documentElement.removeAttribute('data-user-color-scheme');
        localStorage.removeItem('user-color-scheme');
        document.getElementById('theme-color').content = themeColor[setting];
      } else if(reverseDarkList[setting]) {
        document.documentElement.setAttribute('data-user-color-scheme', setting);
        document.getElementById('theme-color').content = themeColor[setting];
      } else {
        document.documentElement.removeAttribute('data-user-color-scheme');
        localStorage.removeItem('user-color-scheme');
        document.getElementById('theme-color').content = themeColor[getCssMediaQuery()];
      }
    };
    setDarkmode();
  </script>
  <script>
    function loadScript(url, cb) {
      var script = document.createElement('script');
      script.src = url;
      if (cb) script.onload = cb;
      script.async = true;
      document.body.appendChild(script);
    }
  </script>
  
  <link rel="preload" href="//at.alicdn.com/t/font_1946621_f7g5jnuftcf.css" as="style" >
  <link rel="preload" href="//at.alicdn.com/t/font_1952792_89b4ac4k4up.css" as="style" >
  
  <link rel="preload" href="//cdn.jsdelivr.net/npm/fslightbox@3.1.0/index.min.js" as="script">
  
  
  <link rel="preload" href="/js/lib/lozad.min.js" as="script">
  
  
  
  
  
  <link rel="prefetch" href="//cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-svg.js" as="script">
  
  
  
  
  
<link rel="stylesheet" href="/css/main.css">

  
  
<link rel="stylesheet" href="//at.alicdn.com/t/font_1946621_f7g5jnuftcf.css">

  
  
<link rel="stylesheet" href="//at.alicdn.com/t/font_1952792_89b4ac4k4up.css">

  
  
  
<meta name="generator" content="Hexo 5.1.1"></head>


<body>
  <div class="wrapper">
    
    <nav class="navbar">
  <div class="navbar-logo">
    <span class="navbar-logo-main">
      
      <img class="navbar-logo-img" src="/img/logo.jpg">
      
      <span class="navbar-logo-dsc">Tan Qing Bo's Blog</span>
    </span>
  </div>
  <div class="navbar-menu">
    
    <a href="/" class="navbar-menu-item">
    
    首页
    
    </a>
    
    <a href="/archives" class="navbar-menu-item">
    
    归档
    
    </a>
    
    <a href="/tags" class="navbar-menu-item">
    
    标签
    
    </a>
    
    <a href="/categories" class="navbar-menu-item">
    
    分类
    
    </a>
    
    <a href="/about" class="navbar-menu-item">
    
    关于
    
    </a>
    
    <a href="/links" class="navbar-menu-item">
    
    友链
    
    </a>
    
    <a class="navbar-menu-item darknavbar" id="dark"><i class="iconfont icon-weather"></i></a>
    <a class="navbar-menu-item searchnavbar" id="search"><i class="iconfont icon-search" style="font-size: 1.2rem; font-weight: 400;"></i></a>
  </div>
</nav>
    
    <div id="local-search" style="display: none;">
      <input class="navbar-menu-item" id="search-input" placeholder="请输入搜索内容...">
      <div id="search-content"></div>
    </div>
    
    <div class="section-wrap">
      <div class="container">
        <div class="columns">
          <main class="main-column">
<article class="card card-content">
  <header>
    <h1 class="post-title">
      【无监督学习之线性降维】Unsupervised Learning-Linear Dimension Reduction
    </h1>
  </header>
  <div class="post-meta post-show-meta">
    <time datetime="2018-04-04T06:23:18.000Z" style="display: flex; align-items: center;">
      <i class="iconfont icon-calendar" style="margin-right: 2px;"></i>
      <span>2018-04-04</span>
    </time>
    
    <span class="dot"></span>
    
    <a href="/categories/机器学习/" class="post-meta-link">机器学习</a>
    
    
    
    <span class="dot"></span>
    <span>1.1k 字</span>
    
  </div>
  
  </header>
  <div id="section" class="post-content">
    <h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><ul>
<li>本节主要介绍了<strong>两种线性降维的方法</strong>：<strong>Cluster和PCA</strong>,并从两个角度解释了PCA。</li>
</ul>
<h2 id="聚类-Cluster"><a href="#聚类-Cluster" class="headerlink" title="聚类(Cluster)"></a>聚类(Cluster)</h2><ul>
<li>聚类的基本思想是将数据集中的样本划分为若干个通常是不相交的子集，每个子集称为一个**”簇”(cluster)**。<h3 id="K均值算法（K-means）"><a href="#K均值算法（K-means）" class="headerlink" title="K均值算法（K-means）"></a>K均值算法（K-means）</h3></li>
</ul>
<ol>
<li>随机初始化K个样本(点)，称之为簇中心(cluster centroids)；</li>
<li>簇分配: 对于所有的样本，将其分配给离它最近的簇中心；</li>
<li>移动簇中心：对于每一个簇，计算属于该簇的所有样本的平均值，移动簇中心到平均值处；</li>
<li>重复步骤2和3，直到找到我们想要的簇.</li>
<li>如下图演示了特征量个数和簇数均为2的情况：</li>
</ol>
<center>
![](https://images2015.cnblogs.com/blog/788978/201605/788978-20160515010206539-637882739.gif)
</center>

<h3 id="分层凝聚聚类（Hierarchical-Agglomerative-Clustering-HAC）原理"><a href="#分层凝聚聚类（Hierarchical-Agglomerative-Clustering-HAC）原理" class="headerlink" title="分层凝聚聚类（Hierarchical Agglomerative Clustering,HAC）原理"></a>分层凝聚聚类（Hierarchical Agglomerative Clustering,HAC）原理</h3><ul>
<li>顾名思义就是要一层一层地进行聚类，可以从下而上地把小的cluster合并聚集，也可以从上而下地将大的cluster进行分割。似乎一般用得比较多的是从下而上地聚集，因此这里我就只介绍这一种。</li>
<li>所谓从下而上地合并cluster，具体而言，就是每次找到距离最短的两个cluster，然后进行合并成一个大的cluster，直到全部合并为一个cluster。整个过程就是建立一个树结构，类似于下图。 </li>
</ul>
<center>
![](https://img-blog.csdn.net/20160601212744464)
</center>

<ul>
<li>层次聚类最大的优点，就是它一次性地得到了整个聚类的过程，只要得到了上面那样的聚类树，想要分多少个cluster都可以直接根据树结构来得到结果，改变cluster数目不需要再次计算数据点的归属。层次聚类的缺点是计算量比较大，因为要每次都要计算多个cluster内所有数据点的两两距离。另外，由于层次聚类使用的是贪心算法，得到的显然只是局域最优，不一定就是全局最优，这可以通过加入随机效应解决，这就是另外的问题了。</li>
</ul>
<h2 id="主成分分析-Principle-Component-Analysis-PCA"><a href="#主成分分析-Principle-Component-Analysis-PCA" class="headerlink" title="主成分分析(Principle Component Analysis,PCA)"></a>主成分分析(Principle Component Analysis,PCA)</h2><ul>
<li>PCA降维原理可以从<strong>两个角度来考虑</strong>：<ol>
<li><strong>基于最大方差原理</strong>，样本点在这个超平面上的投影尽可能分开。</li>
<li><strong>基于最小化误差原理</strong>，样本点到这个超平面距离都足够近。</li>
</ol>
</li>
</ul>
<h3 id="基于最大方差原理"><a href="#基于最大方差原理" class="headerlink" title="基于最大方差原理"></a>基于最大方差原理</h3><ul>
<li><p>需要找到一个投影矩阵W，使得x在W上的投影方差尽可能大，其中W是由多个向量组成，其中W是由多个向量组成(w1,w2,w3…),希望x在w1上的投影的方差最大，w2上的投影的方差其次…..依次类推。</p>
<center>
![](https://i.imgur.com/rvlJPsm.png)
</center>
</li>
<li><p>并且，W是一个单位正交矩阵，即<strong>（w1,w2,w3,…）相互正交，且都是单位向量</strong>。</p>
<center>
![](https://i.imgur.com/2LWLhMU.png)
</center>
</li>
<li><p><strong>PCA达到的效果就是decorrelation（去关联）</strong>，所以最后投影之后得到z的协方差矩阵D是对角矩阵； </p>
<ul>
<li><strong>投影矩阵W是单位正交矩阵。</strong></li>
<li><strong>W就是x协方差矩阵S的特征向量。</strong></li>
</ul>
</li>
</ul>
<center>
![](https://i.imgur.com/PNxZK3S.png)
</center>

<h3 id="基于最小化误差原理"><a href="#基于最小化误差原理" class="headerlink" title="基于最小化误差原理"></a>基于最小化误差原理</h3><ul>
<li>基本思想：将<img src="https:/ srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20300%20300'%3E%3C/svg%3E" data-src="https://i.imgur.com/9aNN1eZ.png" class="lozad post-image"/i.imgur.com/9aNN1eZ.png"/>近似看成由多个u组成，求解最小化他们之间的error时的系数c和分量u。</li>
<li>其中向量(u1,u2,u3…)表示一个<code>Basic component</code>,如下图：</li>
</ul>
<center>
![](https://i.imgur.com/ihgYAOa.png)
![](https://i.imgur.com/pJugCGi.png)
</center>

<ul>
<li>为了求解c和u（component），可以将X做奇异值分解SVD，用分解后的U代替u，ΣxV代替系数c<br>其中U就是XXT的特征向量 </li>
<li>有时候只选取特征值比较大的<code>component</code>。</li>
<li>PCA相当于只含一层hidden layer的网络。</li>
</ul>
<center>
![](https://i.imgur.com/ZejRQSr.png)
</center>

<h2 id="PCA与LDA-Linear-Discriminant-Analysis-的比较"><a href="#PCA与LDA-Linear-Discriminant-Analysis-的比较" class="headerlink" title="PCA与LDA(Linear Discriminant Analysis)的比较"></a>PCA与LDA(Linear Discriminant Analysis)的比较</h2><ul>
<li>PCA是无监督的，LDA是有监督的；</li>
<li>PCA基本思想是方差最大，LDA基本思想是让不同类别分的尽可能开；</li>
<li>PCA和LDA都是线性映射；</li>
<li>对于结构比较复杂的降维，只能采用非线性流行学习比如局部线性嵌入(Locally Linear Embedding，LLE)等方法.</li>
</ul>
<h2 id="PCA和非负矩阵分解-Non-negative-Matrix-Factorization-NMF-比较"><a href="#PCA和非负矩阵分解-Non-negative-Matrix-Factorization-NMF-比较" class="headerlink" title="PCA和非负矩阵分解(Non-negative Matrix Factorization,NMF)比较"></a>PCA和非负矩阵分解(Non-negative Matrix Factorization,NMF)比较</h2><ul>
<li>NMF分解之后的component的系数都是正的，就拿image来说，也就是说分解之后的component像是原始image的一部分;</li>
<li>而PCA的系数可正可负，涉及到component的“加加减减” .</li>
</ul>

  </div>
  <div>
  
  <div class="post-note note-warning copyright" style="margin-top: 42px">
    <p><span style="font-weight: bold;">作者：</span><a target="_blank" rel="nofollow noopener noreferrer" href="http://tanqingbo.cn/about">谭庆波</a></p>
    <p><span style="font-weight: bold;">文章链接：</span><a target="_blank" rel="nofollow noopener noreferrer" href="http://tanqingbo.cn/2018/04/04/%E3%80%90%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E3%80%91Unsupervised%20Learning-Linear%20Dimension%20Reduction/">http://tanqingbo.cn/2018/04/04/%E3%80%90%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E3%80%91Unsupervised%20Learning-Linear%20Dimension%20Reduction/</a></p>
    <p><span style="font-weight: bold;">版权声明：</span>本博客所有文章除特别声明外，均采用<a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">CC BY-NC-SA 4.0 协议</a>。转载请注明出处！</p>
  </div>
  
  </div>
</article>
<div class="nav">
  
  <div class="nav-item-prev">
    <a href="/2018/04/04/无监督学习：Word Embedding/" class="nav-link">
      <i class="iconfont icon-left nav-prev-icon"></i>
      <div>
        <div class="nav-label">上一篇</div>
        
        <div class="nav-title">无监督学习之词嵌入or词向量(Word Embedding) </div>
        
      </div>
    </a>
  </div>
  
  
  <div class="nav-item-next">
    <a href="/2018/04/03/机器学习之半监督学习/" class="nav-link">
      <div>
        <div class="nav-label">下一篇</div>
        
        <div class="nav-title">机器学习之半监督学习（Semi-supervised learning） </div>
        
      </div>
      <i class="iconfont icon-right nav-next-icon"></i>
    </a>
  </div>
  
</div>

<div class="card card-content toc-card" id="mobiletoc">
  <div class="toc-header"><i class="iconfont icon-menu" style="padding-right: 2px;"></i>目录</div>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%81%9A%E7%B1%BB-Cluster"><span class="toc-text">聚类(Cluster)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#K%E5%9D%87%E5%80%BC%E7%AE%97%E6%B3%95%EF%BC%88K-means%EF%BC%89"><span class="toc-text">K均值算法（K-means）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%B1%82%E5%87%9D%E8%81%9A%E8%81%9A%E7%B1%BB%EF%BC%88Hierarchical-Agglomerative-Clustering-HAC%EF%BC%89%E5%8E%9F%E7%90%86"><span class="toc-text">分层凝聚聚类（Hierarchical Agglomerative Clustering,HAC）原理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-Principle-Component-Analysis-PCA"><span class="toc-text">主成分分析(Principle Component Analysis,PCA)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E6%9C%80%E5%A4%A7%E6%96%B9%E5%B7%AE%E5%8E%9F%E7%90%86"><span class="toc-text">基于最大方差原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E6%9C%80%E5%B0%8F%E5%8C%96%E8%AF%AF%E5%B7%AE%E5%8E%9F%E7%90%86"><span class="toc-text">基于最小化误差原理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PCA%E4%B8%8ELDA-Linear-Discriminant-Analysis-%E7%9A%84%E6%AF%94%E8%BE%83"><span class="toc-text">PCA与LDA(Linear Discriminant Analysis)的比较</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PCA%E5%92%8C%E9%9D%9E%E8%B4%9F%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3-Non-negative-Matrix-Factorization-NMF-%E6%AF%94%E8%BE%83"><span class="toc-text">PCA和非负矩阵分解(Non-negative Matrix Factorization,NMF)比较</span></a></li></ol>
</div></main>
          <aside class="left-column">
            
            <div class="card card-author">
              
<img src="/img/logo.jpg" class="author-img">

<p class="author-name">Tan Qing Bo</p>
<p class="author-description">designed by Tan Qing Bo</p>
<div class="author-message">
  <a class="author-posts-count" href="/archives">
    <span>319</span>
    <span>文章</span>
  </a>
  <a class="author-categories-count" href="/categories">
    <span>15</span>
    <span>分类</span>
  </a>
  <a class="author-tags-count" href="/tags">
    <span>34</span>
    <span>标签</span>
  </a>
</div>

            </div>
            
            <div class="sticky-tablet">
  
  
  <article class="display-when-two-columns spacer">
    <div class="card card-content toc-card">
      <div class="toc-header"><i class="iconfont icon-menu" style="padding-right: 2px;"></i>目录</div>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%81%9A%E7%B1%BB-Cluster"><span class="toc-text">聚类(Cluster)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#K%E5%9D%87%E5%80%BC%E7%AE%97%E6%B3%95%EF%BC%88K-means%EF%BC%89"><span class="toc-text">K均值算法（K-means）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%B1%82%E5%87%9D%E8%81%9A%E8%81%9A%E7%B1%BB%EF%BC%88Hierarchical-Agglomerative-Clustering-HAC%EF%BC%89%E5%8E%9F%E7%90%86"><span class="toc-text">分层凝聚聚类（Hierarchical Agglomerative Clustering,HAC）原理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-Principle-Component-Analysis-PCA"><span class="toc-text">主成分分析(Principle Component Analysis,PCA)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E6%9C%80%E5%A4%A7%E6%96%B9%E5%B7%AE%E5%8E%9F%E7%90%86"><span class="toc-text">基于最大方差原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E6%9C%80%E5%B0%8F%E5%8C%96%E8%AF%AF%E5%B7%AE%E5%8E%9F%E7%90%86"><span class="toc-text">基于最小化误差原理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PCA%E4%B8%8ELDA-Linear-Discriminant-Analysis-%E7%9A%84%E6%AF%94%E8%BE%83"><span class="toc-text">PCA与LDA(Linear Discriminant Analysis)的比较</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PCA%E5%92%8C%E9%9D%9E%E8%B4%9F%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3-Non-negative-Matrix-Factorization-NMF-%E6%AF%94%E8%BE%83"><span class="toc-text">PCA和非负矩阵分解(Non-negative Matrix Factorization,NMF)比较</span></a></li></ol>
    </div>
  </article>
  
  
  <article class="card card-content categories-widget">
    <div class="categories-card">
  <div class="categories-header"><i class="iconfont icon-fenlei" style="padding-right: 2px;"></i>分类</div>
  <div class="categories-list">
    
      <a href="/categories/转载">
        <div class="categories-list-item">
          转载
          <span class="categories-list-item-badge">117</span>
        </div>
      </a>
    
      <a href="/categories/漂来漂去">
        <div class="categories-list-item">
          漂来漂去
          <span class="categories-list-item-badge">40</span>
        </div>
      </a>
    
      <a href="/categories/机器学习">
        <div class="categories-list-item">
          机器学习
          <span class="categories-list-item-badge">37</span>
        </div>
      </a>
    
      <a href="/categories/C语言">
        <div class="categories-list-item">
          C语言
          <span class="categories-list-item-badge">4</span>
        </div>
      </a>
    
      <a href="/categories/资源分享">
        <div class="categories-list-item">
          资源分享
          <span class="categories-list-item-badge">17</span>
        </div>
      </a>
    
      <a href="/categories/图像处理">
        <div class="categories-list-item">
          图像处理
          <span class="categories-list-item-badge">15</span>
        </div>
      </a>
    
      <a href="/categories/技术博客">
        <div class="categories-list-item">
          技术博客
          <span class="categories-list-item-badge">38</span>
        </div>
      </a>
    
      <a href="/categories/Linux">
        <div class="categories-list-item">
          Linux
          <span class="categories-list-item-badge">5</span>
        </div>
      </a>
    
      <a href="/categories/Java">
        <div class="categories-list-item">
          Java
          <span class="categories-list-item-badge">24</span>
        </div>
      </a>
    
      <a href="/categories/大话设计模式">
        <div class="categories-list-item">
          大话设计模式
          <span class="categories-list-item-badge">5</span>
        </div>
      </a>
    
      <a href="/categories/东搞西搞">
        <div class="categories-list-item">
          东搞西搞
          <span class="categories-list-item-badge">10</span>
        </div>
      </a>
    
      <a href="/categories/网络原理">
        <div class="categories-list-item">
          网络原理
          <span class="categories-list-item-badge">4</span>
        </div>
      </a>
    
      <a href="/categories/操作系统">
        <div class="categories-list-item">
          操作系统
          <span class="categories-list-item-badge">2</span>
        </div>
      </a>
    
      <a href="/categories/设计模式">
        <div class="categories-list-item">
          设计模式
          <span class="categories-list-item-badge">1</span>
        </div>
      </a>
    
      <a href="/categories/资源分享">
        <div class="categories-list-item">
          资源分享
          <span class="categories-list-item-badge">1</span>
        </div>
      </a>
    
  </div>
</div>
  </article>
  
  <article class="card card-content tags-widget">
    <div class="tags-card">
  <div class="tags-header"><i class="iconfont icon-biaoqian" style="padding-right: 2px;"></i>热门标签</div>
  <div class="tags-list">
    
    <a href="\tags\Java" title="Java"><div class="tags-list-item">Java</div></a>
    
    <a href="\tags\算法" title="算法"><div class="tags-list-item">算法</div></a>
    
    <a href="\tags\java" title="java"><div class="tags-list-item">java</div></a>
    
    <a href="\tags\框架" title="框架"><div class="tags-list-item">框架</div></a>
    
    <a href="\tags\面试" title="面试"><div class="tags-list-item">面试</div></a>
    
    <a href="\tags\网络" title="网络"><div class="tags-list-item">网络</div></a>
    
    <a href="\tags\操作系统" title="操作系统"><div class="tags-list-item">操作系统</div></a>
    
    <a href="\tags\排序" title="排序"><div class="tags-list-item">排序</div></a>
    
    <a href="\tags\项目" title="项目"><div class="tags-list-item">项目</div></a>
    
    <a href="\tags\hibernate" title="hibernate"><div class="tags-list-item">hibernate</div></a>
    
    <a href="\tags\Sping" title="Sping"><div class="tags-list-item">Sping</div></a>
    
    <a href="\tags\数据结构" title="数据结构"><div class="tags-list-item">数据结构</div></a>
    
    <a href="\tags\博客" title="博客"><div class="tags-list-item">博客</div></a>
    
    <a href="\tags\Python" title="Python"><div class="tags-list-item">Python</div></a>
    
    <a href="\tags\Linux" title="Linux"><div class="tags-list-item">Linux</div></a>
    
    <a href="\tags\技术" title="技术"><div class="tags-list-item">技术</div></a>
    
  </div>
</div>
  </article>
  
  
</div>
          </aside>
          <aside class="right-column">
            <div class="sticky-widescreen">
  
  
  <article class="card card-content toc-card">
    <div class="toc-header"><i class="iconfont icon-menu" style="padding-right: 2px;"></i>目录</div>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%81%9A%E7%B1%BB-Cluster"><span class="toc-text">聚类(Cluster)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#K%E5%9D%87%E5%80%BC%E7%AE%97%E6%B3%95%EF%BC%88K-means%EF%BC%89"><span class="toc-text">K均值算法（K-means）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%B1%82%E5%87%9D%E8%81%9A%E8%81%9A%E7%B1%BB%EF%BC%88Hierarchical-Agglomerative-Clustering-HAC%EF%BC%89%E5%8E%9F%E7%90%86"><span class="toc-text">分层凝聚聚类（Hierarchical Agglomerative Clustering,HAC）原理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-Principle-Component-Analysis-PCA"><span class="toc-text">主成分分析(Principle Component Analysis,PCA)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E6%9C%80%E5%A4%A7%E6%96%B9%E5%B7%AE%E5%8E%9F%E7%90%86"><span class="toc-text">基于最大方差原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E6%9C%80%E5%B0%8F%E5%8C%96%E8%AF%AF%E5%B7%AE%E5%8E%9F%E7%90%86"><span class="toc-text">基于最小化误差原理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PCA%E4%B8%8ELDA-Linear-Discriminant-Analysis-%E7%9A%84%E6%AF%94%E8%BE%83"><span class="toc-text">PCA与LDA(Linear Discriminant Analysis)的比较</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PCA%E5%92%8C%E9%9D%9E%E8%B4%9F%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3-Non-negative-Matrix-Factorization-NMF-%E6%AF%94%E8%BE%83"><span class="toc-text">PCA和非负矩阵分解(Non-negative Matrix Factorization,NMF)比较</span></a></li></ol>
  </article>
  
  
  <article class="card card-content">
    <div class="recent-posts-card">
  <div class="recent-posts-header"><i class="iconfont icon-wenzhang_huaban" style="padding-right: 2px;"></i>最近文章</div>
  <div class="recent-posts-list">
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2020-11-09</div>
        <a href="/2020/11/09/哪本书适合推荐给 Java 初学者？/"><div class="recent-posts-item-content">哪本书适合推荐给 Java 初学者？</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2020-10-29</div>
        <a href="/2020/10/29/历年微软面试中出现的leetcode算法题/"><div class="recent-posts-item-content">历年微软面试中出现的leetcode算法题</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2020-10-22</div>
        <a href="/2020/10/22/推荐两本书/"><div class="recent-posts-item-content">推荐两本书</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2020-10-14</div>
        <a href="/2020/10/14/如何学习大数据模式？/"><div class="recent-posts-item-content">如何学习设计模式？</div></a>
      </div>
    
  </div>
</div>
  </article>
  
  
</div>
          </aside>
        </div>
      </div>
    </div>
  </div>
  
  <footer class="footer">
  <div class="footer-container">
    <div>
      <div class="footer-dsc">
        <span>Copyright ©
          
          2020 -
          
          2020
        </span>
        &nbsp;
        <a href="/" class="footer-link">Tan Qing Bo's Blog </a>
      </div>
    </div>

    
    <div class="footer-dsc">
      
      Powered by
      <a href="https://hexo.io/" class="footer-link" target="_blank" rel="nofollow noopener noreferrer">&nbsp;Hexo </a>
      
      
      <span>&nbsp;|&nbsp;</span>
      
      
      Theme -
      <a href="https://github.com/theme-kaze" class="footer-link" target="_blank"
        rel="nofollow noopener noreferrer">&nbsp;Kaze</a>
      
    </div>
    
    
    
    
      <div class="footer-dsc">
        
        本站总访问量<span id="busuanzi_value_site_pv"></span>次
        
        
        <span>&nbsp;|&nbsp;</span>
        
        
        本站总访客数<span id="busuanzi_value_site_uv"></span>次
        
      </div>
      
    
</footer>
  <a role="button" id="scrollbutton" class="basebutton" >
  <i class="iconfont icon-arrowleft button-icon"></i>
</a>
<a role="button" id="menubutton" class="basebutton">
  <i class="iconfont icon-menu button-icon"></i>
</a>
<a role="button" id="popbutton" class="basebutton">
  <i class="iconfont icon-expand button-icon"></i>
</a>
<a role="button" id="darkbutton" class="basebutton darkwidget">
  <i class="iconfont icon-weather button-icon"></i>
</a>
<a role="button" id="searchbutton" class="basebutton searchwidget">
  <i class="iconfont icon-search button-icon"></i>
</a>

  
  
  

  
  
  <script>
  var addImgLayout = function () {
    var img = document.querySelectorAll('.post-content img');
    var i;
    for (i = 0; i < img.length; i++) {
      var wrapper = document.createElement('a');
      wrapper.setAttribute('data-fslightbox', 'gallery');
      wrapper.setAttribute('href', img[i].getAttribute('data-src'));
      wrapper.style.cssText = 'width: 100%; display: flex; justify-content: center;';
      img[i].before(wrapper);
      wrapper.append(img[i]);
    }
    refreshFsLightbox();
  }
</script>
<script>loadScript("//cdn.jsdelivr.net/npm/fslightbox@3.1.0/index.min.js", addImgLayout)</script>
  
  
  
<script src="/js/main.js"></script>

  
  <script>loadScript("/js/lib/busuanzi.min.js")</script>
  
  
  <script>
    var addLazyload = function () {
      var observer = lozad('.lozad', {
        load: function (el) {
          el.srcset = el.getAttribute('data-src');
        },
        loaded: function (el) {
          el.classList.add('loaded');
        }
      });
      observer.observe();
    }
  </script>
  <script>loadScript("/js/lib/lozad.min.js", addLazyload)</script>
  
  
  <script>
    var googleAnalytics = function() {
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-178024758-1');
    }
  </script>
  <script>loadScript("https://www.googletagmanager.com/gtag/js?id=" + "UA-178024758-1", googleAnalytics)</script>
  
</body>

</html>