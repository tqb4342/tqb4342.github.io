[{"title":"","url":"http://tanqingbo.cn/2020/09/15/Convolutional networks for kidney segmentation in contrast-enhanced CT scans/","content":"Convolutional networks for kidney segmentation in contrast-enhanced CT scans\n","categories":[],"tags":[]},{"title":"推荐两本经典的算法书，入门以及找工作必备！","url":"http://tanqingbo.cn/2020/09/14/推荐两本经典算法书/","content":"记得我上本科的时候，我们老师一直跟我们强调：“算法才是编程的灵魂，一定要把算法学好。”因为不管你是Java编程爱好者、还是python的忠实粉丝，亦或觉得PHP才是这个世界最好的编程语言，都跨不过算法这个门槛。甚至可以说，懂算法的程序员才是一个合格的程序员，大部分互联网企业笔试环节必考算法，面试的时候也会让你手写算法，所以给大家推荐两本书，帮大家搞定算法这个难题。一本适合新手入门，一本适合找工作进阶。\n1、《我的第一本算法书》这本书是京都大学一个计算机教授和朋友联合出品的动画讲解算法的App 所衍生出来的书籍，非常适合新手朋友们。里面有枯燥的理论和复杂的公式，而是通过大量的步骤图帮助读者加深对数据结构原理和算法执行过程的理解，便于学习和记忆。将本书作为算法入门的第一步，是非常不错的选择。\n\n下载地址：\n链接：https://pan.baidu.com/s/1r_lxqzfg7YTHvAEQhNJwnQ提取码：en9j\n2、《剑指offer》这本书大家一定如雷贯耳吧，基本上只要你是程序员就一定会用到这本书，书里面剖析了50个典型的程序员面试题，从基础知识、代码质量、解题思路、优化效率和综合能力五个方面系统整理了影响面试的5个要点。\n\n下载地址：\n链接：https://pan.baidu.com/s/1GD9yTglFZkn5n__965dKjA提取码：mas8\n","categories":["资源分享"],"tags":[]},{"title":"批量规范化：加速深度网络培训减少内部协变量偏移","url":"http://tanqingbo.cn/2020/09/06/批量规范化：加速深度网络培训减少内部协变量偏移/","content":"1、摘要\n训练深度神经网络很复杂，因为随着前一层的参数变化，每层输入的分布在训练期间发生变化。这通过要求较低的学习速率和仔细的参数初始化来减慢训练，并且使得训练具有饱和非线性的模型变得非常困难。我们将这种现象称为内部协变量偏移，并通过归一化层输入来解决问题。\n优势在于使标准化成为模型体系结构的一部分，并为每个训练小批量执行标准化。批量标准化允许我们使用更高的学习率并且不太关心初始化。应用于最先进的图像分类模型，批量标准化实现了相同的精度，培训步骤减少了14倍，并且大大超过了原始模型。\n\n2、介绍\n使用小批量的示例，而不是一次一个示例，在几个方面是有帮助的。 首先，小批量损失的梯度是对训练集的梯度的估计，其质量随批量增加而改善。 其次，由于现代计算平台提供的并行性，批量计算可以比单个示例的m计算更有效。 虽然随机梯度简单有效，但需要仔细调整模型超参数，特别是优化中使用的学习率，以及模型参数的初始值。 由于每层的输入受到所有前面层的参数的影响，因此训练变得复杂。 因此，随着网络变得更深，网络参数的微小变化会放大。\n\n考虑到每一层使用sigmoid激活函数g(x),当|x|增加时，g`趋近于零，也就是说早训练过程中除了绝对值小的x，训练会减慢，梯度会减缓或者消失。\n\n在训练期间对这些参数的改变可能将x的多维度移动到非线性的饱和状态并且减慢收敛。 随着网络深度的增加，这种效应会被放大。在实践中，饱和问题和由此产生的消失梯度通常通过使用整流线性单元（ReLU）来解决，也就是激活函数采用ReLU.\n\n如果我们能够确保非线性输入的分布在网络训练时保持更稳定，那么优化器将不太可能陷入饱和状态，并且训练将加速。\n\n我们将在训练过程中深度网络内部节点分布的变化称为内部协变量偏移。为了消除它并且提供更快的训练。我们提出了一种新的机制，我们称之为批量归一化。\n\n它在减少内部协变量偏移方面迈出了一步，并且这样做大大加速了深度神经网络的训练。它通过标准化步骤来实现这一点，该步骤修复了层输入的均值和方差。\n\n批量标准化的优点：\n\n批量标准化还通过降低梯度对参数或其初始值的比例的依赖性，对通过网络的梯度流有益。这使我们可以使用更高的学习率而不会出现分歧的风险。\n批量标准化使模型正规化并减少了对Dropout的需求。最后，批量标准化可以通过防止网络陷入饱和模式。\n\n\n\n3、减少内部协变量偏移\n我们将内部协变量偏移定义为由于训练期间网络参数的变化导致的网络激活分布的变化。 为了改善训练，我们寻求减少内部协变量的变化。\n众所周知，线性变换为具有零均值和单位方差，并且去相关，则网络训练收敛得更快（whitened）。 由于每层观察由下面的层产生的输入，因此实现每层的输入的相同whitening将是有利的。 通过增加每层的输入，我们将朝着实现固定的输入分布迈出一步，这将消除内部协变量偏移的不良影响。\n\n","categories":["机器学习"],"tags":[]},{"title":"24岁这一年！","url":"http://tanqingbo.cn/2019/12/24/24岁这一年/","content":"哈喽，圣诞节快乐！\n还有6天就是2020年了，时间真的过得很快，刚过完生日，本命年就要结束了。\n都说本命年是多灾多难的一年，仔细回想一下，今年确实遇到过很多不愉快的事情，但总的来说，还是运气不错的一年。\n完成了很多目标，也放弃了不少目标，简单做个总结，顺便展望一下2020年。\n1、公众号和知乎注册公众号快两年时间了，目前公众号读者4.3万、知乎读者3万左右，但是其实我年初定的目标是公众号6万，可惜由于一些原因，我荒废了半年多时间，导致读者数停滞不涨。\n好在结果还算不错，由年初的2万增长到现在的4.3万，现在读者也恢复了正常的增长速度，而且知乎最近3个月也涨了1万多读者。\n\n2、收入方面我觉得有钱可以让一个人活得更加的自信，只有具备了足够的经济基础，遇事才有底气。\n你的财务状况应该成为一个你不惧任何阻碍的证明。\n虽然我的钱还远没有到让我有安全感的地步，但也算是超额完成了年初的目标。\n具体金额就不透露了，因为多少都是相对的，有人觉得多，有人觉得少，说出来容易拉仇恨。\n收入主要有4个来源：\n\n学校每个月发的钱\n公众号的广告收入\n知乎的广告收入\n理财收入\n\n其中公众号收入大于理财收入，理财收入大于等于学校发的钱，学校发的钱大于知乎的收入。\n理财的收入主要是基金定投，因为现在孤身一人，正是能承担风险的年纪，所以规划了一笔金额不少的定投计划，也因此帮我省下了很多不必要的开销。\n之前写过一篇基金定投的文章《如何基金定投》，分享了一些基本的常识，大家感兴趣的可以看一下。\n3、生活方面今年最明显的感觉就是生活质量提高了不少，想吃什么、想买什么、想玩什么不会因为钱这个原因而犹豫了。应该算是在金钱上实现了低阶级的选择自由。\n去国外旅行过，电影里那种度假胜地终于去过了，确实美的让人陶醉，体验过潜水和滑翔伞，下次再出去玩又多了一些选择。\n\n4、失败总结\n晚睡晚起的毛病一直改不掉，手机是罪魁祸首，玩手机有时是为了看书，有时是为了追剧，晚睡导致早上起不来，希望明年可以改掉这个毛病。\n科研进展缓慢，这个原因比较多，我们实验室的情况很复杂，暂时还不能透露具体情况。\n\n5、2020年展望\n还需要多看一些书，仔细想想，今年看过的书其实很少，一些有价值的书需要多看几遍；\n公众号和知乎继续保持下去，试着拓展其他平台；\n多学习一些投资理财的知识，在能够承担风险的年纪多给自己攒点经验；\n养成运动的习惯，并坚持下来。\n\n电影神之一手里面有句台词：**这个世界,对高手来说是游乐场,对下手来说就是痛苦不堪的地狱。**\n\n虽然我不是高手，但我希望大家2020年在这个世界都玩的开心。\n","categories":["漂来漂去"],"tags":[]},{"title":"去他妈的月入百万！","url":"http://tanqingbo.cn/2019/12/19/自媒体时代的韭菜/","content":"不知道大家是不是经常被这样的所标题吸引？\n\n95 后姑娘做自媒体月入百万！\nTa用3年，快速积累第一个500万资产，定居北京。\n我是如何从小白变成自由撰稿人的？\n\n乍一看这些标题，还以为真的是要传授你武林秘籍，教你如何赚钱，走上人生巅峰。可是点进去一看，大多数都是来割韭菜的。\n俗话说：土肥韭菜才茂盛，割韭菜的镰刀自然就多。\n那么自媒体这块地到底有多肥呢？\n据统计，微信日活跃用户数超10亿、抖音日活跃用户超4亿、微博月活跃用户数超5亿，这个数字的背后是取之不尽、用之不竭的流量，你这可以在这些平台上输出有价值的内容，吸引对你感兴趣的人，从而通过流量精准变现。\n而且做自媒体门槛低，成本也低，任何一个普通人都可以去尝试，身边也时不时听说有人通过做自媒体实现了阶级的跨越。\n年轻人的焦虑+低门槛+美好的钱景，让无数的韭菜们投入了自媒体行业，富了一波又一波割韭菜的镰刀们。\n今天我就以我亲身的经历来告诉大家，做自媒体赚钱的都是哪一波人，而你又是如何成为韭菜的。\n1、为什么成了韭菜？\n很多人都忘了，任何一个行业，其实都遵循“二八原则”。也就是说，不管你在哪个行业，赚钱的永远都是前20%，20%的人掌握着80%的财富。\n然而自媒体给大家绘制的愿景太过美好，觉得自己就是下一个通过自媒体实现阶级跨越、迎娶白富美、走上人生巅峰的人。如果你是抱着这种心态来的，那么恭喜你，喜提“又肥又大韭菜勋章”一枚。教人做自媒体的“导师”们绝对不会闲韭菜太多，割的手酸，反而会大声叫好！\n在原来的赛道都没有做到前20%，换个赛道凭什么觉得自己能赢。\n2、自媒体谁最赚钱\n不少人是真的有真才实学，凭借着自己多年的学习和摸爬滚打，眼界和见识都高出常人一等，能够持续不断的输出优质的内容，从而吸引越来越多的读者，通过优质的内容和个人的魅力留住人心，这个人就是我们常说的意见领袖（KOL），而他的号也是很具商业价值的，有多种途径可以变现。\n但是想要成为一个领域的KOL也不容易，不仅要能够持续输出优质的内容，也要不断的学习，这样才能够在自己的领域逐渐被大众接受认可。这个早期的积累是非常重要的，时间成本也很高，但是吸引的用户数到达一定数量之后，赚钱自然不是问题。\n还有一种自媒体赚钱的人就是我前面说的自媒体“导师”们了。\n他们不靠输出优质内容赚钱，而是靠教人做自媒体赚钱，他们最擅长的就是帮助小白快速成为大佬，月入百万走上人生巅峰，这种精神可以说是毫不利己专门利人。\n自已有月入百万的法子，却不偷偷的用这个法子去赚钱，反而慷慨的教给大家，让每个人都有钱赚，而且只收费198元，简直就是当代的活雷锋。\n就像19世纪，美国加州的淘金热一样，最后发财的不是去淘黄金的人，而是那些给淘金客提供服务的人。现在的自媒体热潮亦是如此，历史总是惊人的相似。\n最后总结一下，自媒体最赚钱的，一类是那些头部的KOL，他们在某个领域深耕已久，靠自己优质的内容和个人魅力留住读者去赚钱；还有一类教别人做自媒体的“导师”们，他们手中掌握着“月入百万”的武林秘籍，手舞屠刀，毫不留情。\n写这篇文章的目的是想告诫大家，也提醒自己，认清自己的赛道在哪里，打好自己手中的牌，当你觉得哪个行业有赚快钱的机会的时候，也许镰刀已经盯上你了。\n","categories":["漂来漂去"],"tags":[]},{"title":"怎么学习Python？","url":"http://tanqingbo.cn/2019/12/10/怎么学习Python？/","content":"如果是零基础学习编程的话，从python开始是一个非常不错的选择，虽然很多人最开始学习编程的时候都是从C语言开始的，但是C语言有点底层，对零基础的人来说不太友好，而且现在很多学校都已经将Python作为入门的编程语言了，在目前特别火的机器学习、人工智能领域，Python可以说是标配的编程语言。\n所以我由浅入深的整理了一些Python的资源和路线，建议从前往后阅读，看完之后肯定对你有帮助！\nPython基础Python基础01  安装Python\nPython基础02  第一个Python程序\nPython基础03  Python 变量类型\nPython基础04  Python 运算符\nPython基础05  Python 循环语句\nPython基础06  Python 条件语句\nPython基础07  Python 列表(List)\nPython基础08  Python 函数\nPython基础09  Python 模块\nPython基础10 Python 文件I/O\nPython基础11 Python File(文件) 方法\nPython基础12  Python 异常处理\nPython进阶Python基进阶01  Python 面向对象\nPython基进阶02  Python 正则表达式\nPython基进阶03  Python CGI 编程 \nPython基进阶04  Python 操作 MySQL 数据库  \nPython基进阶05  Python 网络编程\nPython基进阶06  Python SMTP发送邮件\nPython基进阶07  Python 多线程\nPython基进阶08  Python XML 解析 \nPython基进阶09  Python GUI 编程(Tkinter) \nPython基进阶10  Python JSON\nPython高级到目前为止，如果你看完了上面的内容，那么你对Python应该有了基本的认识，接下来可以用Python来做一些小项目来巩固你学过的东西。\n下面分享几个提供Python项目实践的网站！\n实验楼实验楼提供在线编程及在线实训学习平台，有很多项目都是免费的。\n\n自强学堂 Django教程Django 是用Python开发的一个免费开源的Web框架，可以用于快速搭建高性能，优雅的网站！\n\n崔庆才Python爬虫系列崔庆才老兄写的Python爬虫系列教程不仅很棒，而且还很火，访问量超百万，不少人是看他的博客入门的爬虫。\n\nPython IDE（集成开发环境）学完了Python基础，有了可以练手的项目，好用的 IDE（集成开发环境）当然也必不可少了！\nPyCharmPyCharm 是由 JetBrains 打造的一款 Python IDE。\nPyCharm 具备一般 Python IDE 的功能，比如：调试、语法高亮、项目管理、代码跳转、智能提示、自动完成、单元测试、版本控制等。\n另外，PyCharm 还提供了一些很好的功能用于 Django 开发，同时支持 Google App Engine，更酷的是，PyCharm 支持 IronPython。\n效果图查看：\n\n\nSublime TextSublime Text 具有漂亮的用户界面和强大的功能，例如代码缩略图，Python 的插件，代码段等。还可自定义键绑定，菜单和工具栏。\nSublime Text 的主要功能包括：拼写检查，书签，完整的 Python API ， Goto 功能，即时项目切换，多选择，多窗口等等。\nSublime Text 是一个跨平台的编辑器，同时支持 Windows、Linux、Mac OS X等操作系统。\n\n这两个IDE开发软件可以在公众号「轮子工厂」，后台回复「python」领取！包含Windows、Linux版本！\nPython学习资料\n包括视频教程、Python职业发展分析、经典电子书，这些学习资料在微信公众号「轮子工厂」，后台回复「python」就可以全部领走了！\n推荐的Python书籍1 Python核心编程(第二版)\n\n本书是经典的Python[1] 指导书，在第一版的基础上进行了全面升级。全书分为两个部分：第1部分占据了大约三分之二的篇幅，阐释这门语言的“核心”内容，包括基本的概念和语句、语法和风格、Python对象、数字类型、序列类型、映射和集合类型、条件和循环、文件和输入/输出、错误和异常、函数和函数式编程、模块、面向对象编程、执行环境等内容：第2部分则提供了各种高级主题来展示可以使用Python做些什么，包括正则表达式、网络编程、网络客户端编程、多线程编程、图形用户界面编程、Web编程、数据库编程、扩展Python 和一些其他材料。\n\n2 Python高级编程\n\n《Python高级编程》针对具备一定Python基础并希望通过在项目中应用最佳实践和新的开发技术来提升自己的Python开发人员。\n\n3 Python数据结构与算法\n\n主要是介绍了如何使用Python实现常用的一些数据结构,例如堆栈、队列、二叉树等等。\n\n4 利用Python进行数据分析\n\n从pandas库的数据分析工具开始利用高性能工具对数据进行加载、清理、转换、合并以及重塑；利用matpIotlib创建散点图以及静态或交互式的可视化结果；利用pandas的groupby功能对数据集进行切片、切块和汇总操作；处理各种各样的时间序列数据。\n\n上面列的所有资源和书籍都可以在公众号「轮子工厂」，后台回复「python」领取！\n","categories":["技术博客"],"tags":[]},{"title":"学习Python的博客","url":"http://tanqingbo.cn/2019/12/03/学习python的博客/","content":"1、廖雪峰Python教程如果是刚入门的小白，想从第一个“Holle world”学起，推荐看廖雪峰老师的Python教程博客，他的博客非常系统有条理，从Python安装开始讲起，特别适合小白从零开始学起。\n我本科学校没有开Python的课，我就是看他的Python教程入门的。\n\n2、Python菜鸟教程菜鸟教程，从名字就可以看出是入门级的教程，但是内容详细到令人发指的地步，对菜鸟来说可以当做字典来查询。\n\n3、崔庆才Python爬虫系列崔庆才老兄写的Python爬虫系列教程不仅很棒，而且还很火，访问量超百万，不少人是看他的博客入门的爬虫。\n\n4、the5fire的Python博客the5fire是《Django企业开发实战》这本书的作者，而Django是用python写的web框架。他的python技术博客也很值得看。\n\n5、小明明S À DOMICILE小明明是《Python-Web开发实战》的作者，他的python技术博客也值得学习。\n\n6、Python官方文档库这个绝对要压轴推荐，写的非常详细，而且都有代码例子示范，学一门语言，一定要学会查阅官方文档。\n\n","categories":["技术博客"],"tags":[]},{"title":"有哪些面向新手的个人理财书籍值得推荐？","url":"http://tanqingbo.cn/2019/12/02/有哪些面向新手的个人理财书籍值得推荐？/","content":"1、《小狗钱钱》这本书有点像是写给小孩看的童话书，用特别通俗易懂的原理给你介绍了股票、基金背后的原理，干货特别多。\n如果你以为是写个小孩子看的那你就错了，大人了看了一样会有很多收获。入门必读！\n2、《富爸爸穷爸爸》这本书可以说是大名鼎鼎，很多大佬他们的财商启蒙都是源自这本书，看完之后你会知道什么是资产，什么是负债，如何利用你的资产带来更多的收益，怎么合理安排你的现金流。\n相信我，看完之后你会做出真正意义上的改变，特别推荐去看！\n3、《财富自由之路》这本书和《小狗钱钱》是同一个作者写的，有成人版《小狗钱钱》之誉。不仅是一本教年轻人如何规划财务的书，还是一本“教你做人”的书。让你思考的不仅是如何制定财务上的目标和规划，还包括了更宏观的人生课题：我希望成为怎样的人，多年后过怎样的生活。\n4、《读财报就像一本故事书》以沃尔玛等公司为例介绍了三张表，主要是从经营者的角度分析公司的竞争力，讲了一些基本的财务概念。\n5、《巴菲特的护城河》作者剖析了巴菲特选股的原理，用许多生动的商业案例分析了什么是护城河，如何找到有护城河的优质企业，如何对企业进行估值和价值投资。学会分析巴菲特护城河，是掌握价值投资的基础技能。\n6、《投资中最重要的事》作者是霍华德·马克斯。书中详细阐述了“第二层次思维”、价格/价值关系、耐心等待机会、以及多元化投资等概念，对自身的决策以及偶尔的失误做出了坦诚的评价，为读者进行批判性思考、风险评估、建立投资策略提供了宝贵的经验教训。\n7、《怎样选择成长股》以通俗易懂的解释，配以简单明了的图示，向我们介绍了一套能够对公司经营与财务状况进行快速分析的技巧。\n8、《证券分析》巴菲特唯一亲笔作序推荐图书。本书作者格雷厄姆被誉为 “现代证券分析之父”“华尔街父”，价值投资理论奠基人，其地位相当于物理学界爱因斯坦，生物学界达尔文。\n上面整理的这个书单，部分书可以在公众号【轮子工厂】中回复“理财书籍”领取！\n","categories":["漂来漂去"],"tags":[]},{"title":"见明误终身之江南大屠杀","url":"http://tanqingbo.cn/2019/12/02/见明误终身之江南大屠杀/","content":"在上一篇《东林党和朱元璋的南明朝》中说到南明仅存的几只正规部队正被东林党挑拨在打内战，导致清军一日便攻下了扬州。\n北方的战斗民族，不管是当年的蒙古还是现在的清军，向南方进军的时候通常都会采用“屠城“的方法来震慑当地的百姓。所以清军攻下扬州之后便开始屠城，著名“扬州十日”还上过历史课本呢！\n由于国内的部队正在打内战，加上清军“屠城”的buff加成，周围望风归降，从扬州到南京几乎没有遇到什么阻扰，直下南京，当年皇太极在关宁锦防线被孙承宗和袁崇焕虐的死去活来的时候，要是知道南京这么好打，估计能笑醒。\n此时清军的首领是多尔衮，他觉得南京都被我占领了，看来收取天下指日可待，于是他便想推行一些他们满人的习俗：让全国人民剃发！其实对于老百姓来说，改朝换代对他们的影响并不大，换个皇帝而已，而且你还给我们减免税收，我们愿意臣服于你，但是你让我剃发，这可不行。\n因为汉人自古以来都有一个信仰：身体发肤，受之父母，不敢毁伤，孝之始也。剃发就是不孝啊！所以剃发的命令一来，这可不得了了，被清军占领的地方又重新乱了起来，各地纷纷组织乡勇起义，并且发誓：头可断，发型不可乱。但是多尔衮也不虚，颁布诏令：留发不留头，想要保住发型那就要砍头。\n既然谈不拢，那就打吧！这一打，可不得了，光江阴这个小地方就打了八十一天。\n八十一天是什么概念呢？扬州城壕宽城厚，还有首辅史可法亲自前线督军，可是只坚持了一天就被清军攻下了，而江阴自发组织的乡勇竟然抵抗了八十一天。以至于后来明朝投降的将军亲自去城下劝降，但是将军劝降也不好使，还别江阴的一个典史给怼回来了，怼人的姿势特别霸气，他说：明朝有投降的将军，但是没有投降的典史。后来八十一天之后，江阴城破，全城屠尽。\n另外一个比较有名的屠城事件是嘉定三屠。也是因为剃发这个事情，嘉定人民坚决抵抗，然后城破之日被屠杀，二十多天之后，又有乡勇起来自发抵抗，老子就不剃发，然后清军再次破城屠杀，这次差不多把人都屠杀没了。\n清军以为这回应该可以消停了，但是并没有，四乡八里的江南农民推举乡绅又竖起义旗，重新占领了嘉定，誓死不剃发，然后清军的大部队第三次破嘉定城，再再再次屠杀。\n后来因为剃发这个事，多尔衮在江南屠城都已经屠到快怀疑人生了，后来实在没有办法，就把洪承畴从北京调过来，让他来收拾这个烂摊子，因为洪承畴本来就是南方人，又是之前的明朝首辅，懂汉人的习俗文化。他来了以后立刻停止了剃发，又出台了一系列得民心的政策，这才慢慢的使江南稳定下来。\n所以别看江南水软风清，出才子美人，江南的人民抵抗外族的侵略也是相当有血性的。宋朝在北方沦陷之后，南宋抵抗蒙古抵抗了150多年；抗日战争的时候，东北几乎没有抵抗就投降了，北方也很快沦陷，但是江南这块地方，日本直到最后投降的时候也不算完全占领。\n","categories":["漂来漂去"],"tags":[]},{"title":"Windows神器软件","url":"http://tanqingbo.cn/2019/11/29/Windows神器软件/","content":"你的电脑是不是在使用的过程中经常弹出广告小弹窗，类似下面这种，不厌其烦。或者桌面上突然出现陌生的软件图标。\n\n这其实是当我们浏览网页、安装应用软件时在不知情的情况下被安装恶意程序，这些程序并不是你主动安装的，而是恶意安装的广告弹窗程序，会占用您的计算机内存，使你的计算机变慢并且存在极大的安全风险。 \n所以今天给大家推荐一个软件：Wise AD Cleaner，这个神器软件可以实时拦截非广告程序弹出的广告弹窗。\n还可以够有效的检测、清理系统中存在的广告软件，而且能够修复被恶意篡改的浏览器首页设置，以及清理被恶意添加到资源管理器的图标。如下图所示：\n\n只需要点击右上角的“’扫描”按钮，就可以迅速帮你找到系统里的各种广告图标和广告弹窗，然后点击“修复”按钮就可以帮你一键这些垃圾广告了！\n\n这个软件给大家整理好了，大家微信关注公众号：轮子工厂，回复“拦截广告”领取！\n","categories":["技术博客"],"tags":[]},{"title":"穷，怎么啦？","url":"http://tanqingbo.cn/2019/11/29/穷，怎么啦？/","content":"我们经常听到一句话叫“小时候穷，一辈子穷”，因为小时候的贫穷确实会带来很多不良的后果，比如缺乏安全感，或者长大后一旦有了权力就会用赤裸裸的手段贪污腐败，比如《人民的名义》里面的祁同伟，又比如有科举的朝代比没有科举的朝代贪腐的现象更多。\n但是我并不认同“小时候穷，一辈子穷”这种说法，很多人小时候过的都是穷日子、苦日子，长大后不但没有上述毛病，反而因为吃过苦，更有努力向上的动力，甚至在经济条件好了之后开始回报社会，对周围的朋友也相当慷慨。相反，一些从小锦衣玉食的孩子，长大后除了贪图享受，没有更多值得称道的地方，这样的人也不在少数。\n确实小时候的贫穷和长大后发展的诸多不顺有相关性，但是相关并不代表因果关系，我觉得过得诸事不顺的人都有三个共同的问题：\n\n缺乏见识。没有见识，视野就被局限了，你可能有这样的体会：和有些人讲道理永远讲不通。并不是他们故意要和你作对，而是大家的认知水平不在一个水平线上，有些东西就是和他们沟通不了。\n\n缺乏爱。很多人因为小时候家里穷，父母不得不出去打工，自己便成了留守儿童，父母没有条件爱他们。如果大家留心的话，会发现大多数父母都在身边的孩子个个都很活泼开朗。相反，父母不在身边的孩子就显得比较内向沉闷，不善言谈。\n还有一个是独生子女的问题，独生子女也会导致爱的缺失，第一代独生子女感受不到兄弟姐妹的关爱，第二代独生子女连堂表兄妹都没有了，这才是可怕之处。人活在世上光有父母的爱是不够的，还需要有兄弟姐妹的关爱，毕竟社会是由人组成，缺乏这方面的爱，可能导致不知道怎么去关爱别人，不知道如何与别人分享，走向社会后不顺的事或许会更多一点。\n\n缺乏规则。缺乏规则会令人踩到别人的脚趾而不自知，其结果是，轻则没有人愿意帮他们，重则大家都会和他们作对，而这个世界上没有人帮助实不行的。这些人也会感觉到别人对他们不友善或者敬而远之，但是还常常不知道原因，于是便对人、对社会产生一种戾气。\n\n\n缺乏见识、缺乏爱、缺乏规则，是比缺钱更可怕的事情，而它们的缺乏其实和穷没有必然的联系。贫穷可能会在短期内使物质条件差一点，但是并不影响父母在见识、爱、和规矩上培养孩子。\n所以，“小时候穷，一辈子穷”这话并没有什么道理，主要还是看孩子是在什么样的成长环境中成长，以及家长是怎样教育孩子的。\n","categories":["漂来漂去"],"tags":[]},{"title":"东林党和朱元璋的南明朝","url":"http://tanqingbo.cn/2019/11/19/南明悲歌/","content":"故事应该从李自成攻陷北京，崇祯煤山殉国开始说起，大家知道明朝是陪都制，就是一个国家有两个首都，一个在北京一个在南京，都设有六部、内阁。北京的那套机构班子在南京有一套一模一样的，所以北京沦陷之后，其实问题不大，咱南京还有一套权力机构，又有长江天险，在南京重新立一个新皇帝，然后打回去收复北方那是完全有可能的，毕竟李自成的闯军算不上正规部队，辽东的清军还只是个小部落，军队不到10万，论实力，南明依然是最强的。可是历史往往都不会按照预想的那样发展。\n有句说：心脏不好的人千万不要读南明史，因为会被气死。为什么这么说呢？给大家看一组数据就知道了，同样是南方政权，南宋跑到南京的时候没有现成的机构，需要重新组建领导班子，南宋的北方有金、辽和蒙古人（就是那个从欧洲一直打到了韩国的建立史上最大帝国元朝的蒙古人），可谓是群狼环伺，在这种情况下南宋撑了152年。再来看看南明当时的情况，南京有现成的领导班子，赋税徭役正常征收，按说不缺钱，而且北方只有李自成和张献忠的农民军以及皇太极的清军，李自成和张献忠后来还帮着明朝抗清，多好局面啊！可是南明只撑了18年就被清朝灭了。\n\n为什么这么迅速就被灭了呢？那就要感谢明朝可爱的文官集团了！\n当时北京没了，南京的内阁六部便扛起了大明的重担，他们面临的第一件大事就是立新皇帝，因为国不可一日无君嘛！于是以史可法为首的内阁便开始讨论立哪个王爷当皇帝比较好。\n其实也没啥好讨论的，因为当时朱元璋建国的时候明确就在宪法里规定了皇位继承的办法：\n\n1、立嫡长子，就是皇后的大儿子；\n2、没有嫡子，立长子；\n3、没有儿子，立皇帝的兄弟；\n4、没有兄弟，立皇帝最近的血亲。\n\n你看朱元璋想的多周到，各种情况都考虑到了，如果按照这个规矩的话，其实应该立福王，而且福王离南京也近，可以最快速度到南京主持大局，但是东林党们死活不肯立福王，为什么呢？因为当年万历皇帝当政的时候，他最喜欢的儿子是福王，本来想立福王为太子，可惜福王不是嫡长子，东林党以宪法捍卫为由，和万历死磕了十几年，最后万历认输，立皇后的儿子为太子，福王去了自己的封地。\n可是这回东林党却不捍卫宪法了，说要立贤，不能立福王。这不扯淡吗？你咋知道人家福王不贤，其他的王爷就贤呢？明眼人都能看出来这里面的私心，当年反对福王当太子，现在也绝对不能让福王当皇帝，而且福王还不好控制，得立一个容易被自己控制的皇帝。因为在古代，谁拥立了皇帝，就相当于挟持了皇帝，定策之功啊！\n于是讨论来讨论去， 得出结论：立潞王为新皇上。可人家潞王在几千里以外呢，一来一回到南京都得一个月以后了，北方正在打战，哪有这么多时间等！而且等这么长时间也给了福王谋划的时间，福王离南京近，他也不傻，知道现在内阁是什么情况，于是跑到江北四镇去，那里有明朝的四支主力部队，他和四个将军说，如果你们拥立我，我肯定会报答你们，给你们特权和福利。\n要知道在明朝，将军的地位一直都是比文官低的，这四个将军一看天上掉馅饼，那当然开心了，于是南京选的潞王还没到南京，这边将军们就带着军队把福王送到南京拥立他当皇帝。这样一来，东林党们失去了定策之功，还让将军们挟持了皇帝。那皇帝肯定是更听将军们的话不停东林党的话了。\n如果将军们和东林党一起尽心辅佐皇上倒也没什么事，可是在双方合作的过程中马士英将军提拔了自己的好哥们阮大成来一起辅佐皇帝，这下子明朝的官场又爆炸了，因为阮大成是阉党啊！崇祯在的时候东林党和阉党斗的多凶，好不容易把魏忠贤给灭了，现在阉党又当政了，东林党彻底疯了，刚停歇没多久的党争又上演了。其实这个时候矛盾还是可以协调的，毕竟阮大成不是魏忠贤，只要我们的首辅大人史可法尽力协调双方关系还是有可能缓和的。\n但是并没有，史可法觉得南京这么乱，我这么有声望的人绝对不能参与这场斗争，有损形象。于是他主动离开南京去江北督军。国家已经到了最危急的关头，京城已经乱成一锅粥，您史阁老作为首辅首先想到的竟然是维护自己清高的形象，而不是解决京城里的问题，还有比这更荒谬的吗？\n事实告诉我们，当然还有比这更荒谬的事，历史就是喜欢打我们的脸。史阁老来到前线之后发现事情跟他想的有点不一样，因为此时的江北四镇已经不是原来的江北四镇，此时他们有拥立定策之功，史可法根本就压不住他们，为了收服这些军队，史可法决定给他们赐封地。\n因为史阁老这个英明神武的决定，本来还有救的大明彻底断送了生机。自古以来，军队的上升阶梯就是听从中央的调配，去打战，打赢了升官，现在有了地盘，他们可以再自己的地盘收税，还因为有定策之功，中央也得给他们钱花，这谁还愿意打战啊？\n最后荒谬到什么程度了呢？山东、河南、河北自发组织的乡勇已经把清军、李自成的闯军赶跑了，就等朝廷的王者之师前来接收，可是朝廷的部队就是不来，最后乡勇打下来的地方又被清军抢走了。\n其实本来史可法已经鼓动四镇中其中一支军队北伐了，可是首领高杰出发之前被人杀死了，高杰的儿子本来想认史可法为干爹，因为自己的亲爹刚死，自己想在朝廷找点依靠，史阁老正好是最好的人选，如果此时史可法同意收这个干儿子，他就相当于掌握这支部队，可是“英明神武”的史阁老并没有收这个干儿子，他觉得你是农民出身，我是当朝首辅，你不配当我的干儿子。不仅如此，他还让人家认一个太监做干爹，军人也是有血性的，认太监做干爹不是侮辱人嘛！造成的结果就是后来清军打过来的时候，高杰的部队是第一个投降清军的，并且是帮清军抢地盘的队伍中最卖力的那支。\n史阁老把江北四镇祸害的差不多了，我们接着来看没有史阁老的南京现在乱成什么样子了。马士英与阮大成手上有军队，又有定策之功，东林党自然处在下风，东林党一想：这样不行，我们也需要军队的支持。于是他们相中了武昌左良玉的部队，给左良玉写信，让他以“清君侧”的名义带部队进京。本来只是小小的党争，现在竟然演变成了内战，\n这导致什么结果呢？北方部队南下去打左良玉，导致南明的北方防线无人防守，清军打到扬州的时候基本没有费力气，一天就攻下了。更讽刺的是南京沦陷的时候，东林党们在他们魁首钱谦益的带领下，集体跪在城门口迎接清军入成，而当时和他们互殴的“阉党”们以及李自成的闯军却和清军斗争到了最后。\n我不想评价明末的这帮知识分子，他们有太多次机会挽救大明，就算不北伐，让南明活上更长的时间也完全有可能。如果东林党从一开始就按照宪法拥立福王，也不至于让军队功高震主不受控制；如果史可法放下自己的清高，协调好东林党与马士英、阮大成的关系，也不至于发生内战；如果史可法没有给军队封地，军队仍有战意去收复北方…….\n可是没有如果，这就是尘埃落定的历史！\n","categories":["漂来漂去"],"tags":[]},{"title":"臭知识分子们的美好时代","url":"http://tanqingbo.cn/2019/11/17/历史上的知识分子们！/","content":"如果顺着时间轴看的话，中国的知识分子们其实经历了几个大起大落的时代，在“起”的时代，只要你努力读书，哪怕是贫苦出身，社会也会给你提供出头的机会。\n第一个知识分子的美好时代可能得数春秋战国时代，在那个时候还没有“君为天的说法”，知识分子和君王是师友臣的关系，我可以做君王的而老师和朋友，我愿意辅助你，我才是你的臣，但是也不是那种“君要臣死，臣不得不死”的那种臣。而是“不召之臣”，这个词语是孟子说的，不召之臣就是得像伊尹之于商汤，管仲之于齐桓，君王要惯我、宠我，我要是觉得你行，就辅助你，要你觉得你不行可以辞职换个国家接着干。\n比如商鞅本来是在魏国当官，后来又跑到秦国去当丞相；张仪本来是在秦国挂相，后来秦惠王死后，他跑到魏国接着当丞相。这要是放在其它朝代可是通敌叛国要诛九族的大罪。此外，就算没有君王重用我，我也可以去游学，收徒弟宣讲学说，比如说孔子。春秋战国就是这样一个知识分子的美好时代，也正是因为这样才酝酿出了诸子百家，百花齐放的局面。\n有起便有落，紧接着大家都知道了，秦始皇统一六国之后便“焚书坑儒”，把书都烧掉，读书人都活埋掉，知识分子的社会地位一下子发生了翻天覆地的转变。汉朝基本上沿袭了秦朝的制度，知识分子基本上也没有出头之路，没有科举制度，民间的读书人上升无门，士族大家的知识分子社会地位也是比较低下的，比如说汉朝的史学大家司马迁，说宫刑你就宫刑你。到了魏晋时期，知识分子同样是社会地位低下，曹操连孔融都敢杀，孔融可是孔子的直系后代啊。所以作为一个读书人，你想要穿越的话，千万不要穿越到这个时期来。\n到了唐宋时期，中国的知识分子们又迎来了他们的第二春，因为这个时期开始有科举制度了，这个时候全国的知识分子又开始有了新的目标：那就是考科举。科举制度为所有的读书人树立了一个上升的阶梯，只要你努力，你甚至有可能做到宰相，唐宋时期的宰相那可不像明清时期的首辅，宪法里明确规定宰相就是负债整个帝国运转的人，皇上负债指一个大方向，宰相负债指挥整个文官集团去实现这个目标，有点像现在的董事长和CEO的关系，宰相就是整个帝国的CEO。\n而且在这个时期，就算知识分子之间有竞争，那也只是政见不同，内心还是互相尊敬对方的，竞争输了顶多也就是被流放一下，终宋一朝也没有杀仕，依然会允许你诗篇流传，歌颂你的功德。不像明朝，政见不同，输了的人不仅得死，连祖坟都要被挖出来。\n到了元明清时期，知识分子社会地位又不行了，元朝时期，读书人叫臭老九，就是说人分十等，知识分子仅排在乞丐前面，排第九，比娼妓的社会地位还要低。而且元朝大部分时间是没有科举的，读书人不用忙着准备科举，也不当官，他们无处安放的笔便开始了长篇文学作品的创作，反正也是闲着，于是开始写戏剧。\n为什么是戏剧呢？因为读书人还有另外一个爱好：逛青楼！我的笔不能治国安天下，那就给青楼女子写戏曲吧！所以元曲是很有名的，不像唐宋的知识分子，他们写诗词，四五句话就写完了，不费时间，因为他们忙着当官，要处理政务，没时间进行长篇作品创作。\n你可能会问，为啥明朝的知识分子不写戏曲，明朝的读书人哪有钱去逛青楼啊。其实明朝也是有科举制度的，但是明朝的科举和唐宋有点不一样，明朝没有宰相了，首先从权利上就达不到唐宋的高度，而且在明朝时期，“忠君”思想特别严重，皇上比父亲还重要，君要臣死，臣不得不死。更要命的是明朝有一个官职叫言官，这个官不干别的，主要的工作就是骂人，而且是写进宪法里面的，可以合法的骂人，谁都不能把他怎么样。大家有空可以看看《明朝那些事》，看看明朝的官儿们互相骂成什么样了，尤其是进了内阁的官员们，被言官骂的最凶，就算有人想实现自己的理想抱负也是力不从心（看看张居正的下场）。所以后来明朝内忧外患和这帮人互相内斗有很大的关系。\n到了清朝就更不用说了，当官的人连称呼都改了，在皇帝面前，所有人都得自称：奴才。也就是你们这帮知识分子都是我们皇家养的奴才。\n到了民国时期，知识分子们又迎来了自己的春天，我们现在听说过的那些“大家”、语文课本上学的一些课文，都是那个时期的那帮人所创作的。民国时期有点像春秋战国时期，世界各个国家的文化不停的交流碰撞，大批学子出国留学，带回了很多不同的思想。孙中山带回了三民主义、李大钊第一个在中国宣传共产主义。蔡元培、王国维、胡适、钱学森等等，一大批教育家、科学家不断的涌现，“鲁郭茅巴老曹”他们的文学作品依然是中国近代文学的巅峰，形成了百家争鸣的局面。\n其实现在回过头来看，不管是知识分子的春天也好，冬天也罢，都是统治者们为了巩固自己的政权而导致的，春秋战国时期，君王们为了抢到更多的地盘，他们需要人才来辅佐自己，因为那个时候国家很多，知识分子有太多的选择，君王们必须礼贤下士才能吸引人才。到了秦朝国家已经统一，太多的学说只会让社会动荡不安，秦始皇为了让自己的王朝世代延续下去，只好杀光知识分子，因为愚民最好统治了。到了隋唐宋时期，一方面统治者们看到了士族大家对自己权力的威胁，另一方面国家刚经历乱世（五胡乱华），国家人才库凋零，于是科举制度产生，从民间选拔人才辅佐君王。\n到了元朝，我一直都觉得蒙古人只是占领了中国，算不上统治，因为他们还没来得及吃透中原的文化，又被朱元璋给赶走了，所以元朝的知识分子们自然很难得到被重要的机会。到了明朝，明朝真的是很奇葩的一个朝代，读书人日子不好过，就算他们上朝为官了也很难实现自己的抱负理想，大环境不允许，老百姓的日子自然也苦，就连皇帝的日子也不好过，一辈子只能呆在紫禁城，还要被言官们骂。\n","categories":["漂来漂去"],"tags":[]},{"title":"这几个百度搜索技巧，太好用了","url":"http://tanqingbo.cn/2019/11/15/这几个百度搜索技巧，太好用了/","content":"百度作为国内最大的搜索引擎网站，虽然很多人都喷它的搜索页面广告太多，但是对于不会科学上网的同学来说，似乎除了继续用百度以外也没有更好的选择。\n其实搜索引擎一般都会内涵一些高级的搜索技巧，掌握这些技巧之后就可以过滤掉一些不想要的噪音，迅速找带自己想要的信息，只是很少人知道和使用，下面就给大家来分享一下这些搜索技巧。\n1、 关键词加引号比如我要搜索：小胖穷，在搜索的时候很有可能会把”小胖“和“穷”拆分开，然后分别进行搜索，这时候我们可以把关键词放入引号内，就代表完全匹配搜索，也就是所显示的搜索结果一定包含完整的关键词，不会出现近义词和拆分的情况。 \n\n2、site：用于搜索指定网站下的关键信息比如我只想在我自己博客网站上搜索“计算”这个信息，我可以使用关键词   site：tanqingbo.com 计算   进行搜索，这样搜出来的信息都是我博客上的内容。如下图：\n\n3、在标题里面限定进行精准搜索如果我们想得到搜索结果的标题中包含我们输入的关键词，这时候可以用intitle：进行限定。\n比如我想搜索引擎返回的结果在标题里面包含“计算机”这个关键词，可以输入关键词：intitle：计算机。如下图：\n\n4、 精准搜索你要的文档类资料有时候我们想在百度上找某个课程的文档，但是搜出来的信息总不是自己想要的，可以试一下关键词：filetype:+文档格式。\n比如我们想在网上搜索高等数学课doc格式的文章，我们可以这样搜索：高等数学 filetype:doc，如下图：\n\n5、 指定链接进行精准搜索在网页链接中我们可以限定关键词进行搜索，只要在关键词前面加：inurl:\n例如：我要精准搜索关键词：Java\n可以输入关键词：inurl:Java，如下图：\n\n","categories":["技术博客"],"tags":[]},{"title":"微信不仅可以关闭朋友圈，还可以关闭这些功能","url":"http://tanqingbo.cn/2019/11/14/微信不仅可以关闭朋友圈，还可以关闭这些功能/","content":"大家每天玩微信应该都知道，在发现页经常会有个小红点，只要是发现页面的某个功能项有更新（不止朋友圈），小红点就会亮，每次打开微信的时候都会被这个小红点分散注意力。\n其实朋友圈和一些发现页里面的一些功能是可以关闭的，关闭之后，不仅微信的界面干净了，也不会被微信的红点分散我们的注意力。\n\n有段时间我为了准备某个考试，把发现也所有的功能都关了，瞬间感觉世界变清净了，经常注意力不集中的同学可以试试。\n那么怎么关闭朋友圈等一些发现页功能呢？\n1、首先打开微信的设置，然后找到通用，如下图：\n\n2、接着就可以看到发现页管理了，点击开就可以选择关闭一些不想使用的功能了。\n\n此外，现在微信支付里面的功能也是越来越多了，如下图所示：\n\n里面的这些服务也是都可以关闭的，如果你只想让你的微信支付做个安静、简洁的支付工具，就可以把这些服务都关掉。\n关闭支付页的服务，操作也很简单。\n先打开支付页右上角的多功能符号，然后找到里面的服务管理，在服务管理也里面就可以关闭那些不想看到、也不需要使用的服务功能，还你一个简洁的微信。如下图：\n\n（钱包只剩1.45元，打扰了！）\n","categories":["技术博客"],"tags":[]},{"title":"有哪些值得推荐的在线编程网站？","url":"http://tanqingbo.cn/2019/11/13/有哪些比较好的在线编程网站/","content":"经常听到一个段子说：大分部伟大的想法都死在配环境上面。\n我知道对于一个新手来说，可能配运行环境要比上手写代码要难受的多。所以我就抽时间整了一些在线编程测试的网站，虽然推荐了这些网站，但是还是推荐大家平时写代码的时候在本地用IDE写。\n这篇文章的意义在于：\n\n工作或者考研的时候，针对特定的算法题在网站上练习；\n一台临时电脑，没有编程环境，但是需要运行代码；\n突然需要运行一个自己不常用的语言的代码，自己电脑上没有环境；\n想要了解其它系统，自己安装很麻烦，用线上的系统练一下手。\n\n下面是正文，欢迎大家补充：\n1、牛客网要说在线编程网站，肯定要提到牛客网，很多大厂的机试都是在牛客网上进行的，找工作之前，可以在上面找到以前的校招真题进行练习，想刷剑指offer、LeetCode的题也可以在上面刷，不会的题有大神在讨论区分享答案，不仅如此，计算机专业的考研/保研机考在牛客网上也能找到。自带的编译器主流的编程语言都支持（见第二个图）。\n\n\n2、 LeetCode 算法刷题网站肯定绕不开LeetCode，业界一直有句话说把LeetCode上的题都刷烂熟了就可以进谷歌了。不过上面的题都是英语描述，需要一定的英语基础，还需要一定的算法基础。不过好像LeetCode也有一个中国区网站，算法题目都是中文描述的，觉得看英文费劲的同学可把中国区的网站收藏一下： https://leetcode-cn.com/problemset/all/ \n\n此外我这里还有一本LeetCode题解的书，也一起分享给大家。微信关注公众号：轮子工厂，回复“leetcode”就可以领取了。\n3、 北京大学的OJ北京大学的Online Judge。POJ上面的题目有点老了，但好处是做的人多，经典算法题多，解题报告也多，适合上手。 \n  \n4、 杭电的OJ 杭州电子科技大学的OJ。杭电OJ在近几年取代了POJ，成为是目前国内最主流的OJ。它的题目丰富，难度梯度合理，广受全国各大高校的青睐。每年也会有大大小小的比赛挂在杭电的OJ上举办，去年的亚洲区网络赛也是在这上面做的。由此可见其在国内广大ACMer心目中的地位。也正因为如此，网上hdu的解题报告也很多，适合个人进阶训练。\n\n5、AnyCodesAnycodes是一个在线编程的系统，用户可以随时随地，通过电脑，通过手机，平板等的浏览器，或者App访问网站，然后在线写程序代码，目前支持中英韩文三个版本，支持九种编程语言C/C++/Java/Matlab/TCL/Php/Python/Perl/Ruby，不但支持语法高亮、行数显示、代码自动折叠、部分纠错，而且还支持多文件，标准输入（stdin），命令行参数和代码下载，程序可以在线运行，其中matlab程序可以输出图片。\n\n6、 Codepad网页界面简洁，一目了然，适合手机浏览器。且支持C,C++,D,PHP,PYTHON,Perl,Ruby等十几种编程语言，非常强大。查看执行结果时，高亮显示代码。而且不需要注册就能用。\n\n7、Dabblet学前端的朋友一定不能错过这个网站，特别适合新手和想尝试最新HTML5标签和CSS3样式的前端攻城师使用。Dabblet的一大特色是代码编写时可免加CSS前缀。因为，Lea Verou（工具的作者）本人就是免CSS前缀JavaScript脚本 -prefix-free的作者，Dabblet拥有此功能当然是顺理成章的事。HTML和CSS代码间的切换也很方便，点击隐藏工具栏右上方的标签即可。用户可以根据习惯，调整前端代码的预览效果，浏览器内全屏预览将新标签页中打开。\n\n8、实验楼实验楼不仅可以练习编程，它还是一个操作系统，除了学习写代码，还可以学习操作系统、编译原理什么的。比如想学一下linux系统，就不用再去装一个linux虚拟机了。实验楼直接提供Linux系统环境，在线就可以使用。\n\n","categories":["技术博客"],"tags":[]},{"title":"互推文案","url":"http://tanqingbo.cn/2019/11/12/推荐一位大佬！/","content":"今天给大家推荐一位大佬的公众号【轮子工厂】，这个号我关注很久了，博主目前是哈工大计算机系的在读博士，他本科毕业之后直接保送攻读博士学位，平时喜欢读书、善于思考、对编程技术、程序员成长规划有着独到的见解。\n他的每一篇文章我都读过，除了给读者讲解技术知识点外，他还会分享一些自己的读书笔记以及平时的一些思考和感悟，是不少读者眼中的“宝藏公众号”。为了证明我不是在自卖自夸，挑几个读者的留言大家感受一下：\n\n\n\n\n类似这样的留言还有很多，所以推荐大家都去扫码关注一下。\n\n随便挑几篇他的文章，大家看一下：\n","categories":["技术博客"],"tags":[]},{"title":"推荐几本大学生必看的书单","url":"http://tanqingbo.cn/2019/11/08/给大家推荐几本书/","content":"文学类：1、平凡的世界这本书对我有着特别的意义，每次我处于低谷的时候、或者没有动力学习工作的时候都会把这本书拿出来读一下，因为我觉得我就像书中的孙少平一样，因为多读了几本书，对外面的世界有着很大的向往，凭自己的努力和倔强，尽可能的去看到更大的世界，孙少平没有放弃，我也不应该放弃！\n当然它不止适合农村出来的孩子读，它适合每个人读，因为小说刻画了从建国初期到改革开放之后，中国社会演化的全过程，我知道不少高校在给学生寄录取通知书的时候还会顺便给他们寄一套《平凡的世界》，可见这本书影响之深！\n2、穆斯林的葬礼这也是一本史诗级小说，作者是回族的女作家霍达，故事讲的是北京一个回族玉匠家庭半个多世纪两代人的故事，讲述了北京从民国到解放后社会的变迁。因为讲的是玉匠的故事，小说里面穿插讲了很多中国文化的元素以及回族的一些文化礼节和习俗。非常值得阅读！\n3、海边的卡夫卡 这本书的作者是村上春树，他的小说看过不少，最喜欢的是这本，看完之后才真真切切感受不愧是若奖级作家，对情节的把控，对少年精神世界的刻画，对生活意义的探讨都非常深刻。 \n4、三体这本书表面上是讲外星人入侵的故事，实际上是一本刻画人性的小说，大刘不仅懂世界历史，对人性也洞察的一清二楚，书里面每一个重大情节在人类历史上都能找到原型，罗辑发现黑暗森林法阻止了三体人的入侵换了来短暂的和平，成为了救世主，可是和平没多久他却被大家认为是有史以来最大的罪犯，因为他试验黑暗森林法则的时候毁灭了一个星系，因此被赶下救世主的神坛。华盛顿建立美国，后来美国人发现华盛顿其实是黑人奴隶主，不配做美国人的国父，有没有发现和罗辑很像。\n三体人占领地球后，把人类全部赶去了太平洋中央的澳大利亚，剩下的领土全部归三体人所有。欧洲移民到美洲之后，把本土的印第安人全部赶去了贫瘠的得克萨斯州，是不是一模一样！\n而且现在互联网行业特别推崇三体里面的黑暗森林法则，作为一家初创公司，必须深谙黑暗森林法则，才有可能在这丛林中活下来。所以推荐大家都去看看这本书，保证你有很多收获的。\n思维类：1、见识《见识》是吴军老师的书，虽然内容有点散碎，但是是他几十年的视野解读和感悟，干货满满。 看完之后会改变你的一些思维方式的。\n2、增长黑客在国外专门有一个职位叫做增长黑客，在国内一般指的是运营岗，并不是大家想的那种黑客，书中结合一些经典的例子给大家介绍了一个产品是如何吸引新客户、促活跃、做转化的，以前你可能只知道支付宝给你发红、打车软件给你发优惠券、扫码关注给你送礼物，自己占到便宜了。\n但看完这本书之后，你能看到事情的全部面貌，你会知道支付宝是出于什么目的给你发红包，为什么扫一下码就能得到精美礼物，他们是出于什么目的这么做的，他们能得到什么，自己是不是被割韭菜了。\n理财类：1、富爸爸穷爸爸认识不少的大佬，他们的财商启蒙都是源自这本书，看完之后你会知道什么是资产，什么是负债，如何利用你的资产带来更多的收益，怎么合理安排你的现金流。\n相信我，看完之后你会做出真正意义上的改变，特别推荐去看！\n2、小狗钱钱这本书有点像是写给小孩看的童话书，用特别通俗易懂的原理给你介绍了股票、基金背后的原理，干货特别多。\n如果你以为是写个小孩子看的那你就错了，大人了看了一样会有很多收获。入门必读！\n历史类：我是个明史迷，所以给大家推荐三本明朝相关的历史书。\n1、明朝那些事这本书就算大家没有看过也应该听过，当年明月老师把历史写的跟小说一样有趣。有一天，你终于读到最后一章，读到末尾那句“成功只有一种：按照自己的方式，去度过人生。”\n你突然安静下来，看过的那些王侯将相还历历在目，大明王朝的风云还在脑中翻涌，你却在那一瞬间，觉得它们都不重要了。一切烟消云散，你终于拨云见日。这就是这本书的厉害之处。\n2、万历十五年相对于《明朝那些事》，这本书对细节刻画到了恐怖的程度，《那些事》对明朝一些人物的描写以及明朝灭亡的原因加了很多个人情感在里面，而《万历十五年》则客观一些，更像一本史书，以小见大，深入剖析，使读者能有自己的判断。而且从书里面你也能看到现在官场的一些影子，总之这本书是个大宝藏，你能挖掘出很多有用的东西，不仅仅只是历史。\n3、显微镜下的大明马亲王今年的新书，很多人应该都看过马亲王的《长安十二时辰》，不过《十二时辰》讲的是唐朝，这本书讲得是明朝民间的一些故事，《明朝那些事》和《万历十五年》讲的都是朝堂上的事，如果你想对明朝有进一步的了解，那这本书一定不能错过。\n","categories":["漂来漂去"],"tags":[]},{"title":"人生需要做减法","url":"http://tanqingbo.cn/2019/10/31/人生需要做减法/","content":"1、不做选择的幸福\n为什么印度人在美国、乃至全世界跨国公司中担任高管的人比中国人多？原因可能有以下几个：\n\n中国改革开放才40年左右，印度人走出国门比中国人早半个多世纪；\n印度的英语交流能力比中国人强，印度曾经被英国殖民过很长时间，讲英语的基数比中国要高很多；\n中国的教育重理轻文，使得中国年轻人算术水平不错，但表达和写作能力欠缺；\n在意识形态方面，西方国家对中国多少有些防范，但是他们不会认为印度是威胁。\n\n但上面列的这4点都不是根本的原因，根本原因是在美国的印度人他们缺乏选择。\n虽然印度这几年发展很快，但是依然很穷，当印度的精英们通过读书或者工作移民到另一个国家时，几乎不回再回到印度，因为国家没有能力给他们提供很好的就业机会。所以绝大多数到了美国的印度人，他们没有退路，只好死心塌地在新的国家经营自己的工作，削尖脑袋往上爬！\n反观在美国的中国人，今天他们的选择可就太多了，这要感谢祖国的快速发展。很多人在美国毕业后，在当地公司工作几年就会有国内的大公司猎头来挖人，以至很多人想的不是努力工作晋升，而是如何巧妙的利用自己在美国和大公司的经历包装自己。\n不仅在工业界，在学术界也是如此，近年来，在美国顶级大学做到顶级教授、获得突出贡献奖的华人也越来越少。\n\n\n2、西瓜与芝麻生活中捡芝麻的例子：\n\n为了拿免费的东西打破头；\n为了省一元出租车钱，在路上走十多分钟；\n为了抢几块钱红包，隔几分钟刷一下淘宝微信；\n为了“双十一”抢货不睡觉。\n\n这些人的这些问题不仅在于时间利用的非常没有效率，更糟糕的是他门渐渐习惯于非常低层次的追求。\n人一旦心志变得非常低，就很难提升自己，让自己走到越来越高的层次上。当一个人的心思放在捡芝麻上，他就永远失去了捡西瓜的可能性。\n苹果公司的产品线一个巴掌能数的过来，却是全世界最赚钱的公司，因为它在捡西瓜。\n每个在职场中的人，与其把心思放在赚小钱上，不如把他们聚焦到一点，练就捡西瓜的能力，让自己从同事中脱颖而出。\n3、生也有崖，知也无涯生活中经常遇到这样的人：他们有习惯性迟到的毛病，而且每次都不是故意的。比如，早上出门，母亲打电话来了，不好不接，于是耽搁了一点时间；昨天迟到是因为在地铁站遇到一个老同学，就聊了一会，不和人家说话会显得架子大，不给面子；大前天下班聚会也迟到了，本来已经做好准备提前下班了，但是快到聚会地点的时候，一看时间还早，就去附近家乐福逛了一下，结果结账的时候赶上排长队…….\n这些人的迟到毛病基本改不掉，因为他们有一个思维定式：临时插进来的事必须要做，否则就会没礼貌、没面子、或者就能亏了。其实那些事情如果不做，天根本不会踏下来。\n如果你想通了很多事情不做其实也无关大体，就不要去做它们，这样你就不会天天忙忙碌碌了。如果一个人不能够把一件事情做好，他首先应该想到的是少做事情，而不是让自己更忙碌。\n","categories":["漂来漂去"],"tags":[]},{"title":"最让你震惊的网站有哪些？","url":"http://tanqingbo.cn/2019/10/30/最让你震惊的网站有哪些？/","content":"1、MSDN我告诉你（https://msdn.itellyou.cn/）想重装系统，但是不知道在哪下载系统镜像？这个网站不仅可以免费下载系统镜像，而且版本特别全，最重要的是没有广告，现在很多网上的电脑系统安装完成后，都会给你的电脑安装诸多你并不需要的全家桶，但这个网站上是真正的纯净版系统，一个插件都没有。\n\n2、大学生资源网（http://www.dxzy163.com/）是一个功能超级强大的在线视频网站，里面不仅有从考研到大学到小学的免费课程，还有关于电脑网络、医学视频、历史地理等全面的知识，非常适合在校大学生。\n包括资格考试的视频也有：工程建筑、考试认证、财会考试、公务员考试、司法考试。\n这都是花钱都买不到的财富！\n\n3、自己整理的网站书签（ http://www.bewindoweb.com/dwg.php ）这是实验室一个师兄把他大部分能想到的、有用的网站都整理成了书签，其中包括了**写论文必备、程序员通用、数据源下载、在线工具网站、设计素材、办公常用、学生常用…….**你能想到的，想不到的有用的网站都收集在这里面了，一共100多个，当你需要学习工作的时候，直接去对应的网站找到你想要的东西，大大提升你的效率，具体看下面：\n1、 写论文必备\n2、程序员通用\n3、数据下载源\n4、设计素材\n5、在线工具网站\n6、学生常用\n7、程序员学习\n4、在线办公（ https://uzer.me/ ）不需要安装，就可以在线编辑Office，使用PS、Visio、Xmind、Matlab、Jupyter等等大型软件。\n还有CAD、WPS、SPSS等，有了它，我们的PC上就不需要装那么多软件了。\n  \n5、全球电视直播（http://bddn.cn/zb.htm）这是一个丰富眼界的网站，你想看看外国人看的电视内容都是什么吗？这里面统统都有，不仅包含港澳台、美国、西雅图、伦敦、俄罗斯的电视节目这里都有。\n\n6、PPT导航网站(http://www.hippter.com/)这个网站相当一个文件合集，对PPT的资源网站进行分门别类的整理。你见过的，没见过的，它都帮你找到了！解决你所有的素材资源问题！\n\n7、格式转换大全（ https://cn.office-converter.com/ ）**office文档格式、视频格式、音频格式、图片格式、电子书格式…….**只有你想不到，没有你找不到，有所的格式都可以在这个网站上转换。你瞅瞅：\n\n\n甚至文件压缩也是可以在这个网站上完成的：\n\n8、geektyper（ http://geektyper.com/ ）这个是程序员装B神器，我们看过很多电影，里面的黑客随便敲击两下键盘，然后代码快速滚动，然后蹦出一个进度条，某个特别厉害的系统就被破解了，后者银行的钱就没了。这个网站就可以让你体验一下当黑客的感觉，看下面的图片，是不是似曾相似：\n\n\n9、谷歌插件网（ http://chromecj.com/ ）因为一些冲所周知的原因，谷歌浏览器上面很多实用的插件都用不了，但是有了这个网站之后，无需科学上网也可以下载chrome浏览器插件。\n\n10、免费下载电子书（ http://freecomputerbooks.com/ ） 这是一个专注于计算机、变成、数学、电子工程、软件工程等技术书籍的网站，所有资源均可免费下载。网站的分类做得非常棒，资源也很丰富，还能看到不少2019年新出版的新书。 \n\n就这些，各位朋友，觉得有用的话记得点个赞哦。 \n对了，欢迎大家关注我的公众号：轮子工厂， 上面有很多干货文章和学习资料，  4万多人的选择，绝对值得关注！ 关注回复关键词：\n\n回复“简历”，获取100多个各行各业经典商务简历模板；回复“爬虫”，获取两本经典的python爬虫电子书，包括爬虫入门、进阶、实战等内容；回复“1024”，获取几十本经典计算机专业必读电子书！ \n\n","categories":["技术博客"],"tags":[]},{"title":"你应该知道什么是爬虫？","url":"http://tanqingbo.cn/2019/10/26/你应该知道什么是爬虫？/","content":"\n来源：https://www.zhihu.com/question/20899988/answer/783269460本回答针对初学者，我会用最简单的案例告诉你如何入门python爬虫！想要入门Python 爬虫首先需要解决四个问题熟悉python编程了解HTML了解网络爬虫的基本原理学习使用python爬虫库一、你应该知道什么是爬虫？网络爬虫，其实叫作网络数据采集更容易理解。就是通过编程向网络服务器请求数据（HTML表单），然后解析HTML，提取出自己想要的数据。归纳为四大步：根据url获取HTML数据解析HTML，获取目标信息存储数据重复第一步这会涉及到数据库、网络服务器、HTTP协议、HTML、数据科学、网络安全、图像处理等非常多的内容。但对于初学者而言，并不需要掌握这么多。二、python要学习到什么程度如果你不懂python，那么需要先学习python这门非常easy的语言（相对其它语言而言）。编程语言基础语法无非是数据类型、数据结构、运算符、逻辑结构、函数、文件IO、错误处理这些，学起来会显枯燥但并不难。刚开始入门爬虫，你甚至不需要去学习python的类、多线程、模块之类的略难内容。找一个面向初学者的教材或者网络教程，花个十几天功夫，就能对python基础有个三四分的认识了，这时候你可以玩玩爬虫喽！当然，前提是你必须在这十几天里认真敲代码，反复咀嚼语法逻辑，比如列表、字典、字符串、if语句、for循环等最核心的东西都得捻熟于心、于手。教材方面比较多选择，我个人是比较推荐python官方文档以及python简明教程，前者比较系统丰富、后者会更简练。三、为什么要懂HTML前面说到过爬虫要爬取的数据藏在网页里面的HTML里面的数据，有点绕哈！维基百科是这样解释HTML的超文本标记语言（英语：HyperTextMarkupLanguage，简称：HTML）是一种用于创建网页的标准标记语言。HTML是一种基础技术，常与CSS、JavaScript一起被众多网站用于设计网页、网页应用程序以及移动应用程序的用户界面[3]。网页浏览器可以读取HTML文件，并将其渲染成可视化网页。HTML描述了一个网站的结构语义随着线索的呈现，使之成为一种标记语言而非编程语言。总结一下，HTML是一种用于创建网页的标记语言，里面嵌入了文本、图像等数据，可以被浏览器读取，并渲染成我们看到的网页样子。所以我们才会从先爬取HTML，再 解析数据，因为数据藏在HTML里。学习HTML并不难，它并不是编程语言，你只需要熟悉它的标记规则，这里大致讲一下。HTML标记包含标签（及其属性）、基于字符的数据类型、字符引用和实体引用等几个关键部分。HTML标签是最常见的，通常成对出现，比如&lt;h1&gt;与&lt;/h1&gt;。这些成对出现的标签中，第一个标签是开始标签，第二个标签是结束标签。两个标签之间为元素的内容（文本、图像等），有些标签没有内容，为空元素，如&lt;img&gt;。以下是一个经典的Hello World程序的例子：&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n  &lt;title&gt;This is a title&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n  &lt;p&gt;Hello world!&lt;/p&gt;\n&lt;/body&gt;\n&lt;/html&gt;HTML文档由嵌套的HTML元素构成。它们用HTML标签表示，包含于尖括号中，如&lt;p&gt;[56]在一般情况下，一个元素由一对标签表示：“开始标签”&lt;p&gt;与“结束标签”&lt;/p&gt;。元素如果含有文本内容，就被放置在这些标签之间。四、了解python网络爬虫的基本原理在编写python爬虫程序时，只需要做以下两件事：发送GET请求，获取HTML解析HTML，获取数据 这两件事，python都有相应的库帮你去做，你只需要知道如何去用它们就可以了。五、用python库爬取百度首页标题和图片首先，发送HTML数据请求可以使用python内置库urllib，该库有一个urlopen函数，可以根据url获取HTML文件，这里尝试获取百度首页“https://www.baidu.com/”的HTML内容# 导入urllib库的urlopen函数\nfrom urllib.request import urlopen \n# 发出请求，获取html\nhtml = urlopen(\"https://www.baidu.com/\")\n# 获取的html内容是字节，将其转化为字符串\nhtml_text = bytes.decode(html.read())\n# 打印html内容\nprint(html_text)看看效果：输出html内容部分截取我们看一下真正百度首页html是什么样的，如果你用的是谷歌浏览器，在百度主页打开设置&gt;更多工具&gt;开发者工具，点击element，就可以看到了：在谷歌浏览器中查看HTML对比一下你就会知道，刚才通过python程序获取到的HTML和网页中的一样！获取了HTML之后，接下就要解析HTML了，因为你想要的文本、图片、视频都藏在HTML里，你需要通过某种手段提取需要的数据。python同样提供了非常多且强大的库来帮助你解析HTML，这里以著名的python库BeautifulSoup为工具来解析上面已经获取的HTML。BeautifulSoup是第三方库，需要安装使用。在命令行用pip安装就可以了：pip install bs4BeautifulSoup会将HTML内容转换成结构化内容，你只要从结构化标签里面提取数据就OK了：比如，我想获取百度首页的标题“百度一下，我就知道”，怎么办呢？这个标题是被两个标签套住的，一个是一级标签&lt;head&gt;&lt;head&gt;,另一个是二级标签&lt;title&gt;&lt;title&gt;，所以只要从标签中取出信息就可以了# 导入urlopen函数\nfrom urllib.request import urlopen\n# 导入BeautifulSoup\nfrom bs4 import BeautifulSoup as bf\n# 请求获取HTML\nhtml = urlopen(\"https://www.baidu.com/\")\n# 用BeautifulSoup解析html\nobj = bf(html.read(),'html.parser')\n# 从标签head、title里提取标题\ntitle = obj.head.title\n# 打印标题\nprint(title)看看结果：这样就搞定了，成功提取出百度首页的标题。如果我想要下载百度首页logo图片呢？第一步先获取该网页所有图片标签和url，这个可以使用BeautifulSoup的findAll方法，它可以提取包含在标签里的信息。一般来说，HTML里所有图片信息会在“img”标签里，所以我们通过findAll(\"img\")就可以获取到所有图片的信息了。# 导入urlopen\nfrom urllib.request import urlopen\n# 导入BeautifulSoup\nfrom bs4 import BeautifulSoup as bf\n# 请求获取HTML\nhtml = urlopen(\"https://www.baidu.com/\")\n# 用BeautifulSoup解析html\nobj = bf(html.read(),'html.parser')\n# 从标签head、title里提取标题\ntitle = obj.head.title\n# 使用find_all函数获取所有图片的信息\npic_info = obj.find_all('img')\n# 分别打印每个图片的信息\nfor i in pic_info:\n  print(i)看看结果：打印出了所有图片的属性，包括class（元素类名）、src（链接地址）、长宽高等。其中有百度首页logo的图片，该图片的class（元素类名）是index-logo-src。[&lt;img class=\"index-logo-src\" height=\"129\" hidefocus=\"true\" src=\"//www.baidu.com/img/bd_logo1.png\" usemap=\"#mp\" width=\"270\"/&gt;, &lt;img alt=\"到百度首页\" class=\"index-logo-src\" src=\"//www.baidu.com/img/baidu_jgylogo3.gif\" title=\"到百度首页\"/&gt;]可以看到图片的链接地址在src这个属性里，我们要获取图片链接地址：# 导入urlopen\nfrom urllib.request import urlopen\n# 导入BeautifulSoup\nfrom bs4 import BeautifulSoup as bf\n# 请求获取HTML\nhtml = urlopen(\"https://www.baidu.com/\")\n# 用BeautifulSoup解析html\nobj = bf(html.read(),'html.parser')\n# 从标签head、title里提取标题\ntitle = obj.head.title\n# 只提取logo图片的信息\nlogo_pic_info = obj.find_all('img',class_=\"index-logo-src\")\n# 提取logo图片的链接\nlogo_url = \"https:\"+logo_pic_info[0]['src']\n# 打印链接\nprint(logo_url)结果：获取地址后，就可以用urllib.urlretrieve函数下载logo图片了# 导入urlopen\nfrom urllib.request import urlopen\n# 导入BeautifulSoup\nfrom bs4 import BeautifulSoup as bf\n# 导入urlretrieve函数，用于下载图片\nfrom urllib.request import urlretrieve\n# 请求获取HTML\nhtml = urlopen(\"https://www.baidu.com/\")\n# 用BeautifulSoup解析html\nobj = bf(html.read(),'html.parser')\n# 从标签head、title里提取标题\ntitle = obj.head.title\n# 只提取logo图片的信息\nlogo_pic_info = obj.find_all('img',class_=\"index-logo-src\")\n# 提取logo图片的链接\nlogo_url = \"https:\"+logo_pic_info[0]['src']\n# 使用urlretrieve下载图片\nurlretrieve(logo_url, 'logo.png')最终图片保存在'logo.png'六、结语本文用爬取百度首页标题和logo图片的案例，讲解了python爬虫的基本原理以及相关python库的使用，这是比较初级的爬虫知识，还有很多优秀的python爬虫库和框架等待后续去学习。当然，掌握本文讲的知识点，你就已经入门python爬虫了。加油吧，少年！\n\n","categories":["转载"],"tags":[]},{"title":"计算机专业必读哪些经典书籍？","url":"http://tanqingbo.cn/2019/10/22/不同领域的圣经级书籍有哪些？/","content":"耗时一天，吐血整理的计算机经典书籍，包括计算机专业必读经典、 C、Java、Python学习的经典教材等， 从入门到进阶，各个阶段都有。文末附带免费获取方式，希望能有帮助~ \n必读经典深入理解计算机系统（原书第3版） 9.7分 2383人评价本书的最大优点是为程序员描述计算机系统的实现细节，帮助其在大脑中构造一个层次型的计算机系统，从最底层的数据在内存中的表示到流水线指令的构成，到虚拟存储器，到编译系统，到动态加载库，到最后的用户态应用。 \n\n现代操作系统（第3版） 8.9分 717人评价本书适合作为高等院校计算机专业操作系统课程教材，也是设计、开发操作系统的重要参考书。 \n\n计算机程序的构造和解释 : 原书第2版 9.5分 2229人评价 美国麻省理工学院(MIT)多年使用的教材。\n \n计算机网络（第4版） : 自顶向下方法 8.8分 734人评价本书采用了独创的自顶向下方法，即从应用层开始沿协议栈向下讲解计算机网络的基本原理，强调应用层范例和应用编程接口，内容深入浅出，注重教学方法，理论与实践相结合。 \n\n数据库系统概念 : 第五版 8.2分 417人评价本书是数据库系统方面的经典教材之一。国际上许多著名大学包括斯坦福大学、耶鲁大学、得克萨斯大学、康奈尔大学、伊利诺伊大学、印度理工学院等都采用本书作为教科书。 \n\n设计模式 : 可复用面向对象软件的基础 9.1分 2805人评价设计模式有多重要，等你工作的时候就明白了。 这本书结合设计实作例从面向对象的设计中精选出23个设计模式，总结了面向对象设计中最有价值的经验，并且用简洁可复用的形式表达出来。 \n\nC/C++1 The Design and Evolution of C++    8.5分\n\n首先肯定要读一读Bjarne Stroustrup的The Design and Evolution of C++，了解一下这个语言的历史。接下来就可以看别的书了，但要不停地回头看这本书，看到你不断地学到的新技术是怎么样一点点地被接纳到这个语言中去的。\n\n2 C++ Primer   9.3分\n\n第一本书因人而异，基础好一些的，可以看Stanley B. Lippman的C++ Primer，这本书非常地巨大，你打星号的部分可以不要看。基础不太好的，可以看Stanley B.Lippman的Essential C++，这本书份量要轻得多，不过四个C++的范型都讲了，而且讲得非常清楚。\n\n3 Thinking in C++    9.1分\n\n第二本书，就应该是Bruce Eckel写的、候捷译的Thinking in C++，这本书技术运用的非常高的境界，但是语言非常平实，只要认真地读，即使基础不行，也一定可以懂。\n\n4 Effective C++和More Effective C++     9.5分\n\n第三本应该静下心来看看Scott Meyers的Effective C++和More Effective C++，好好地整理一下，在程序设计中应该有哪些注意的事项。可以指导项目运作了，可以编写一切你想做的程序了，可以指出别人看起来不错的代码的大小问题了\n\nJavaJava基础\n1 Java编程思想(第4版)    9.1分\n\n本书赢得了全球程序员的广泛赞誉，即使是最晦涩的概念，在Bruce Eckel的文字亲和力和小而直接的编程示例面前也会化解于无形。从Java的基础语法到最高级特性（深入的面向对象概念、多线程、自动项目构建、单元测试和调试等），本书都能逐步指导你轻松掌握.\n\n2 Java核心技术 卷Ⅰ 基础知识(第8版)     8.7分\n\n这本书在Java领域是和Java编程思想齐名的一本书，很多知识点都讲的特别细，我初次看的时候发现课上好多没讲的基础知识这本书上都提到了，非常有助于你练好扎实的基础知识。\n\nJava中级\n1 大话设计模式    8.3分\n\n设计模式体现的是一种思想，思想是指导行为的一切。理解和掌握设计模式，记住23种或者更多的设计场景和解决策略是不够的，更要接受一种思想的熏陶和洗礼。\n本书通过故事讲述程序如何设计。希望能给渴望了解面向对象程序设计的初学者及困惑、无法复用的代码编程体验者一些好的建议和提示。\n\n2 分布式Java应用基础与实践   7.8分\n\n本书介绍分布式Java应用涉及的知识点，分为基于Java实现网络通信、RPC；基于SOA实现大型分布式Java应用；编写高性能Java应用；构建高可用、可伸缩的系统四个部分，共七章内容。\n\n3 Java并发编程实践   8.9分\n\n《JAVA并发编程实践》随着多核处理器的普及，使用并发成为构建高性能应用程序的关键。Java 5以及6在开发并发程序中取得了显著的进步，提高了Java虚拟机的性能以及并发类的可伸缩性，并加入了丰富的新并发构建块。在《JAVA并发编程实践》中，这些便利工具的创造者不仅解释了它们究竟如何工作、如何使用，还阐释了创造它们的原因，及其背后的设计模式。\n\nJava高级\n1大型网站技术架构：核心原理与案例分析    7.9分\n\n该书通过梳理大型网站技术发展历程，剖析大型网站技术架构模式，深入讲述大型互联网架构设计的核心原理。\n\n2 代码整洁之道    9.1分\n\n这本书重在对细节的关注。书的编排极其合理，从最小的点开始一点点往大处讲。感觉对刚开始工作的小朋友们，代码看得、写得还不够多，读设计模式之类的书可能还没什么体会。但这本代码细节的书，却是能立竿见影，直接用到工作中去的。\n\nPython1 Python核心编程(第二版)  7.7分\n\n本书是经典的Python[1] 指导书，在第一版的基础上进行了全面升级。全书分为两个部分：第1部分占据了大约三分之二的篇幅，阐释这门语言的“核心”内容，包括基本的概念和语句、语法和风格、Python对象、数字类型、序列类型、映射和集合类型、条件和循环、文件和输入/输出、错误和异常、函数和函数式编程、模块、面向对象编程、执行环境等内容：第2部分则提供了各种高级主题来展示可以使用Python做些什么，包括正则表达式、网络编程、网络客户端编程、多线程编程、图形用户界面编程、Web编程、数据库编程、扩展Python 和一些其他材料。\n\n2 Python高级编程   7.6分\n\n《Python高级编程》针对具备一定Python基础并希望通过在项目中应用最佳实践和新的开发技术来提升自己的Python开发人员。\n\n3 Python数据结构与算法   8.3分\n\n主要是介绍了如何使用Python实现常用的一些数据结构,例如堆栈、队列、二叉树等等。\n\n4 利用Python进行数据分析   8.5分\n\n从pandas库的数据分析工具开始利用高性能工具对数据进行加载、清理、转换、合并以及重塑；利用matpIotlib创建散点图以及静态或交互式的可视化结果；利用pandas的groupby功能对数据集进行切片、切块和汇总操作；处理各种各样的时间序列数据。\n\n上面整理的所有书籍，都可以在微信公众号：轮子工厂    中回复“1024”领取，一共21本！不要想太多，也别着急，任何大神都是从菜鸟开始的，只要你开始踏踏实实的去学习了，一定会有回报的。别忘了去微信上去领书啊！加油~ \n","categories":["技术博客"],"tags":[]},{"title":"机器学习必读经典书籍与论文","url":"http://tanqingbo.cn/2019/10/22/机器学习必读经典书籍与论文/","content":"\n原文地址： http://blog.sina.com.cn/s/blog_7e5f32ff0102vlgj.html \n\n\n部分经典机器学习书籍已经整理好了，在公众号【轮子工厂】后台回复“机器学习”可以领取，另外还配套有视频教程、课件和项目练习！\n\n入门书单1.《数学之美》作者吴军博士是我特备喜欢的以为人工智能专家，他的大部分我都看过，在本书中以极为通俗的语言讲述了数学在机器学习和自然语言处理等领域的应用。\n2.《集体智慧编程》作者Toby Segaran也是《数据之美：解密优雅数据解决方案背后的故事》的作者。这本书最大的优势就是里面没有理论推导和复杂的数学公式，是很不错的入门书。目前中文版已经脱销，对于有志于这个领域的人来说，英文的pdf是个不错的选择，因为后面有很多经典书的翻译都较差，只能看英文版，不如从这个入手。还有，这本书适合于快速看完，因为据评论，看完一些经典的带有数学推导的书后会发现这本书什么都没讲，只是举了很多例子而已。\n3.《智能web算法》作者Haralambos Marmanis、Dmitry Babenko。这本书中的公式比《集体智慧编程》要略多一点，里面的例子多是互联网上的应用，看名字就知道。不足的地方在于里面的配套代码是BeanShell而不是python或其他。总起来说，这本书还是适合初学者，与上一本一样需要快速读完，如果读完上一本的话，这一本可以不必细看代码，了解算法主要思想就行了。\n4.《统计学习方法》作者李航，是国内机器学习领域的几个大家之一，曾在MSRA任高级研究员，现在华为诺亚方舟实验室。书中写了十个算法，每个算法的介绍都很干脆，直接上公式，是彻头彻尾的“干货书”。每章末尾的参考文献也方便了想深入理解算法的童鞋直接查到经典论文；本书可以与上面两本书互为辅助阅读。\n5.《Machine Learning》（《机器学习》）作者Tom Mitchell是CMU的大师，有机器学习和半监督学习的网络课程视频。这本书是领域内翻译的较好的书籍，讲述的算法也比《统计学习方法》的范围要大很多。据评论这本书主要在于启发，讲述公式为什么成立而不是推导；不足的地方在于出版年限较早，时效性不如PRML。但有些基础的经典还是不会过时的，所以这本书现在几乎是机器学习的必读书目。\n6.《Mining of Massive Datasets》（《大数据》）作者Anand Rajaraman[3]、Jeffrey David Ullman，Anand是Stanford的PhD。这本书介绍了很多算法，也介绍了这些算法在数据规模比较大的时候的变形。但是限于篇幅，每种算法都没有展开讲的感觉，如果想深入了解需要查其他的资料，不过这样的话对算法进行了解也足够了。还有一点不足的地方就是本书原文和翻译都有许多错误，勘误表比较长，读者要用心了。\n7.《数据挖掘：实用机器学习技术》作者Ian H. Witten 、Eibe Frank是weka的作者、新西兰怀卡托大学教授。他们的《ManagingGigabytes》[4]也是信息检索方面的经典书籍。这本书最大的特点是对weka的使用进行了介绍，但是其理论部分太单薄，作为入门书籍还可，但是，经典的入门书籍如《集体智慧编程》、《智能web算法》已经很经典，学习的话不宜读太多的入门书籍，建议只看一些上述两本书没讲到的算法。\n8.《机器学习及其应用》周志华、杨强主编。来源于“机器学习及其应用研讨会”的文集。该研讨会由复旦大学智能信息处理实验室发起，目前已举办了十届，国内的大牛如李航、项亮、王海峰、刘铁岩、余凯等都曾在该会议上做过讲座。这本书讲了很多机器学习前沿的具体的应用，需要有基础的才能看懂。如果想了解机器学习研究趋势的可以浏览一下这本书。关注领域内的学术会议是发现研究趋势的方法嘛。\n\n进阶书单1.《Pattern Classification》（《模式分类》第二版）作者Richard O. Duda[5]、Peter E. Hart、David。模式识别的奠基之作，但对最近呈主导地位的较好的方法SVM、Boosting方法没有介绍，被评“挂一漏万之嫌”。\n2.《Pattern Recognition And Machine Learning》作者Christopher M. Bishop[6]；简称PRML，侧重于概率模型，是贝叶斯方法的扛鼎之作，据评“具有强烈的工程气息，可以配合stanford 大学 Andrew Ng 教授的 Machine Learning 视频教程一起来学，效果翻倍。”\n3.《统计学习基础：数据挖掘、推理与预测》第二版作者RobertTibshirani、Trevor Hastie、Jerome Friedman。“这本书的作者是Boosting方法最活跃的几个研究人员，发明的Gradient Boosting提出了理解Boosting方法的新角度，极大扩展了Boosting方法的应用范围。这本书对当前最为流行的方法有比较全面深入的介绍，对工程人员参考价值也许要更大一点。另一方面，它不仅总结了已经成熟了的一些技术，而且对尚在发展中的一些议题也有简明扼要的论述。让读者充分体会到机器学习是一个仍然非常活跃的研究领域，应该会让学术研究人员也有常读常新的感受。”\n4.《数据挖掘：概念与技术》第三版作者（美）Jiawei Han[8]、（加）Micheline Kamber、（加）Jian Pei，其中第一作者是华裔。本书毫无疑问是数据挖掘方面的的经典之作，不过翻译版总是被喷，没办法，大部分翻译过来的书籍都被喷，想要不吃别人嚼过的东西，就好好学习英文吧。\n5.《AI, Modern Approach 2nd》Peter Norvig，无争议的领域经典。\n6.《Foundations of Statistical Natural Language Processing》自然语言处理领域公认经典。\n7.《Statistical Learning Theory》Vapnik的大作，统计学界的权威，本书将理论上升到了哲学层面，他的另一本书《The Nature ofStatistical Learning Theory》也是统计学习研究不可多得的好书，但是这两本书都比较深入，适合有一定基础的读者。\n\n数学基础书单1.《矩阵分析》Roger Horn。矩阵分析领域无争议的经典\n2.《概率论及其应用》威廉·费勒。极牛的书，可数学味道太重，不适合做机器学习的\n3.《All Of Statistics》机器学习这个方向，统计学也一样非常重要。推荐All of statistics，这是CMU的一本很简洁的教科书，注重概念，简化计算，简化与Machine Learning无关的概念和统计内容，可以说是很好的快速入门材料。\n4.《Nonlinear Programming, 2nd》最优化方法，非线性规划的参考书。\n5.《Convex Optimization》Boyd的经典书籍，被引用次数超过14000次，面向实际应用，并且有配套代码，是一本不可多得的好书。\n6.《Numerical Optimization》第二版，Nocedal著，非常适合非数值专业的学生和工程师参考，算法流程清晰详细，原理清楚。\n7.《Introduction to Mathematical Statistics》第六版，Hogg著，本书介绍了概率统计的基本概念以及各种分布，以及ML，Bayesian方法等内容。\n8.《An Introduction to Probabilistic Graphical Models》Jordan著，本书介绍了条件独立、分解、混合、条件混合等图模型中的基本概念，对隐变量（潜在变量）也做了详细介绍，相信大家在隐马尔科夫链和用Gaussian混合模型来实现EM算法时遇到过这个概念。\n9.《Probabilistic Graphical Models-Principles and Techniques》Koller著，一本很厚很全面的书，理论性很强，可以作为参考书使用。\n大家的补充1. 线性代数 (Linear Algebra)：我想国内的大学生都会学过这门课程，但是，未必每一位老师都能贯彻它的精要。这门学科对于Learning是必备的基础，对它的透彻掌握是必不可少的。Introduction to Linear Algebra (3rd Ed.) by Gilbert Strang.\n的难度适中，讲解清晰，重要的是对许多核心的概念讨论得比较透彻。我个人觉得，学习线性代数，最重要的不是去熟练矩阵运算和解方程的方法——这些在实际工作中MATLAB可以代劳，关键的是要深入理解几个基础而又重要的概念：子空间(Subspace)，正交(Orthogonality)，特征值和特征向量(Eigenvalues and eigenvectors)，和线性变换(Linear transform)。从我的角度看来，一本线代教科书的质量，就在于它能否给这些根本概念以足够的重视，能否把它们的联系讲清楚。Strang的这本书在这方面是做得很好的。\n而且，这本书有个得天独厚的优势。书的作者长期在MIT讲授线性代数课(18.06)，课程的video在MIT的Open courseware网站上有提供。有时间的朋友可以一边看着名师授课的录像，一边对照课本学习或者复习。\nhttp://ocw.mit.edu/OcwWeb/Mathematics/18-06Spring-2005/CourseHome/index.htm8\n2.概率和统计 (Probability and Statistics):概率论和统计的入门教科书很多，我目前也没有特别的推荐。我在这里想介绍的是一本关于多元统计的基础教科书：\nApplied Multivariate Statistical Analysis (5th Ed.) by Richard A. Johnson and Dean W. Wichern\n这本书是我在刚接触向量统计的时候用于学习的，我在香港时做研究的基础就是从此打下了。实验室的一些同学也借用这本书学习向量统计。这本书没有特别追求数学上的深度，而是以通俗易懂的方式讲述主要的基本概念，读起来很舒服，内容也很实用。对于Linear regression, factor analysis, principal component analysis (PCA), and canonical component analysis (CCA)这些Learning中的基本方法也展开了初步的论述。\n之后就可以进一步深入学习贝叶斯统计和Graphical models。一本理想的书是\nIntroduction to Graphical Models (draft version). by M. Jordan and C. Bishop.\n我不知道这本书是不是已经出版了（不要和Learning in Graphical Models混淆，那是个论文集，不适合初学）。这本书从基本的贝叶斯统计模型出发一直深入到复杂的统计网络的估计和推断，深入浅出，statistical learning的许多重要方面都在此书有清楚论述和详细讲解。MIT内部可以access，至于外面，好像也是有电子版的。\n3.分析 (Analysis)：我想大家基本都在大学就学过微积分或者数学分析，深度和广度则随各个学校而异了。这个领域是很多学科的基础，值得推荐的教科书莫过于\nPrinciples of Mathematical Analysis, by Walter Rudin\n有点老，但是绝对经典，深入透彻。缺点就是比较艰深——这是Rudin的书的一贯风格，适合于有一定基础后回头去看。\n在分析这个方向，接下来就是泛函分析(Functional Analysis)。\nIntroductory Functional Analysis with Applications, by Erwin Kreyszig.\n适合作为泛函的基础教材，容易切入而不失全面。我特别喜欢它对于谱论和算子理论的特别关注，这对于做learning的研究是特别重要的。Rudin也有一本关于functional analysis的书，那本书在数学上可能更为深刻，但是不易于上手，所讲内容和learning的切合度不如此书。\n在分析这个方向，还有一个重要的学科是测度理论(Measure theory)，但是我看过的书里面目前还没有感觉有特别值得介绍的。\n4.拓扑 (Topology)：在我读过的基本拓扑书各有特色，但是综合而言，我最推崇：\nTopology (2nd Ed.) by James Munkres\n这本书是Munkres教授长期执教MIT拓扑课的心血所凝。对于一般拓扑学(General topology)有全面介绍，而对于代数拓扑(Algebraic topology)也有适度的探讨。此书不需要特别的数学知识就可以开始学习，由浅入深，从最基本的集合论概念（很多书不屑讲这个）到Nagata-Smirnov Theorem和Tychonoff theorem等较深的定理（很多书避开了这个）都覆盖了。讲述方式思想性很强，对于很多定理，除了给出证明过程和引导你思考其背后的原理脉络，很多令人赞叹的亮点——我常读得忘却饥饿，不愿释手。很多习题很有水平。\n5.流形理论 (Manifold theory)：对于拓扑和分析有一定把握时，方可开始学习流形理论，否则所学只能流于浮浅。我所使用的书是\nIntroduction to Smooth Manifolds. by John M. Lee\n虽然书名有introduction这个单词，但是实际上此书涉入很深，除了讲授了基本的manifold, tangent space, bundle, sub-manifold等，还探讨了诸如纲理论(Category theory)，德拉姆上同调(De Rham cohomology)和积分流形等一些比较高级的专题。对于李群和李代数也有相当多的讨论。行文通俗而又不失严谨，不过对某些记号方式需要熟悉一下。\n虽然李群论是建基于平滑流形的概念之上，不过，也可能从矩阵出发直接学习李群和李代数——这种方法对于急需使用李群论解决问题的朋友可能更加实用。而且，对于一个问题从不同角度看待也利于加深理解。下面一本书就是这个方向的典范：\nLie Groups, Lie Algebras, and Representations: An Elementary Introduction. by Brian C. Hall\n此书从开始即从矩阵切入，从代数而非几何角度引入矩阵李群的概念。并通过定义运算的方式建立exponential mapping，并就此引入李代数。这种方式比起传统的通过“左不变向量场(Left-invariant vector field)“的方式定义李代数更容易为人所接受，也更容易揭示李代数的意义。最后，也有专门的论述把这种新的定义方式和传统方式联系起来。\n机器学习领域经典论文除了以上推荐的书以外，出版在Foundations and Trends in Machine Learning上面的survey文章都值得一看。\n入门：\nPattern Recognition And Machine Learning\nChristopher M. Bishop\nMachine Learning : A Probabilistic Perspective\nKevin P. Murphy\nThe Elements of Statistical Learning : Data Mining, Inference, and Prediction\nTrevor Hastie, Robert Tibshirani, Jerome Friedman\nInformation Theory, Inference and Learning Algorithms\nDavid J. C. MacKay\nAll of Statistics : A Concise Course in Statistical Inference\nLarry Wasserman\n优化：\nConvex Optimization\nStephen Boyd, Lieven Vandenberghe\nNumerical Optimization\nJorge Nocedal, Stephen Wright\nOptimization for Machine Learning\nSuvrit Sra, Sebastian Nowozin, Stephen J. Wright\n核方法：\nKernel Methods for Pattern Analysis\nJohn Shawe-Taylor, Nello Cristianini\nLearning with Kernels : Support Vector Machines, Regularization, Optimization, and Beyond\nBernhard Schlkopf, Alexander J. Smola\n半监督：\nSemi-Supervised Learning\nOlivier Chapelle\n高斯过程：\nGaussian Processes for Machine Learning (Adaptive Computation and Machine Learning)\nCarl Edward Rasmussen, Christopher K. I. Williams\n概率图模型：\nGraphical Models, Exponential Families, and Variational Inference\nMartin J Wainwright, Michael I Jordan\nBoosting:\nBoosting : Foundations and Algorithms\nSchapire, Robert E.; Freund, Yoav\n贝叶斯:\nStatistical Decision Theory and Bayesian Analysis\nJames O. Berger\nThe Bayesian Choice : From Decision-Theoretic Foundations to Computational Implementation\nChristian P. Robert\nBayesian Nonparametrics\nNils Lid Hjort, Chris Holmes, Peter Müller, Stephen G. Walker\nPrinciples of Uncertainty\nJoseph B. Kadane\nDecision Theory : Principles and Approaches\nGiovanni Parmigiani, Lurdes Inoue\n蒙特卡洛：\nMonte Carlo Strategies in Scientific Computing\nJun S. Liu\nMonte Carlo Statistical Methods\nChristian P.Robert, George Casella\n信息几何：\nMethods of Information Geometry\nShun-Ichi Amari, Hiroshi Nagaoka\nAlgebraic Geometry and Statistical Learning Theory\nWatanabe, Sumio\nDifferential Geometry and Statistics\nM.K. Murray, J.W. Rice\n渐进收敛：\nAsymptotic Statistics\nA. W. van der Vaart\nEmpirical Processes in M-estimation\nGeer, Sara A. van de\n不推荐：\nStatistical Learning Theory\nVladimir N. Vapnik\nBayesian Data Analysis, Second Edition\nAndrew Gelman, John B. Carlin, Hal S. Stern, Donald B. Rubin\nProbabilistic Graphical Models : Principles and Techniques\nDaphne Koller, Nir Friedman\n机器学习经典论文/survey合集Active Learning\nTwo Faces of Active Learning50, Dasgupta, 2011\nActive Learning Literature Survey8, Settles, 2010\nApplications\nA Survey of Emerging Approaches to Spam Filtering9, Caruana, 2012\nAmbient Intelligence: A Survey3, Sadri, 2011\nA Survey of Online Failure Prediction Methods2, Salfner, 2010\nAnomaly Detection: A Survey3, Chandola, 2009\nMining Data Streams: A Review4, Gaber, 2005\nWorkflow Mining: A Survey of Issues and Approaches2, Aalst, 2003\nBiology\nSupport Vector Machines in Bioinformatics: a Survey12, Chicco, 2012\nComputational Epigenetics: The New Scientific Paradigm 3, Lim, 2010\nAutomated Protein Structure Classification: A Survey4, Hassanzadeh, 2009\nChemoinformatics - An Introduction for Computer Scientists3, Brown, 2009\nComputational Challenges in Systems Biology2, Heath, 2009\nComputational Epigenetics 3, Bock, 2008\nProgress and Challenges in Protein Structure Prediction3, Zhang, 2008\nA Review of Feature Selection in Bioinformatics4, Saeys, 2007\nMachine Learning in Bioinformatics: A Brief Survey and Recommendations for Practitioners6, Bhaskar, 2006\nBioinformatics - An Introduction for Computer Scientists1, Cohen, 2004\nComputational Systems Biology2, Kitano, 2002\nProtein Structure Prediction and Structural Genomics2, Baker, 2001\nRecent Developments and Future Directions in Computational Genomics1, Tsoka, 2000\nMolecular Biology for Computer Scientists1, Hunter, 1993\nClassification\nSupervised Machine Learning: A Review of Classification Techniques22, Kotsiantis, 2007\nClustering\nXML Data Clustering: An Overview4, Algergawy, 2011\nData Clustering: 50 Years Beyond K-Means6, Jain, 2010\nClustering Stability: An Overview5, Luxburg, 2010\nParallel Clustering Algorithms: A Survey4, Kim, 2009\nA Survey: Clustering Ensembles Techniques2, Ghaemi, 2009\nA Tutorial on Spectral Clustering4, Luxburg, 2007\nSurvey of Clustering Data Mining Techniques4, Berkhin, 2006\nSurvey of Clustering Algorithms4, Xu, 2005\nClustering of Time Series Data - A Survey3, Liao, 2005\nClustering Methods4, Rokach, 2005\nRecent Advances in Clustering: A Brief Survey2, Kotsiantis, 2004\nSubspace Clustering for High Dimensional Data: A Review2, Parsons, 2004\nUnsupervised and Semi-supervised Clustering: a Brief Survey3, Grira, 2004\nClustering in Life Sciences3, Zhao, 2002\nOn Clustering Validation Techniques2, Halkidi, 2001\nData Clustering: A Review3, Jain, 1999\nA Survey of Fuzzy Clustering4, Yang, 1993\nComputer Vision\nPedestrian Detection: An Evaluation of the State of the Art7, Dollar, 2012\nA Comparative Study of Palmprint Recognition Algorithms3, Zhang, 2012\nHuman Activity Analysis: A Review2, Aggarwal, 2011\nSubspace Methods for Face Recognition2, Rao, 2010\nContext Based Object Categorization: A Critical Survey2, Galleguillos, 2010\nObject tracking: A Survey3, Yilmaz, 2006\nDetecting Faces in Images: A Survey2, Yang, 2002\nDatabases\nData Fusion3, Bleiholder, 2008\nDuplicate Record Detection: A Survey2, Elmagarmid, 2007\nOverview of Record Linkage and Current Research Directions2, Winkler, 2006\nA Survey of Schema-based Matching Approaches3, Shvaiko, 2005\nDeep Learning\nRepresentation Learning: A Review and New Perspectives17, Bengio, 2012\nDimension Reduction\nDimensionality Reduction: A Comparative Review6, Maaten, 2009\nDimension Reduction: A Guided Tour4, Burges, 2009\nA Survey of Manifold-Based Learning Methods2, Huo, 2007\nToward Integrating Feature Selection Algorithms for Classification and Clustering3, Liu, 2005\nAn Introduction to Variable and Feature Selection3, Guyon, 2003\nA Survey of Dimension Reduction Techniques2, Fodor, 2002\nEconomics\nAuctions and Bidding: A Guide for Computer Scientists1, Parsons, 2011\nComputational Sustainability1, Gomes, 2009\nComputational Finance1, Tsang, 2004\nGame Theory\nComputer Poker: A Review4, Rubin, 2011\nGraphical Models\nAn Introduction to Variational Methods for Graphical Models5, Jordan, 1999\nKernel Methods\nKernels for Vector-Valued Functions: a Review4, Alvarez, 2012\nLearning Theory\nIntroduction to Statistical Learning Theory7, Bousquet, 2004\nMachine Learning\nA Few Useful Things to Know about Machine Learning7, Domingos, 2012\nA Tutorial on Bayesian Nonparametric Models4, Blei, 2011\nDecision Forests for Classification, Regression, Density Estimation, Manifold Learning and Semi-Supervised Learning2, Criminisi, 2011\nTop 10 Algorithms in Data Mining4, Wu, 2008\nSemi-Supervised Learning Literature Survey, Zhu, 2007\nInterestingness Measures for Data Mining: A Survey, Geng, 2006\nA Survey of Interestingness Measures for Knowledge Discovery1, McGarry, 2005\nA Tutorial on the Cross-Entropy Method, Boer, 2005\nA Survey of Kernels for Structured Data, Gartner, 2003\nSurvey on Frequent Pattern Mining, Goethals, 2003\nThe Boosting Approach to Machine Learning: An Overview1, Schapire, 2003\nA Survey on Wavelet Applications in Data Mining, Li, 2002\nMathematics\nTopology and Data3, Carlsson, 2009\nMulti-armed Bandit\nRegret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems3, Bubeck, 2012\nNatural Computing\nReservoir Computing Approaches to Recurrent Neural Network Training, Jaeger, 2009\nArtificial Immune Systems, Aickelin, 2005\nA Survey of Evolutionary Algorithms for Data Mining and Knowledge Discovery, Freitas?? , 2003\nData Mining in Soft Computing Framework: A Survey, Mitra, 2002\nNeural Networks for Classification: A Survey1, Zhang, 2000\nNatural Language Processing\nProbabilistic Topic Models2, Blei, 2012\nOntology Learning From Text: A Look Back And Into The Future1, Wong, 2012\nMachine Transliteration Survey, Karimi, 2011\nTranslation Techniques in Cross-Language Information Retrieval, Zhou, 2011\nComprehensive Review of Opinion Summarization, Kim, 2011\nA Survey on Sentiment Detection of Reviews, Tang, 2009\nWord Sense Desambiguation: A Survey, Navigli, 2009\nTopic Models, Blei, 2009\nOpinion Mining and Sentiment Analysis, Pang, 2008\nInformation Extraction, Sarawagi, 2008\nStatistical Machine Translation, Lopez, 2008\nA Survey of Named Entity Recognition and Classification, Nadeau, 2007\nAdaptive Information Extraction, Turmo, 2006\nSurvey of Text Clustering, Jing, 2005\nMachine Learning in Automated Text Categorization, Sebastiani, 2002\nWeb Mining Research: A Survey, Kosala, 2000\nNetworks\nCommunity Detection in Graphs1, Fortunato, 2010\nA Survey of Statistical Network Models, Goldenberg, 2010\nCommunities in Networks, Porter, 2009\nGraph Clustering, Schaeffer, 2007\nGraph Mining: Laws, Generators, and Algorithms, Chakrabarti, 2006\nComparing Community Structure Identification, Danon, 2005\nLink Mining: A Survey1, Getoor, 2005\nDetecting Community Structure in Networks, Newman, 2004\nLink Mining: A New Data Mining Challenge, Getoor, 2003\nOn-Line Learning\nOn-Line Algorithms in Machine Learning1, Blum, 1998\nOthers\nA Survey of Very Large-Scale Neighborhood Search Techniques, Ahuja, 2001\nPlanning and Scheduling\nA Review of Machine Learning for Automated Planning1, Jimenez, 2009\nProbabilistic\nApproximate Policy Iteration: A Survey and Some New Methods, Bertsekas, 2011\nAn Introduction to MCMC for Machine Learning1, Andrieu, 2003\nProbabilistic Models\nAn Introduction to Conditional Random Fields1, Sutton, 2010\nRandomized Algorithms\nRandomized Algorithms for Matrices and Data1, Mahoney, 2011\nRecommender Systems\nRecent advances in Personalized Recommender Systems1, Liu, 2009\nMatrix Factorization Techniques for Recommender Systems1, Koren, 2009\nA Survey of Collaborative Filtering Techniques1, Su, 2009\nRegression\nEnsemble Approaches for Regression: a Survey4, Moreira, 2012\nReinforcement Learning\nA Survey of Reinforcement Learning in Relational Domains1, Otterlo, 2005\nReinforcement Learning: A Survey, Kaelbling, 1996\nRule Learning\nAssociation Mining, Ceglar, 2006\nAlgorithms for Association Rule Mining - A General Survey and Comparison, Hipp, 2000\nTesting\nControlled Experiments on the Web: Survey and Practical Guide, Kohavi, 2009\nTime Series\nTime-Series Data Mining2, Esling, 2012\nA Review on Time Series Data Mining1, Fu, 2011\nDiscrete Wavelet Transform-Based Time Series Analysis and Mining, Chaovalit, 2011\nTransfer Learning\nA Survey on Transfer Learning, Pan, 2010\nWeb Mining\nA Taxonomy of Sequential Pattern Mining Algorithms, Mabroukeh, 2010\nA Survey of Web Clustering Engines, Carpineto, 2009\nWeb Page Classification: Features and Algorithms, Qi, 2009\nMining Interesting Knowledge from Weblogs: A Survey, Facca, 2005\nAn Overview of Web Data Clustering Practices, Vakali, 2005\nA Survey of Web Metrics, Dhyani, 2002\nData Mining for Hypertext: A Tutorial Survey3, Chakrabarti, 2000\n","categories":["转载"],"tags":[]},{"title":"牛逼，看完它，你就会全网爬虫了","url":"http://tanqingbo.cn/2019/10/17/python爬虫教程/","content":"在前言：最近后台有人留言问：有没有python爬虫的相关教程，爬虫不是我专业方向，很多不是很熟悉，而网上很多资料讲的过于散乱，不能很好的系统性学习爬虫，而且水平参差不齐。特委托一位熟悉爬虫的小伙伴，帮忙把关，将网上现有资料进行整合，整理了一份相对比较系统的资料。小伙伴感兴趣可以自取~\n此外，我还花钱买了两本python爬虫相关的电子书《Python 3网络爬虫开发实战》和《用Python写网络爬虫》，有需要的话也可以找我领取，微信关注公众号：轮子工厂，回复 ”爬虫” 就可以领走了。\n进入正题：对于入门的小伙伴，首先需要解决四个问题：\n\n熟悉Python编程；\n\n了解HTML;\n\n了解网络爬虫的基本原理；\n\n学习使用Python爬虫库.\n\n\n若不知道自己是否满足入门条件，也没关系，这儿有份资料：《入门爬虫》小伙伴可以据此进行一下自我判断、或简单入门，emm…培养一下爬虫兴趣也是很棒的！！如果觉得太复杂了，这儿有份10分钟Python爬虫菜鸟教程。\n循序渐进教程篇：来源于https://cuiqingcai.com/1052.html一、爬虫入门\nPython爬虫入门一之综述\n\nPython爬虫入门二之爬虫基础了解\n\nPython爬虫入门三之Urllib库的基本使用\n\nPython爬虫入门四之Urllib库的高级用法\n\nPython爬虫入门五之URLError异常处理\n\nPython爬虫入门六之Cookie的使用\n\nPython爬虫入门七之正则表达式\n\n\n二、爬虫实战\nPython爬虫实战一之爬取糗事百科段子\n\nPython爬虫实战二之爬取百度贴吧帖子\n\nPython爬虫实战三之实现山东大学无线网络掉线自动重连\n\nPython爬虫实战四之抓取淘宝MM照片\n\nPython爬虫实战五之模拟登录淘宝并获取所有订单\n\nPython爬虫实战六之抓取爱问知识人问题并保存至数据库\n\nPython爬虫实战七之计算大学本学期绩点\n\nPython爬虫实战八之利用Selenium抓取淘宝匿名旺旺\n\n\n三、爬虫利器\nPython爬虫利器一之Requests库的用法\n\nPython爬虫利器二之Beautiful Soup的用法\n\nPython爬虫利器三之Xpath语法与lxml库的用法\n\nPython爬虫利器四之PhantomJS的用法\n\nPython爬虫利器五之Selenium的用法\n\nPython爬虫利器六之PyQuery的用法\n\n\n四、爬虫进阶\nPython爬虫进阶一之爬虫框架概述\n\nPython爬虫进阶二之PySpider框架安装配置\n\nPython爬虫进阶三之爬虫框架Scrapy安装配置\n\nPython爬虫进阶四之PySpider的用法\n\nPython爬虫进阶五之多线程的用法\n\nPython爬虫进阶六之多进程的用法\n\nPython爬虫进阶七之设置ADSL拨号服务器代理\n\n\n高端段位实战篇：来源：https://zhuanlan.zhihu.com/p/73742321\nPython 岗位分析报告\n\nSelenium介绍\n\n抖音App视频抓包\n\nBilibili 用户\n\nBilibili 视频\n\nBilibili 小视频\n\nBing美图爬虫\n\nB站760万视频信息爬虫\n\n博客园(node.js)\n\n百度百科(node.js)\n\n北邮人水木清华招聘\n\n百度云网盘\n\n琉璃神社爬虫\n\nBoss 直聘\n\n贝壳网找房爬虫\n\n暗网爬虫(Go)\n\n豆瓣读书\n\n豆瓣爬虫集\n\n豆瓣害羞组\n\n豆瓣图书广度爬取\n\nDNS记录和子域名\n\nDHT网络磁力种子爬虫\n\n抖音\n\n爱丝APP图片爬虫\n\n京东\n\n京东搜索+评论\n\n京东商品+评论\n\n机票\n\n煎蛋妹纸\n\n煎蛋妹纸selenium版本\n\n今日头条，网易，腾讯等新闻\n\n计算机书籍控图书\n\nQQ空间\n\nQQ 群\n\n清华大学网络学堂爬虫\n\n去哪儿\n\n前程无忧Python招聘岗位信息爬取分析\n\nsoundcloud\n\nStackoverflow 100万问答爬虫\n\nShadowsocks 账号爬虫\n\nspider163 网易云音乐爬虫\n\n时光网电影数据和海报爬虫\n\ntumblr\n\n下载tumblr喜欢内容\n\nTuShare\n\n天猫双12爬虫\n\nTaobao mm\n\nTmall 女性文胸尺码爬虫\n\n淘宝直播弹幕爬虫(node)\n\n天涯论坛文章\n\n天眼查爬虫\n\n乌云公开漏洞\n\n微信公众号\n\n“代理”方式抓取微信公众号文章\n\n网易新闻\n\n网易精彩评论\n\n微博主题搜索分析\n\n网易云音乐\n\n新.网易热评\n\n唯品会商品\n\nZOL 手机壁纸爬虫\n\n知乎(python)\n\n知乎(php)\n\n知网\n\n知乎妹子\n\n自如实时房源提醒\n\n中国大陆高校列表爬虫\n\n游戏直播行业真的如你想象般暴利？\n\n五一不看人人人人人人，哪儿耍合适？\n\n大碗宽面 VS 律师函警告，情感分析吴亦凡自黑式圈粉！\n\n没经验没学历的外教为啥能拿1.4W+的高薪？\n\n大胆，都是哪些程序员在反对996？！\n\n儿科医生的眼泪，全被数据看见了\n\n用大数据扒一扒蔡徐坤的真假流量粉\n\n北上广深租房图鉴\n\n六万条数据全面解析，城市春节禁放烟花爆竹真的有用吗？\n\n十万条评论告诉你，给《流浪地球》评1星的都是什么心态？\n\n开年表情包局部富有指南，盘它！\n\n看完这篇分析，楼下的Tony和Kevin都改名了！\n\n回复“实习僧”CTO之换种姿势爬取实习僧网站\n\n【20G】Kaggle数据集强势分析“绝地求生”，攻略吃鸡！\n\n50行代码教你打造一个公众号文章采集器\n\n《我是大侦探》到底怎么了？(上：数据爬取篇)\n\n《我是大侦探》到底怎么了？（下：情感分析篇）\n\n帮了个小忙|破解“实习僧”网站字体加密\n\n“小忙”连载篇|实习僧网站数据分析\n\nFacebook模拟登录\n\n微博网页版模拟登录\n\n知乎模拟登录\n\nQQZone模拟登录\n\nCSDN模拟登录–已恢复\n\n淘宝爬虫–重构中\n\nBaidu模拟登录一\n\n果壳爬虫程序\n\nJingDong 模拟登录和自动申请京东试用\n\n163mail–已恢复\n\n拉钩模拟登录–已失效\n\nBilibili模拟登录\n\n\n附录：1. Python网络爬虫知识架构\n","categories":["技术博客"],"tags":[]},{"title":"读书笔记|人生最重要的投资","url":"http://tanqingbo.cn/2019/10/17/读书笔记幸福是目的，成功是手段/","content":"最近在读吴军老师《见识》这本书，已经是第二次读了，读完还是感觉收获满满，我把我整理的一些读书笔记分享给大家，以下是第一章的内容：\n1、这个世界没有欠你什么寒窗苦读只是一种读书态度，这种态度是好的，但是社会竞争是一种非常复杂的长期系统性的竞赛，它只能算是成功因素之一，和经济条件好、智商高、出身好、颜值高一样，都只是其中一个变量而已，然而命运却是多个变量互动的结果。 \n在任何的国家、任何时代、社会都是分层的，稍微好一点的社会上下层之间会有一个通道，让人员可以流动，向上流动的过程也就是我们所说的“逆袭”。不要期望一辈子能从第80层上升到前10层，每一代人能够努力向上挤几层就已经很好了，前华盛顿州长骆家辉，从他爷爷家到州长官邸只有100米距离，但是他们家却走了三代人的时间。\n2、人生最重要的投资对于年轻人来讲，对自己的投资和在职业上的进步，远比在股市上捞点钱或者向父母借钱买一套房子更为重要，也更为靠得住。此外，还有一个和投资自己同样重要的投资就是找一个好的配偶。\n\n巴菲特给女生的这偶建议：\n找比自己更优秀的人；\n趁着年轻的时候把自己嫁出去。\n\n\n\n给男生的建议：\n聪明人会欣赏聪明人，而且只有聪明人才会欣赏聪明人。对于一个聪明的男生来说，他打动一个漂亮且聪明的女生要比打动一个漂亮但不聪明的女生要容易很多。\n母亲的智力水平对孩子的影响要比父亲大，所以如果男生希望自己的孩子比较聪明，最好找聪明的女生。\n一个人，特别是年轻的时候，可塑性很重要，虽说喜欢一个人就要包容她的缺点，但是包容一天可以，一年可以，包容一辈子还是很有难度的。\n\n给女生的建议：\n婚姻和恋爱不同，恋爱是激情，婚姻则是由两个人共同创造的舒适共同体，在那个共同体中，双方都将受益。\n世界上没有老实和不老实男生之分，只有对你好和对你不好的人，维持长久婚姻靠对方老实是没有用的，因为人的基因里都有好色的基因在里面，男生女生有一样。\n那么如何判断一个人是否对自己好呢？看他的婚姻观，看他是否认可夫妻之间的关系重要性要高于其它关系的重要性。此外还要看他有没有对你好的能力，这个能力不是看他有多少钱，而是看他未来的潜力，因为一辈子这么长，多少钱都能花完，但是潜力却可以创造更多的钱。\n能够发现一个男生的美德和未来的潜力很重要。\n\n3、让父母先成熟起来父母应该明白，自己生活的年代比子女早了30年，接受的是30年前的理念，代沟是一定存在的，而且30年前的婚恋观非常简单，他们那点成功的婚姻经验，放到现在其实参考价值并不大。\n父母是孩子最好的老师，孩子的观察能力非常强，父母身上哪怕有一点点坏的习惯，孩子很容易就学会。\n要想孩子将来成为精英，自己首先成为精英的父母。\n","categories":["漂来漂去"],"tags":[]},{"title":"以牙还牙、以硬碰硬、逢敌必亮剑","url":"http://tanqingbo.cn/2019/10/16/以牙还牙，以硬碰硬，逢敌必亮剑/","content":"我最近学会了一个特别有用的知识，对付登门推销、校园霸凌、性骚扰等事件都很有用。\n不开玩笑，认真点，这是重点，考试要考啊！（难得写一篇讲道理的文章）\n开始之前先讲个故事：\n二战的时候，苏联和日本在中国内蒙一个叫 诺门坎的地方打了一场大战，这场战虽然名气不大，但是却影响了整个二战的格局，战争的结果是苏联几乎以2:1的损失，惨胜日本。\n当时的格局是这样的，德国正在欧洲磨刀霍霍，而日本只是在中国霍霍，还没有入侵苏联境内，按理说苏联的主要敌人应该是德国才对，但是斯大林却分散大量的兵力在中国和日本干了一战，斯大林为什么要这么做呢？活雷锋吗？\n当然不是，要讨论这个问题，那就得先来分析一下日本是一个什么样的敌人，在偌门坎战役之前，日本在中国采取的策略一直都是先干点坏事，看看中国人的反应，要是有便宜占，那就得寸进尺，无论是炸死张作霖，还是九一八事件占领东北，还是后来的卢沟桥事件都是这样的，用互联网的话来说就是“小步快跑，快速迭代”，拱一步，看一下，有甜头，再向前。\n所以，在日本打算北上入侵苏联的时候，也打算采用“小步快跑，快速迭代”的互联网战略，先试探一下，看看有没有甜头，斯大林深知日本人的调性，宁愿自己在欧洲战场暂时不利，也要调配重兵给日本人迎头痛击，在这场战争中，日本损失19000人，但是苏联损失了26000多人，可谓是损失惨重，但是赢了，强行把硬边界划出来了。\n这场战争导致的结果就是，日本东京董事局发现北上并没有甜头，于是砍掉了北上的项目，开始南下着重布局东南亚战场。后来斯大林和希特勒在莫斯科拼的快油尽灯枯的时候，斯大林大胆把20个亚洲师全部调回莫斯科，最终打败希特勒，也奠定了二战的胜局。也正是因为诺门坎之战把日本人打痛了，斯大林才敢冒这个险把亚洲师全部调回莫斯科。\n你看，诺门坎之战，苏联看似惨胜，但是放眼整个战局，苏联却是用很小的代价换来了巨大的战略利益。\n在生活中，我们也会经常遇到像日本这样的恶人，怎么对付呢？可以借鉴一下诺门坎之战中苏联的变现，让他们在第一次试探的时候就遇到强大的阻力，强行把硬边界划出来。\n校园霸凌可能就是从抢一块橡皮开始，性骚扰可能是从一次黄腔开始，这个时候其实一个反抗的眼神就能解决问题，但如果你不做，就会付出更大的代价。中国的九一八、卢沟桥事件就是血淋淋的例子。因此，面对恶人，要学会划出硬边界，不能给对方得寸进尺的机会。\n在博弈论中，经过计算机无数次模拟，发现只有一种策略是最优的，叫“以牙还牙”策略，如果对方发起挑衅，最好的策略就是以硬碰硬，逢敌必亮剑。\n","categories":["漂来漂去"],"tags":[]},{"title":"怎么判断一项技术是否靠谱？","url":"http://tanqingbo.cn/2019/10/16/怎么判断一项技术是否靠谱？/","content":"作为吴军老师的粉丝，我又来了分享吴军老师的东西了。\n吴军老师在《前言科技》里面分享了一个别有用的东西，就是如何判断一项技术是否靠谱？这对自己以后就业和职业规划都有帮助。\n那么判断一项技术靠不靠谱的通用准则是什么呢？是能量和信息。\n如果你判断不了技术演化的方向，那就抓住这两根线索。技术演化，总是向越来越高的能量使用效率，和越来越高的信息传输效率的方向走的。\n两年前，工信部的一位退休的老领导和吴军老师聊起当年邮电部变革的故事。\n他说，第一次变革是邮政和电信分家，绝大部分人都去邮政那一边。为啥？因为当时中国的电信规模还非常小，不普及。而邮政呢？家大业大历史久远。\n第二次变革是有线电话业务和移动通信业务分家，也是大家都去有线那边。原因一样，有线电话业务家大业大历史久远。\n但是今天回看这些人的选择，都错了。但问题是，每个人都只能根据自己当前看到的利弊得失来做选择啊？怎么能让身在局中的人有长远眼光呢？\n吴军老师说，有一条线索可以供大家参考，就是考虑信息和能量的关系。邮政这件事，单位能量传递的信息很低，邮递员跑半天，消耗那么高的能量才送一封信。\n有线电话这件事效率也不高，一根根线拉到家里，只传递每秒64比特的信息，效率也不高，即使安装了有线电话，升级服务的可能性也不大。\n移动通信就好很多了，这也是中国为什么农村有线电话发展不起来，而移动电话却很快普及的原因。\n根据这个原理，做人生选择的时候，就应该选择那些信息传递效率更高，能量使用效率更高的行业，就不会犯大错了。你看，如果穿越回当年，邮政部门的那些人要是有了这个方法论，重新选择一次，也许就有了超越当前局限的判断力了。\n","categories":["漂来漂去"],"tags":[]},{"title":"你不会天真的以为“双11”只是一个购物节吧！","url":"http://tanqingbo.cn/2019/10/14/你不会天真的以为“双11”只是一个购物节吧！/","content":"双11快到了，你的钱包准备好了吗？\n明明是单身狗的节日，现在却变成了掏空钱包的节日了，更惨的是钱包都掏空了依然没有对象，想想就难过。\n哈尔滨每年双11的时候都下大雪，我记得我本科的时候，每次下课回到宿舍，第一件事就是和室友抢双11红包，运气好的话，到双11这一天能攒下来200多现金红包。\n然后熬夜到12点去秒杀自己想要的商品，接着朋友圈该上演一出大戏了：抢到想要的商品的同学会假装低调的朋友圈秀一下，没有抢到的同学会在朋友圈骂爹。阿里官方也会不断更新成交额，那蹭蹭上涨的数字，能晃瞎你的眼，要多热闹有多热闹！\n但是，如果你以为双11只是一个购物节，那你就错了。\n双11这一天的成交额一出来，也就指示了未来两个多月的股市走向，如果这一天业绩不好，阿里的股价肯定会大幅波动，不止阿里，一些大的商业品牌，在这一天的成交额也会影响他们未来的股价。\n其次，这一天的销售业绩表现，也反映了大家对未来经济有没有信心，如果大家觉得自己的收入稳定，职场上也没有什么风险，那肯定会多花钱，反之则不敢花钱，所以是不是职场寒冬，从双11这一天的销售业绩也能窥探一二。也正是这个原因，一些经济学专家和基金经理对购物节会特别关注。\n还一件特别有意思的事情不知道大家注意到没有，大分部的科技公司，他们的产品发布会都是定在11月以前，几乎没有哪一家公司会在11月以后再开发布会的。原因嘛，你们猜和双11购物节有没有关系？\n谷歌曾经和索尼、飞利浦合作开发过一款非常酷的电子产品，但是赶不及在购物节之前推出，公司就把它推迟到了第二年，结果第二年遇上了金融危机，公司干脆就砍掉了这个项目，它的负责人也被辞退了。\n你看，双11不仅绑架了顾客，其实它也绑架了公司。\n我知道，不管双11绑架了谁，你还是会准备好银子，守到12点，去抢你想要买的东西。\n我也是一样，真香！\n","categories":["漂来漂去"],"tags":[]},{"title":"支付宝慌了？","url":"http://tanqingbo.cn/2019/10/14/支付宝慌了？/","content":"年初的时候，央行宣布要造自己的数字货币了，项目叫作DCEP（Digital Currency Electronic Payment），也就是数字货币和电子支付工具。 \n一提到电子支付工具，大家首先想到的肯定是支付宝微信以及银联，但这些都是民间的支付工具。\n央行，作为人民币的发行者，他们自己发行的数字货币都具有哪些特征呢？官方是这样解释的：\n1、属性和纸币完全一样用纸币进行支付的时候是不需要账户的，使用DCEP也一样， 只要你我手机上都有DCEP的数字钱包，那连网络都不需要，只要手机有电，两个手机碰一碰，就能把一个人数字钱包里的数字货币，转给另一个人。 \n 比如说你到地下的超市去买东西，没有手机信号，微信、支付宝都用不了。又或者在飞机上，也没有信号，如果你坐的是廉价航空公司的航班，吃饭就需要花钱，你可以用央行的数字货币支付。这在以前你只能用现金支付。\n2、央行的数字货币是法偿性的就是说他跟人民币一样，你不能拒绝接受DCEP， 我们看到现在私营的支付机构或平台，会设置各种支付壁垒，用微信的地方不能用支付宝，用支付宝的地方不能用微信， 京东买东西不能用支付宝，淘宝购物不能用微信， 但对央行数字货币来说，只要你能使用电子支付的地方，就必须接受央行的数字货币。 就像你去超市买东西不能拒绝接受人民币一样，因为它本来就是官方规定的交易媒介。\n3、央行的数字货币安全性是最好的咱们用的纸钞是央行货币，DCEP也是央行发行的， 用支付宝或微信做电子支付的时候，背后结算的时候还是用户存在银行的货币，也就是说归根结底还是用央行发行的货币在结算， 但是微信和支付宝会有破产的一天，央行不会。 也就是说，微信和支付宝在法律地位、安全性上，没有达到和纸钞同样的水平，但DCEP和纸钞是一样的。\n4、央行为什么要做数字货币呢？首先是要保护自己的货币主权和法币地位。\n其次是现在的纸钞、硬币的发行，印制、回笼、贮藏各个环节成本都非常高，还要投入一些成本做防伪技术，流通体系的层级也比较多，携带又不方便，现在谁也不愿意带现金了。 \n说了这么多，你可能会问， DCEP会对支付宝、微信的地位产生影响吗？我觉得不会产生影响，就算有影响也是微乎其微，因为微信和支付宝本来就是用人民币结算的， 央行数字货币推出后， 他们可以将结算方式换成央行的数字货币，使用的场景和渠道不会有任何改变。\n虽说用户多了一个电子支付工具的选择，但是想一下百度钱包和小米钱包的下场，其实我们一直都面临很多的选择，但是为什么选择了微信和支付宝，绝对不是仅仅只因为他们具备支付这一个属性！所以我想大家仍然会保留原来的支付习惯。除非支付宝、微信自己作死，否则它们的地位很难被动摇！\n","categories":["漂来漂去"],"tags":[]},{"title":"知识付费里面装的是什么，没错，是韭菜！","url":"http://tanqingbo.cn/2019/10/09/谈谈我对知识付费的理解/","content":"昨天自己花钱在公众号上给大家送了几本书，很多人也在留言区分享了自己的故事，谢谢大家的支持，没有阅读文章昨天文章的同学，可以去看一下，没准也能领到书，链接在这里：不想干活，就想放假，怎么啦！\n我之前说过，知识付费这东西很重要，降低了学习门槛，还可以很好的过滤一些伸手党，但是为什么里面装的是韭菜呢？\n因为很多人（包括我自己）对于知识这东西都有个误区，不少人花了不少钱订阅了一些付费课程，知道了很多高大上的术语，什么认知升级、黑天鹅、降维打击、KOC、跨界创业、区块链…….都能说得头头是道，然而却什么事都没做成。\n我之前也是这样，一些专业术语张嘴就能说出来，以为自己很牛逼，但是后来发现知道这些东西并不能给我带来帮助，我们都进入了一个误区，以为看了知识就等于拥有了智慧，学了财务自由的课程就以为自己真的能财务自由了！太天真了！！！！\n没有实践作为支撑的知识都TM是在扯淡，理论知识学得再好，一上手写代码，全是bug，有人敢用你吗？空中楼阁搭的再好，终究只是幻影。\n现在针对知识付费的平台有很多，得到、知识星球、极客时间、知乎live……，各种五花八门的付费专栏，价格都不便宜，但又都想买，买了吴军的得到的专栏，又加入了张哥的知识星球，还有一些其它的星球也想加入，生怕自己错过什么关键的信息，就像小孩上补习班一样，怕自己输在职场的起跑线上！\n但是花钱买的这些知识，看完之后思考了吗？总结了吗？实践了吗？没有，我们只是看完了，然后换另一个心里安慰，看，我又学会了一个新的专有名词，厉害吧！\n其实成为韭菜的最大一个原因是我们自己缺少总结的习惯，把专栏中看的知识，分析总结，然后拿到工作和学习中去实践，这样才会慢慢转化成为自己的东西，否则自己钱也花了，然后啥也没学会，赖谁？\n我支持知识付费，虽然我买过没用的专栏，但我也确实从中获得了好处，我之前买了一个理财的知识星球，我按照星主的理财方法，现在理财收益已经超过了一万多。我也听朋友分享，他按照《富爸爸穷爸爸》里的方法，成功将负债变成资产。\n你看，是不是成为韭菜的关键在自己，所以请不要忘记自己知识付费的初衷，千万不要只是简单的看过，以为买了就是会了，自欺欺人要不得！\n","categories":["漂来漂去"],"tags":[]},{"title":"开心就好","url":"http://tanqingbo.cn/2019/10/07/开心就好/","content":"一今天是十一小长假之后的第二天，大家有找回点上班或者学习的感觉吗？\n反正我是没有，我在现在在等双十一，因为十一放7天假，说不定双十一回放14天假，哈哈！\n先简单跟大家汇报一下我都干了啥，因为我正好是9月末考完试，考完之后从哈尔滨飞福州去了，和我爸妈在福州玩了几天，第一次带爸妈出去旅游，虽然花了不少钱，但是很开心！\n网上都说去福州一定要去爬鼓山，和我爸妈去爬了鼓山，个人觉得没啥意思，没有海边好玩，然后给我妈买了几套衣服，本来要给我爸也买，但是他死活不肯要，说我飞福州花了不少钱，死活不肯再花我的钱了，唉！老年人的思想劝不动，遂作罢~\n\n回哈尔滨的时候正好赶上哈尔滨降温，半夜3度左右，穿短袖的我在机场冻的半死，差点冻感冒。第二天在宿舍躺尸了一天，然后终于有时间写文章了，所以最后两天假写了两篇原创文：\n不懂了吧！这才是名校的正确打开方式\n厉害的人遇到问题时的思维模式与普通人之间差别在哪？\n个人觉得这两篇文章的质量都很高，强烈推荐大家阅读！\n二不知道大家记不记得之前每篇文章下面都会有一个广告小卡片，戳一下那个广告小卡片，腾讯会给作者支付几毛到一块钱左右的广告费，但是我觉得那个广告小卡片有点影响阅读体验，而且内容也比较乱，为了改善大家的阅读体验，我把那个广告关闭了，以后再也看不到了，我损失一点收入没有关系，重要的是大家看的舒服。\n以后如果大家觉得文章有帮助的话，可以赞赏我一下，金额不重要，重要的是心意，当然不想赞赏也没有关系，还是感谢你关注我！\n三昨天在整理东西的时候，发现我有好多有用的专业书，而且都是新的没有拆封的，都是之前出版社送给我的，大部分我都用不到，所以就送给大家吧，祝大家开工大吉！\n书单和照片如下：\n书是直接送给大家的，不用转发朋友圈，也不用赞赏，但是由于人数太多，书的数量有限，所以从留言区抽几个朋友送吧！\n你们可以在留言区告诉我想要哪本书为什么是这本书，或者说一下假期好玩的事情，或者生活学习中高兴不高兴的事情都行，走心即可，抽中的同学，书送给你，邮费也由我出，大家赚钱都不容易，能节省点就省点！\n最后，祝大家都牛逼！\n","categories":["漂来漂去"],"tags":[]},{"title":"139元百度云服务器的年中大促","url":"http://tanqingbo.cn/2019/10/06/139元百度云服务器的年中大促/","content":"\nhttp://www.bewindoweb.com/205.html快速介绍【抢购地址】点我【推荐抢购机型及其用途】云服务器BCC/39元/实验娱乐，云服务器BCC/139元/爬虫、接口【活动时间】2018年6月19日 - 2018年7月26日【秒杀时间】每天上午9点【供应数量】每款产品只供应50台【限制条件】之前没有买过百度云服务器详细介绍百度云终于开始发力了，推出了4个主要促销机型：机型&nbsp;CPU&nbsp;内存&nbsp;带宽&nbsp;硬盘&nbsp;其他价格&nbsp;BCC&nbsp;1核1G1Mbps40G&nbsp;&nbsp;-39/半年&nbsp;BCC&nbsp;2核4G2Mbps&nbsp;40G&nbsp;在苏州139/半年&nbsp;BCH/BC01&nbsp;-128M1Mbps2G1000M数据库9.9/一年&nbsp;BCH/BC03&nbsp;-512M2Mbps&nbsp;5G1000M数据库19.9/一年前两个是云服务器，后两个是云虚拟主机，暂时还不知道云虚拟主机用来干什么，估计是搭建网站吧，因为它说提供的环境是Nginx+php。如果手头宽裕的话，完全可以买第二个139元的（我已经买了），比如对比一下价格：服务器商&nbsp;CPU&nbsp;内存&nbsp;硬盘&nbsp;带宽&nbsp;活动价格&nbsp;阿里云&nbsp;1核1G&nbsp;20G2Mbps年中大促第二波454/一年&nbsp;腾讯云&nbsp;1核1G&nbsp;50G1Mbps西南地区特惠375/一年&nbsp;百度云&nbsp;2核4G&nbsp;40G2Mbps年中大促139/半年当然之前我的网站bewindoweb.com买的腾讯云+com域名打折326+28=354/年，按月的价格对比一下：阿里云37.8元/月，腾讯云31.25元/月，百度云23.16元/月，百度云的这台是最便宜的，再加上配置比其他的都高得多，怎么都很划算啊~~~~抢购完可以参与抽奖，不过我抽中的是代金券……按热度来看，最热门的就是前两个，当9点过一会的时候，前两个就会被抢光，而最后一个也会先于9.9的被抢光，9.9的似乎没人抢，毕竟128M内存……由于只有6个月，用完6个月肯定会让你按原价���费，不太推荐用来做网站。但是看看4G的内存，2Mbps带宽也就是256kb/s的网速，又有公网IP，很适合用来做个爬虫爬爬数据，或者做一些简单的供自己使用的接口，完美。注意如果这样做最好申请一个域名，在设计接口的时候用域名，然后当服务器到期更换服务器时，只需要把程序都拷贝过去，重配域名解析就好啦~                \n\n\n","categories":["转载"],"tags":[]},{"title":"360区块链试水：区块猫","url":"http://tanqingbo.cn/2019/10/06/360区块链试水：区块猫/","content":"\nhttp://www.bewindoweb.com/150.html一、什么是360的区块猫2月14日，360推出了领取“区块猫”活动，首批限量5万只，分为0代、1代、2代。2018年2月14日12点到2018年2月21日24点可以领取，每个手机号可领取一只1代猫，分享10位好友就能领一只0代猫了~二、免费快速领取1、进入网址，点击立即预约官方网址：http://huodong.mobilem.360.cn/html/kitty2018.html带我的分享链接的网址：http://huodong.mobilem.360.cn/html/kitty2018.html?sharekey=226906_5a8a6d3e29b23_85a655b6a9a8990fa13c3eb09ae181a2&amp;fid=2269062、填入手机号和验证码，领取完成放心填写，因为域名是360.cn，是360的官方域名三、注意事项本次活动仅记录用户预约及转发活动领养区块猫的信息。待区块猫平台及产品正式上线后，用户才能真正领取所领养的区块猫。                \n\n\n","categories":["转载"],"tags":[]},{"title":"3月1日七牛云存储割韭菜的应对方法","url":"http://tanqingbo.cn/2019/10/06/3月1日七牛云存储割韭菜的应对方法/","content":"\nhttp://www.bewindoweb.com/246.html��言早上起来看邮件，看到一封被七牛云割韭菜的公告：内心冰冰凉，不过大家都要吃饭的嘛总不能一直免费下去。所以来研究一下对于我们这种穷人应该如何应对。一、七牛CDN加速流程主要流程分析1、用户通过浏览器访问我的网站（腾讯云服务器），网站下发HTML给浏览器，HTML里包含了图片URL，域名为cdn.bewindoweb.com，于是浏览器继续去这个域名获取图片。2、这个CDN域名是我在腾讯云域名解析构建的子域名，因此会去解析，我添加了一条CNAME，将cdn.bewindoweb.com指向了cdn.bewindoweb.com.qiniu.com，会继续解析这个七牛融合CDN的域名。3、七牛融合CDN看看有没有缓存（自定义缓存30天），如果有，则直接下发，流程结束。4、如果没有缓存，根据3种回源策略：1）通过七牛云对象存储回源，会去对象存储那里下载图片文件，如果对象存储里也没有，则利用镜像同步服务去指定的位置下载图片文件，我指定的位置是我的服务器，所以会从服务器下载到对象存储，再从对象存储下载到融合CDN，对象存储也会保留一份缓存（自定义30天）。2）通过域名回源，会去解析域名，然后访问对应服务器拿到图片文件，缓存在融合CDN后下发。3）通过IP地址回源，直接访问对应服务器拿到图片文件，缓存在融合CDN后下发。加速原理分析1、CDN服务器的缓存融合CDN是由很多台全国各地的服务器组成的，因此如果CDN服务器里有，直接就下发给用户了，不用从我的网站服务器拿。比如新疆的网友可能就在位于新疆的CDN服务器拿到图片，本地的延迟很低，而不用来我的广东服务器拿图片，延迟很高。如果有多个用户同时拿图片，不但距离远导致网络传输慢，我的1M带宽小水管也会挤爆，每个人以10KB/s的速度下载图片，那场景可以想象……而CDN会提供很大的下行带宽，不需要担心服务器成为瓶颈。2、对象存储的缓存如果设置成对象存储，当CDN缓存失效，可以直接从对象存储里拿图片，而不需要从我的服务器拿。对象存储是七牛云自己的，肯定也是分布式大带宽的，所以很快就能拿到失效的图片。由于我设置的都是1个月缓存时间，所以基本没有用，只有当CDN服务器的缓存失效时间比对象存储更小，CDN才会比对象存储更快失效去拿数据。为什么大部分默认的CDN都设置的4小时而不是1个月呢？因为大部分CDN都是整站缓存，所以当网站有更新之后，如果不设置更新，用户访问到的仍然是旧网站。我这里设置1个月是因为我只缓存图片（用的PHP伪静态缓存HTML没有用），图片名称都是md5随机Hash的值，一旦图片改变，命名也会改变，不用担心更新后没有及时显示。如果要不改变名称更新图片，可以去七牛云后台手动刷新图片在CDN上的缓存。3、通过域名/IP回源如果不用对象存储，直接采用域名/IP，则会直接从服务器拿图片缓存到CDN，可能会出现如果CDN缓存同一时间大量失效，大量请求打到服务器造成服务器短时间无法访问的问题。我设置成1个月，每天更新的频率不高的话，压力也还好（而且网站也没什么人访问QwQ）。二、应对措施分析完了原理，再看看七牛云的公告：对象存储CDN回源流出流量以0.15/GB价格进行收费。对象存储CDN回源流出流量指的就是采用“通过对象存储回源”的方案，���CDN缓存失效时，对象存储下发给CDN的流量。看看官网的服务收费：服务&nbsp;名目&nbsp;收费情况&nbsp;&nbsp;融合CDN&nbsp;HTTP下载流量&nbsp;&nbsp;国内0~10GB免费&nbsp;对象存储（标准存储）&nbsp;存储空间&nbsp;0~10GB免费&nbsp;对象存储（标准存储）&nbsp;写请求&nbsp;0~10万次免费&nbsp;对象存储（标准存储）&nbsp;读请求&nbsp;0~100万次免费&nbsp;对象存储（标准存储）&nbsp;CDN 回源流出流量&nbsp;0.15元/GB没错，就是最后一项收费。那么我们将CDN回源策略改为直接从服务器域名回源就可以了。1、登录七牛云，选择融合CDN→域名管理，选择之前配置的cdn，点击配置2、在回源配置里，点击修改配置3、将回源方式从七牛云存储改为源站域名，填写域名4、它需要测试一下域名是否可用，随便填写一个合法的图片文件通过测试，就能够确定啦（否则确定按钮是不可用的）。三、一些注意事项1、修改完后会有短时间图片访问失败的问题在确认的期间，访问网站图片可能会报404找不到、409有冲突等等，如果直接访问图片URL还会提示{\"error\":\"no such domain\"}，或者DNS解析错误：都是正常的，等待就好了。2、此方法仅限于只用了七牛CDN的用户因为很多像WordPress之类的博客，会提供插件上传图片直接放到七牛云存储。那些同学可能需要下载所有文件，然后修改所有文件中的链接，停用七牛云存储才行。我当时总是觉得把文件直接放到其他的服务器不放心，还是放到我自己的服务器只加个CDN外壳同步就好，我可真是个小机灵鬼~3、不要妄想更换CDN如果实在不行，不要更换CDN，0.15已经是行业低价了（其他的基本都是0.25、0.35），如果网站访问量不高，还是可以考虑支持七牛云存储这波操作的。我今天尝试更换了几次CDN，发现以前和百度合作的免费的加速乐，它的图片加载速度感人，一查对应的CDN服务器，只有两台……而看看七牛云的：七牛云真的很良心。我还试用了360网站卫士，效果也很差（而且还会担心各家都屏蔽360）。360网站卫士免费是为了360搜索引擎等其他的服务能够得到更多的数据，毕竟用360就要做好给360提供数据的心理准备。百度云加速的性能还不知道，审核都要2个工作日，所以今天周六是不行了，以后再看吧。其他野鸡的免费CDN就最好不要尝试了，因为工信部要求CDN注册需要提供手持身份证照片，所以把自己的信息传到野鸡服务器上去还是不太好……我已经做好了下一波七牛云融合CDN割韭菜的准备了……那就是……放弃挣扎！                \n\n\n","categories":["转载"],"tags":[]},{"title":"AWS IoT Hello World：设备点对点通信","url":"http://tanqingbo.cn/2019/10/06/AWS IoT Hello World：设备点对点通信/","content":"\nhttp://www.bewindoweb.com/230.html前言借着AWS免费账户，我们来进行一次虚拟的设备点对点通信实验。IoT的含义是Internet of things，也就是所谓的物联网，现在已经渗透到了各行各业，目前我们主要关心的是各种智能家居的物联网。智能家居国内有很多厂商，包括小米、魅族（黄了）、阿里、腾讯等等企业都在搞，但国内只有阿里提供了云平台解决方案，也就是可以借助阿里云搭建自己的IoT云平台，国外的话AWS的IoT则很出名。IoT云平台的架构大同小异，大概有如下特点：（1）采用“订阅”的方式推拉消息，是现在分布式的主流通信方式，好处是方便一对多、多对多通信。（2）业界通用的通信协议是MQTT，好处是体积小，适合嵌入式设备（3）云平台上有设备的“影子”或者“实例”，保存着这个设备最后一次的属性，这样即使它离线了，其他IoT设备发给它的命令在它上线之后也能获取到，从而“弥补差异”。（4）有“规则引擎”，也就是根据一定的规则，当消息里面出现指定内容时，转发给指定的程序处理。例如当收到“msg”消息，则转发给存储平台，存储日志；当收到人脸识别消息，则转发给机器学习平台，进行人脸识别等等。（5）统一的安全身份认证例如AWS IoT Core的架构：我们先不考虑影子，直接让设备和设备通过IoT云进行通信，来体会过程。一、实验信息1、实验目的熟悉IoT配置的一些过程&nbsp; &nbsp;&nbsp;2、实验所需材料（1）AWS IoT核心服务：AWS IoT Core（2）AWS 桶存储：AWS S3（3）AWS IoT基于JS的SDK：aws-iot-device-sdk-js二、实验步骤1、创建事物一个事物代表着一台设备。（1）进入控制台，注册事物（2）点击创建单个事物（3）给事物起个名字这里我们注册一个温度传感器，命名为TmperatureSensor。类型、组、属性可以暂时不填。（4）添加事物证书AWS IoT支持多种方式，这里选择默认的一键添加。（5）下载并激活生成的四个证书注意要去下载根CA证书，随便选个CA1就可以，这里选择CA1：随后点击完成，因为我们还没有创建策略，所以等一会再去附加策略。（6）创建另一个事物重复前面的步骤，创建另一个事物，我们假设是IoT智能空调BWBAriConditioner。2、配置策略在创建完事物之后，证书还是非活动的，因为还没有配置策略：（1）附加策略（2）定义策略附加最基本的权限策略（注意Version不要修改）：&#123;\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n  &#123;\n    \"Action\": [\n      \"iot:Publish\",\n      \"iot:Subscribe\",\n      \"iot:Connect\",\n      \"iot:Receive\",\n      \"iot:Message\"\n    ],\n    \"Effect\": \"Allow\",\n    \"Resource\": [\n      \"*\"\n    ]\n  &#125;\n]\n&#125;（3）将策略附加给证书（4）证书就变为活动的了3、创建规则我们假设是，当温度传感器感应到温度低于15℃的时候，则通知空调开暖气了，并同时在存储桶S3记录下当前温度异常的日志信息。（1）创建好一个S3存储桶这里命名为com.bewindoweb.test.iotdata（2）配置规则基本信息主要是需要去构建规则转发的SQL：SELECT tprt AS Temprature FROM 'bwbiot/Instance20181211123456/Sensors' WHERE tprt &lt; 15（3）配置规则操作将前面的S3桶配置进来，键值本来应该从消息中提取（比如时间戳），这里直接用固定的键值，角色名称创建一个（如果发现S3没有存储消息，则回来点击更新角色，因为很可能是创建后没有更新角色导致的）4、安装本地sdk环境这里选择的是js版本的aws-iot-device-sdk-js，AWS还有C、C++版本的IoT SDK。注意nodejs版本需要在4以上。可以直接安装：npm install aws-iot-device-sdk-js如果直接安装失败，则去下载源代码，然后执行：npm install5、开始实验（1）在sdk下创建keys文件夹，将证书都复制进去：（2）找到IoT平台的host方式一，通过左侧测试→查看终端节点→转有终端节点找到：方式二，通过事物→交互→HTTPS找到：（3）找到两个事物的arn唯一标识（4）仿照example/device.js，编写设备js脚本实质上是编写一些回调函数。&nbsp;TemperatureSensor.js：启动后订阅bwbiot/Instance20181211123456/Sensors主题，并发送JSON字符串报告当前温度。const deviceModule = require('..').device;\nvar device = deviceModule(&#123;\n  keyPath: 'keys/da81ad3c5a-private.pem.key',\n  caPath: 'keys/AmazonRootCA1.pem',\n  certPath: 'keys/da81ad3c5a-certificate.pem.crt',\n  clientId: 'arn:aws:iot:us-east-2:443548522685:thing/TemperatureSensor',\n  host: 'a3nxkugk0zu3q5-ats.iot.us-east-2.amazonaws.com'\n&#125;);\n\n\n\ndevice.on(‘connect’, function(err) &#123;    console.log(‘TemperatureSensor: connect.’);    device.subscribe(‘bwbiot/Instance20181211123456/Sensors’);    device.publish(‘bwbiot/Instance20181211123456/Sensors’, JSON.stringify(&#123;            tprt:11,            msg: “TemperatureSensor: It’s so cold.”         &#125;));&#125;);device.on(‘message’, function(topic, payload) &#123;    console.log(topic, payload.toString());&#125;);BWBAirConditioner.js：连接后订阅主题并等待，接收到消息后立刻回复消息，表明自己启动了。const deviceModule = require('..').device;var device = deviceModule(&#123;    keyPath: 'keys/94ebe4fdf2-private.pem.key',    caPath: 'keys/AmazonRootCA1.pem',    certPath: 'keys/94ebe4fdf2-certificate.pem.crt',    clientId: 'arn:aws:iot:us-east-2:443548522685:thing/BWBAirConditioner',    host: 'a3nxkugk0zu3q5-ats.iot.us-east-2.amazonaws.com'&#125;);device.on('connect', function(err) &#123;    console.log('BWBAirConditioner: connect');    device.subscribe('bwbiot/Instance20181211123456/Sensors');&#125;);device.on('message', function(topic, payload) &#123;    console.log(topic, payload.toString());    device.publish('bwbiot/Instance20181211123456/Sensors', JSON.stringify(&#123;            state:'on',            message: \"BWBAirConditioner: Get it, The air contitioner is up.\"         &#125;));&#125;);（5）启动程序开两个cmd窗口，用命令node examples\\BWBAirConditioner.js先启动BWBAirConditioner.js，然后启动TemperatureSensor.js：当然信息还有很多，因为我们没有停止回调函数，也没有设置条件去发包。很明显，两个设备连上了IoT云平台，并通过这个主题来进行了通信。（6）查看主面板监控数据开始有了一些数据（其中一些是我之前实验的数据）（7）查看S3存储桶发现有了一个key为20181211225100的文件：下载下来（在线预览似乎要计费……），其数据是：&#123;\"Temperature\":11&#125;也就是通过SQL将tprt字段和值写为了Temperature到S3桶里面去。总结整个实验过程体会到了IoT的核心思路，设备数据相互发送，然后云平台通过规则引擎将数据转发给指定的程序去处理更复杂的事情。六、相关资料1、《AWS IOT接入及测试》2、《AWS IOT Device SDK使用（nodejs ）》3、16进制到文本字符串的转换，在线实时转换4、AWS IoT SQL 参考5、https://github.com/aws/aws-iot-device-sdk-js6、亚马逊云物联网AWS IoT初体验                \n","categories":["转载"],"tags":[]},{"title":"CMAKE的CMakeList相关语法（未完成）","url":"http://tanqingbo.cn/2019/10/06/CMAKE的CMakeList相关语法（未完成）/","content":"\nhttp://www.bewindoweb.com/185.html前言用于编写ITK的CMakeList文件。gcc、make、cmake的关系gcc是GNU Compiler Collection，编译器，当只有一个源程序时候，使用gcc即可；当源文件很多的时候，gcc逐个编译工作量很大且容易出错。于是出现了make，makefile包含了所有调用gcc去编译的命令，然而makefile是平台依赖的，换平台就需要重写，而且makefile语法复杂，语句重复。于是出现了更高级的cmake，cmake根据CMakeList.txt生成makefile，一次编写，到处运行。当然，cmake之后还是要make一下才能生成最终的可执行程序。CMake常用语法PROJECTPROJECT(projectname [CXX] [C] [Java])指定工程名称,并可指定工程支持的语言。支持语言列表可忽略,默认支持所有语言SETSET(VAR [VALUE] [CACHE TYPE DOCSTRING [FORCE]])定义变量(可以定义多个VALUE,如SET(SRC_LIST main.c util.c reactor.c))参考文献1、《cmake使用示例与整理总结》2、《GCC 和 cmake的关系？》                \n\n\n","categories":["转载"],"tags":[]},{"title":"Debian 8下定时自动备份Mysql数据库","url":"http://tanqingbo.cn/2019/10/06/Debian 8下定时自动备份Mysql数据库/","content":"\nhttp://www.bewindoweb.com/125.html一、教程内容Debian下定时自动备份Mysql数据库，把写入的文章等数据备份一份。二、操作方法1、在服务器下建立三个文件夹mkdir /bak\nmkdir /bak/bakmysql\nmkdir /bak/bakmysqlold2、建立shell脚本，更改文件权限touch /bak/bakmysql/backup.sh\nchmod 755 /bak/bakmysql/backup.sh3、编辑/bak/bakmysql/backup.sh，内容如下：（1）保存旧的备份（2）备份今天的（3）如果发现七天前的旧备份存在，则删除它。这样保证了只备份7天的数据库内容。#!/bin/sh \ncd /bak/bakmysql\necho \"You are in bakmysql directory\"\nmv bakmysql* /bak/bakmysqlold\necho \"Old databases are moved to bakmysqlold folder\"\nNow=$(date +\"%Y-%m-%d\") \nFile=bakmysql-$Now.sql \n/opt/mysql/server-5.6/bin/mysqldump -uroot -p'password' db_bbs &gt; $File \necho \"Your database backup successfully completed\"\nSevenDays=$(date -d -7day  +\"%Y-%m-%d\") \nif [ -f /bak/bakmysqlold/bakmysql-$SevenDays.sql ] \nthen\nrm -rf /bak/bakmysqlold/bakmysql-$SevenDays.sql \necho \"You have delete 7days ago bak file \"\nelse\necho \"7days ago bak file not exist \"\nfi橙色部分改成要备份的数据库，注意mysqldump要用绝对路径，否则会备份成空文件，通过which mysqldump查看绝对路径。4、设置crontab定时执行脚本【第一步】编辑crontabvi /etc/crontab【第二步】写入设置：分钟，小时，日，月，星期，命令。我最迟凌晨5点左右才睡，最早6点起床，因此设置为每天凌晨5：30最合适了。30 5 * * * root /bak/bakmysql/backup.sh【第三步】重启crontab/etc/init.d/cron restart\n提示：[ ok ] Restarting cron (via systemctl): cron.service.【可选���骤】 查看是否设置crontab为了开机启动：ls /etc/systemd/system/multi-user.target.wants/\n提示：atd.service  cron.service  nginx.service  php7.0-fpm.service  remote-fs.target    rsyslog.service  ssh.service我的已经设置了。三、出错记录1、发现直接执行.sh脚本可以备份，而crontab自动执行的脚本却是空文件（文件正确地移动和创建，只是内容为空）。解决：mysqldump命令一定要是绝对路径！可以通过which mysqldump来查看绝对路径，2017.12.12日已经更新操作步骤中的相关内容。                \n\n\n","categories":["转载"],"tags":[]},{"title":"Debian 8发送附件邮件到QQ邮箱","url":"http://tanqingbo.cn/2019/10/06/Debian 8发送附件邮件到QQ邮箱/","content":"\nhttp://www.bewindoweb.com/127.html一、教程内容备份了mysql数据库内容后，想让它定时发送到QQ邮箱进行备份，所以用了sendmail，这里仅介绍如何配置，没有发送成功，原因是腾讯云封禁了25端口。操作系统：debian 8.9二、操作步骤1、安装sendmail-binapt-get install sendmail-bin如果不装这个会报错：下列软件包有未满足的依赖关系：\n     sendmail : 依赖: sendmail-bin 但是它将不会被安装\nE: 无法修正错误，因为您要求某些软件包保持现状，就是它们破坏了软件包间的依赖关系。2、安装sendmailapt-get install sendmail期间报错，但是没有管，因为不需要php发送邮件。正在设置 php7.0-fpm (7.0.24-1~dotdeb+8.1) ...\nNOTICE: Not enabling PHP 7.0 FPM by default.\nNOTICE: To enable PHP 7.0 FPM in Apache2 do:\nNOTICE: a2enmod proxy_fcgi setenvif\nNOTICE: a2enconf php7.0-fpm\nNOTICE: You are seeing this message because you have apache2 package installed.\nJob for php7.0-fpm.service failed. See 'systemctl status php7.0-fpm.service' and 'journalctl -xn' for details.\ninvoke-rc.d: initscript php7.0-fpm, action \"restart\" failed.\n在处理时有错误发生： php7.0-fpmE: Sub-process /usr/bin/dpkg returned an error code (1)3、修改主机名vi /etc/hostname输入内容bewindoweb.cn使其快速生效（F要大写）hostname -F /etc/hostname查看是否生效hostname\n提示：bewindoweb.cn4、添加域名解析A记录和MX记录（我的是腾讯云），等待生效。腾讯云添加A和MX记录&nbsp;主机记录记录类型&nbsp;线路类型&nbsp;记录值MX优先级&nbsp;&nbsp;mailA&nbsp;默认&nbsp;我的服务器ip&nbsp;&nbsp;@MX默认&nbsp;&nbsp;mail.bewindowb.cn&nbsp;55、修改/etc/mail/sendmail.mcvi /etc/mail/sendmail.mc默认情况下，sendmail只支持本地，我开始发了一封就发现分给了自己……因此要修改sendmail.mc的这一行（port为stmp），将127.0.0.1改为0.0.0.0：DAEMON_OPTIONS(`Family=inet,&nbsp;&nbsp;Name=MTA-v4,&nbsp;Port=smtp,&nbsp;Addr=0.0.0.0′)dnl在末尾加入：MASQUERADE_AS(bewindoweb.cn)dnl\nFEATURE(masquerade_envelope)dnl\nFEATURE(masquerade_entire_domain)dnl\nMASQUERADE_DOMAIN(bewindoweb.cn)dnl6、执行命令：m4 /etc/mail/sendmail.mc &gt; /etc/mail/sendmail.cf这时可能出现：*** ERROR: FEATURE() should be before MAILER()\n\n* MAILER(local&#39;) must appear after FEATURE(always_add_domain’)* ERROR: FEATURE() should be before MAILER()* MAILER(local&#39;) must appear after FEATURE(allmasquerade’)* ERROR: FEATURE() should be before MAILER()* ERROR: FEATURE() should be before MAILER()* ERROR: FEATURE() should be before MAILER()找到/etc/mail/sendmail.mc中的以下内容，放到文档的最后，再重新执行m4命令，就不会出现问题了。MAILER_DEFINITIONSMAILER(local&#39;)dnl MAILER(smtp')dnl7、把需要发送的邮件的域放进accessvi /etc/mail/access内容加入：163.com        RELAYqq.com         RELAYgmail.com     RELAY生成access.db文件：makemap – v hash /etc/mail/access.db &lt; /etc/mail/access8、重启sendmailservice sendmail restart查看状态：netstat -tlunp | grep 25提示：tcp        0      0 0.0.0.0:25              0.0.0.0:*               LISTEN      6269/sendmail: MTA:或者：service sendmail status提示：● sendmail.service - LSB: powerful, efficient, and scalable Mail Transport Agent   Loaded: loaded (/etc/init.d/sendmail)   Active: active (running) since 四 2017-12-07 21:37:13 CST; 27min ago  Process: 12002 ExecStop=/etc/init.d/sendmail stop (code=exited, status=0/SUCCESS)  Process: 12033 ExecStart=/etc/init.d/sendmail start (code=exited, status=0/SUCCESS)   CGroup: /system.slice/sendmail.service           ├─ 6522 sendmail: MTA: ./vB7CbI1x006520 163mx02.mxmail.netease.com.: user open           ├─12078 sendmail: MTA: accepting connections           └─13839 sendmail: MTA: ./vB7DaUiS011921 mx1.qq.com.: user open9、发送邮件echo \"测试内容\" | mail -s \"测试标题\" -a 附件.txt 12345678@qq.commail 12345678@qq.com -s \"主题\" &lt; 邮件内容.txt三、其他相关内容0、一些解释sendmail.cf：sendmail核心配置文件sendmail.mc：sendmail提供sendmail文件模板，通过编辑此文件后再使用m4工具将结果导入sendmail.cf完成配置sendmail核心配置文件，降低配置复杂度access.db：用来设置sendmail服务器为哪些主机进行转发邮件,位于/etc/mail/access.db&nbsp;aliases.db：用来定义邮箱别名，位于/etc/mail/aliases.dbMUA：邮件用户代理（Mail User Agent）MTA：邮件传输代理（Mail Transfer Agent）MDA：邮件递送代理（Mail Delivery Agent）1、查看邮件队列滞留情况：sendmail -bp或者：mailq2、删除邮件队列：cd /var/spool/mqueuerm -rf *3、查看邮件：mail查看邮件：enter退出：exit4、强制送信对MTA队列强制送信：sendmail -q -v对MSP队列强制送信：sendmail -q -v -Ac四、我为什么没发成功sendmail -bp发信的状态提示是：(Deferred: Connection timed out with mx1.qq.com.)于是查到可能是安全组设置没有开放25端口，于是去腾讯云面板查看发现：注意：为了提升腾讯云IP地址发邮件的质量，将默认限制云主机TCP25端口连接外部地址。您申请自动解封：鼠标移动到导航栏-帐号-25端口解封。看了《云主机 TCP 25 端口出方向被封禁？》这篇官方文档，发现：&lt;bhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” letter-spacing:=”” line-height:=”” 30px;=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” 0px;”=””&gt;如果您发起解封申请，腾讯云将默认您已确认并承诺：保证 TCP 25 端口仅用来连接第三方的 SMTP 服务器&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 30px;=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(247,=”” 247,=”” 247);”=””&gt;，并从第三方的 SMTP 服务器向外发邮件。如发现您使用申请的 IP 直接通过 SMTP 发送邮件，腾讯云有权永久性封禁 TCP 25 端口，并不再提供解封服务，如有其它问题，请提 工单申请。厉害了我的腾讯云，阿里云也是一样���。查到的一篇解决方法：《阿里云服务器不能发邮件，禁用25端口的解决办法》，以后再继续弄，php代码如下：&lt;?phpheader(\"content-type:text/html;charset=utf-8\");include(\"/PHPMailer/class.phpmailer.php\");include(\"/PHPMailer/class.smtp.php\");\n$mail = new PHPMailer(true);$mail-&gt;IsSMTP();$mail-&gt;CharSet=’UTF-8’; //设置邮件的字符编码，这很重要，不然中文乱码$mail-&gt;SMTPAuth = true; //开启认证$mail-&gt;SMTPSecure = ‘ssl’;//设置使用ssl加密方式登录鉴权$mail-&gt;Port = 465;$mail-&gt;Host = “smtp.163.com”;$mail-&gt;Username = “邮箱名”;$mail-&gt;Password = “授权码”;//$mail-&gt;IsSendmail(); //如果没有sendmail组件就注释掉，否则出现“Could not execute: /var/qmail/bin/sendmail ”的错误提示$mail-&gt;AddReplyTo(“邮箱名”,”mckee”);//回复地址$mail-&gt;From = “邮箱名”;$mail-&gt;FromName = “www.phpddt.com&quot;;$to = “收件人”;$mail-&gt;AddAddress($to);$mail-&gt;Subject = “本测试标题”;$mail-&gt;Body = “&lt;h1&gt;phpmail演示&lt;/h1&gt;这是php点点通（&lt;font color=red&gt;www.phpddt.com&lt;/font&gt;）对phpmailer的测试内容&quot;;$mail-&gt;AltBody = “To view the message, please use an HTML compatible email viewer!”; //当邮件不支持html时备用显示，可以省略$mail-&gt;WordWrap = 80; // 设置每行字符串的长度//$mail-&gt;AddAttachment(“f:/test.png”); //可以添加附件$mail-&gt;IsHTML(true);if(!$mail-&gt;Send())&#123;echo “邮件发送有误 &lt;p&gt;”;echo “邮件错误信息: “ . $mail-&gt;ErrorInfo;exit;&#125;else &#123;echo “邮件发送成功!&lt;br /&gt;”;&#125;?&gt;\n其实也就在配置里加了$mail-&gt;SMTPSecure = ‘ssl’;//设置使用ssl加密方式登录鉴权$mail-&gt;Port = 465;                \n","categories":["转载"],"tags":[]},{"title":"Debian8安装Docker和DockerCompose","url":"http://tanqingbo.cn/2019/10/06/Debian8安装Docker和DockerCompose/","content":"\nhttp://www.bewindoweb.com/239.html前言前言有点长，讲述Docker和DockerCompose用来做什么的和一些使用感受，不看可跳过。随着我使用Docker越来越频繁，开始逐渐理解一些Docker的作用了。刚接触Docker总是会听说“Docker是Linux上的虚拟机”，然后就会把Docker和Vmware来类比，虽然有些相似，但你用多了就会发现区别：Docker镜像用起来最大的感受就是，它的读写是不会保存的。Vmware不管你在虚拟机操作了什么，它都会保存，而Docker更多地是一个独立的镜像，可以无限复制到任意安装了Docker的机器上跑，而且对外表现一致——这给服务的部署带来了便利。比如我买的服务器到期了，续费比活动购买新机要贵得多，这时候就需要迁移服务，如果我直接安装到机器上，那迁移服务就很累了，可能会依赖很多组件，你要重新构建环境，这可能包括数据库、Redis集群、Kafka集群……所以我为什么在初期喜欢写脚本，什么一键搭建好LNMP环境之类的脚本。现在这个阶段，只需要你搭建的时候放在Docker里面就好了，迁移只需要复制过来跑，可能需要重新配置下端口，但任何其他的操作都不需要你来做，这就是从脚本搭服务过渡到Docker搭服务的现代部署方式。这时候我会有个巨大的疑问，Docker不保存读写，那它的数据怎么办呢？Docker有一个配置叫做Volume，通过这个参数的配置你可以将容器中的文件对应到宿主机中，比如你的Redis有日志吧，有AOF或者RDB备份文件吧，这些你都可以通过这个参数配置到宿主机中，容器里面发生的任何变化都会写入宿主机对应的地方。所以从这里看来，Docker更像是一个进程，它只帮你跑程序，你的数据都自己保存在本地。到这里应该能解开很多疑惑了，Docker好处就在于它帮你把物理机隔开了，你要迁移只需要像文件一样拷贝走就好了（还包括宿主机上的数据），然后在新机器上运行，完全不需要重新搭建现场，简直无敌好用……而且Docker有无数官方镜像，都把环境搭建好了，想换什么系统就换什么系统，你只需要在上面写你自己的东西，然后生成自己的镜像，分分钟部署。DockerCompose是什么呢？DockerCompose就是多容器部署的神器。假设我们要安装Kafka集群，那就需要部署多个Kafka镜像实例，还需要部署多个Zookeeper镜像实例，ZooKeeper集群还必须在Kafka之前部署好，DockerCompose就是来做这个的。通过编写DockerCompose的配置文件，你可以Volume数据到合适的地方，配置先启动哪个容器，后启动哪个容器，后面的容器依赖前面容器的哪个参数，以及每个容器刚起来的时候执行什么命令，容器之间如何组网���信等等。对比一下制作镜像用的dockerfile，dockerfile是用来制作镜像的，导入哪些包、如何安装、如何创建文件夹等等，它都是在一个系统内操作；而docker-compose.yml配置文件配置的是多个不同镜像（很可能不同的系统）之间的交互。这时候疑问又来了，为什么不都放到一个镜像去呢？首先，我们要搭集群，集群就是不同物理机，都放到一个镜像上去，一台机器挂了集群就当场去世，集群还有什么用呢；第二，分开得越独立，使用越方便，比如ZooKeeper可能除了管理Kafka，还管理微服务，还管理Redis；第三，使用基础软件版本可能有冲突，比如一个必须用Java8，一个必须用Java10，分开更好。Debian 8 安装Docker CE如果只是想体验一下玩一玩，可以参考以前写的文章《Hello Docker》，很容易搭建。这里讲述的是Docker CE的安装方法。Docker从2017年3月1号开始，将Docker分为社区版Docker CE（Docker Community Edition）和企业版Docker EE（Docker Enterprise Edition），这也是目前开源软件的趋势，一个免费的CE快速迭代，一个收费的EE提供额外服务，我们用Docker CE就好。按照官网手册去安装。1、检查是否能够安装Debian 8 Jessie 几乎是Docker CE 可��支持的最低版本（好险= =），因为它需要Linux内核3.10+，如果不够就需要自己去升级内核了。查看Linux内核版本，系统架构必须是X64：$ uname -r\n\n3.16.0-7-amd64查看Debian名称：$ lsb_release -csjessie2、设置apt源官方源，一定要加：$ vi /etc/apt/sources.list\n官方deb http://http.debian.net/debian jessie-backports main\ndotdeb很好用deb http://packages.dotdeb.org jessie alldeb-src http://packages.dotdeb.org jessie all辅助源幸福二选一：# ====== 163 ========deb http://mirrors.163.com/debian/ jessie main non-free contribdeb http://mirrors.163.com/debian/ jessie-updates main non-free contribdeb http://mirrors.163.com/debian/ jessie-backports main non-free contribdeb-src http://mirrors.163.com/debian/ jessie main non-free contribdeb-src http://mirrors.163.com/debian/ jessie-updates main non-free contribdeb-src http://mirrors.163.com/debian/ jessie-backports main non-free contribdeb http://mirrors.163.com/debian-security/ jessie/updates main non-free contribdeb-src http://mirrors.163.com/debian-security/ jessie/updates main non-free contrib\n================== 清华 ================= https://mirrors.tuna.tsinghua.edu.cn/help/debian/ ==deb https://mirrors.tuna.tsinghua.edu.cn/debian/ jessie main contrib non-free\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ jessie main contrib non-freedeb https://mirrors.tuna.tsinghua.edu.cn/debian/ jessie-updates main contrib non-free\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ jessie-updates main contrib non-freedeb https://mirrors.tuna.tsinghua.edu.cn/debian/ jessie-backports main contrib non-free\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ jessie-backports main contrib non-freedeb https://mirrors.tuna.tsinghua.edu.cn/debian-security jessie/updates main contrib non-free\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/debian-security jessie/updates main contrib non-free然后更新：$ sudo apt-get update3、卸载旧版Docker$ sudo apt-get remove docker docker.io  docker-engine containerd runc4、安装基础环境基础依赖包，安装过程中会有readme文件弹出来，不要慌，回车到最后根据提示q退出即可：$ sudo apt-get install \\ apt-transport-https \\\n ca-certificates \\\n curl \\\n gnupg2 \\\n software-properties-common&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;加入Docker官方GPG密钥，提示OK：&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;prettyprint lang-bsh linenums&quot;&gt;$ curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add -&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;检查密钥有效性：&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;prettyprint lang-bsh linenums&quot;&gt;$ sudo apt-key fingerprint 0EBFCD88\n你应该能够找到以下的密钥：pub   4096R/0EBFCD88 2017-02-22      Key fingerprint = 9DC8 5822 9FC7 DD38 854A  E2D8 8D81 803C 0EBF CD88uid                  Docker Release (CE deb) &lt;&#x64;&#111;&#x63;&#107;&#x65;&#114;&#64;&#100;&#x6f;&#99;&#107;&#101;&#x72;&#x2e;&#x63;&#x6f;&#109;&gt;sub   4096R/F273FCD8 2017-02-22选择安装仓库，这里选择稳定版+amd64：$ sudo add-apt-repository    \"deb [arch=amd64] https://download.docker.com/linux/debian    $(lsb_release -cs)    stable\"5、安装Docker更新源：$ sudo apt-get update如果要安装最新版，只需要：$ sudo apt-get install docker-ce如果要选择版本，先列出所有版本，例如列出18.09.0ce-0debian：$ apt-cache madison docker-ce然后安装指定版本，例如填入docker-ce=18.03.0.ce：$ sudo apt-get install docker-ce=&lt;VERSION_STRING&gt;6、运行测试检查安装版本：$ docker --versionDocker version 18.06.1-ce, build e68fc7a跑Hello-world测试一下：$ sudo docker run hello-worldHello from Docker!This message shows that your installation appears to be working correctly.此外还可以通过直接安装deb包去安装Docker，有兴趣可看官网手册。Debian 8 安装DockerComposeDockerCompose安装非常简单。1、安装【第一种方式】直接下载bin包然后设置去github选择合适的版本，这里选1.22.0用如下命令获取可执行文件，替换指定版本号即可。（uname -s就是Linux，uname -m就是系统架构x86_64）$ sudo curl -L https://github.com/docker/compose/releases/download/1.22.0/docker-compose-`uname -s-uname -m` -o /usr/local/bin/docker-compose赋予执行权限就搞定了$ sudo chmod +x /usr/local/bin/docker-compose【第二种方式】当作python应用，用pip下载一行命令搞定：$ sudo pip install -U docker-compose2、检查DockerCompose版本$ docker-compose --versiondocker-compose version 1.22.0, build f46880fe                \n","categories":["转载"],"tags":[]},{"title":"EMQ源码分析（一）：在Windows上用IDEA搭建Erlang编译平台","url":"http://tanqingbo.cn/2019/10/06/EMQ源码分析（一）：在Windows上用IDEA搭建Erlang编译平台/","content":"\nhttp://www.bewindoweb.com/255.html前言虽然目前遇到的所有Broker设计问题都似乎得到了解决，但还是希望能够借鉴更多优秀的代码设计思路。Java开源的Broker代码都有局限性，而免费开源的完整的速度快的MQTT Broker也就只有EMQ了，没有办法只能花时间研究Erlang和EMQ源码了。首先需要搭建Erlang的IDE，之前用IDEA来作为Lua的IDE，没想到IDEA还能作为Erlang的IDE，实在是太好用了。一、用IDEA搭建Erlang集成开发环境搭建流程已经放到了wiki：软件安装手册 →&nbsp;《Erlang + Windows + IDEA IDE环境搭建》，这里重复地描述下重要步骤。1、去Erlang官网下载对应的Erlang程序官网地址：http://www.erlang.org/downloads下载链接：如果知道版本就会很简单，只需要替换对应版本的部分，例如下载21.3：源码：http://erlang.org/download/otp_src_21.3.tar.gzwin32：http://erlang.org/download/otp_win32_21.3.exe&nbsp;win64：http://erlang.org/download/otp_win64_21.3.exe官网打开可能会很慢，但下载还算能够接受，可以去CSDN找一些资源下载会快一些。EMQ 2.3.11 的编译版本是 Erlang OTP 20.0，想要学习MQTT3.1/3.1.1的可以看2.x版本代码&nbsp;EMQ X 3.1-beta.1 Released 的编译版本是Erlang OTP 21.2，想要学习MQTT5.0的可以看3.x的代码我下载的20.0.1。2、安装Erlang1）正常安装EXE2）配置Path环境变量，例如：E:\\erl10.0.1\\bin3）测试是否安装成功：cmd → erl：&nbsp;&nbsp;3、配置IDEA的Erlang插件1）打开IDEA，文件 → 设置 → 插件，搜索Erlang，界面提示本地们找到，是否搜索库：&nbsp;2）搜索仓库，在线安装Erlang插件&nbsp;3）重启IDEA&nbsp;4、配置Rebar3rebar3用来编译Erlang程序。）下载rebar3  \n打开IDEA，文件 → 设置 → 其他设置 → Erlang扩展工具 → 点击Download the latest rebar3：选择合适的文件夹，下载后，会自动填充路径：2）设置rebar3为编译器\n设置 → 构建、执行和部署 → 编译器 → Erlang编译器 → 勾选Compile project with rebar���Add debug info：5、Erlang Hello World1）文件 → 新建项目 → Erlang：2）配置SDK为Erlang安装根目录，会自动识别Erlang：3）建立一个名为hello的Erlang的文件&nbsp;4）将默认生成的代码改为Helloworld默认生成代码：%% API\n\n-export([]).Helloworld：&nbsp;-export([start/0]).\nstart() -&gt;  io:fwrite(“Hello, world!\\n”).5) 配置编译右上角选择编译结构&nbsp;增加一个Erlang Application选择工程、选择要使用哪个模块的哪个函数来启动&nbsp;&nbsp;6）启动程序7、配置文档默认文档是去网上在线查的，这里改成本地查。选择文件 → 项目结构 → SDKs → Erlang 21 → 增加本地的doc文件目录：可以顺便把网上查的删掉。ctrl+Q就可以查系统函数了：&nbsp;&nbsp;8、用rebar.config来编译，用app.src来运行EMQ的所有项目都不是直接运行，而是编写rebar.config的，这样可以用rebar.lock去控制插件版本，就和前端的package.json、package-lock.json类似：xxx.app.src则是入口，例如emqx-2.3.11首先会启动这些代码：1）建立rebar.config&#123;escript_incl_extra,[&#123;\"priv/templates/*\",\".\"&#125;]&#125;.\n&#123;erl_opts,  [    debug_info,    &#123;src_dirs,      [        “src”      ]&#125;  ]&#125;.\n&#123;pre_hooks,[]&#125;.\n&#123;cover_enabled, true&#125;.&#123;sub_dirs,[  “src”]&#125;.2）建立hello.app.src（OTP application resource file）注意这里直接写带“.”的名字会报错，需要先写hello，再重命名为hello.app.src。如果写的是hello.erl，mod则写hello：&#123;application, hello, [  &#123;description, \"\"&#125;,  &#123;vsn, \"1\"&#125;,  &#123;registered, []&#125;,  &#123;applications, [    kernel,    stdlib  ]&#125;,  &#123;mod, &#123;hello, []&#125;&#125;,  &#123;env, []&#125;]&#125;.3）配置erlang rebar编译命令写compile，跳过依赖编译。4）执行rebar编译：如果直接执行，会报错，原因是之前设置的rebar3路径被清空了，重新配置一次，这次不用Download了，直接选择。设置→其他设置→Erlang扩展工具→Path：&nbsp;再编译就能通过了：5）执行编译后的程序找到编译后hello.app、hello.beam的路径：重新配置一个erlang application，将working directory配置成相应路径：执行hello2，会产生和之前一样的结果：二、导入EMQ项目我下载的最后一个EMQ2.3.11版本代码，直接导入是不会高亮的，我们先用IDEA建立一个空的Erlang工程，然后将EMQ代码复制到该工程下，重新打开工程，就会语法高亮了：可以用Ctrl+点击来跳转函数来源代码，和IntelliJ全家桶逻辑一致。注意去标记对应的目录：                \n","categories":["转载"],"tags":[]},{"title":"EMQ源码分析（二）：Erlang相关概念","url":"http://tanqingbo.cn/2019/10/06/EMQ源码分析（二）：Erlang相关概念/","content":"\nhttp://www.bewindoweb.com/256.html前言这里对Erlang概念的掌握只是能基本看懂EMQ写的是什么就可以了，不需要具备二次开发EMQ的能力，达到开发的熟练度还需要花费大量时间。一、Erlang基本了解1）首先要知道Erlang是用C语言写的，所以它的大部分语法都和C语言近似。2）Erlang发明的目的就是分布式、并发的，编程的时候用单机编程思路就好了，分布式是透明的，所以适合用来写分布式并发程序。3）Erlang的核心是进程，这里的进程是Erlang自己的概念，和Linux的系统进程是完全不同的，比C语言的线程切换快得多。4）Erlang的运行时环境是一个虚拟机，类似Java的一次编译随处运行。二、Erlang/OTP1、OTPOTP (Open Telecom Platform，开放电信平台)是一个开源的 Erlang 分发和一个用 Erlang 编写的应用服务器，由爱立信开发。OTP 包含：一个 Erlang 解释器一个 Erlang 编译器服务器之间的通讯协议一个 Corba 对象请求代理名为 Dialyzer 的静态分析工具一个分布式的数据库服务Mnesia大量的开发库其中最重要的就是Mnesia了，这是一个分布式数据库，对编程透明，编程就好像在访问一个集中式数据库一样，底层数据同步由Mnesia完成，在EMQ中被大量使用。OTP帮助解决了容错的问题。2、OTP设计原则OTP设计原则是面向行为（behavihour）编程，行为类似于接口的概念，EMQ完全依照OTP设计原则进行的开发。1）代码的物理组织方式doc：存放程序文档和配置文件include：存放.hrl头文件（类似C语言.h），一般包含大量Record（类似C语言struct）和宏定义（类似C语言宏定义）priv：类似Reference文件夹，存放需要引用的第三方类库src：源代码，包括.app.src入口文件、.erl模块文件test：单元测试代码.erl文件ebin：编译的目标文件夹，存放.app和.beam文件来观察下EMQ2.3.11的代码结构，就是这样组织的：2）标准的Erlang/OTP行为gen_server：用于实现C/S结构中的服务端gen_fsm：用于实现有限状态机gen_event：用于实现事件处理功能supervisor：用于实现监督树中的监督进程gen_statem：新版本中的有限状态机3）代码的逻辑组织方式本质是如何组织进程，OTP的进程组织方式是监控树（Supervision Tree），分为Supervisor和Worker两类：1）Worker：实际执行业务逻辑的进程。一般使用gen_event，gen_fsm或gen_server等行为来实现。2）Supervisor：监督子进程执行的监督进程，简称督程，如果Worker出错，则以一定方式进行重启。监督的子进程可以是Worker，也可以是另一个Supervisor，使用supervisor行为来实现的话会有一套接口方法标准集，包括跟踪、错误报告之类的功能。重启的策略有四种：【one_for_one】如果一个子进程停止，则只重启该进程【one_for_all】如果一个子进程停止，则其他所有子进程都停止并全部重启【rest_for_one】如果一个子进程停止，则启动顺序在它之后的所有其他子进程都停止并重启【simple_one_for_one】简化版one_for_one，所有子进程都是同样的类型且都是动态添加的实例。EMQ2.3.11采用的【one_for_one】—— src/emqttd_mod_sup.erl：%%--------------------------------------------------------------------\n%% Supervisor callbacks\n%%--------------------------------------------------------------------\n\n\n\ninit([]) -&gt;    &#123;ok, &#123;&#123;one_for_one, 10, 100&#125;, []&#125;&#125;.三、Erlang/OTP的数据库Erlang的数据库有两种：【ETS】内存K-V数据库，存储Erlang Term【DETS】基于磁盘的ETSOTP数据库：【Mnesia】基于ETS和DETS的分布式数据库EMQ中ETS、Mnesia两种数据库被大量运用。                \n","categories":["转载"],"tags":[]},{"title":"EMQ源码分析（五）：Mnesia数据库","url":"http://tanqingbo.cn/2019/10/06/EMQ源码分析（五）：Mnesia数据库/","content":"\nhttp://www.bewindoweb.com/260.html\n前言基于EMQ2.3.11。Mnesia是分布式电信数据库管理系统，有以下特性：DBMS查询语言数据持久性：表是持久化到存储的集群复制：表可以在多个节点上复制原子事务：支持事务透明：对编程来说是透明的实时数据搜索：查询速度很快一、Mnesia表的创建参数1、type 表类型【取值】set：唯一键值，1:1，一个键一条记录ordered_set：唯一键值，1:1，带排序bag：1:n，一个键可以映射很多条记录2、record_name 记录名称【取值】记录名所有表中的记录都必须是同一个记录的实例3、ram_copies 内存复制【取值】节点列表可以指定要备份到哪些节点的内存中去，不保证事务更新。可以定时刷盘。4、disc_copies 磁盘复制【取值】节点列表&nbsp;&nbsp;指定要备份到哪些节点的内存和磁盘中去，内存操作表格，磁盘追加操作日志。5、disc_only_copies 强制磁盘复制【取值】节点列表&nbsp;&nbsp;指定备份到哪些节点的磁盘中去，操作都是基于磁盘操作，速度慢。6、index 索引【取值】属性名或整数列表指定额外维护的索引表的元组位置7、local_content 本地内容【取值】true/false，默认false表名对其他节点是已知的，但数据只在自己节点上。8、majority&nbsp;【取值】true/false，默认falsetrue：大多数表的副本都必须同步成功更新（保证数据一致性）false：不需要立刻同步，副本数据可能某段时间不一致9、snmp【取值】SNMP键类型将基于集合的表自动变为简单网络管理协议（SNMP）有序表。10、attributes【取值】Record的属性列表指定要插入哪些属性到表中。EMQ的表都是内存复制，而且是用的自行开发的ekka_mnesia库。EMQ路由表是bag类型，因为一个Topic可能有多个Node都会订阅，是一个类似Map的表：-record(mqtt_route,\n      &#123; topic :: binary(),\n        node  :: node()\n      &#125;).\n\n  ok = ekka_mnesia:create_table(mqtt_route, [\n          &#123;type, bag&#125;,\n          &#123;ram_copies, [node()]&#125;,\n          &#123;record_name, mqtt_route&#125;,\n          &#123;attributes, record_info(fields, mqtt_route)&#125;]);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;EMQ的session是set类型，因为必须要保证clientId唯一性：&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;prettyprint lang-c linenums&quot;&gt;-record(mqtt_session,\n  &#123; client_id  :: binary(),\n    sess_pid   :: pid(),\n    clean_sess :: boolean()\n  &#125;).\n  %% Global Session Table  ok = ekka_mnesia:create_table(mqtt_session, [\n          &#123;type, set&#125;,\n          &#123;ram_copies, [node()]&#125;,\n          &#123;record_name, mqtt_session&#125;,\n          &#123;attributes, record_info(fields, mqtt_session)&#125;]);&lt;/code&gt;&lt;/pre&gt;&lt;h1&gt;二、Mnesia表操作&lt;/h1&gt;&lt;p&gt;这里只简单的记录EMQ用到过的表格操作是什么含义。&lt;/p&gt;&lt;h2&gt;1、select 按条件读取表格&lt;/h2&gt;&lt;p&gt;【原型】&lt;/p&gt;&lt;p&gt;select(Tab, MatchSpec [, Lock]) -&amp;gt; transaction abort | [Object]&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Tab：表名&lt;br&gt;&lt;/li&gt;&lt;li&gt;MatchSpec：匹配参数&lt;br&gt;&lt;/li&gt;&lt;li&gt;Lock：是否加锁读取&lt;br&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;【示例】&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;prettyprint lang-java linenums&quot;&gt;mnesia:select(mqtt_session, [&#123;#mqtt_session&#123;client_id = &#39;$1&#39;, sess_pid = &#39;$2&#39;, _ = &#39;_&#39;&#125;,[&#123;&#39;==&#39;, &#123;node, &#39;$2&#39;&#125;, Node&#125;], [&#39;$1&#39;]&#125;])&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;2、write 写记录&lt;/h2&gt;&lt;p&gt;【原型】&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;prettyprint lang-c linenums&quot;&gt;write(Record) -&amp;gt; transaction abort | ok\nwrite(Tab, Record, LockKind) -&gt; transaction abort | okTab：表名Record：记录值LockKind：write写入锁，sticky_write粘滞写入锁默认的write/1是本表+记录值+写入锁。sticky_write粘滞写入锁是一种用于优化锁获取的机制。如果您使用复制表的目的主要是为了容错（而不是为了快速读取访问），则粘滞锁可能是最佳选择。当获取粘滞写入锁时，将通知所有节点哪个节点被锁定。然后，来自同一节点的粘滞锁定请求将作为本地操作执行，而不与其他节点进行任何通信。即使在事务结束后，粘滞锁仍会留在节点上。&nbsp;&nbsp;【示例】mnesia:write(Route).3、delete 删除记录【原型】delete(&#123;Tab, Key&#125;) -&gt; transaction abort | okdelete(Tab, Key, LockKind) -&gt; transaction abort | ok和前面一致，默认用write写入锁，删除一行数据。【示例】mnesia:delete(&#123;mqtt_trie_node, Topic&#125;)4、delete_object 删除对象【原型】delete_object(Record) -&gt; transaction abort | okdelete_object(Tab, Record, LockKind) -&gt; transaction abort | ok如果表是bag类型，一对多，可以用这个来删除所有数据，默认写入锁。【示例】mnesia:delete_object(mqtt_route, R, write)5、wread【原型】wread(&#123;Tab, Key&#125;) -&gt; transaction abort | RecordListread(Tab, Key, LockKind) -&gt; transaction abort | RecordListwread调用的read，使用写入锁（不可写）。read的锁可以是：read、write、sticky_write。【示例】mnesia:wread(&#123;mqtt_route, Topic&#125;)6、ets【原型】ets(Fun, [, Args]) -&gt; ResultOfFun | exit(Reason)调用一个非事务的函数，会去内存取本地ets表，速度很快，相当于取缓存。【示例】EMQ只有一处用到了，在订阅树匹配的时候，因为只是读操作，但是操作次数太多，可以容忍脏读，所以用这个直接读内存：Matched = mnesia:ets(fun emqttd_trie:match/1, [Topic])7、transaction 事务【原型】transaction(Fun [[, Args], Retries]) -&gt; &#123;aborted, Reason&#125; | &#123;atomic, ResultOfFun&#125;以事务的方式执行Fun函数。【示例】mnesia:transaction(Clean)8、abort 中止事务【原型】abort(Reason) -&gt; transaction abort主动表明事务执行失败，数据库恢复到事务之前的状态。【示例】在进行delete_path的时候，递归到最后发现找不到指定节点，需要主动表明自己执行失败（因为是业务逻辑错误），所以使用了abort：mnesia:abort(&#123;node_not_found, NodeId&#125;)9、dirty_read 脏读【原型】dirty_read(Tab,Key)-&gt;ValueList | exit(&#123;aborted,Reason&#125;)读取当前的数据，不需要事务。【示例】mnesia:dirty_read(mqtt_session, ClientId)10、dirty_delete_object 脏删【原型】dirty_delete_object(Tab, Record)删除当前数据，不需要事务。【示例】remove_session(Session) -&gt;  mnesia:dirty_delete_object(Session).11、async_dirty 异步执行【原型】async_dirty(Fun, [, Args]) -&gt; ResultOfFun | exit(Reason)不要事务地执行Fun函数。【示例】只在路由表相关操作中使用到，因为增加路由表无需加锁：add_direct_route(Route) -&gt;  mnesia:async_dirty(fun mnesia:write/1, [Route]).12、dirty_all_keys&nbsp;【原型】dirty_all_keys(Tab) -&gt; KeyList | exit(&#123;aborted, Reason&#125;)注意这里的dirty不是动词，而是只all_keys的脏操作版本，获取表的所有键值。【示例】只在一处用到，路由表：topics() -&gt;  mnesia:dirty_all_keys(mqtt_route).参考资料1、《Erlang官方英文Mnesia手册》2、《腾讯云开发者文档：mnesia》（相当于手册的中文翻译，基本是机器翻译，很多错误）                \n\n\n","categories":["转载"],"tags":[]},{"title":"EMQ源码分析（六）：EMQ的工程结构","url":"http://tanqingbo.cn/2019/10/06/EMQ源码分析（六）：EMQ的工程结构/","content":"\nhttp://www.bewindoweb.com/259.html前言基于EMQ2.3.11。一、整体目录结构doc：文档。包括mqtt3.1.1协议、README等文档。etc：静态资源。包括acl.conf、emq.conf、安全证书和密钥。include：头文件。包括一堆hrl文件，定义了Record和宏定义。priv：应用相关文件。EMQ存放的是参数配置转换工具。src：主文件。包含了全部的.erl模块。test：测试文件。主要用于单元测试。Makefile：编译文件。EMQ2.3.11没有使用rebar.config，而是用Linux的Makefile来编译；EMQ3.x全部开始使用rebar.config了。二、etc1、certs密钥文件。2、acl.conf权限控制ACL配置文件，可以限制ip、限制user、限制主题等等，例如：&#123;allow, &#123;user, \"dashboard\"&#125;, subscribe, [\"$SYS/#\"]&#125;.\n&#123;allow, &#123;ipaddr, \"127.0.0.1\"&#125;, pubsub, [\"$SYS/#\", \"#\"]&#125;.\n&#123;deny, all, subscribe, [\"$SYS/#\", &#123;eq, \"#\"&#125;]&#125;.3、emq.confEMQ配置文件，包括集群发现、MQTT服务器参数等等，例如：listener.ssl.external = 88834、ssl_dist.confSSL安全通信配置文件。三、include1、emqttd.hrl核心头文件，定义了大量数据结构，包括系统主题、队列主题、共享订阅主题前缀PubSub / Topic / Subscription                \n\n\n","categories":["转载"],"tags":[]},{"title":"EMQ源码分析（四）：调试模块和fwrite","url":"http://tanqingbo.cn/2019/10/06/EMQ源码分析（四）：调试模块和fwrite/","content":"\nhttp://www.bewindoweb.com/258.html前言有时候看不懂代码，可以直接去debug一些模块，写一些单元测试。虽然Erlang提供了专门的单元测试方法，但由于没有整体配置（暂时不想二次开发），有一些模块无法启动，所以干脆只把需要的代码拷贝出来做debug观察数据，从而理解原理。整个分析基于EMQ2.3.11。一、调试方法1、准备好一个空Erlang工程参考《EMQ源码分析（一）：在Windows上用IDEA搭建Erlang编译平台》，构建一个Helloworld就好。2、拷贝代码将需要测试的部分代码从EMQ里面拷贝出来，例如我想要了解订阅树如何构建的，就需要了解Topic如何被切分成三元组的，三元组具体的数据又是怎样的，把emqttd_trie、emqttd_topic相关代码拷贝出来：-module(hello).\n\n-author(“BEWINDOWEB”).-import(lists, [reverse/1]).\n%% API-type(word()   :: ‘’ | ‘+’ | ‘#’ | binary()).-type(words()  :: list(word())).-type(triple() :: &#123;root | binary(), word(), binary()&#125;).-type(topic() :: binary()).\n-export([start/0]).\n-spec(triples(topic()) -&gt; list(triple())).triples(Topic) when is_binary(Topic) -&gt;  triples(words(Topic), root, []).\ntriples([], _Parent, Acc) -&gt;  reverse(Acc);\ntriples([W|Words], Parent, Acc) -&gt;  Node = join(Parent, W),  triples(Words, Node, [&#123;Parent, W, Node&#125;|Acc]).\n%% @doc Split Topic Path to Words-spec(words(topic()) -&gt; words()).words(Topic) when is_binary(Topic) -&gt;  [word(W) || W &lt;- binary:split(Topic, &lt;&lt;”/“&gt;&gt;, [global])].\nword(&lt;&lt;&gt;&gt;)    -&gt; ‘’;word(&lt;&lt;”+”&gt;&gt;) -&gt; ‘+’;word(&lt;&lt;”#”&gt;&gt;) -&gt; ‘#’;word(Bin)     -&gt; Bin.\njoin(root, W) -&gt;  bin(W);join(Parent, W) -&gt;  &lt;&lt;(bin(Parent))/binary, $/, (bin(W))/binary&gt;&gt;.bin(‘’)  -&gt; &lt;&lt;&gt;&gt;;bin(‘+’) -&gt; &lt;&lt;”+”&gt;&gt;;bin(‘#’) -&gt; &lt;&lt;”#”&gt;&gt;;bin(B) when is_binary(B) -&gt; B.\nstart() -&gt;  io:fwrite(“Hello, world!\\n”),  Triples = triples(&lt;&lt;”a/b/c”&gt;&gt;),  Triples2 = triples(&lt;&lt;”a/+/c”&gt;&gt;).3、断点调试打上断点调试，就能得到自己想看的数据，从而理解原理：二、控制台格式化输出有时候debug的数据不正确（比如位串会以有符号8位来显示），这时需要fwrite，和printf类似。fwrite可以类似printf去简单控制输出格式，标准格式如下：F.P.PadModC1、不带参数示例io:fwrite(\"123\").2、格式化参数示例% io:fwrite(\"F.P.C\",data).io:fwrite(\"|10.5s|n|\",[&lt;&lt;\"aaa\"&gt;&gt;]).% |     aaa  |% |���似%；F：输出长度，10代表总共10位；P：输出精度，5代表a有5位；C：输出格式，s代表字符串输出，n代表换行符；&lt;&lt;”aaa”&gt;&gt;是&lt;&lt;$a,$a,$a&gt;&gt;的语法糖；其余字符按正常字符输出。所以最后的第一行包含了”|”+5个空格+3个a+2个空格+”|”，第二行只有”|”。3、格式化参数的含义符号C&nbsp;含义&nbsp;F&nbsp;P参数&nbsp;c&nbsp;ascii码&nbsp;最大长度重复次数&nbsp;f&nbsp;浮点数&nbsp;最大长度精度&nbsp;e&nbsp;科学计数法&nbsp;最大长度精度&nbsp;n&nbsp;换行符&nbsp;最大次数重复次数&nbsp;s&nbsp;字符串&nbsp;最大长度截取长度&nbsp;w&nbsp;任意元&nbsp;最大长度字串长度&nbsp;W&nbsp;w、限制打印深度&nbsp;最大长度字串长度深度&nbsp;p&nbsp;任意元、适当换行和缩进、列表输出为字串&nbsp;单行/多行缩进长度&nbsp;P&nbsp;p、限制打印深度&nbsp;单行/多行缩进长度深度&nbsp;b&nbsp;进制整数（小写字母）&nbsp;最大长度进制&nbsp;B&nbsp;进制整数（大写字母）&nbsp;最大长度进制&nbsp;x&nbsp;带任意前缀进制整数（小写字母）&nbsp;最大长度进制前缀&nbsp;X&nbsp;带任意前缀进制整数（大写字母）&nbsp;最大长度进制前缀&nbsp;+&nbsp;带进制前缀整数（小写字母）&nbsp;最大长度进制&nbsp;#&nbsp;带进制前缀整数（大写字母）&nbsp;最大长度进制4、格式化参数上下界的意义符号C&nbsp;小于最大长度F超过最大长度F小于精度P超过精度P&nbsp;c&nbsp;左侧补空格报错右侧补空格截断&nbsp;f&nbsp;左侧补空格输出*小数点后补0小数点后截断&nbsp;e&nbsp;左侧补空格输出*小数点后补0小数点后截断&nbsp;n&nbsp;（最大次数）（最大次数）&nbsp;&nbsp;（重复次数）&nbsp;&nbsp;（重复次数）&nbsp;&nbsp;&nbsp;s&nbsp;左侧补空格报错右侧补空格从头部开始截断&nbsp;w&nbsp;左侧补空格输出*-输出*&nbsp;W&nbsp;左侧补空格输出*-输出*&nbsp;p&nbsp;（0单行/1多行）（0单行/1多行）&nbsp;&nbsp;（缩进长度）（缩进长度）&nbsp;&nbsp;&nbsp;P&nbsp;（0单行/1多行）&nbsp;&nbsp;（0单行/1多行）&nbsp;&nbsp;&nbsp;（缩进长度）（缩进长度）&nbsp;&nbsp;b&nbsp;左侧补空格输出*（进制）（进制）&nbsp;B&nbsp;左侧补空格输出*（进制）（进制）&nbsp;x&nbsp;左侧补空格输出*&nbsp;&nbsp;（进制）（进制）&nbsp;X&nbsp;左侧补空格输出*&nbsp;&nbsp;（进制）（进制）&nbsp;+&nbsp;左侧补空格输出*&nbsp;&nbsp;（进制）（进制）&nbsp;#&nbsp;左侧补空格输出*&nbsp;&nbsp;（进制）（进制）5、格式化参数实例start() -&gt;  io:fwrite(\"[c]10.3cn”,[$a]),  % [c]       aaa  io:fwrite(“[f]10.1fn”,[1.23]),  % [f]       1.2  io:fwrite(“[e]10.2en”,[1.23]),  % [e]    1.2e+0  io:fwrite(“[n]2.9n”),  % [n]  %  io:fwrite(“[s]10.3sn”,[“aaabbbbbbb”]),  % [s]       aaa  io:fwrite(“[w]60.90wn”,[&#123;“1231231231”,”aaaaaa”&#125;]),  % [w]       &#123;[49,50,51,49,50,51,49,50,51,49],[97,97,97,97,97,97]&#125;  io:fwrite(“[W]60.30Wn”,[&#123;“1231231231”,”aaaaaa”&#125;,5]),  % [W]                                &#123;[49,50,51|…],[97,97|…]&#125;  io:fwrite(“[p]3.0pn”,[&#123;“123123”,”123123”,”aaaa”&#125;]),  % [p]&#123;“123123”,  % “123123”,  % “aaaa”&#125;  io:fwrite(“[P]1.20Pn”,[&#123;“123123”,”123123”,”aaaa”&#125;,10]),  % [P]&#123;“123123”,  %                     “123123”,  %                     “aaaa”&#125;  io:fwrite(“[b]10.16bn”, [109]),  % [b]        6d  io:fwrite(“[B]10.16Bn”, [109]),  % [B]        6D  io:fwrite(“[x]10.16xn”, [109,”prefix”]),  % [x]  prefix6d  io:fwrite(“[X]10.16Xn”, [109,”prefix”]),  % [X]  prefix6D  io:fwrite(“[+]10.16+n”, [109]),  % [+]     16#6d  io:fwrite(“[#]10.16#n”, [109]).  % [#]     16#6D6、Pad、ModPad可以指定填充符号，默认空格：io:fwrite(\"[c]10.3.+cn\",[$a]).% [c]+++++++aaaMod可以指定模式，只有t可以选择，t表示unicode：io:format(\"s\",[&lt;&lt;\"三颗豆子\"/utf8&gt;&gt;]),% 三颗豆子io:format(\"ts\",[&lt;&lt;\"三颗豆子\"/utf8&gt;&gt;]).% \\x&#123;4E09&#125;\\x&#123;9897&#125;\\x&#123;8C46&#125;\\x&#123;5B50&#125;                \n","categories":["转载"],"tags":[]},{"title":"GitHub私有仓库免费：支持3人协作","url":"http://tanqingbo.cn/2019/10/06/GitHub私有仓库免费：支持3人协作/","content":"\nhttp://www.bewindoweb.com/237.htmlGitHub私有仓库免费2019年1月7日，GitHub推送了最新博文《New year, new GitHub: Announcing unlimited free private repos and unified Enterprise offering》，主要有两个更新：1、私有存储库免费没有数量限制、每个仓库支持最多3个开发者协作。打开GitHub创建界面，不会再提示收费：其实国内早就有了码云这类免费私有仓库，前几天我还重新去使用了一下2年前注册的账号。免费的东西确实不错，甚至结合了一些代码检查工具，不过整体体验还是没有GitHub好。所以这次GitHub开放免费私有仓库是真心舒服。2、统一了企业云和企业服务器统一化的企业云（GitHub Businiess Cloud）和企业服务器（GitHub Enterprise），可以使用GitHub Connect进行无缝连接。微软的GitHub自从微软收购GitHub之后，好多大佬都认为GitHub已经违背了开源的初衷，还被最鄙视的啥都不公开啥都收费到处打官司的微软收购，都把自己仓库转移到了GitLab上，或者自己搭的git服务器上去了。而像我这种渣渣，既没有钱去买服务，开放一个免费私有仓库都会高兴半天；又没有能力去转移阵地，因为即使在GitHub上也没有人follow，GitHub仍然是程序员的名片，转移之后就更没有人看了。所以，只能混迹交友平台，希望微软带来的都是雄厚资本说免费就免费的这种好处，而不会有其他的问题吧。附录——博客全文New year, new GitHub: Announcing unlimited free private repos and unified Enterprise offeringJan,07, 2019&nbsp; /&nbsp; &nbsp;nat&nbsp; &nbsp;/&nbsp; &nbsp;AnnouncementsToday we’re announcing two major updates to make GitHub more accessible to developers: unlimited free private repositories, and a simpler, unified Enterprise offering. We’re excited about these updates to our Free and Enterprise offerings:GitHub Free&nbsp;now includes unlimited private repositories. For the first time, developers can use GitHub for their private projects with up to three collaborators per repository for free. Many developers want to use private repos to apply for a job, work on a side project, or try something out in private before releasing it publicly. Starting today, those scenarios, and many more, are possible on GitHub at no cost. Public repositories are still free (of course—no changes there) and include unlimited collaborators.GitHub Enterprise&nbsp;is the new unified product for Enterprise Cloud (formerly GitHub Business Cloud) and Enterprise Server (formerly GitHub Enterprise). Organizations that want the flexibility to use GitHub in a cloud or self-hosted configuration can now access both at one per-seat price. And with&nbsp;GitHub Connect, these products can be securely linked, providing a hybrid option so developers can work seamlessly across both environments.Learn moreGitHub Pro (formerly GitHub Developer) and GitHub Team are also available for developers and teams who need professional coding and collaboration features. And of course, open source contributors will still have everything they need to collaborate on public repositories, including our free version of GitHub Team.Whether you’re a student about to write your first line of code, an enterprise leader with teams around the world, or an open source maintainer, we want GitHub to be the best place for you to code, collaborate, and connect with the global community of developers. Today’s changes are a big investment in the future of GitHub, and we’re excited to see what you build in 2019.                \n\n\n","categories":["转载"],"tags":[]},{"title":"Github协议详解","url":"http://tanqingbo.cn/2019/10/06/Github协议详解/","content":"\nhttp://www.bewindoweb.com/224.html��言github上项目可以选择的协议有很多，相信大家都选择或者看见过None、GNU GPLv3、MIT License、Apache License 2.0，平时懒得选就点个MIT开源共享，但github提供了更多的协议可供选择，那么接下来仔细地分析每个协议的作用吧。一、协议分析1、None / No LicenseNone并不是所谓的“不注明就放弃所有权利”哦，而是“保留所有权利”。也就是作者完全保留这个源码的所有权，不允许他人进行复制、分发、使用和修改。但是如果你把它上传到了github，那么默认允许他人查看（view）源码、分叉（fork）到自己的仓库，只是不能使用、修改而已。2、GNU GPLv3GNU GPLv3（General Public License v3.0），开源正是由于GPL而变得越来越强大，GPLv3在2007年发布，它允许个人使用、商业使用、专利授权，允许复制、分发、修改，并且作者不承担用户使用的一切后果。但是它有很多限制：（1）必须开源一旦使用了这个协议，如果他人想要进行分发、修改，那么他们修改后的源代码也必须开源。这是开源的核心保障，如果没有这条规定，就没有人愿意持续公开自己的源码了。（2）保留协议和版权保留对协议和版权的叙述。（3）不允许更换协议如果有人修改了一些源码，觉得自己改得还挺多的，想要换一个MIT或者什么协议，这是不允许的。一旦最原始的源码使用了GPL，其衍生的所有代码都必须使用GPL。这也是开源保障之一。（4）声明变更对于代码的变更需要有文档进行说明改了哪些地方。3、MIT LicenseMIT是一个简单协议，只有三段话，允许任何人进行个人使用、商业使用、复制、分发、修改，唯一的限制就是，必须得加上源码作者的版权信息（CopyRight）。适合不想用来赚钱，又想保留一点点自己的权利，提高自己声望的那些项目。4、Apache License 2.0Apache License 2.0协议经常被使用在大型开源软件项目上，它允许许任何人进行个人使用、商业使用、复制、分发、修改，作者免责，需要保留作者版权信息，声明更改的地方。特点在于对于贡献者（Contributors）可以提供快速的专利授予。5、BSD 2-Clause \"Simplified\" LicenseBSD 2-Clause协议是BSD协议分支，和MIT协议类似，允许许任何人进行个人使用、商业使用、复制、分发、修改，除了加上作者的版权信息，还必须保留免责声明，免去作者的一些责任（比如使用后果）。6、BSD 3-Clause “New” or “Revised” LicenseBSD 3-Clause在BSD 2-Clause上增加了一个条款：未经特别事先书面许可，著作权人的姓名和其贡献者的姓名不得用于认可或推销源自该软件的产品。肯定是有人把这种开源软件拿去商业使用，宣传说是谁谁谁编写的，造成了不良的影响233337、Eclipse Public License 2.0Eclipse Public License 2.0是一种商业友好型协议���允许个人使用、商业使用、专利授权、复制、分发和修改，作者免责，需要保留版权信息、必须开源、不允许更换协议。特点在于可以对软件进行商业使用，对专利授权免去版税。8、GNU AGPLv3GNU AGPL v3（GNU Affero General Public License v3.0）允许个人使用、商业使用、专利授权、复制、分发和修改，作者免责，贡献者可以快速专利授予，需要保留版权信息、必须开源、不允许更换协议、声明变更。和GPL类似，不同点在于，如果你修改了源码并在放到网上提供服务，那么你必须公开这个修改版本的完整的源代码。9、GNU GPLv2GNU GPLv2&nbsp;相比于 GNU GPLv3，不能进行专利授予。10、GNU LGPLv2.1GNU LGPLv2.1（GNU Lesser General Public License v2.1），主要被用于软件库（Library），和GNU GPLv3基本权利义务类似，不允许专利授予，并且虽然要求其衍生作品必须使用此协议，但只是链接到它（link to it）的代码则不受影响。11、GNU LGPLv3GNU LGPLv3和GNU GPLv3基本权利义务类似，对大型项目做出了一些限制。12、Mozilla Public License 2.0Mozilla Public License 2.0&nbsp;是BSD系协议和GPL系协议的折中，允许个人使用、商业使用、专利授权、复制、分发和修改，作者免责，需要保留版权信息、必须开源，不允许更换协议（但允许更换成某些GNU协议），不允许使用商标。13、The UnlicenseUnlicense是一个完全免费无约束的协议，也就是你放弃你的所有权利，将劳动成功无私奉献出来。允许任何人为了任何目的使用任何手段进行任何操作，不用保留任何信息，当然，作者免责。二、特性总结许可协议&nbsp;许可限制条件&nbsp;其他&nbsp;&nbsp;None不允许任何操作&nbsp;-&nbsp;-&nbsp;GNU GPLv3个人使用商业使用专利授权复制分发修改必须开源保留版权信息声明变更不允许更换协议作者免责&nbsp;MIT License个人使用商业使用复制分发修改保留版权信息作者免责&nbsp;Apache License 2.0个人使用商业使用专利授权复制分发修改保留版权信息声明变更不允许使用商标&nbsp;&nbsp;作者免责&nbsp;BSD 2-Clause个人使用商业使用复制分发修改保留版权信息作者免责&nbsp;BSD 3-Clause个人使用商业使用复制分发修改保留版权信息作者信息不允许用于推销作者免责&nbsp;Eclipse Public License 2.0个人使用商业使用专利授权复制分发修改必须开源保留版权信息不允许更换协议作者免责&nbsp;GNU AGPLv3个人使用商业使用专利授权复制分发修改必须开源保留版权信息声明变更不允许更换协议网络服务需公开完整源码作者免责&nbsp;GNU GPLv2个人使用商业使用复制分发修改必须开源保留版权信息声明变更不允许更换协议作者免责&nbsp;GNU LGPLv2.1个人使用商业使用复制分发修改必须开源保留版权信息声明变更不允许更换协议（衍生库）作者免责&nbsp;GNU LGPLv3个人使用商业使用专利授权复制分发修改必须开源保留版权信息声明变更不允许更换协议（衍生库）&nbsp;&nbsp;作者免责&nbsp;Mozilla Public License 2.0个人使用商业使用专利授权复制分发修改必须开源保留版权信息声明变更不允许更换协议（文件）作者免责&nbsp;The Unlicense个人使用商业使用复制分发修改&nbsp;-作者免责三、推荐的使用姿势1、普通开发者如果你是信仰开源大法的普通开发者，使用MIT协议即可，它会保留你的版权信息，又允许他人进行修改。2、用到了GNU的开发者如果你用到了GNU的库，由于“传染性”，不允许更换协议，必须选择GNU相关的协议。3、开源库开发者推荐使用GNU LGPL相关协议。4、无私奉献的雷锋感谢你为世界作出的贡献，必选The Unlicense。5、不知道该选什么选择默认的None即可，保留你的全部权利，后续再去决定要不要更换协议。                \n\n\n","categories":["转载"],"tags":[]},{"title":"Hello Docker","url":"http://tanqingbo.cn/2019/10/06/Hello Docker/","content":"\nhttp://www.bewindoweb.com/145.html一、什么是Dockerdocker是基于Go语言实现的云开源项目，诞生于2013年，由dotCloud公司发起。官方定义如下：docker是一个开源的软件部署解决方案；docker也是轻量级的应用容器框架；docker可以打包、发布、运行任何的应用。另一定义：Docker是一个开源的引擎，可以轻松的为任何应用创建一个轻量级的、可移植的、自给自足的容器。开发者在笔记本上编译测试通过的容器可以批量地在生产环境中部署，包括VMs（虚拟机）、bare metal、OpenStack 集群和其他的基础应用平台。&nbsp;根据我目前所知的理解，docker是随时可以运行的完整环境，它并不保持一个恒定的状态，而是有所需则取所需，更像是一个“操作系统+相关依赖+主要内容.exe&nbsp;”，自己把需要的环境都已经部署好了，在别的计算机上能够完美地复现。docker的三大核心：镜像（Image）、容器（Container）、仓库（Repository）。二、轻松安装Docker根据官方文章《Docker安装手册》，看评论说Docker基于Linux 64位的，因此需要64bit操作系统，不过我也查到一些32位的安装网页，以后懂了再来重写这段吧，那么，在更熟悉一点的Debian 8下实施安装：【系统环境】阿里云服务器，Debian 8.9 64位。【配置说明】Debian 8自带了3.16的内核，已经满足Docker的运行条件，由于Go语言包版本问题，docker.io包被放在了backports里而不是stable里。1、添加backports源vi /etc/apt/sources.list\ndeb http://http.debian.net/debian jessie-backports main\napt-get update\n如果你刚刚装上新系统，都还没有基础的一些deb，比如Vim编辑器都还没有安装，那么可以参考这个debian 8 deb来设置，这是163的源：&nbsp;&nbsp;deb http://packages.dotdeb.org jessie all\ndeb-src http://packages.dotdeb.org jessie all\ndeb http://mirrors.163.com/debian/ jessie main non-free contrib\ndeb http://mirrors.163.com/debian/ jessie-updates main non-free contrib\ndeb http://mirrors.163.com/debian/ jessie-backports main non-free contrib\ndeb-src http://mirrors.163.com/debian/ jessie main non-free contrib\ndeb-src http://mirrors.163.com/debian/ jessie-updates main non-free contrib\ndeb-src http://mirrors.163.com/debian/ jessie-backports main non-free contrib\ndeb http://mirrors.163.com/debian-security/ jessie/updates main non-free contrib\ndeb-src http://mirrors.163.com/debian-security/ jessie/updates main non-free contrib\ndeb http://mirrors.baidubce.com/debian jessie-backports main contrib non-free\ndeb-src http://mirrors.baidubce.com/debian jessie-backports main contrib non-free\ndeb http://http.debian.net/debian jessie-backports main2、安装docker.io包apt-get install docker.io3、确认docker运行是否正常docker run --rm hello-world 会提示：本地没有找到hello-world项目 → 正在拉取hello world项目 → Hello from Docker！This message shows that your installation appears to be working correctly.三、Hello Docker准备Docker系统有两个程序：docker服务端和docker客户端。其中docker服务端是一个服务进程，管理着所有的容器。docker客户端则扮演着docker服务端的远程控制器，可以用来控制docker的服务端进程。大部分情况下，docker服务端和客户端运行在一台机器上。查看docker版本docker version\n提示：\nClient version: 1.6.2\nClient API version: 1.18\nGo version (client): go1.3.3\nGit commit (client): 7c8fca2\nOS/Arch (client): linux/amd64\nServer version: 1.6.2\nServer API version: 1.18\nGo version (server): go1.3.3\nGit commit (server): 7c8fca2\nOS/Arch (server): linux/amd64搜索可用的docker镜像用docker search命令来检索docker可用的镜像docker search tutorial镜像都是按照用户名/镜像名来存储的：NAME                                                DESCRIPTION                                                            STARS     OFFICIAL   AUTOMATED\nlearn/tutorial                                                                                                                        36                   \ngeorgeyord/reactjs-tutorial             This is the backend of the React comment b...        5                               [OK]\nmhausenblas/kairosdb-tutorial      GitHub fetcher for KairosDB tutorial                         1                               [OK]\nlinkedin/photon-ml-tutorial           An interactive tutorial of the Photon ML m...           1有的镜像经过了官方验证，可以不用用户名，直接以镜像名存储，如：NAME                                                   DESCRIPTION                                                         STARS     OFFICIAL   AUTOMATED\nubuntu                                                 Ubuntu is a Debian-based Linux operating s...    7340                          [OK]       \ndorowu/ubuntu-desktop-lxde-vnc    Ubuntu with openssh-server and NoVNC            165                            [OK]\nrastasheep/ubuntu-sshd                     Dockerized SSH service, built on top of of...        132                            [OK]下载可用的docker镜像下载docker镜像时需要把用户名/镜像名写完整，使用docker pull命令拉取，如：docker pull learn/tutorial在docker容器中运行命令docker容器就像是一个拥有所有环境的沙盒进程，它默认是不运行任何程序的，需要你运行一个进程来启动一个容器，当运行的进程结束时，容器也会停止。利用刚刚下载的learn/tutorial来进行Hello world，命令为 docker run [用户名/镜像名] [命令语句]，例如：docker run learn/tutorial echo \"hello world\"\nhello world在docker容器中安装新程序利用刚刚的run命令，learn/tutorial是基于ubuntu的，因此用apt-get install -y来执行安装，-y是为了不进行交互，因为docker是无法响应这种交互的（不过尝试后发现docker只是停顿了几秒，也能成功安装）。来安装一个ping程序：docker run learn/tutorial apt-get install -y ping保存对docker容器的修改利用docker ps -l命令，即可查看进行操作后docker容器的容器ID号，再利用docker commit [容器id] [用户名/镜像名]就能提交。整个过程保存了新旧状态之间的区别，从而产生了一个新版本，注意commit命令提交的容器id只需要简写前面几个字符即可识别。docker ps -l\nCONTAINER ID        IMAGE                      COMMAND             CREATED             STATUS                                 PORTS               NAMES\n2bef2995887e        learn/tutorial:latest  apt-get install -y      4 seconds ago        Exited (0) 1 seconds ago                            silly_bohr\ndocker commit 2bef learn/ping\n9660801322a6953232e3663a7deed632027898b8d23c4b58596a3dd8aebe6040使用新的docker容器刚刚保存为了learn/ping，因此使用新的名字就能用新的容器了，测试如下：docker run learn/ping ping www.baidu.com\nPING www.a.shifen.com (115.239.211.112) 56(84) bytes of data.\n64 bytes from 115.239.211.112: icmp_req=1 ttl=53 time=29.7 ms\n64 bytes from 115.239.211.112: icmp_req=2 ttl=53 time=29.6 ms\n64 bytes from 115.239.211.112: icmp_req=3 ttl=53 time=29.6 ms按ctrl+C即可停止查看运行中的镜像docker ps可以查看所有正在运行中的镜像，docker inspect [容器id]可以查看某个容器的详细运行信息。例如，我们一个SSH运行ping的docker：docker run learn/ping ping www.baidu.com另开一个SSH来检查这个运行中的docker：docker ps\nCONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS               NAMES\n5f76db829af0        learn/ping:latest   \"ping www.baidu.com\"   9 seconds ago       Up 8 seconds                            nostalgic_lovelacedocker inspect 5f7\n[&#123;\n  \"AppArmorProfile\": \"\",\n    \"Args\": [\n      \"www.baidu.com\"\n  ],\n  \"Config\": &#123;\n      \"AttachStderr\": true,\n      \"AttachStdin\": false,\n      \"AttachStdout\": true,\n        \"Cmd\": [\n          \"ping\",\n          \"www.baidu.com\"\n      ],\n      \"CpuShares\": 0,\n      \"Cpuset\": \"\",\n      \"Domainname\": \"\",\n      \"Entrypoint\": null,\n      \"Env\": [],\n      \"ExposedPorts\": &#123;&#125;,\n        \"Hostname\": \"5f76db829af0\",\n      \"Image\": \"learn/ping\",\n      \"Labels\": &#123;&#125;,\n      \"MacAddress\": \"\",\n      \"Memory\": 0,\n      \"MemorySwap\": 0,\n      \"NetworkDisabled\": false,\n      \"OnBuild\": null,\n      \"OpenStdin\": false,\n      \"PortSpecs\": null,\n      \"StdinOnce\": false,\n      \"Tty\": false,\n      \"User\": \"\",\n      \"Volumes\": &#123;&#125;,\n      \"WorkingDir\": \"\"\n  &#125;,\n  \"Created\": \"2018-03-07T12:52:43.618113724Z\",\n  \"Driver\": \"aufs\",\n  \"ExecDriver\": \"native-0.2\",\n  \"ExecIDs\": null,\n  \"HostConfig\": &#123;\n      \"Binds\": null,\n      \"CapAdd\": null,\n      \"CapDrop\": null,\n      \"CgroupParent\": \"\",\n      \"ContainerIDFile\": \"\",\n      \"CpuShares\": 0,\n      \"CpusetCpus\": \"\",\n      \"Devices\": [],\n      \"Dns\": null,\n      \"DnsSearch\": null,\n      \"ExtraHosts\": null,\n      \"IpcMode\": \"\",\n      \"Links\": null,\n      \"LogConfig\": &#123;\n          \"Config\": null,\n          \"Type\": \"json-file\"\n      &#125;,\n      \"LxcConf\": [],\n      \"Memory\": 0,\n      \"MemorySwap\": 0,\n      \"NetworkMode\": \"bridge\",\n      \"PidMode\": \"\",\n      \"PortBindings\": &#123;&#125;,\n      \"Privileged\": false,\n      \"PublishAllPorts\": false,\n      \"ReadonlyRootfs\": false,\n      \"RestartPolicy\": &#123;\n          \"MaximumRetryCount\": 0,\n          \"Name\": \"no\"\n      &#125;,\n      \"SecurityOpt\": null,\n      \"Ulimits\": null,\n      \"VolumesFrom\": null\n  &#125;,\n  \"HostnamePath\": \"/var/lib/docker/containers/5f76db829af03f915c67495cd025c4fa401bf862d8f056763b2868b9b830c6d1/hostname\",\n  \"HostsPath\": \"/var/lib/docker/containers/5f76db829af03f915c67495cd025c4fa401bf862d8f056763b2868b9b830c6d1/hosts\",\n    \"Id\": \"5f76db829af03f915c67495cd025c4fa401bf862d8f056763b2868b9b830c6d1\",\n  \"Image\": \"798a12b7257efd2fb2c91a5581dfa7d258af136fa05a447650748caa577620af\",\n  \"LogPath\": \"/var/lib/docker/containers/5f76db829af03f915c67495cd025c4fa401bf862d8f056763b2868b9b830c6d1/5f76db829af03f915c67495cd025c4fa401bf862d8f056763b2868b9b830c6d1-json.log\",\n  \"MountLabel\": \"\",\n  \"Name\": \"/nostalgic_lovelace\",\n  \"NetworkSettings\": &#123;\n      \"Bridge\": \"docker0\",\n      \"Gateway\": \"192.168.42.1\",\n      \"GlobalIPv6Address\": \"\",\n      \"GlobalIPv6PrefixLen\": 0,\n      \"IPAddress\": \"192.168.42.19\",\n      \"IPPrefixLen\": 24,\n      \"IPv6Gateway\": \"\",\n      \"LinkLocalIPv6Address\": \"fe80::42:c0ff:fea8:2a13\",\n      \"LinkLocalIPv6PrefixLen\": 64,\n      \"MacAddress\": \"02:42:c0:a8:2a:13\",\n      \"PortMapping\": null,\n      \"Ports\": &#123;&#125;\n  &#125;,\n  \"Path\": \"ping\",\n  \"ProcessLabel\": \"\",\n  \"ResolvConfPath\": \"/var/lib/docker/containers/5f76db829af03f915c67495cd025c4fa401bf862d8f056763b2868b9b830c6d1/resolv.conf\",\n  \"RestartCount\": 0,\n  \"State\": &#123;\n      \"Dead\": false,\n      \"Error\": \"\",\n      \"ExitCode\": 0,\n      \"FinishedAt\": \"0001-01-01T00:00:00Z\",\n      \"OOMKilled\": false,\n      \"Paused\": false,\n      \"Pid\": 1790,\n      \"Restarting\": false,\n      \"Running\": true,\n      \"StartedAt\": \"2018-03-07T12:52:43.713174245Z\"\n  &#125;,\n  \"Volumes\": &#123;&#125;,\n  \"VolumesRW\": &#123;&#125;\n&#125;\n]四、发布自己的docker镜像使用docker images可以查看当前所有的镜像：docker images\nREPOSITORY          TAG             IMAGE ID               CREATED                  VIRTUAL SIZE\nlearn/ping          latest              798a12b7257e       12 minutes ago        139.9 MB\n&lt;none&gt;              &lt;none&gt;         455fcbe970b7        12 minutes ago        139.9 MB\n&lt;none&gt;              &lt;none&gt;         9660801322a6        19 minutes ago        139.9 MB\nhello-world         latest              690d80202531       3 months ago           1.848 kB\nlearn/tutorial      latest              8dbd9e392a96       4.905907 years ago   128 MB使用docker push [用户名/镜像名]可以发布到自己的用户名下面（需要输入登录信息）docker push learn/ping\nThe push refers to a repository [learn/ping] (len: 1)\n798a12b7257e: Image push failed \n798a12b7257e: Buffering to Disk \nPlease login prior to push:\nUsername: 123\nPassword: \nEmail: qewr\nFATA[0014] Error response from daemon: Registration: \"Wrong username format (it has to match \\\"^[a-z0-9]&#123;4,30&#125;$\\\")\"                \n\n\n","categories":["转载"],"tags":[]},{"title":"JavaWeb的HelloWorld","url":"http://tanqingbo.cn/2019/10/06/JavaWeb的HelloWorld/","content":"\nhttp://www.bewindoweb.com/220.html前言&nbsp;超级多的废话上次努力学JavaWeb还在2013年的大二，URP计划开始跟着老师一年（其实就是每周开个会…），从JSP+Servlet学起，然后觉得JSP用个标签，服务器用个Struts+Spring+Hibernate框架就非常高级了。其实我原本跟着老师的原因是超级喜欢数据库，想自己开发一个新型数据库，结果做了JavaWeb……不过还是非常感谢老师，是我人生中不多的敬佩的人。我只学到了一些增删改查的皮毛，那时候还非常喜欢用easyui作为前端。我也没想到大学临近毕业去的那个什么软件课程几天教的软件工程UML图，才是我现在工作需要的东西。晃眼五年过去了，做了好多好多好多选择，研究生阶段没接触Java了，但是顺便用了一下所谓的“JavaWeb“做了这个博客，开始是想用来分享一些自己做的QQ三国游戏脚本之类的，后来用来进行技术积累，然而又移植成PHP发现更方便，不过再也没深入学下去了。开头本来在做一些预研工作，提了一句用可以用JavaWeb做个简单的展示，其实我只是想用Jsp+Servlet简单地调用一下而已……后来被布置了一个大任务，还是很兴奋的。当我重新上手的时候，发现JavaWeb早已不是当年那个它了……MyEclipse早就被IDEA取代了；Struts已被弃用，取代它的是SpringMVC；甚至SSH框架已经被Spring Boot替代；有一些从来没接触过的“懒加载”之类的新技术；Spring的AOP原理是必备的；openLDAP、Spring Security；接口管理；前后端分离早就很成熟了；Redis从以前的可选项变成了必学的东西……看看别人代码那么整齐规范，再看看我还处于写个println都要去查一下是System.out.println的阶段……都工作四个月了，还在做这个东西，一个能用的版本都没有。前几天被老大提醒，你的效率是不是太低了，什么东西都没有。虽然被这样说心里不好受，但是对啊，我自己的一年应该到什么程度的计划呢，都已经过了半年了。我也没有在玩啊，应该反省一下我的时间都花到哪里去了。认真对比一下实习三个月和现在的工作四个月的区别，看了一些别人是怎么一步一步处理的（趁着年轻），反省的内容已经记在小本本上了。不多说，开始JavaWeb的HelloWorld。Java版本使用1.8：下载Java SE Development Kit 8u181环境变量记得配置环境变量（一定要采用规范的大小写和下划线）：#JAVA_HOME\nE:\\jdk1.8\n#CLASSPATH\n.;%JAVA_HOME%/lib/dt.jar;%JAVA_HOME%/lib/tools.jar;\n#Path\n%JAVA_HOME%/bin;%JAVA_HOME%/jre/bin;使用IDEAIDEA全名IntelliJ IDEA，JetBrains全家桶之一，可以说得上是JAVA最人性化的IDE了。喜欢上IDEA的第一个理由一开始写一些方法，都调用methoda：然后方法名上点右键→重构→重命名，修改成bewindoweb，提示有不同的类型：我们可以挑选一些进行移除，发现其他的调用语句自动都修改了，而字符串没有被修改：它的这个操作可以跨越文件，甚至可以智能识别和提示你批量修改一些New对象的名称。IDEA下载我下载的版本是IDEA ULTIMATE 2018.1 for windows（531MB），你可以在这里下载其他版本。IDEA注册激活注册的方法一是可以采用成都没有派对等大佬搭建的公用激活服务���，如果有兴趣的话，里面有相关的搭建原理，可以尝试自己搭建。另一种方式是使用EDU邮箱免费注册一年期的授权，参考《用EDU邮箱免费注册JetBrains全家桶》认识MavenMaven的作用Maven是apache全家桶之一，也是JavaWeb规范化的第一个标志。以前学长学姐也都是手动导入Jar包，然而总是会报各种冲突，非常浪费时间。Maven的作用就是你只需要进行文本配置，由Maven来帮你导入合适版本的依赖包。Maven读音读音一定要在最开始认识的时候读对：读作“美ven”，千万别读成“马ven”了。                \n\n\n","categories":["转载"],"tags":[]},{"title":"Jquery实现文章目录侧边栏导航","url":"http://tanqingbo.cn/2019/10/06/Jquery实现文章目录侧边栏导航/","content":"\nhttp://www.bewindoweb.com/143.html\n一、教程内容需要用Jquery实现根据文章内容自动生成侧边栏导航的功能，具体的来说有以下的需求：1、能自动生成文章h1-h5标签的标题2、点击标题能跳转到对应的位置3、如果文章过长，下滑后导航要保持在右侧4、如果没有标题，需要用“无文章目录”填充目录区域。二、具体操作HTML&lt;div id=\"category-ct\" class=\"global-card card-side\"&gt;\n      &lt;div class=\"card-side-title\"&gt;\n          &lt;b&gt;文章目录&lt;/b&gt;\n      &lt;/div&gt;\n      &lt;ul class=\"card-body\"&gt;\n          &lt;div id=\"category\"&gt;\n              &lt;div id=\"c-default\" style=\"display:none;font-size:14px;text-align:center;color:#242424;line-height:20px;margin-top: 10px;padding-top: 5px;\"&gt;\n                  无文章目录\n              &lt;/div&gt;\n          &lt;/div&gt;\n      &lt;/ul&gt;\n  &lt;/div&gt;1、自动生成文章h1-h5标题只需要遍历文章内容，找到h1-h5的文字内容，然后加入到右侧的id=\"category\"里面即可。2、点击标题跳转位置有四种方法，第四种最好。【方法1】给锚点文本添加id，使用&lt;a href=\"#\"&gt;目录文字&lt;/a&gt;来定位。&lt;a href=\"#c1\"&gt;目录&lt;/a&gt;\n&lt;h1 id=\"c1\"&gt;需要跳转的标题&lt;/h1&gt;然而这样做会使得浏览器URL变为：http://www.bewindoweb.cn/122.html#c1并产生一条历史记录，如果多次跳转，想返回上一页面，则需要返回N次点过的锚点URL，才能返回。【方法2】添加一个空的锚点，使用name定位，同样使用&lt;a href=\"#\"&gt;目录文字&lt;/a&gt;来定位。&nbsp;&nbsp;&lt;a href=\"#c1\"&gt;目录&lt;/a&gt;\n&lt;a name=\"c1\"&gt;&lt;/a&gt;\n&lt;h1&gt;需要跳转��标题&lt;/h1&gt;缺点非常多，首先添加了不必要的空文本，外观会显示为一个空行（当然可以用CSS调整），其次name只对a标签起作用，最后仍然有方法1的问题。【方法3】使用js定位。onclick=\"javascript:document.getElementById('c1').scrollIntoView()\"很好，不改变URL，同时能跳转，但是比较突兀。【方法4】使用jquery定位。$(document).on('click', '.cbtn', function(e) &#123;\n          $('html,body').animate(&#123;scrollTop: $(\"#\" + this.name).offset().top&#125;, 500);\n      &#125;);将按钮加个.cbtn的class，把要跳转的id保存在name属性里，然后用animate模拟滚动条滑动跳转，平滑跳转到需要的位置。3、如果文章过长，下滑后导航要保持在右侧和“返回顶部”按钮的思路一致，当滚动到一定程度（看不到目录，也就是滚动距离超过了目录div离浏览器上边距的距离），就将目录的div固定在右侧。var navH = $(\"#category-ct\").offset().top;\n      //滚动条事件\n      $(window).scroll(function()&#123;\n          //获取滚动条的滑动距离\n          var scroH = $(this).scrollTop();\n          //滚动条的滑动距离大于等于定位元素距离浏览器顶部的距离，就固定\n          if(scroH&gt;=navH)&#123;\n              $(\"#category-ct\").css(&#123;position: 'fixed'&#125;);\n              $(\"#category-ct\").animate(&#123;top: '30px'&#125;,1000);\n          &#125;\n          else&#123;\n              $(\"#category-ct\").css(&#123;position: 'static',top:'0px'&#125;);\n          &#125;\n      &#125;);这里还加了个缓慢下降的效果，不过经常当返回顶部时，top不会变回0px，不知道为什么。4、如果没有标题，需要用“无文章目录”填充目录区域。如果没搜索到h1-h5，那么就将“无文章目录”的CSS置为显示即可。三、完整代码&lt;script&gt;\n  $(function()&#123;\n      var notdefault = 0;\n      $('.card-article-text').find('h1,h2').each(function(index,item)&#123;\n          notdefault = 1;\n          $(this).attr('id','c'+index);\n          var headerText=$(this).text();\n          var tagName=$(this)[0].tagName.toLowerCase();\n          var tagIndex=parseInt(tagName.charAt(1));\n          //设置不同等级header的排列及缩进样式\n          if (tagIndex == 1)//href=\"#c'+index+'\"\n              $('#category').append($('&lt;a name=c'+index+' class=\"cbtn article-ch'+tagIndex+'\" &gt;'+headerText+'&lt;/a&gt;'));\n          else\n              $('#category').append($('&lt;a name=c'+index+' class=\"cbtn article-ch'+tagIndex+'\" &gt;&gt; '+headerText+'&lt;/a&gt;'));\n\n  &#125;);\n  if (notdefault == 0)&#123;\n      $(&#39;#c-default&#39;).css(&#39;display&#39;,&#39;block&#39;);\n  &#125;\n\n\n    var navH = $(&quot;#category-ct&quot;).offset().top;\n    //滚动条事件\n    $(window).scroll(function()&#123;\n        //获取滚动条的滑动距离\n        var scroH = $(this).scrollTop();\n        //滚动条的滑动距离大于等于定位元素距离浏览器顶部的距离，就固定\n        if(scroH&amp;gt;=navH)&#123;\n            $(&quot;#category-ct&quot;).css(&#123;position: &#39;fixed&#39;&#125;);\n            $(&quot;#category-ct&quot;).animate(&#123;top: &#39;30px&#39;&#125;,1000);\n        &#125;\n        else&#123;\n            $(&quot;#category-ct&quot;).css(&#123;position: &#39;static&#39;,top:&#39;0px&#39;&#125;);\n        &#125;\n    &#125;);\n\n    $(document).on(&#39;click&#39;, &#39;.cbtn&#39;, function(e) &#123;\n        $(&#39;html,body&#39;).animate(&#123;scrollTop: $(&quot;#&quot; + this.name).offset().top&#125;, 500);\n        //document.getElementById($(this).attr(&#39;name&#39;)).scrollIntoView()\n       // onclick=&quot;javascript:document.getElementById(&#39;+&#39;\\&#39;c3\\&#39;&#39;+&#39;).scrollIntoView()\n    &#125;);\n\n&#125;);\n&lt;/script&gt;                \n","categories":["转载"],"tags":[]},{"title":"MQTT Broker 数据结构：订阅树","url":"http://tanqingbo.cn/2019/10/06/MQTT Broker 数据结构：订阅树/","content":"\nhttp://www.bewindoweb.com/268.html一、MQTT主题和主题过滤器匹配需求MQTT协议规定，客户端可以订阅（Subscribe）主题过滤器（TopicFilter），主题过滤器可能为：完全精确的主题过滤器。例如：abc/def/123含有单层通配符（+，SINGLE）的主题过滤器。例如：abc/+/123含有多层通配符（#，MULTI）的主题过滤器。例如：abc/#同时，客户端还可以向某个主题（Topic）发布（Publish）消息，比如abc/def/123，主题不能含有通配符。MQTT Broker需要查询有哪些客户端订阅了匹配这个主题的主题过滤器，并将消息发送给它们。例如下图所示情况：客户端X是发布者，将数据发布到主题\"abc/def/123\"；客户端A、B、C、D都是订阅者，但只有A、B、C订阅的主题过滤器和该主题匹配：A订阅\"abc/+/123\"，\"+\"匹配了单层任意字符\"def\"；B订阅\"abc/#\"，\"#\"匹配了多层任意字符\"def/123\"；C订阅\"abc/def/123\"，完全精确地匹配。那么，MQTT消息代理（MQTT Broker）应该如何做“主题”到“主题过滤器”的匹配呢？很容易想到一种基础实现——“暴力扫描”。算法1-1 暴力扫描伪代码 \n/**\n\n\n查询Topic匹配的订阅者\n*/FUNCTION Set findSubscriber（subscriptionArray, publishTopic）   // 订阅者   subscribers = []   // 发布主题token数组   topicTokenArray = split(publishTopic,”/“)   // 遍历所有订阅   FOR i = 0 to size(subscriptionArray)   // 订阅主题过滤器token数组\n   topicFilterTokenArray = split(subscriptionArray[i].topicFilter,&quot;/&quot;)\n   //逐个比对是否匹配\n   IF matchTopic(topicTokenArray, TopicFilterTokenArray)\n       subscribers.add(subscriptionArray[i])\n   END\n   END   RETURN subscribersEND\n\n/**\n\n匹配主题和主题过滤器\n*/FUNCTION boolean matchTopic(topicTokenArray, topicFilterTokenArray)   topicSize = size(topicTokenArray)   topicFilterSize = size(topicFilterTokenArray)   // 遍历所有主题token，逐个token比对   FOR i = 0 to topicSize   // 如果filter是单层通配符，或者token相同，则匹配\n   IF topicTokenFilterArray[i] == &quot;+&quot; || topicTokenFilterArray[i] == topicTokenArray[i]\n       CONTINUE\n   // 如果filter是多层通配符且在最后，则完全匹配\n   ELSEIF topicTokenFilterArray[i] == &quot;#&quot; &amp;amp;&amp;amp; i == topicFilterSize\n       RETURN true\n   // 不匹配，直接返回\n   ELSE\n       RETURN false\n   END   // 如果遍历完成，说明topic过了一遍都匹配，则当二者长度相等时，说明完全匹配   IF (topicSize == topicFilterSize)   RETURN true\n   ELSE   RETURN false\n   ENDEND很��易看出，两层for循环，时间复杂度O(S✖T)，其中S是订阅信息数量（Subscription，不是订阅者Subscriber数量），T是发布主题的平均长度（划分成token的平均个数）。仔细想一想，虽然实现了功能，但是在生产环境上，假设一个Broker连接2W设备，每个设备订阅10个TopicFilter，发布主题的平均长度约为10，执行一次匹配，要执行200W次token比较，要知道这还没有计算每秒钟客户端会发送多少条消息，这个时延都已经完全无法接受。二、订阅树简介2.1 订阅树的定义订阅树（Topic Tree / Subscription Tree）是解决这个匹配问题的一种方法。TopicTree本质是一棵按token划分的字典树（Trie Tree），每个节点上存储着订阅信息，一棵典型的订阅树如下图所示：订阅树有如下性质：（1）有一个根节点Root，一个父节点可以有多个子节点（2）每条边代表一个Token，从根节点遍历到子节点所经历的路径定义为TopicFilter（3）任何节点的内容都可能为空，也可能包含订阅信息例如，这棵订阅树有一个根节点Root，每条边上都有一个token。从��节点遍历到最左边的叶子节点经历的路径“abc/+/123”就是一个TopicFilter。叶子节点包含了一条订阅信息{客户端A以QoS0的质量订阅了abc/+/123}。并且中间的节点可能为空，也可能包含订阅信息；叶子节点可能包含订阅信息，也可能为空。2.2 订阅树的匹配过程有了订阅树的数据结构，如何匹配Topic和TopicFilter呢？仍以这棵树为例，我们给节点加上编号：其中，订阅信息为：&nbsp;节点编号&nbsp;&nbsp;订阅客户端&nbsp;&nbsp;订阅主题&nbsp;&nbsp;订阅质量&nbsp;&nbsp;N5A&nbsp;&nbsp;abc/+/123&nbsp;0&nbsp;N3B&nbsp;&nbsp;abc/#&nbsp;1&nbsp;N3A&nbsp;&nbsp;abc/#&nbsp;0&nbsp;N4B&nbsp;&nbsp;abc/def&nbsp;0&nbsp;N6B&nbsp;abc/def/123&nbsp;0&nbsp;N6C&nbsp;&nbsp;abc/def/123&nbsp;1&nbsp;N7&nbsp;D&nbsp;abc/def/456&nbsp;0整个匹配过程是宽度优先搜索（BFS）或深度优先搜索（DFS）的过程，这里按DFS描述，假设客户端X发布主题为“abc/def/123”，从根节点开始遍历：（1）进入Root，查找匹配的边，只有一条边abc，且和第一个token“abc”匹配，进入子节点N1（2）查找匹配的边，找到三条边“+”、“#”、“def”（3.1.1）进入子节点N2，查找匹配的边，找到匹配边“123”，进入N5（3.1.2）进入N5，匹配完成，返回订阅信息｛A，”abc/+/123”，0｝（3.2.1）进入子节点N3，匹配完成，返回订阅信息{B，“abc/#”，1}和订阅信息｛A，“abc/#”，0｝（3.3.1）进入子节点N4，查找匹配的边，只有一条边“123”，进入N6（3.3.2）进入子节点N6，匹配完成，返回订阅信息{B，“abc/def/123”，0}和订阅信息{C，“abc/def/123”，1}（4）回退到Root，查找结束我们就得到了匹配这个主题的5条订阅信息：&nbsp;节点编号&nbsp;&nbsp;订阅客户端&nbsp;&nbsp;订阅主题&nbsp;&nbsp;订阅质量&nbsp;&nbsp;N5A&nbsp;&nbsp;abc/+/123&nbsp;0&nbsp;N3B&nbsp;&nbsp;abc/#&nbsp;1&nbsp;N3A&nbsp;&nbsp;abc/#&nbsp;0&nbsp;N6B&nbsp;abc/def/123&nbsp;0&nbsp;N6C&nbsp;&nbsp;abc/def/123&nbsp;1注意，在这里A订阅的两个主题“abc/+/123”、”abc/#”都成功匹配，但下发给客户端A的时候要去重，只能下发1条消息，因为Broker是依赖MQTT-Publish给客户端下发消息的，发布的主题就是客户端X发布的主题“abc/+/123”，区分不出是客户端哪条订阅匹配的，所以发过去由客户端自己本地匹配出2条订阅（客户端本地也有订阅结构）。回头来看，客户端A这种“重复主题过滤器”的设计是不好的，在实际应用上应该极力避免这种设计，一个客户端的各个订阅都最好都是独立接受消息的。如果区分出通配符和非通配符，那么查找的时间复杂度就是字典树的查找时间复杂度，为O(T)，其中T是发布主题的平均长度（划分成token的平均个数）。2.3 增加订阅（1）增加订阅时部分节点不存在当增加新订阅时，对于划分出来的token，订阅树可能会有一部分节点/边已经存在，有一部分节点/边不存在，那么就需要增加不存在的新节点/边。如图所示，客户端F以QoS0的质量订阅新主题过滤器“abc/ghi/789”，这个时候“abc”是存在的，“ghi”、”789”都是不存在的，那么我们需要增加两个新节点和两条新边，并在最下面的节点放置F的这条订阅信息。（2）添加订阅时节点已存在如果节点已经存在，只需要增加订阅信息到对应节点中去即可。如图所示，左侧为客户端F订阅“abc/+”，节点都已存在，将F加入到空节点中；右侧为客户端F订阅“abc/+/123”，节点都已存在，A所在节点增加一条订阅信息F。插入的时间复杂度同样为O(T)，其中T是发布主题的平均长度（划分成token的平均个数）。2.4 取消订阅（1）取消订阅后没有订阅者如果取消订阅后没有订阅者，可以不用管（可能存在内存溢出的风险），也可以通过一些方式删除该节点。如图所示，假设客户端A取消了订阅“abc/+/123”，节点没有任何其他订阅信息了，那么该节点（灰色节点）可以被删除掉。（2）取消订阅后仍然有订阅者如果取消订阅后仍然有订阅者，那么只需要移除该订阅信息即可。如图所示，假设客户端C取消了订阅“abc/def/123”，客户端B仍然存在订阅“abc/def/123”，那么只需要去掉此节点上C的订阅信息。三、订阅树实现难点和业界解决方案3.1 订阅树实现难点（1）MQTT客户端可能并发地订阅、取消订阅，如何保证并发安全？例如：A订阅abc/+的时候，B也订阅、取消订阅abc/+，需要保证并发安全。（2）订阅树是内存结构，在分布式环境下如何同步？例如：如下订阅、发布情况，Broker2怎么知道Broker1上有客户端订阅了这个主题？（3）MQTT客户端订阅数据量非常大的时候，如何加快查找速度？例如：10W客户端，每个客户端40个订阅，如果采用锁的机制控制并发，订阅/取消订阅会产生大量冲突造成查询获锁缓慢。3.2 业界订阅树的实现（1）并发安全EMQ：底层采用Erlang的Mnesia分布式数据库，利用分布式数据库的事务保证并发 —— Erlang语言开发者很少JMQTT：采用锁的机制控制并发 &nbsp;Moquette：利用CAS控制并发&nbsp;Mosquitto：采用锁的机制控制并发&nbsp;MqttWk：无内存订阅树结构，订阅存放在分布式Redis里（通配符直接扫描），由Redis保证并发 —— 通配符扫描效率极低知乎网关：采用锁的机制控制并发（单Broker23万客户端、23万订阅量）（2）分布式同步EMQ：底层采用Erlang的Mnesia分布式数据库保证同步 —— Erlang语言开发者很少JMQTT 1.x：单机，无同步Moquette 0.10：采用Hazelcast，靠订阅数据全量广播来同步 ——量太大且不可靠（同时宕机数据丢失），水平扩展无法扩展消费速率Moquette 0.12+：单机，无同步Mosquitto：可通过“桥接”搭建伪分布式，靠订阅数据全量广播来同步 ——量太大且不可靠 ，水平扩展无法扩展消费速率MqttWk：无内存订阅树结构，订阅存放在分布式Redis里（通配符直接扫描），不需要同步百度IoT：由Kafka存储订阅数据，靠读取Kafka同步 —— 比较好的实现机制HiveMQ：自制向量时钟组件，可以分析本地订阅树数据之间的差异，通过Jgroups将差异部分协商同步 —— 代码不开源，自己实现困难&nbsp;某车联网代码：Broker自己作为MQTT客户端连接到其他Broker上，当真实的客户端在自己节点订阅时，自己再发出一个订阅请求到所有其他Broker节点 —— 类似桥接模式，非标准分布式模式，且订阅数量较少、客户端较少（一台5万连接）（3）查找速度EMQ：底层采用Erlang的Mnesia分布式数据库保证速度 —— Erlang语言开发者很少JMQTT：无优化&nbsp;Moquette 0.10：无优化&nbsp;Moquette 0.12+：无优化Mosquitto：无优化 修改版Mosquitto：分离精确订阅和通配符订阅，精确订阅采用Hash表，通配符订阅采用订阅树 —— 比较好的优化方向MqttWk：无优化&nbsp;知乎网关：根据clientId进行Hash，划分到100+个哈希表空间（没有通配符所以没用订阅树） —— 比较好的优化方向总结MQTT的订阅匹配最好这样处理：订阅树 —— 负责通配符的匹配，查找速率O(T)，需要注意控制树的深度宽度、取消订阅的内存回收哈希表 —— 负责精确匹配，查找速率O(1)，需要注意并发冲突这是带通配符字符串匹配的常见解决方案——精确用表、前缀用树。具体判断用什么数据结构，主要依靠如下三点衡量：数据总量有多大 —— 数据量较大，尽量不用树。数据是否持续增长 —— 连接量有上限、订阅量有上限，所以订阅数据有上限，如果没有上限的话，重哈希会比较耗时。查找是否频繁 —— 物联网消息非常多，非常频繁，因此能用哈希表就用哈希表。订阅树的原理很简单，但是上了并发和分布式就会有很多问题，这些解决方案都需要压力测试和生产环境检验。                \n\n","categories":["转载"],"tags":[]},{"title":"MQTT Broker测试工具推荐","url":"http://tanqingbo.cn/2019/10/06/MQTT Broker测试工具推荐/","content":"\nhttp://www.bewindoweb.com/248.html一、功能测试工具1、eclipse/paho.mqtt-spy【链接】github下载地址|&nbsp;mqtt-spy官方功能介绍&nbsp;&nbsp;【简介】这是一个基于java做的GUI工具，需要jdk8+。界面一看就懂，建议连接的时候开启Details模式，这样功能会全一些：【功能介绍】1）连接、安全协议：mqtt3.1/3.1.1连接方式：IP + 任意端口 + TCP/Websocket + TLS（CA、TrustStore）1.1、1.2、1.3ClientID：可以帮助你自动生成随机IDCleanSession标志位连接超时、失败重连、失败重订阅、重连间隔KeepAlive设置Username、Password设置遗嘱设置：Topic、QoS、Retain、Data2）订阅和发布订阅任意主题（用颜色帮你区分），包括通配符订阅订阅主题接收信息打印和统计发布QoS、Retain编写发布脚本开启多个客户端、拆分窗口显示【使用限制】mqtt-spy测试的都是正常情况下的功能，比如正常连接、发布、断开。没有提供异常断开、不发心跳包、ClientID格式错误（它会自己检测格式错误不通过就不让发送）等等异常情况的测试界面。2、eclipse paho【链接】官网下载地址|&nbsp;github paho（Java）【简介】纯代码的客户端，可以自己去定制功能，支持多种语言：我还没有使用过，不过既然支持Java，就可以打断点或者自行编写异常的测试了。二、性能测试工具1、emqtt/emqtt_benchmark【链接】emqtt_benchmark githubEMQ的官方性能测试工具，Erlang语言编写，我安装的时候有BUG，发现其他人也遇到了，暂时不知道目前解决没有。2、emqx/mqtt-jmeter【链接】mqtt-jmeter这是EMQ编写的jmeter插件，熟悉Jmeter的可以用它来压测，我用它来测试过moquette0.12，功能能够使用，不过不齐全。3、krylovsk/mqtt-benchmark【链接】krylovsk/mqtt-benchmarkhui6075/mosquitto-cluster所使用的性能测试工具，Go语言编写，已经是三年前的了，不知道好不好用。                \n\n\n","categories":["转载"],"tags":[]},{"title":"Manacher算法：最长回文子串（二.1图，二.J）","url":"http://tanqingbo.cn/2019/10/06/Manacher算法：最长回文子串（二.1图，二.J）/","content":"\nhttp://www.bewindoweb.com/161.html\n一、算法简介算法名称Manacher算法算法作用求取一个字符串的最长回文子串。二、算法内容算法思路求回文子串容易第一个想到的解法是：蛮力算法Brute-force，其时间复杂度为O（n^3），核心步骤：（1）找到字符串的所有子串（2）遍历每个子串，看是否是回文串Brute-force算法的改进，利用回文左右相同的特征，找到所有的中心点，然后向外扩展，再来搜索最长的这样的扩展串，就是最长回文子串。字符串中心点一共有2^n-1个，注意不是n个，因为中心点可能由两个字符组成，例如\"abba\"的中心点是\"bb\"，核心步骤：（1）找到所有中心点（2）遍历中心点，每个中心点向外扩展，直到遇到左右不等的字符（3）记录最大长度的子串再次改进，成为Manacher算法。注意到第二种方法的缺陷：【缺陷1】中心点有奇偶两种，例如位置 i&nbsp;0&nbsp;1&nbsp;23&nbsp;奇字串 s1a&nbsp;b&nbsp;a&nbsp;&nbsp;偶字串 s2ab&nbsp;ba&nbsp;【缺陷2】很多遍历过的子串信息没有利用，例如位置 i&nbsp;0&nbsp;1&nbsp;2&nbsp;34&nbsp;字串 sb&nbsp;e&nbsp;b&nbsp;e&nbsp;b&nbsp;（1）访问s[1]=e，扩展beb；（2）访问s[2]=b，扩展bebeb；（3）访问s[3]=e，扩展beb；访问s[3]的时候，并没有用上s[1]、s[2]的信息，因为既然s1是回文beb，s[2]是回文bebeb，那么有：s[0] = s[2]；s[0] = s[4]；则有：s[2] = s[4]；可以直接推断至少是长度为3的回文s[2,3,4] = beb，这就是Manacher算法的核心思想。【解决1】插入字符解决长度奇偶性的问题在每个字符前后都插入一个特殊字符，要求这个字符不在原来的字符串中出现，例如：位置 i&nbsp;0&nbsp;1&nbsp;2&nbsp;3&nbsp;4&nbsp;5&nbsp;6&nbsp;7&nbsp;8&nbsp;新字符串 ns1#a#&nbsp;b&nbsp;#&nbsp;a&nbsp;#&nbsp;新字符串 ns2#a#b#&nbsp;b#a&nbsp;#&nbsp;原来的奇字符串，变为了偶字符串，然而由于中心的#和b并不相同，因此中心仍然只有1个，为b；原来的偶字符串，变为了奇字符串，中心从bb变为了#。因此，全都转为了1个字符作为中心。【解决2】已得到的回文信息利用Manacher将回文中最左和最右位置的字符与其对称轴的距离（含对称轴）称为回文半径，记为PR，例如：位置 i0&nbsp;1&nbsp;2&nbsp;3&nbsp;4&nbsp;5&nbsp;6&nbsp;7&nbsp;8&nbsp;&nbsp;新字符串 ns2#&nbsp;a&nbsp;#b#&nbsp;b&nbsp;#&nbsp;a&nbsp;#&nbsp;&nbsp;回文半径PR[i]12&nbsp;1&nbsp;2&nbsp;5&nbsp;2121&nbsp;最大长度PR[i]-101&nbsp;0&nbsp;1&nbsp;4&nbsp;1010可以看出，PR[i]-1的最大值就是回文串的最大值，并且如果去掉#，就能得到最长回文子串了，例如以#为中心，扩展5个半径，得到字符串#a#b#b#a#，去掉所有#，得到回文串abba。那么如何快速求解PR呢，利用回文串的对称性，不难发现一些规律：！------- ------ -图图图图疑问和解答1、设置的间隔字符如果字符串中出现了呢？暂时没发现有什么影响……时间复杂度O(n)最坏情况：for语句平均访问每个字符5次，O(n)；最好情况：平均访问每个字符4次，O(n)；详细的见参考文献[2]。空间复杂度O(n)字符串线性，新字符串线性，RL数组线性，因此O(n)。算法伪代码（1）将间隔字符ch插入字符串s，构成新字符串ns；\n（2）初始化最大右坐标maxRight、对称轴midpos、最大回文子串长度maxLen\n（3）FOR i = 1:length(ns)\n         （3.1）IF i&lt;maxRight\n                           PR[i] = min(对称位置PR值，右侧距离)\n                      ELSE\n                           PR[i] = 1\n          （3.2）WHILE 没越界 AND 左右字符相等    \n                           PR[i]  = PR[i] + 1\n          （3.3）IF PR[i]右侧更右\n                           更新MaxRight\n                           更新midpos\n          （3.4）maxLen = max(maxLen，PR[i])\n（4） return maxLen - 1C代码char* Manacher(char* s) &#123;\n  char ns[10000];\n  int i, j;\n  int len, nlen;\n  int maxright, midpos, p,maxPR;\n  int PR[10000];\n  char* as;\n\n  //添加间隔符号  len = strlen(s);  for (i = 0; i &lt; len; i++)&#123;\n  ns[i*2+1] = s[i];\n  ns[(i+1)*2] = &#39;#&#39;;\n  }  ns[0] = ‘#’;   ns[i*2+1] = ‘\\0’;  nlen = strlen(ns);\n  //指针记录  maxright = 0; //最大右坐标  midpos = 0; //对称轴  p = 0; //最大PR坐标  maxPR = 0; //最大PR值\n  //遍历ns求得PR数组  for (i = 0; i &lt; nlen; i++){\n  &lt;font color=&quot;#f9963b&quot;&gt;//比较i和maxright&lt;/font&gt;\n  if (i &amp;lt; maxright)\n      PR[i] = PR[2 * midpos - i]&amp;gt;maxright - i ? maxright - i : PR[2 * midpos - i];\n  else\n      PR[i] = 1;\n  &lt;font color=&quot;#f9963b&quot;&gt;//扩展回文，注意边界&lt;/font&gt;\n  while (i - PR[i] &amp;gt;= 0 &amp;amp;&amp;amp; i + PR[i] &amp;lt; nlen &amp;amp;&amp;amp; ns[i - PR[i]] == ns[i + PR[i]])\n      PR[i]++;\n  &lt;font color=&quot;#f9963b&quot;&gt;//更新maxright、midpos&lt;/font&gt;\n  if (i + PR[i]-1&amp;gt;maxright)&#123;\n      maxright = i + PR[i] - 1;\n      midpos = i;\n  &#125;\n  &lt;font color=&quot;#f9963b&quot;&gt;//更新p和maxPR&lt;/font&gt;\n  if (PR[i] &amp;gt; maxPR)&#123;\n      maxPR = PR[i];\n      p = i;\n  &#125;\n  }\n\n\n&lt;font color=&quot;#f9963b&quot;&gt;//返回回文子串&lt;/font&gt;\nas = (char*)malloc(10000 * sizeof(char));\nj = 0;\nfor (i = p - PR[p]+2; i &amp;lt;= p + PR[p]-2; i+=2)&#123;\n    as[j] = ns[i];\n    j++;\n&#125;\nas[j] = &#39;\\0&#39;;\nreturn as;\n}Java代码Java code三、实战题目相关链接1、LeetCode：最长回文子串2、《LeetCode 第5题：最长回文子串》AC代码char* longestPalindrome(char* s) &#123;    char ls[2002];    int i, j;    int len, llen;    int maxright, midpos, p,maxPL;    int PL[2002];    char* as;    len = strlen(s);\n//添加间隔符号\nfor (i = 0; i &amp;lt; len; i++)&#123;\n    ls[i*2+1] = s[i];\n    ls[(i+1)*2] = &#39;#&#39;;\n&#125;\nls[0] = &#39;#&#39;;\n ls[i*2+1] = &#39;\\0&#39;;\nllen = strlen(ls);\n\n//指针记录\nmaxright = 0;\nmidpos = 0;\np = 0;\nmaxPL = 0;\n\n//遍历ls求得PL数组\nfor (i = 0; i &amp;lt; llen; i++)&#123;\n    //比较i和maxright\n    if (i &amp;lt; maxright)\n        PL[i] = PL[2 * midpos - i]&amp;gt;maxright - i ? maxright - i : PL[2 * midpos - i];\n    else\n        PL[i] = 1;\n    //扩展回文\n    while (i - PL[i] &amp;gt;= 0 &amp;amp;&amp;amp; i + PL[i] &amp;lt; llen &amp;amp;&amp;amp; ls[i - PL[i]] == ls[i + PL[i]])\n        PL[i]++;\n    //更新maxright、midpos\n    if (i + PL[i]-1&amp;gt;maxright)&#123;\n        maxright = i + PL[i] - 1;\n        midpos = i;\n    &#125;\n    //更新p\n    if (PL[i] &amp;gt; maxPL)&#123;\n        maxPL = PL[i];\n        p = i;\n    &#125;\n&#125;\n\nas = (char*)malloc(1001 * sizeof(char));\nj = 0;\nfor (i = p - PL[p]+2; i &amp;lt;= p + PL[p]-2; i+=2)&#123;\n    as[j] = ls[i];\n    j++;\n&#125;\nas[j] = &#39;\\0&#39;;\nreturn as;\n}四、参考文献1、个人博客《Manacher算法》2、SegmentFault《最长回文子串——Manacher算法》                \n","categories":["转载"],"tags":[]},{"title":"Maven简单入门","url":"http://tanqingbo.cn/2019/10/06/Maven简单入门/","content":"\nhttp://www.bewindoweb.com/238.html\n前言相信经历过很久以前初代Java Web开发的程序员都应该有体验，在那个时候是没有Maven这种东西的，每引入一个新功能，就需要手动下载依赖的JAR包导入，还可能和已经导入的JAR包产生冲突。更难受的是，运行的时候抛出异常查半天，到处修改业务代码以为自己写错了，结果发现问题处在JAR包冲突……所以，之前一直在用师兄师姐传承下来的经过多年验证的Jar包组……而有了Maven，所有的JAR包问题都不用担心，可以完全集中精力写逻辑了。当然，管理Jar包只是Maven的其中一个功能，它还可以用来拆分和聚合模块，将整个大项目分成多个独立的模块分别开发，然后自动部署。本文将只注重基础的管理Jar包的基础功能，其他的以后填坑。Maven简单入门Maven读音官方的读法应该是[ˈmevən]，“美ven”，其实“A”也可以读成苹果“apple”的“a”，但千万别读成“马ven”。Maven官网http://maven.apache.org/使用Maven管理JAR包（1）Maven的世界坐标Maven通过：【包名 / groupId】：通常是公司域名反写，如com.bewindoweb.javaweb【项目名 / artifactId】：如webdemo【版本 / version】：如0.0.1-SNAPSHOT三个参数来定位一个Jar包，可以把这三个参数看作是X轴、Y轴、Z轴，一旦参数确定，Jar包也就确定了。很容易理解，如果是你开发的工程打包的Jar包，只要你的公司名确定、项目名确定、项目版本确定，这个工程也就确定了。（2）Maven的快照版本和发布版本我们常常可以看到许多不同的version，但对于Maven来说只有两种版本，一种是快照版本SNAPSHOT，一种是稳定版本RELEASE。识别的标准就一个，只要没有写SNAPSHOT，通通归为RELEASE。例如：1、1.12、1.0.3、2.0-rc1、4.3.5-Final、4.0.3-RELEASE、2.0-beta9等等，虽然字面意思看来，存在软件工程角度的beta测试版、Release Candidate最终测试版，但对于Maven的约定而言，全都是稳定版本。SNAPSHOT什么时候用？就是你内部快速迭代不同功能模块的时候用。例如，我们开发了两个模块A、B，假设B发布的版本是1.0.0-RELEASE，A依赖于B的1.0.0，当B发生了新的修改，那么就必须发布一个1.0.1，A也必须修改B为1.0.1。两个模块还好，如果有100个A呢？如果B只是每次改1行代码，一天提交100个版本呢？所以，在开发期间，活跃的模块应该使用SNAPSHOT。只要采用SNAPSHOT，其他依赖它的模块会自动部署为最新的版本，而无需改变版本号。例如，B发布的版本是1.0.0-SNAPSHOT，B提交更新并部署到仓库后，A只需要重新构建就可以得到最新版本的B，完全不用去改变版本号。但这样会带来一个问题，那就是如果B更改了A依赖的关键代码，A在没有更改自己任何代码的情况下，发现竟然构建失败了，这对于A来说是很诡异的事情。所以，线上一定要采用RELEASE版本。但如果B只提供了SNAPSHOT版本呢？你需要使用versions-maven-plugin插件来将SNAPSHOT固定下来，例如使用之后会将1.0.0-SNAPSHOT变为1.0.0.20181231.123456-1这种时间戳，就可以把SNAPSHOT固定了。（3）Maven解决Jar包冲突有可能会有两个Jar依赖不同版本的相同底层Jar，Maven需要解决Jar包冲突的问题。【方法一】让Maven自己处理。Maven用两个原则处理Jar包冲突。① 第一原则：最短路径优先对于两个依赖关系A→B→C→D（1.0.0-RELEASE）E→D（2.0.0-RELEASE）Maven会选择最短依赖路径E→D，加入D（2.0.0-RELEASE）。② 第二原则：第一原则如果失效，那么最先声明优先对于两个相同长度依赖路径的依赖关系A→D（1.0.0-RELEASE）E→D（2.0.0-RELEASE）Maven会选择最先声明的A→D，加入D（1.0.0-RELEASE）。【方法二】通过exclusions手动处理通过exclusions排除不想要的包，例如：&lt;dependency&gt;\n  &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n  &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;\n  &lt;scope&gt;test&lt;/scope&gt;\n  &lt;exclusions&gt;\n      &lt;exclusion&gt;\n          &lt;groupId&gt;junit&lt;/groupId&gt;\n          &lt;artifactId&gt;junit&lt;/artifactId&gt;\n      &lt;/exclusion&gt;\n  &lt;/exclusions&gt;\n&lt;/dependency&gt;就排除了spring-boot-starter-test中的junit包。（4）scope依赖范围对于Jar包，需要什么范围内才使用，什么范围内不使用，可以使用scope来进行约束。例如前面的spring-boot-starter-test就只会在测试阶段才会被导入。scope取值含义列表如下：scope取值&nbsp;编译阶段&nbsp;测试阶段&nbsp;运行阶段&nbsp;典型Jar&nbsp;&nbsp;compile&nbsp;√&nbsp;√&nbsp;√&nbsp;默认值&nbsp;test&nbsp;&nbsp;√&nbsp;&nbsp;Junit&nbsp;provided&nbsp;√&nbsp;√&nbsp;&nbsp;servlet-api&nbsp;runtime&nbsp;&nbsp;√&nbsp;√&nbsp;JDBC-driver&nbsp;system&nbsp;√&nbsp;√&nbsp;&nbsp;本地jarcompile：默认就是comile，三个阶段均有效。test：一些测试时才会用到的包。provided：一些容器提供的包，编译和测试需要用，但运行不需要。runtime：一些编译不需要的接口之类的包。system：自己手动导入的包。但其实最常使用的就只有test和provided而已。POM文件以上所有的内容都写在pom.xml里，POM的含义是项目对象模型（Project Object Model），只要编写好pom.xml，Maven就会按照你的思路去进行操作了。常见的spring-boot工程pom.xml如下，可以很容易地读懂：&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt;\n  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n  &lt;parent&gt;\n      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n      &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;\n      &lt;version&gt;2.1.2.RELEASE&lt;/version&gt;\n      &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;\n  &lt;/parent&gt;\n\n  &lt;groupId&gt;com.example&lt;/groupId&gt;  &lt;artifactId&gt;demo&lt;/artifactId&gt;  &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;  &lt;name&gt;demo&lt;/name&gt;  &lt;packaging&gt;war&lt;/packaging&gt;  &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;\n  &lt;properties&gt;\n  &amp;lt;java.version&amp;gt;1.8&amp;lt;/java.version&amp;gt;\n  &amp;lt;lombok.version&amp;gt;1.16.10&amp;lt;/lombok.version&amp;gt;\n  &lt;/properties&gt;\n  &lt;dependencies&gt;\n  &amp;lt;dependency&amp;gt;\n      &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;\n      &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt;\n  &amp;lt;/dependency&amp;gt;\n\n  &amp;lt;dependency&amp;gt;\n      &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;\n      &amp;lt;artifactId&amp;gt;spring-boot-starter-test&amp;lt;/artifactId&amp;gt;\n      &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;\n  &amp;lt;/dependency&amp;gt;\n\n  &amp;lt;dependency&amp;gt;\n      &amp;lt;groupId&amp;gt;org.projectlombok&amp;lt;/groupId&amp;gt;\n      &amp;lt;artifactId&amp;gt;lombok&amp;lt;/artifactId&amp;gt;\n      &amp;lt;version&amp;gt;$&#123;lombok.version&#125;&amp;lt;/version&amp;gt;\n  &amp;lt;/dependency&amp;gt;\n  &lt;/dependencies&gt;\n  &lt;build&gt;\n  &amp;lt;plugins&amp;gt;\n      &amp;lt;plugin&amp;gt;\n          &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt;\n          &amp;lt;artifactId&amp;gt;spring-boot-maven-plugin&amp;lt;/artifactId&amp;gt;\n      &amp;lt;/plugin&amp;gt;\n  &amp;lt;/plugins&amp;gt;\n  &lt;/build&gt;\n\n\n&lt;/project&gt;主要就是需要编写dependency，如果你只知道包名，不知道其他信息，你可以通过mvnrepository这个网站来查询，它会提供有哪些版本、每个版本使用情况如何等信息：以及不同的管理工具对应的语法应该怎么写：非常方便。总结这些都是基础的Maven用法，掌握了这些之后写一个Java Web就会很顺利的。如果还想了解更多，可以去了解Parent、import、type、properties中的固定约定、如何手动导入Jar包（不推荐、还是自己使用nexus搭建本地服务器比较好），和前面提到拆分模块等等。另外，如果你还在使用Java 1.7、1.6，或者还在使用eclipse、myeclipse，希望能够尝试一下Java8+、IntelliJ IDEA，你会打开新世界大门的。                \n","categories":["转载"],"tags":[]},{"title":"Moquette源码分析（二）v0.12 订阅树","url":"http://tanqingbo.cn/2019/10/06/Moquette源码分析（二）v0.12 订阅树/","content":"\nhttp://www.bewindoweb.com/270.html一、M12简介Moquette 0.12（以下简称M12）的订阅树实现在moquette-0.12/broker/src/main/java/io/moquette/broker/subscriptions，包括：订阅树版本&nbsp;M10&nbsp;M12&nbsp;&nbsp;订阅树增删改查SubscriptionDirectory&nbsp;CTrieSubscriptionDirectory&nbsp;订阅树&nbsp;-&nbsp;CTrie&nbsp;片段&nbsp;Token&nbsp;Token&nbsp;主题&nbsp;Topic&nbsp;Topic&nbsp;订阅信息&nbsp;Subscription&nbsp;Subscription&nbsp;普通节点&nbsp;TreeNode&nbsp;CNode&nbsp;封装节点&nbsp;-&nbsp;INode&nbsp;墓碑节点&nbsp;-&nbsp;TNode查看源码的时候应该从CTrie开始阅读。二、M12定义为了修复M10的问题，M12提升了很大的数据结构复杂度。细分了三种节点：普通节点：去掉了M10的订阅数量属性，订阅数量通过单独的一次遍历来计算获得&nbsp;封装节点：封装了一个可以原子替换的结构，在被父节点引用不变的情况下，替换掉节点内容墓碑节点：当没有客户端再订阅的时候，用来临时标记需要被移除的节点，然后通过一个独立的CAS替换方法来清理这个墓碑节点。如下图所示是一棵典型的M12订阅树：三、匹配订阅信息过程M12匹配算法和M10类似，递归遍历整棵树，不再赘述。&nbsp;四、增加订阅M10中，增加订阅的时候从根节点开始浅拷贝，然后从第一个没有创建的节点开始创建新节点，最后用CAS替换根节点；M12中，封装了INode，可以让父节点到子节点的指针引用不变，替换子节点的CNode内容，因此去掉了从根节点开始的浅拷贝，直接遍历然后创建节点，算法如下：&nbsp;算法4-1 M12增加节点 \nFUNCTION Action insert（Topic topic, INode inode, Subscription newSubscription）\n  // 弹出第一个token\n  token = topic.headToken\n  // 如果有子节点匹配，递归遍历\n  IF ANY inode.child.token match token\n      RETURN insert(topic.remainingTopic, inode.child.inode, newSubscription)\n  // 如果没有节点，开始创建节点\n  ELSE\n      // 如果遍历完成，说明路径存在，直接加入订阅信息\n      IF topic == EMPTY\n          insertSubscription(inode, newSubscription)\n      ELSE\n          // 递归创建新节点，并且把订阅信息加入叶子节点\n          newSubINode = recursiveCreateINodeAndAddSubscription(topic, newSubscription)\n          // 浅拷贝当前节点，加入新子节点\n          newINode = inode.mainNode.copy().addChild(newSubINode)\n          // 比较并替换当前节点为新节点\n          inode.cas(inode.mainNode, newINode)\nEND例如，现在客户端F增加一个新订阅\"abc/+/123/new1/new2/new3\"，订阅质量为0，我们看看是如何插入的：（1）递归遍历到N5（2）递归创建新节点，并赋值订阅信息（3）浅拷贝当前节点（4）比较并替换（N2永远指向N5，只是新N5替换了旧N5）五、取消订阅取消订阅后仍然有订阅，则只需要更新subscriptions即可，这里也不再叙述。主要描述取消订阅后没有订阅信息的情况。假设A取消订阅“abc/+/123”：（1）遍历到N5，当发现N5没有其他订阅者后，为N5建立一个墓碑节点：（2）建立完成后清理掉这个墓碑节点，浅拷贝一个N2，将N5从children中去掉，并通过CAS将旧N2替换为新N2：六、总结可以看到，M12提升了数据结构复杂度，但降低了逻辑复杂度，并且去掉了重复统计订阅数量的耗时操作，增加了清理工作。很容易看出还是有一些问题：仍然没有区分非通配符订阅和通配符订阅，无论哪种都要遍历一次树“墓碑节点”的设计只能清除最后一个叶子节点，中间节点为空的时候并没有递归清除（比如N2节点已经空了，但没有清除），因为是单向引用，无法向上追溯父节点&nbsp;Moquette现在一直停留在0.12.1版本（2019年3月3日），作者说要优先进行MQTT 5.0的兼容，所以订阅树这块近期都不会再有太多更新了。                \n\n\n","categories":["转载"],"tags":[]},{"title":"MqttWk源码分析（一）：代码结构和初步运行","url":"http://tanqingbo.cn/2019/10/06/MqttWk源码分析（一）：代码结构和初步运行/","content":"\nhttp://www.bewindoweb.com/247.html前言基于MqttWk v1.0.7。&nbsp;&nbsp;MqttWk是我见过最清晰、代码量最少的Broker了，分析其源码有利于初步了解。一、代码结构分析1、整体架构mqtt-auth：验证权限方面的代码mqtt-broker：Broker核心代码mqtt-common：抽象出来的持久化接口mqtt-store：持久化接口的Redis、Kafka实现mqtt-zoo：简单测试代码2、mqtt-auth代码结构验证服务的实现，还有一些验证工具类3、mqtt-broker核心代码结构cluster：集群通信的实现，用的是Redis的发布订阅作消息总线codec：基于Websocket的MQTT通信需要特殊的编解码器，这里是为websocket写的编解码器config：Broker参数配置handler：Broker是基于netty做网络通信的，所以这里是netty连接的核心handlerinternal：内部通信代码（Redis集群通信和kafka转发）protocol：MQTT协议逻辑核心代码server：启动MQTT服务器的代码，主要是MQTT over websocket、MQTT TCP、链路加密SSL等分别启动在不同端口提供服务service：Kafka转发的实现，就是一个ProducerMainLauncher：启动器，基于nutzboot，非常简洁，和Spring的Application启动器一样resources：密钥，参数配置。这里的参数配置是直接properties文件配置，config里的参数配置是基于类的配置，都和Spring的概念一样。protocol：在不同MQTT包发过来的时候，Broker应该做的逻辑操作4、mqtt-commonauth：验证接口message | DupPublish：QoS1/QoS2发布的缓存消息message | DupPubRel：QoS2第二阶段的消息message | MessageId：分布式的MessageId生成。这里做得不太好，所有的messageId都用这个，甚至没有区分不同客户端，更不用说入口和出口分开了。message | RetainMessage：保留消息的存储接口session：会话信息存储，包括clientID、遗嘱消息等等subscribe：订阅信息，实际上是一棵构建于Redis之上的订阅树5、mqtt-storecache：Redis的增删改查实现，值得注意的是将精确订阅主题和通配符订阅主题分开存储了kafka：分区的方式，这里采用按Topic分区，可以分得更均匀，避免热点问题。message：消息存储的实现session：会话存储的实现starter：初始化Kafka存储subscribe：订阅信息存储storeutil：序列化、反序列化工具。因为netty默认的mqtt数据结构没有继承Serializable，序列化会出问题，所以作者自己写了一个。6、mqtt-zookeystore：密钥存储，用于验证mqtt-test-kafka：kafka测试mqtt-test-websocket：websocket连接测试二、初步运行1、安装好本地的单机版Redis，推荐使用Redis Desktop Manager来可视化Redis。2、配置broker-application.properties中的redisredis.host=127.0.0.1\nredis.port=6379\nredis.mode=normal3、运行MainLauncher.javanutzboot会打印参数，这是我最喜欢的一点。4、用mqtt-spy测试注意端口默认8885而不是1883，可以在application.properties里面配置。5、观察Redis存储的内容都是JSON格式的，因为作者使用的FastJson存储。                \n\n\n","categories":["转载"],"tags":[]},{"title":"MqttWk源码分析（四）：订阅树","url":"http://tanqingbo.cn/2019/10/06/MqttWk源码分析（四）：订阅树/","content":"\nhttp://www.bewindoweb.com/251.html前言基于MqttWkv1.0.7。MqttWk没有构建内存中的订阅树，直接利用存储在Redis中的订阅信息来获取订阅者。订阅树算法分析主要的代码在cn.wizzer.iot.mqtt.server.store.subscribe.SubscribeStoreService：@Override\n  public List&lt;SubscribeStore&gt; search(String topic) &#123;\n      List&lt;SubscribeStore&gt; subscribeStores = new ArrayList&lt;SubscribeStore&gt;();\n      List&lt;SubscribeStore&gt; list = subscribeNotWildcardCache.all(topic);\n      if (list.size() &gt; 0) &#123;\n          subscribeStores.addAll(list);\n      &#125;\n      subscribeWildcardCache.all().forEach((topicFilter, map) -&gt; &#123;\n          if (StrUtil.split(topic, '/').size() &gt;= StrUtil.split(topicFilter, '/').size()) &#123;\n              List&lt;String&gt; splitTopics = StrUtil.split(topic, '/');//a\n              List&lt;String&gt; spliteTopicFilters = StrUtil.split(topicFilter, '/');//#\n              String newTopicFilter = \"\";\n              for (int i = 0; i &lt; spliteTopicFilters.size(); i++) &#123;\n                  String value = spliteTopicFilters.get(i);\n                  if (value.equals(\"+\")) &#123;\n                      newTopicFilter = newTopicFilter + \"+/\";\n                  &#125; else if (value.equals(\"#\")) &#123;\n                      newTopicFilter = newTopicFilter + \"#/\";\n                      break;\n                  &#125; else &#123;\n                      newTopicFilter = newTopicFilter + splitTopics.get(i) + \"/\";\n                  &#125;\n              &#125;\n              newTopicFilter = StrUtil.removeSuffix(newTopicFilter, \"/\");\n              if (topicFilter.equals(newTopicFilter)) &#123;\n                  Collection&lt;SubscribeStore&gt; collection = map.values();\n                  List&lt;SubscribeStore&gt; list2 = new ArrayList&lt;SubscribeStore&gt;(collection);\n                  subscribeStores.addAll(list2);\n              &#125;\n          &#125;\n      &#125;);\n      return subscribeStores;\n  &#125;对于普通的精确订阅，直接根据主题名得到对应的订阅者。对于通配符订阅，直接获取所有通配符订阅Topic和订阅者，一个一个比对是否匹配，匹配的话就把订阅者加进去。普通精确订阅正是之前有人提出mosquitto的订阅树优化成Hash表的方法。我惊讶的是通配符订阅直接拉取了所有通配符Topic和订阅者，这个量不会巨大吗。后来仔细想想，设备端的订阅全都是以设备deviceId或者什么唯一标识符的精确订阅，根本不会订阅通配符主题，订阅通配符主题的只有后端服务，因为后端服务才会想要/+/connected这种全局的信息。后端服务总共就那么多，所以这样拉取也不会太多，一个一个遍历时长也能够接受。同时采用Redis做集中存储的好处是，集群不需要同步内存中的订阅树，Redis的单线程保证了并发修改订阅信息不会出现问题。                \n\n\n","categories":["转载"],"tags":[]},{"title":"MqttWk源码分析（二）：BrokerServer","url":"http://tanqingbo.cn/2019/10/06/MqttWk源码分析（二）：BrokerServer/","content":"\nhttp://www.bewindoweb.com/249.html\n前言基于MqttWk v1.0.7。BrokerServer是MqttWk从MainLaucher启动之后执行的第一个类。start()public void start() throws Exception &#123;\n      LOGGER.info(\"Initializing &#123;&#125; MQTT Broker ...\", \"[\" + brokerProperties.getId() + \"]\");\n      channelGroup = new DefaultChannelGroup(GlobalEventExecutor.INSTANCE);\n      channelIdMap = new HashMap&lt;&gt;();\n      bossGroup = brokerProperties.getUseEpoll() ? new EpollEventLoopGroup() : new NioEventLoopGroup();\n      workerGroup = brokerProperties.getUseEpoll() ? new EpollEventLoopGroup() : new NioEventLoopGroup();\n      if (brokerProperties.getSslEnabled()) &#123;\n          KeyStore keyStore = KeyStore.getInstance(\"PKCS12\");\n          InputStream inputStream = this.getClass().getClassLoader().getResourceAsStream(\"keystore/server.pfx\");\n          keyStore.load(inputStream, brokerProperties.getSslPassword().toCharArray());\n          KeyManagerFactory kmf = KeyManagerFactory.getInstance(\"SunX509\");\n          kmf.init(keyStore, brokerProperties.getSslPassword().toCharArray());\n          sslContext = SslContextBuilder.forServer(kmf).build();\n      &#125;\n      mqttServer();\n      if (brokerProperties.getWebsocketEnabled()) &#123;\n          websocketServer();\n          LOGGER.info(\"MQTT Broker &#123;&#125; is up and running. Open Port: &#123;&#125; WebSocketPort: &#123;&#125;\", \"[\" + brokerProperties.getId() + \"]\", brokerProperties.getPort(), brokerProperties.getWebsocketPort());\n      &#125; else &#123;\n          LOGGER.info(\"MQTT Broker &#123;&#125; is up and running. Open Port: &#123;&#125; \", \"[\" + brokerProperties.getId() + \"]\", brokerProperties.getPort());\n      &#125;\n  &#125;1）ChannelGroup和ChannelIdMap是Bean，在全局任意位置可以注入，这里是第一次初始化。2）bossGroup和workerGroup是netty的基本概念，Windows上使用Poll，Linux上可以开启Epoll。3）然后根据具体的情况选择是否需要开启SSL，如果需要，则去构建SSL上下文结构。PKCS12是密钥文件类型，SunX509是最基础的JDK方式，兼容性高，速度较慢；你可以自己编写openSSL的方式。4）mqttServer是TCP方式，websocketServer是websocket方式，两种都支持SSL，但不加密和加密是不能共存的。举个例子，开启了TCP+SSL，则不能直接通过TCP访问了，这一块不是太方便，可以自己修改成4种方式同时支持。IoCBean@IocBean(name = \"channelGroup\")\n  public ChannelGroup getChannels() &#123;\n      return this.channelGroup;\n  &#125;\n\n  @IocBean(name = “channelIdMap”)  public Map&lt;String, ChannelId&gt; getChannelIdMap() &#123;\n  return this.channelIdMap;\n  }这是nutzboot的依赖注入方式，和Spring的Bean一样地去使用就好了。注入采用注解@Inject，和@Autowired/@Resources一样的效果。mqttServer()private void mqttServer() throws Exception &#123;\n  ServerBootstrap sb = new ServerBootstrap();\n  sb.group(bossGroup, workerGroup)\n          .channel(brokerProperties.getUseEpoll() ? EpollServerSocketChannel.class : NioServerSocketChannel.class)\n          // handler在初始化时就会执行\n          .handler(new LoggingHandler(LogLevel.INFO))\n          // childHandler会在客户端成功connect后才执行\n          .childHandler(new ChannelInitializer&amp;lt;SocketChannel&amp;gt;() &#123;\n              @Override\n              protected void initChannel(SocketChannel socketChannel) throws Exception &#123;\n                  ChannelPipeline channelPipeline = socketChannel.pipeline();\n                  // Netty提供的心跳检测\n                  channelPipeline.addFirst(&quot;idle&quot;, new IdleStateHandler(0, 0, brokerProperties.getKeepAlive()));\n                  // Netty提供的SSL处理\n                  if (brokerProperties.getSslEnabled()) &#123;\n                      SSLEngine sslEngine = sslContext.newEngine(socketChannel.alloc());\n                      sslEngine.setUseClientMode(false);        // 服务端模式\n                      sslEngine.setNeedClientAuth(false);        // 不需要验证客户端\n                      channelPipeline.addLast(&quot;ssl&quot;, new SslHandler(sslEngine));\n                  &#125;\n                  channelPipeline.addLast(&quot;decoder&quot;, new MqttDecoder());\n                  channelPipeline.addLast(&quot;encoder&quot;, MqttEncoder.INSTANCE);\n                  channelPipeline.addLast(&quot;broker&quot;, ioc.get(BrokerHandler.class));\n              &#125;\n          &#125;)\n          .option(ChannelOption.SO_BACKLOG, brokerProperties.getSoBacklog())\n          .childOption(ChannelOption.SO_KEEPALIVE, brokerProperties.getSoKeepAlive());\n  if (Strings.isNotBlank(brokerProperties.getHost())) &#123;\n      channel = sb.bind(brokerProperties.getHost(), brokerProperties.getPort()).sync().channel();\n  &#125; else &#123;\n      channel = sb.bind(brokerProperties.getPort()).sync().channel();\n  &#125;\n  }Netty的连接管理就是去配置handler，handler是一条链，所有的接入Netty发送的包都会经过整条链的处理。加在最后的的是核心BrokerHandler，其他的都是一些TCP参数设置等等。SSLEngine是开启SSL的，ClientAuth是表明需不需要双向认证，一般都不需要，然后设置成服务器模式即可。最后通过bind方法绑定服务器域名和端口，就能够对外提供连接服务了。websocketServer()private void websocketServer() throws Exception &#123;\n  ServerBootstrap sb = new ServerBootstrap();\n  sb.group(bossGroup, workerGroup)\n          .channel(brokerProperties.getUseEpoll() ? EpollServerSocketChannel.class : NioServerSocketChannel.class)\n          // handler在初始化时就会执行\n          .handler(new LoggingHandler(LogLevel.INFO))\n          .childHandler(new ChannelInitializer&amp;lt;SocketChannel&amp;gt;() &#123;\n              @Override\n              protected void initChannel(SocketChannel socketChannel) throws Exception &#123;\n                  ChannelPipeline channelPipeline = socketChannel.pipeline();\n                  // Netty提供的心跳检测\n                  channelPipeline.addFirst(&quot;idle&quot;, new IdleStateHandler(0, 0, brokerProperties.getKeepAlive()));\n                  // Netty提供的SSL处理\n                  if (brokerProperties.getSslEnabled()) &#123;\n                      SSLEngine sslEngine = sslContext.newEngine(socketChannel.alloc());\n                      sslEngine.setUseClientMode(false);        // 服务端模式\n                      sslEngine.setNeedClientAuth(false);        // 不需要验证客户端\n                      channelPipeline.addLast(&quot;ssl&quot;, new SslHandler(sslEngine));\n                  &#125;\n                  // 将请求和应答消息编码或解码为HTTP消息\n                  channelPipeline.addLast(&quot;http-codec&quot;, new HttpServerCodec());\n                  // 将HTTP消息的多个部分合成一条完整的HTTP消息\n                  channelPipeline.addLast(&quot;aggregator&quot;, new HttpObjectAggregator(1048576));\n                  // 将HTTP消息进行压缩编码\n                  channelPipeline.addLast(&quot;compressor &quot;, new HttpContentCompressor());\n                  channelPipeline.addLast(&quot;protocol&quot;, new WebSocketServerProtocolHandler(brokerProperties.getWebsocketPath(), &quot;mqtt,mqttv3.1,mqttv3.1.1&quot;, true, 65536));\n                  channelPipeline.addLast(&quot;mqttWebSocket&quot;, new MqttWebSocketCodec());\n                  channelPipeline.addLast(&quot;decoder&quot;, new MqttDecoder());\n                  channelPipeline.addLast(&quot;encoder&quot;, MqttEncoder.INSTANCE);\n                  channelPipeline.addLast(&quot;broker&quot;, ioc.get(BrokerHandler.class));\n              &#125;\n          &#125;)\n          .option(ChannelOption.SO_BACKLOG, brokerProperties.getSoBacklog())\n          .childOption(ChannelOption.SO_KEEPALIVE, brokerProperties.getSoKeepAlive());\n  if (Strings.isNotBlank(brokerProperties.getHost())) &#123;\n      websocketChannel = sb.bind(brokerProperties.getHost(), brokerProperties.getWebsocketPort()).sync().channel();\n  &#125; else &#123;\n      websocketChannel = sb.bind(brokerProperties.getWebsocketPort()).sync().channel();\n  &#125;\n  }websocket多了一些配置，主要是需要从Websocket转到netty的MQTT数据结构，其余都是重复代码。stop()public void stop() &#123;\n  LOGGER.info(&quot;Shutdown &#123;&#125; MQTT Broker ...&quot;, &quot;[&quot; + brokerProperties.getId() + &quot;]&quot;);\n  channelGroup = null;\n  channelIdMap = null;\n  bossGroup.shutdownGracefully();\n  bossGroup = null;\n  workerGroup.shutdownGracefully();\n  workerGroup = null;\n  channel.closeFuture().syncUninterruptibly();\n  channel = null;\n  websocketChannel.closeFuture().syncUninterruptibly();\n  websocketChannel = null;\n  LOGGER.info(&quot;MQTT Broker &#123;&#125; shutdown finish.&quot;, &quot;[&quot; + brokerProperties.getId() + &quot;]&quot;);\n  }标准的关闭方法，会在服务器停止时被调用。通过这些BrokerServer的代码就能够直到代码写得有多清晰简洁了。                \n\n\n","categories":["转载"],"tags":[]},{"title":"OJ刷题目录","url":"http://tanqingbo.cn/2019/10/06/OJ刷题目录/","content":"\nhttp://www.bewindoweb.com/241.html前言【大目标】LeetCode OJ刷完（目前976道题），赛码网BAT试题刷完（需要给自己定时）【计划】1、每周至少5道LeetCode OJ，采用Java语言2、每周进行一次总结，总结所有题型的最佳答案，并学习它们的算法。3、每周五晚上定时赛码网BAT试题一套，采用标准的计时方法。【说明】因为大部分只是刷题，所以不占用博客，放到WIKI，遇到特殊的算法再以单独学习算法的形式写博客。LeetCode OJ刷题目录序号题目相关AnyCodes分享码&nbsp;1两数之和&nbsp;32c36f223&nbsp;2两数相加&nbsp;d376ee224&nbsp;3无重复字符的最长子串&nbsp;826f3f225&nbsp;4寻找两个有序数组的中位数&nbsp;9aafc3226&nbsp;5最长回文子串&nbsp;String.&nbsp;substring30e2fb227&nbsp;6Z字形变换&nbsp;&nbsp;7整数反转&nbsp;String.compareTo511f5f228&nbsp;8&nbsp;字符串转换整数(atoi)&nbsp;&nbsp;9&nbsp;回文数&nbsp;&nbsp;10&nbsp;正则表达式匹配&nbsp;&nbsp;11&nbsp;盛最多水的容器&nbsp;&nbsp;&nbsp;12&nbsp;整数转罗马数字&nbsp;&nbsp;&nbsp;13&nbsp;罗马数字转整数&nbsp;&nbsp;&nbsp;14&nbsp;最长公共前缀&nbsp;&nbsp;&nbsp;15&nbsp;三数之和&nbsp;&nbsp;&nbsp;16&nbsp;最接近的三数之和&nbsp;&nbsp;&nbsp;17&nbsp;电话号码的字母组合&nbsp;&nbsp;&nbsp;18&nbsp;四数之和&nbsp;&nbsp;&nbsp;19&nbsp;删除链表的倒数第N个节点&nbsp;&nbsp;&nbsp;20&nbsp;有效的括号&nbsp;&nbsp;&nbsp;21&nbsp;合并两个有序链表&nbsp;&nbsp;&nbsp;22&nbsp;括号生成&nbsp;&nbsp;&nbsp;23&nbsp;合���K个排序链表&nbsp;&nbsp;&nbsp;24&nbsp;两两交换链表中的节点&nbsp;&nbsp;&nbsp;25&nbsp;k个一组翻转链表&nbsp;&nbsp;&nbsp;26&nbsp;删除排序数组中的重复项&nbsp;&nbsp;&nbsp;27&nbsp;移除元素&nbsp;&nbsp;&nbsp;28&nbsp;实现strStr()&nbsp;&nbsp;&nbsp;29&nbsp;两数相除&nbsp;&nbsp;&nbsp;30&nbsp;串联所有单词的子串&nbsp;&nbsp;试题刷题目录序号&nbsp;公司题目相关AnyCodes分享码&nbsp;1百度&nbsp;2016实习：乘法表&nbsp;&nbsp;2百度&nbsp;&nbsp;2016实习：编号转换&nbsp;&nbsp;3百度&nbsp;&nbsp;2016实习：XML文档&nbsp;&nbsp;4百度&nbsp;&nbsp;2017秋招真题：度度熊找子串&nbsp;&nbsp;&nbsp;5百度&nbsp;2017秋招真题：十字架&nbsp;&nbsp;                \n\n\n","categories":["转载"],"tags":[]},{"title":"OTG外接移动硬盘会巨量耗电","url":"http://tanqingbo.cn/2019/10/06/OTG外接移动硬盘会巨量耗电/","content":"\nhttp://www.bewindoweb.com/141.html魅蓝手机烧掉了，于是换成小米5X了，今天本来想用OTG+MicroUSB转USBTypeC的转接头把U盘接入手机，然而发现不行。于是直接用OTG插入小米平板（一代的，是MicroUSB），接U盘，连接上了，但是发现文件管理器找不到入口……查的过程中看到有人接过移动硬盘，想试试，居然接上了移动硬盘！！而且能读取内容！！兴奋完了后，再玩了会平板，突然提示没电……刚打开不是满电的吗……怀疑接入移动硬盘耗电，查了下发现果然是，需要分线器再接个电源……不过我没看到掉电的过程，下次再试试，把过程记录下来，嘻嘻。                \n\n\n","categories":["转载"],"tags":[]},{"title":"PHP将汉字字符串转换为数组","url":"http://tanqingbo.cn/2019/10/06/PHP将汉字字符串转换为数组/","content":"\nhttp://www.bewindoweb.com/135.html一、教程内容想要将“日常歌单”几个字变为\"日 / 常 / 歌 / 单”，然而直接用explode(\"\",\"日常歌单\")返回false，用preg_replace(\"//\",\"/ \\/ /\",\"日常歌单\")也不行，分割中文会出错，因为编码不一样长。于是需要自己做相应的函数。关键点：mb_strlen、mb_substr1、mb_strlen：mixed mb_strlen ( string $str [, string $encoding = mb_internal_encoding() ] )使用mb_strlen(\"xxxx\",\"utf-8\")会使得中文长度按1计算而不是3，例如：$str='日常a歌1单';  \necho strlen($str);//14  \necho mb_strlen($str,'utf8');//62、mb_substr：string mb_substr ( string $str , int $start [, int $length = NULL [, string $encoding = mb_internal_encoding() ]] )按照字符编码多字节安全地截取字符，例如：$str='日常a歌1单'; \necho mb_substr($str,0,4,'utf-8');//截取头5个字，【日常a歌1】3、思路因此，可以先计算长度，然后一个for循环一次截取每个字符，再加入数组，最后implode（或者在截取后马上进行拼接）二、具体操作function str2arr_utf8($str)\n  &#123;\n      $len = mb_strlen($str, 'utf-8');\n      $arr = [];\n      for ($i=0; $i&lt;$len; $i++)\n          $arr[] = mb_substr($str, $i, 1, 'utf-8');\n      return $arr;\n  &#125;                \n\n\n","categories":["转载"],"tags":[]},{"title":"PyCharm汉化","url":"http://tanqingbo.cn/2019/10/06/PyCharm汉化/","content":"\nhttp://www.bewindoweb.com/170.html一、内容简介安装PyCharm汉化包的汉化方法二、具体操作1、下载汉化包resources_cn.jar百度网盘（密码&nbsp;pe5o）2、将汉化包放入Pycharm的lib文件夹例如：E:\\PyCharm 2016.3.2\\lib注意，可以和其他的共存，比如原先有resources.jar和resources_en.jar，直接把resources_cn.jar复制进去就好。3、重启PyCharm重启后可以看到汉化效果了。                \n\n\n","categories":["转载"],"tags":[]},{"title":"QQ三国.pkg文件解析","url":"http://tanqingbo.cn/2019/10/06/QQ三国.pkg文件解析/","content":"\nhttp://www.bewindoweb.com/252.html一、.pkg文件格式.pkg是很多游戏的通用资源打包格式，在QQ的所有游戏都能够见到它的身影，像QQ三国、QQ堂之类。最近还在有小伙伴问我答题器是怎么做的。答题器就只是从数据库查找文本而已，数据就是从pkg文件里提取出来的。解析pkg文件需要知道它的原始格式，pkg文件格式如下：分为Header、Data、Meta三部分：Header：4字节固定标志，4字节文件数，4字节Meta位置偏移，4字节Meta长度Data：所有资源文件的压缩数据Meta：是一个列表，每个项包含文件名长度、文件名、固定识别标志、文件偏移、文件原始大小、文件压缩大小我们可以通过Meta偏移找到Meta列表开始的地方，遍历Meta列表，用文件偏移+文件压缩大小从Data区获取压缩数据，然后利用zlib进行解压就得到原始数据了。二、解压python代码在他人的轮子上改造，基于python3：# -*- coding: utf-8 -*-\n\n\n\nimport os, struct, zlib\nif name == “main“:    pkgfilename = r”H:\\update.pkg”    outdirname = r”H:\\update”    pkgfile = open(pkgfilename, ‘rb’)    pkgfile.read(4)    filenums, = struct.unpack(‘I’, pkgfile.read(4))    filename_table_offset, = struct.unpack(‘I’, pkgfile.read(4))    filename_table_len, = struct.unpack(‘I’, pkgfile.read(4))    pkgfile.seek(filename_table_offset)    for index in range(filenums):        name_len, = struct.unpack(‘H’, pkgfile.read(2))        name = pkgfile.read(name_len)        pkgfile.read(4)        offset, = struct.unpack(‘I’, pkgfile.read(4))        size, = struct.unpack(‘I’, pkgfile.read(4))        zlib_size, = struct.unpack(‘I’, pkgfile.read(4))        current_pos = pkgfile.tell()        pkgfile.seek(offset)        text = pkgfile.read(zlib_size)        text = zlib.decompress(text)        pkgfile.seek(current_pos)        outfilename = os.path.join(outdirname, os.path.join(os.path.splitext(os.path.basename(pkgfilename))[0], str(name, encoding=”utf-8”)))        print(u’进度 [%d/%d]: ‘ % (index + 1, filenums),              os.path.join(os.path.splitext(os.path.basename(pkgfilename))[0], str(name, encoding=”utf-8”)))        if not os.path.exists(os.path.dirname(outfilename)):            os.makedirs(os.path.dirname(outfilename))        open(outfilename, ‘wb’).write(text)三、能得到什么数据可以得到图像、文本等数据，例如答题的数据：四、压缩python代码当修改完数据后，需要重新压缩成pkg文件。这里在他人的轮子上改造，基于python3：# -- coding: utf-8 --import zlib, os, struct\nfilelist = []\nclass FileVisitor:    def init(self, startDir=os.curdir):        self.startDir = startDir    def run(self):        for dirname, subdirnames, filenames in os.walk(self.startDir, True):            for filename in filenames:                self.visit_file(os.path.join(dirname, filename))    def visit_file(self, pathname):        filelist.append(&#123;‘filename’:pathname, ‘size’:0, ‘zlib_size’:0, ‘offset’:0, ‘relative_filename’: pathname.replace(os.path.normpath(self.startDir)+os.sep, ‘’)&#125;)\nif name == “main“:    source_dirname = r”H:\\update”    out_filename = r”H:\\test.pkg”    FileVisitor(source_dirname).run()    total = len(filelist)    fp = open(out_filename + ‘~’, ‘wb’)    fp.write(‘\\x64\\x00\\x00\\x00’.encode())    fp.write(struct.pack(‘I’, len(filelist)))    fp.write(struct.pack(‘I’, 0))    fp.write(struct.pack(‘I’, 0))    offset = 16    for index in range(total):        item = filelist[index]        item[‘offset’] = offset        infile = open(item[‘filename’], ‘rb’)        text = infile.read()        infile.close()        item[‘size’] = len(text)        text = zlib.compress(text)        item[‘zlib_size’] = len(text)        fp.write(text)        offset += item[‘zlib_size’]        print(u’已压缩文件 %d/%d’ % (index + 1, total))    filename_table_offset = offset    for index in range(total):        item = filelist[index]        fp.write(struct.pack(‘H’, len(item[‘relative_filename’])))        fp.write(item[‘relative_filename’].encode())        fp.write(‘\\x01\\x00\\x00\\x00’.encode())        fp.write(struct.pack(‘I’, item[‘offset’]))        fp.write(struct.pack(‘I’, item[‘size’]))        fp.write(struct.pack(‘I’, item[‘zlib_size’]))        offset += 2 + len(item[‘relative_filename’]) + 16        print(u’已输出路径 %d/%d’ % (index+1, total))    filename_table_len = offset - filename_table_offset    fp.close()\nfp = open(out_filename + &#39;~&#39;, &#39;rb&#39;)\nret = open(out_filename, &#39;wb&#39;)\n\nfp.read(16)\nret.write(&#39;\\x64\\x00\\x00\\x00&#39;.encode())\nret.write(struct.pack(&#39;I&#39;, len(filelist)))\nret.write(struct.pack(&#39;I&#39;, filename_table_offset))\nret.write(struct.pack(&#39;I&#39;, filename_table_len))\n\ncopy_bytes = 16\ntotal_bytes = offset\nwhile True:\n    text = fp.read(2**20)\n    ret.write(text)\n    copy_bytes += len(text)\n    print(u&#39;最后的拷贝 %d%%&#39; % (copy_bytes * 100.0 / total_bytes))\n    if not text:\n        break\nfp.close()\nret.close()\nos.remove(out_filename + &#39;~&#39;)&lt;/code&gt;&lt;/pre&gt;&lt;h1&gt;&lt;span style=&quot;font-size: 20px; font-weight: bold;&quot;&gt;五、注意事项&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;仅作为技术交流和娱乐，请勿用于非法用途。&lt;/p&gt;&lt;h1&gt;参考资料&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/feisuzhu/article/details/83986445&quot; target=&quot;_blank&quot;&gt;《腾讯游戏中的yxs.pkg文件格式》&lt;/a&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/safjhgj/article/details/49202383&quot; target=&quot;_blank&quot;&gt;《pkg文件--一种简单的游戏资源打包格式》&lt;/a&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://yq.aliyun.com/articles/228340/&quot; target=&quot;_blank&quot;&gt;《QQ游戏的PKG格式文件解压工具》&lt;/a&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;                &lt;/div&gt;\n","categories":["转载"],"tags":[]},{"title":"SSL v3.0 安全问题：POODLE漏洞实操","url":"http://tanqingbo.cn/2019/10/06/SSL v3.0 安全问题：POODLE漏洞实操/","content":"\nhttp://www.bewindoweb.com/272.html��言各大浏览器、操作系统都屏蔽掉了SSLv2.0、SSLv3.0，原因是“不安全”，我们来分析SSL v3.0为什么不安全。一、 POODLE简介2014年9月Google的一份研究报告《This POODLE Bites: Exploiting The SSL 3.0 Fallback》指出，SSL存在安全漏洞CVE­-2014-3566，代号为POODLE（Padding Oracle On Downgraded Legacy Encryption，基于降级旧加密协议的填充提示），该漏洞可以使得攻击者获取到一段明文数据，比如HTTP的cookie，且除了完全禁用SSL，或者利用TLS_FALLBACK_SCSV字段禁止协议降级到SSL，没有其他更好的手段可以防御。二、Padding Oracle 攻击原理Padding Oracle是Web程序渗透的经典攻击方式，由Juliano Rizzo和Thai Duong于2010年《Practical Padding Oracle Attacks》提出，该攻击利用CBC（Cipher-block chaining，密码块链接模式）加密模式中的填充漏洞给出的提示信息逐步推导出明文数据。2.1 CBC密码块链接模式——加密（1）对明文进行分组，每组长度相同（一般为8字节或16字节），对长度不足的分组需要进行填充（Padding）。填充通常遵循的是PKCS5标准，即填充的字符是需要填充字符的个数。例如，这里的明文字符串为“GET /a HTTP/1.1\\r”，那么按ASCII的十六进制就可以表示为：第一组明文：“0x47、0x45、0x54、0x20、0x2F、0x61、0x20、0x48”第二组明文：“0x54、0x54、0x50、0x2F、0x31、0x2E、0x31、0x0D”假设后面还有字符不能构成8字节的一组，那么需要进行填充，例如（前面字符没有用十六进制表示）：当然，一般不会有全填充的组。（2）随机生成一个初始化向量IV，与第一个明文分组进行异或运算得到中间值（Intermediary Value）。例如这里随机生成的IV为“0x01、0x02、0x03、0x04、0x05、0x06、0x07、0x08”，与第一个分组“0x47、0x45、0x54、0x20、0x2F、0x61、0x20、0x48”进行异或后得到“0x46、0x47、0x57、0x24、0x2A、0x67、0x27、0x40”。（3）将异或结果进行加密，得到第一个明文分组的密文。一般会使用密钥（key）加密，这里简单假设密钥加密效果等同于加密函数y = f(x) = x + 1，那么可以得到第一组密文“0x47、0x48、0x58、0x25、0x2B、0x68、0x28、0x41”。（4）从第二个明文分组开始，将上一组密文当作IV，进行异或运算，再进行加密，得到该组密文。例如这里由第一组密文“0x47、0x48、0x58、0x25、0x2B、0x68、0x28、0x41”与第二组明文“0x54、0x54、0x50、0x2F、0x31、0x2E、0x31、0x0D”进行异或，得到“0x13、0x1C、0x08、0x0A、0x1A、0x46、0x19、0x4C”，再进行相同加密，得到“0x14、0x1D、0x09、0x0B、0x1B、0x47、0x1A、0x4D”，这就是第二组密文。2.2 CBC密码块链接模式——解密加密的IV是随机生成的，而解密则必须使用这个IV。（1）对密文进行分组，每组长度相同（一般为8字节或16字节）。例如这里将密文分为了两组：第一组密文：“0x47、0x48、0x58、0x25、0x2B、0x68、0x28、0x41”第二组密文：“0x14、0x1D、0x09、0x0B、0x1B、0x47、0x1A、0x4D”（2）对密文进行解密，得到中间值。一般使用密钥，同样的这里假设密钥效果等同于函数x = f(y) = y - 1第一组中间值：“0x46、0x47、0x57、0x24、0x2A、0x67、0x27、0x40”第二组中间值：“0x13、0x1C、0x08、0x0A、0x1A、0x46、0x19、0x4C”（3）使用初始化向量IV，与第一个分组进行异或运算得到第一组明文。这是利用异或的性质：a⊕b=c，a⊕c=b，b⊕c=a，所以无论如何异或都能得到唯一的第三个数。例如这里IV为“0x01、0x02、0x03、0x04、0x05、0x06、0x07、0x08”，第一个数0x01与第一组第一个中间值0x46异或结果为0x47，就是明文“G”的ASCII十六进制表示，于是得到第一组明文“0x47、0x45、0x54、0x20、0x2F、0x61、0x20、0x48”（4）从第二组开始，依次将前一组密文和该组中间值异或，得到该组明文。例如第一组密文“0x47、0x48、0x58、0x25、0x2B、0x68、0x28、0x41”和第二组中间值“0x13、0x1C、0x08、0x0A、0x1A、0x46、0x19、0x4C”异或得到第二组明文“0x54、0x54、0x50、0x2F、0x31、0x2E、0x31、0x0D”。值得注意的是，解密可以并行计算，因为密文都是已经获取好的；加密则不行，因为前一组密文必须要计算出来。2.3 Padding Oracle 攻击现在假设密文仍然是上述字段“GET /a HTTP/1.1\\r”，且用户连接到的是公共WIFI，攻击者可以通过抓包获取CBC密文以及初始化向量IV（当然要把IV明文传给服务器否则服务器无法解密第一个分组）。我们现在希望通过密文和IV获取明文，由于“IV⊕中间值=明文”，问题转变为如何求IV对应的中间值。我们知道，对大多数Web服务器而言：如果参数解密成功，且数据合法，返回HTTP 200 OK，提示成功如果参数解密成功，但数据非法，返回HTTP 200 OK，提示非法，或Rest风格接口会返回HTTP 400 Bad Request，提示非法如果参数解密失败，服务器将抛出异常，返回HTTP 500 Internal Server Error这给攻击者提供了判断依据：如果提示HTTP 200或HTTP 400，说明解密成功；如果提示HTTP 500，说明解密失败。IV出现在解密的最后一步，而且是可以构造的，那么攻击者可以通过构造特殊的IV，直到符合“填充”规则通过解密流程（虽然不一定能通过数据合法性校验），具体而言：（1）构造“0x00、0x00、0x00、0x00、0x00、0x00、0x00、0x00”的特殊IV发送给服务端，不断尝试递增最后一位并发送给服务端，直到服务端解密成功。此时必然产生了1位填充（因为我们已经知道IV是0x01、0x02、0x03、0x04、0x05、0x06、0x07、0x08），最多尝试次数为256次。（2）计算出末位中间值，其值等于伪造向量末位异或0x01：0x41⊕0x01=0x40（3）利用原始向量末位值异或中间值，得到明文0x48，即字符“H”：0x40⊕0x08=0x48（4）利用中间值计算出末位为0x02的伪造向量应有值：0x40⊕0x02=0x42（5）通过改变倒数第二位，直到生成0x020x02的末位明文填充字符，符合2位填充规则，然后类似地推测倒数第二位的中间值：重复上述步骤，就能够���到完整的明文信息，这就是Padding Oracle 填充提示攻击。三、POODLE攻击原理3.1 SSLv3.0存在的问题SSLv3.0的记录层可以使用如下加密方式：&nbsp;加密类型&nbsp;&nbsp;加密方式&nbsp;块加密 Block Cipher&nbsp;IDEA&nbsp;&nbsp;块加密 Block Cipher&nbsp;RC2-40&nbsp;块加密 Block Cipher&nbsp;DES-40&nbsp;块加密 Block Cipher&nbsp;DES&nbsp;块加密 Block Cipher&nbsp;3DES&nbsp;块加密 Block Cipher&nbsp;FORTEZZA&nbsp;流加密 Stream Cipher&nbsp;RC-40&nbsp;流加密 Stream Cipher&nbsp;RC4-128流加密这里不讨论，也是有安全问题，主要讨论CBC块加密。SSL记录层加密的是原始数据+MAC（消息验证码）信息摘要+填充字节，MAC一般是Hash值，SSLv3.0中MAC通常为20字节。也就是说，SSL先对数据做完整性校验，再进行CBC加密。在CBC解密的一端（服务器），SSL没有规定padding填充块字节内容，只校验填充块最后一个字节，该字节为填充长度，然后去掉填充的字符，再进行MAC验证，最后获得明文数据。先校验完整性，再加密，使得对端收到数据后先解密，后校验完整性，解密是否成功为攻击提供了判断依据；只验证填充块的最后一个字节，因此填充块可以填充任意字符，且最后字符固定使得攻击者可以利用类似Padding Oracle的攻击机制。我们可以利用类似前面Padding Oracle的思路，将要解密的字符放到最后一个块末尾，不断地调整前一个IV的值（可能是初始化向量，也可能是前一段的密文，并且无论是哪个攻击者都是知道的），直到成功通过解密，此时明文必定为0x07或0x15（16字节一块的话），最多尝试256次（或512次），就能够通过服务器验证，从而推导出对应的中间值，然后利用该中间值和IV推导出明文。这期间不用担心修改IV导致MAC校验失败，因为那是CBC解密之后的事情。3.2 利用SSL漏洞进行POODLE攻击假设攻击者B代理了客户端A的HTTPS访问服务器C的请求，可以截获到SSL密文数据以及SSL握手阶段的IV，且可以通过A去发送HTTPS请求，此时如果A没有退出登录，都会自动携带上Cookie。这样，B可以控制A发送的HTTP请求中的请求路径Path和请求体Body，并通过调整Path和Body，让A发出的请求满足两个条件：填充字段恰好填充了一个块长度Cookie的第一个未知字符刚好出现在前面某个块的末尾例如，加密采用3DES，8字节一个块，且SSL上层为HTTP协议，发送的明文为：GET / HTTP/1.1\\r\\nCookie: abcdefgh \\r\\n\\r\\nXXXX MAC数据 XXXXXX7MAC数据可能并不是刚好8字节，不过无所谓。攻击者并不知道明文，但知道Cookie密文的位置，知道此时想要解密的cookie的最后一个字符在第4个块末尾。然后攻击者将整个块的密文复制到最后一个填充块密文上：然后不断调整前一块（MAC数据）对应密文位置的值，直到通过解密校验，根据SSL的漏洞，此时最后一块最后一个值必然为0x07：这里例子举得不好，0x07密文也是0x07，后面用0x07明、0x07密来区分，此时我们假设未知加密函数为f(x)，其逆为g(y)，那么根据CBC���密流程，有：0x07明 = g(0x07密) ⊕  0x01  =&gt; g(0x07密) = 0x06现在要求：x = 0x6E ⊕ g(0x07密）因此x = 0x68，即字符\"h\"，得到解密明文\"h\"。同理，通过控制请求路径，例如GET /a、GET /aa，不断地把已经解密的Cookie字符挤出，把未知字符留在该块末尾，然后循环进行前述操作，即可得到完整的Cookie字段。3.3 Padding验证和MAC验证返回结果不同的情况前面的操作都是建立在Padding验证和MAC验证返回结果不同的基础之上，如果返回结果相同，那么MAC会校验不过导致失去判断Padding验证成功的依据。此时攻击者需要利用响应时间的差异来进行判断。如果响应时间仍然相同，那么这种攻击就无效了。​3.4 POODLE中“降级”的体现POODLE只在SSLv3.0以下版本才容易攻击成功，TLS会检查填充字符，所以TLS构造的padding通过服务器验证概率极低，TLSv1.3以后则完全避免了该漏洞。2014年，TLS已经得到广泛应用，但不乏少数服务器、客户端（比如IE6）和中间网络设备仍然采用SSL协议。因此为了平滑过渡增加用户体验，TLS1.2、TLS1.1、TLS1.0协议实现都会向后兼容SSLv3.0协议，最终协商通信协议为服务端和客户端支持的最高版本协议。如果记录协议中采用的是RC4流加密或者CBC模式的块加密，那么攻击者就可以进行POODLE攻击。参考资料1、《Web狗要懂的Padding Oracle攻击》：很详细2、《Padding Oracle》3、《百度百科：Padding Oracle》4、《ASCII表》和在线异或计算器：便于实验5、《HTTPS 协议降级攻击原理》：对攻击原理理解透彻6、《CVE-2014-3566 SSLv3 POODLE原理分析 – insight-labs》：有些许理解错误，注意辨别7、《POODLE attacks on SSLv3 (14 Oct 2014)》：英文原文例子8、《漏洞分析---SSLv3降级加密协议Padding Oracle攻击（POODLE）技术分析》：例子详细9、《SSLv3 POODLE 攻击分析》：最正确的一篇分析10、《This POODLE Bites: Exploiting The SSL 3.0 Fallback》：Google研究报告原文                \n\n\n","categories":["转载"],"tags":[]},{"title":"ShadowSocks使用体验","url":"http://tanqingbo.cn/2019/10/06/ShadowSocks使用体验/","content":"\nhttp://www.bewindoweb.com/219.html前言之前一直使用搬瓦工+SSR，然而发现总是被封……无论修改什么参数，或者是深入地理解原理，仍然会被抓到。后来总算被同学点醒，和SSR无关，和服务器IP有关啊。每次被Q后我都使用它的5周免费更换IP功能来更换新的IP，逐渐发现这种更换IP只是更换了最后几位，如果GFW按照IP的规则来进行过滤，判断是不是搬瓦工的服务器IP地址段，当然就会被抓到了（只是猜测）。所以趁着这次搬瓦工解封+双11打折购买了同学之前使用过的一直没有被封的ShadowSocks——它直接以这个协议来命名的网站。购买地址ShadowSocks（嗖嗖搜里有）条件准备由于ShadowSocks网站也是被Q的，所以需要有一个基础的梯子来访问网站。价格、功能和体验产品版本选择一共有5个版本：版本&nbsp;价格&nbsp;同时连接&nbsp;流量节点&nbsp;入门版19.95AUD（100.28元）/年&nbsp;1台设备50GB9台基础&nbsp;高级版79.95 AUD（401.87元）/年&nbsp;5台设备50GB9台基础3台高级&nbsp;旗舰版9.95 AUD（50.01元）/月&nbsp;5台设备50GB9台基础4台高级4台旗舰&nbsp;IPv6 Only19.95 AUD（100.28元）/年&nbsp;5台设备50GB8台基础只支持IPv6&nbsp;商业版499.95 AUD（2513元）/年&nbsp;1000台设备无限中港专线10M独享带宽30M公共带宽我选择的是入门版，双11折扣30%，只花了13.96 AUD（70元）。支付方式支持支付宝和微信扫码，以及其他的正常支付方式。使用体验是已经配置好的服务器，相当于购买服务而已，并不会像搬瓦工或者Linode一样给你一台虚拟机。不过好处在于，如果发生问题可以提交工单，不用自己处理了。周期是按照强制的月来算的，而不是购买的日期：但是续费的日期是按照购买日期来算的，非常良心：节点选择入门版有9个基础节点可以选择：它的服务器IP全都是域名，而不是点分数字串，这样一来如果它的服务发现被Q了，更换新IP，这边客户端不需要做任何操作。开始没有理解这个流量倍率���什么参数，以为是拥挤程度，选择了香港3服务器，结果网速200kb/s，非常慢。然后使用网站测速工具测速发现：节点&nbsp;流量倍率&nbsp;PING值&nbsp;&nbsp;香港1&nbsp;1.00&nbsp;199ms&nbsp;香港3&nbsp;0.01&nbsp;300ms&nbsp;日本1&nbsp;1.50&nbsp;40ms&nbsp;俄罗斯&nbsp;1.20&nbsp;100ms明显的反比关系，所以服务器选择流量倍率最高的速度最快，经测试2M/s是没问题的（看视频不会卡）。小米手机的菜单栏可以非常方便地配置开关：相关下载shadowsocks4.6.1.apk（密码 c2rc ）                \n\n\n","categories":["转载"],"tags":[]},{"title":"Steam和暴雪账户被盗记","url":"http://tanqingbo.cn/2019/10/06/Steam和暴雪账户被盗记/","content":"\nhttp://www.bewindoweb.com/146.htmlSteam从2017.2.27号开始陆续被输入正确密码异地登录，登录地点都是印度尼西亚啥的，但是没有对我造成影响，也就没改密码。两个月一登，不知道被登上来干什么，我就买了两个游戏，也没充钱在里面，今天不想忍了，又被登录了，改密码好了……想起暴雪那个帐号也是，为了玩炉石注册的，后来发现打不过RMB玩家就没玩了，然而从2017.5.27开始（当时还没有中那个脚本病毒，所以肯定不是那个病毒干的）一直被提示验证码。今天凌晨又发了一封，干脆一起改密码好了。用原来的密码登录上去，发现马上发了一封一模一样的邮件：网页端的提示是：说明被成功登录过，才会发这种邮件验证。气死爸爸了，看来这个密码已经泄露了，被各种地方登录，以后不再用了—— 几乎���充钱玩家的抗议。但是，我想不通是从哪里泄露出去的，如果下次还发这种邮件再看看吧。                \n\n\n","categories":["转载"],"tags":[]},{"title":"TCP的KeepAlive机制","url":"http://tanqingbo.cn/2019/10/06/TCP的KeepAlive机制/","content":"\nhttp://www.bewindoweb.com/262.html前言了解TCP的KeepAlive机制有利于服务器调参。TCP的KeepAlive没错，和想象的一样，通过“心跳包”来检查链路是否连通，但在标准的TCP规范中，并没有保活的强制性要求。传输层KeepAilve缺点在传输层做保活有很多缺点：（1）如果中间链路出现短暂的差错（比如某个路由器重启），可能会使得一个非常好的链路被释放掉（2）心跳包耗费了不必要的带宽，增加了流量费用（3）在一些复杂的网络环境下（比如某些网络不响应不带数据的报文），TCP保活机制可能会失效。TCP的KeepAlive机制描述但事实上，许多实现都提供了KeepAlive的功能（默认关闭）。&nbsp;&nbsp;如果一个给定的连接在7200秒（2小时）内没有任何动作，那么服务器就向客户端发送一个探查报文段，此时客户机可能处于如下状态：（1）客户端正常运行，并可达。客户端响应一个报文，服务端收到报文后知道客户端是正常工作的，则将保活定时器复位，2小时后再次触发。此时间段内如果有任何应用报文通信，都会不断重置定时器的下次探测时间。（2）客户端崩溃，已经关闭或者正在重启中。此时服务器收不到任何响应，75秒后，服务端将再次发送探查报文，一共会尝试10次探测报文的发送（包括第一次），每次间隔75秒，直到客户端回复响应或者达到10次。如果客户端都没有恢复，则服务端认为客户端已经关闭并终止连接。（3）客户端崩溃并重启完成。此时服务器会受到客户端的响应，但这个响应是一个复位，使得服务端终止这个连接。（4）客户端正常运行，但不可达。对服务器来说，处理方式和（2）一致。传输层KeepAlive优点（1）在应用层做KeepAlive是最好的事情，但会增加应用开发的设计心跳包复杂度。如果配置传输层就能够检测是否断开连接，应用层似乎就不用写心跳代码了。（2）传输层的报文更小Connection reset by peer当出现情况（3）的时候，任意一端宕机恢复，由于不知道之前的连接信息，所以当之前的连接发过来一条保活探测，就会回送一个复位响应。这个响应将使得对端产生报错，例如：read error: Connection reset by peer在使用jmeter进行服务器压力测试中，也会经常看到connection reset by peer，但这个复位报文通常不是保活探测造成的，而是在TCP三次握手后，服务器Accept达到了最大值，直接拒绝连接产生的RST报文。keepalive参数的修改带来变化tcp_keepalive_time 保活探测时间：默认2小时。越长，则探测到链路断开的敏感度越低；越短，可能在保活上耗费大量带宽。tcp_keepalive_intvl 重发探测报文间隔时间：默认75秒。越长，非法关闭的链路占用资源时间越长；越短，等不到客户端恢复，重试失去意义。tcp_keepalive_probes 重发探测报文次数：默认9次。越多，非法关闭的链路占用资源时间越长；越少，可能只是网络波动就毁掉了一条很好的链路。为什么协议制定者把探测时间设定为默认2小时，就是为了弱化TCP保活的作用，强迫开发者尽可能在应用层做保活。Linux的TCPkeepalive参数配置查看Linux的TCP配置默认值：7200秒探测一次、未响应重试9次（一共10次）、重试时间间隔75秒。修改配置：# 查询保活探测时间\ncat /proc/sys/net/ipv4/tcp_keepalive_time\n# 修改\nsysctl net.ipv4.tcp_keepalive_time=3600\n\n\n\n查询重试间隔时间cat /proc/sys/net/ipv4/tcp_keepalive_intvl\n修改sysctl net.ipv4.tcp_keepalive_intvl=5\n查询重试次数cat /proc/sys/net/ipv4/tcp_keepalive_probes\n修改sysctl net.ipv4.tcp_keepalive_probes=3或者修改/etc/sysctl.conf：net.ipv4.tcp_keepalive_time=7200net.ipv4.tcp_keepalive_intvl=75net.ipv4.tcp_keepalive_probes=9然后立即生效：# 立即生效sysctl -p\n查看当前配置sysctl -a | grep keepaliveNetty设置TCPkeepalive网络通信必学的Netty，提供了.option的方式配置tcp参数：ServerBootstrap sb = new ServerBootstrap();sb.group(bossGroup, workerGroup)     .channel(socketChannelClazz)     .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123;                    ………………      &#125;)     .childOption(ChannelOption.SO_KEEPALIVE, true);ChannelFuture f = sb.bind(host, port);f.sync().addListener(FIRE_EXCEPTION_ON_FAILURE);同时，可以利用Netty的Handler来做应用层的心跳包：// 60秒没有read、write就触发idle事件channel.pipeline().addFirst(\"idleStateHandler\", new IdleStateHandler(60, 0, 0));// 再用一个Handler去检查idle事件，清理资源，断开连接 @Override    public void userEventTriggered(ChannelHandlerContext ctx, Object evt)&#123;        if(evt instanceof IdleStateEvent)&#123;           .................        &#125;    &#125;                \n","categories":["转载"],"tags":[]},{"title":"code-prettify效果测试","url":"http://tanqingbo.cn/2019/10/06/code-prettify效果测试/","content":"\nhttp://www.bewindoweb.com/177.htmlC（√）#include &lt;stdio.h&gt;\nint main()\n&#123;\n printf(\"Hello World123中文!\\n\");\n&#125;C++（√）#include &lt;iostream&gt;\n\n\n\nint main(void)&#123;    std::cout &lt;&lt; “Hello World123中文” &lt;&lt; std::endl;    return 0;&#125;C#（√）using System;using System.Windows.Forms;class HelloWorld&#123;       public static void Main()&#123;               Console.WriteLine(\"This is My First C# Program Hello World!\");               MessageBox.Show(\"Hello World!123中文\");               Console.ReadLine();       &#125;&#125;Java（√）public class HelloWorld &#123;    public static void main(String[] args)&#123;        System.out.println(\"Hello World!123中文\");    &#125;&#125;Php（不支持）&lt;?phpecho \"Hello World123中文\";print_r($arr);var_dump($sacs);preg_replace(\"/dsafds[^123]?a/is\",\"\",$l);?&gt;Python（√）# -- coding: UTF-8 -*-\nFilename : helloworld.pyauthor by : www.runoob.com该实例输出 Hello World!print(‘Hello World!’)Pascal（不支持）program helloworld;\nbegin    writeln(‘Hello, World!’);end.Matlab（需要引用JS）function HelloWorld()%输出Hello，World！%   Detailed explanation goes heredisp('Hello,World!');endHTML（√）&lt;!DOCTYPE html&gt;&lt;html&gt;\n&lt;head&gt;&lt;meta charset=”UTF-8”&gt;&lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;\n&lt;body&gt;&lt;/body&gt;&lt;/html&gt;CSS（√）.card-article-tag&#123;    font-size:14px;    color:#242424;    background:#f2f2f2;    padding:5px 10px 5px 10px;    display:inline-block;    transition: .3s ease-in-out;    margin-right:10px;    margin-bottom:10px;&#125;JS（√）&lt;script type=\"text/javascript\"&gt;            //控制浏览器弹出一个警告框            alert(\"这是我的第一行JS代码\");\n        //可以向body中输出一个内容\n        document.write(&quot;看我出不出来&quot;);\n\n        //向控制台输出一个内容\n        console.log(&quot;你猜我在哪里出来呢&quot;);\n    &amp;lt;/script&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;SQL（√）&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;prettyprint lang-sql linenums&quot;&gt;select * from table where id = 12345&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;span style=&quot;font-weight: bold; color: rgb(194, 79, 74);&quot;&gt;Shell命令（存在，但是显示效果很差）&lt;/span&gt;&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;prettyprint lang-bsh linenums&quot;&gt;vi helloword123.txt\nlscd ..cat hello.txtpwdls -lGo（需要引用JS）package main\nimport “fmt”\nfunc main() &#123;    fmt.Printf(“Hello, world.\\n”)&#125;Lua（需要引用JS）-- defines a factorial functionfunction fact (n)    if n == 0 then        return 1    else        return n * fact(n-1)    endendprint(\"enter a number:\")a = io.read(\"*n\") -- reads a numberprint(fact(a))R（需要引用JS）df&lt;-read.table(file=\"~/a.log\",header=FALSE) summary(df)普通文本（不支持）你可能不知道,所有那些快乐和悲伤的事,你不是独自经历。若有一天,遇见一朵飞不高的小小云,你便能听见阿狸轻轻说着他的故事:不管晴天雨天,我知道,在天上很远很远...1232131231打算范德萨范德萨分abcabc按键精灵（不支持）lsFileName =\"C:\\Helloworld.doc\" '请将此处替换为word文档地址Set wordObj = CreateObject(\"Word.Application\")    '调用word应用类wordObj.Visible = False    '设置为不可见wordObj.Documents.Open (lsFileName) '打开word文档mStr = wordObj.ActiveDocument.Content.Text'读取word文档内容并赋值给mStrwordObj.Quit '退出word应用类Set wordObj = Nothing    '销毁word应用类'MsgBox mStr'弹出word内容窗口(此行作调试用)Call Plugin.Sys.SetCLB(mStr)'把word内容设置为剪贴板'因为word的原因执行可能较慢易语言（不支持）标准输出 (, “Hello World!”)                \n","categories":["转载"],"tags":[]},{"title":"matlab R2014a连接和使用mysql56数据库","url":"http://tanqingbo.cn/2019/10/06/matlab R2014a连接和使用mysql56数据库/","content":"\nhttp://www.bewindoweb.com/153.html一、教程内容当matlab需要输出大文件而内存不够时，可以考虑使用数据库来存储和查询。这里的matlab版本为R2014a，mysql为5.6。二、配置matlab连接mysql的环境1、下载mysql-connector的jar包提供一个百度云盘下载地址mysql-connector-java-5.1.7-bin.jar（密码 73d5）2、拷贝jar到matlab所在的toolbox目录例如我的toolbox目录为：D:\\matlabR2014a\\java\\jar\\toolbox3、写入classpath，让matlab自动加载例如我的classpath.txt所在的位置：D:\\matlabR2014a\\toolbox\\local\\classpath.txt在classpath.txt末尾加入：$matlabroot/java/jar/toolbox/mysql-connector-java-5.1.7-bin.jar注意这里的版本号要和你拷贝进去的文件名一致，否则不会加载。4、启动你已经装好的mysql，并重启matlab。三、一些连接和查询语句1、matlab连接数据库conn = database('databasename', 'root', '123456', 'com.mysql.jdbc.Driver', 'jdbc:mysql://127.0.0.1:3306/databasename');2、执行sql语句的函数function [ ans ] = query(conn,sqlstmt)\n  cursor = exec(conn, sqlstmt);%执行语句\n  r = fetch(cursor);%获取结果\n  ans = r.data;%分出数据\nend应用举例ans = query(conn,'select * from tablename');                \n\n\n","categories":["转载"],"tags":[]},{"title":"matlab：求取笛卡尔积的方法","url":"http://tanqingbo.cn/2019/10/06/matlab：求取笛卡尔积的方法/","content":"\nhttp://www.bewindoweb.com/158.html前言利用matlab的函数完成笛卡尔积的求取。方法a = [1,2,3];\nb = [4,5,6];\n[x,y] = meshgrid(a,b);\nCartesian_product = [x(:),y(:)];解释1、meshgrid生成矩阵的二维网格设a宽度为m，b宽度为n，则会以a横着向下复制n次，以b的转置竖着向右复制m次，例如：a = [1,2];\nb = [3,4,5];\n[x,y] = meshgrid(a,b);\n\n\n\n运行结果：x =     1     2     1     2     1     2y =     3     3     4     4     5     52、x(:)将x的数据按列排成一列所有的元素会按照列的顺序从左到右排成一个一维列向量，例如x = [1,2;3,4];x(:)\n运行结果：ans =     1     3     2     43、将两个列向量合并成矩阵，变成了完美的笛卡尔积。                \n","categories":["转载"],"tags":[]},{"title":"mysql的like语句是否区分大小写","url":"http://tanqingbo.cn/2019/10/06/mysql的like语句是否区分大小写/","content":"\nhttp://www.bewindoweb.com/132.html一、mysql的like语句区分大小写吗？不区分大小写。二、相关信息1、mysql的like语句默认不区分大小写的。2、如果想要某个表的某个字段区分大小写，加binary，如create table xxx&#123;\n      attr_name varchar(500) binary\n&#125;3、如果想在SQL语句实现区分大小写：select * from xxx where attr_name = binary 'ABCdefg';4、如果想统一开启不区分大小写windows下：默认统一不区分大小写（my.ini的lower_case_table_names默认=1，不区分）。linux下：想开启不区分大小写修改my.cnf：[mysqld]\nlower_case_table_names=1                \n\n\n","categories":["转载"],"tags":[]},{"title":"openLDAP原理、安装和使用","url":"http://tanqingbo.cn/2019/10/06/openLDAP原理、安装和使用/","content":"\nhttp://www.bewindoweb.com/223.html一、什么是openLDAPLDAP（Lightweight Directory Access Protocol，轻型目录访问协议），是一种基于TCP/IP的访问在线目录服务的协议，有V2和V3版本，其中现在用得最多的都是V3版本。而openLDAP则是这种协议的开源的实现，被广泛应用于“目录访问权限控制”这一目的。举个例子，假设公司有很多个服务系统，包括个人信息系统、文档协作系统、生产环境系统、工资发放系统等等，如果每个系统都独立使用一个账号，当有人入职或者离职的时候，每个系统都得注册，维护起来异常麻烦；而一些通用信息比如员工姓名等等，会存储很多份，要修改的话需要每个系统都得修改。那么openLDAP就可以干这么一件事，只要你的账号在openLDAP上，那么所有的系统通过接入openLDAP就能够验证你的身份，来判断你可以访问哪些目录，提供一些基本信息等等，入职只需要加入一个openLDAP的Object，离职只需要删除或者移动到指定的组，是不是方便太多啦。目前绝大多数的软件都支持数据库登录+LDAP登录双重登录方式，项目管理工具、bug管理工具、文档管理工具等等，非常有必要学习一下。em……它的logo是这个虫：蜜汁审美……二、简单认识openLDAP的数据结构Entry 条目openLDAP是一个树结构，基本模型是条目（Entry），Entry类似于数据库中的一行数据，像这样：cn：Roger\nsn：BWB\ndisplayName:Roger BWB\ntelephoneNumber:1234567890\nuserPassword：(Md5 hased password)Dn 唯一辨别名每个Entry都具有一个唯一的“标识符”——唯一辨别名Dn（Distinguished Name），像这样：cn=Roger,dc=bewindoweb,dc=com可以看出dn是确定这个Entry所走过的路径的逆序字符串（从根节点dn=bewindoweb,dn=com向下，找到了cn=Roger的Entry）。ObjectClass 对象类接下来是比较难理解的对象类（ObjectClass）。（1）直观感受人员person的ObjectClass长这样：很像Java中的类定义。（2）分类Object分为三种：结构型（Structural）：有account、person等等，一般都具有具体的完整含义，例如account代表账户、person代表人员；辅助型（Auxiliary）：有uidObject等，用于一些辅助型的属性补充，例如增加一个uid的Attribute。抽象型（Abstract）：有top等，只用来被其他ObjectClass继承，top是必须继承的一个抽象类。（3）其他特性子类会继承父类的全部属性（Attribute）。属性有Must（必须）和May之分，Must是必填的Attribute，May是可选的Attribute。比如上面的人员中，姓氏cn和全名sn是一个人必须要有的属性，而电话号���telephoneNumber、描述description等则是可有可无的属性。（4）Entry可以有多个ObjectClass一个Entry至少具有���个，可以具有多个ObjectClass，&nbsp; 比如：一个属性是抽象型对象类top，一个属性是基础的结构型对象类person，一个属性是辅助型对象类uidObject（这个Entry所拥有的ObjectClass也是它的一个属性）。然后person里面有必填的cn、sn，可选的description、telephoneNumber、userPassword；uidObject里有必填的uid。这就构成了一个完整的Entry，它的Dn是cn=roger,dc=bewindoweb,dc=com。其他的相关缩写含义缩写&nbsp;全写&nbsp;含义&nbsp;举例&nbsp;c&nbsp;Country国家&nbsp;cn&nbsp;cn&nbsp;Common Name通用名Roger/Server123&nbsp;&nbsp;dc&nbsp;Domain Component域bewindoweb/com&nbsp;&nbsp;o&nbsp;Organization组织bewindoweb&nbsp;ou&nbsp;Organizational Unit&nbsp;组织单元developer/admin/user完整的LDAP树结构示意图三、开始动手搭建：Hello openLDAP1、搭建环境debian 8 64位服务器2、下载源码包（1）openLDAP源码：官网下载地址&nbsp;|&nbsp;2.4.46百度云下载地址（密码：8ndq）（2）BerkeleyDB源码：官网下载地址（需要Oracle帐号登录，而注册又需要梯子）&nbsp;|&nbsp;5.1.29百度云下载地址（密码：r5vz）（3）Apache Direcotry Studio安装包：官网下载地址&nbsp;|&nbsp;2.0.0 for windows 64百度云下载地址（密码：sjvz）3、编译和安装（1）如果是新系统，先安装基本的gcc、make等工具：apt-get install gcc\napt-get install make（2）安装BerkeleyDB因为openLDAP底层数据库采用的BerkeleyDB，它是一种读数据库，读快写慢，支持分布式但不支持事务。首先，注意比对一下openLDAP所需要的数据库版本：#进入openLDAP源码目录\ncd openldap-2.4.46\n#查看readme含有BDB的上下5行\ncat README |grep BDB -C 5然后，解压BDB源码后，进入build_unix目录（是个空目录），执行configure、make、make install：tar -zxvf db-5.1.29.tar.gz\ncd db-5.1.29/build_unix\n../dist/configure\nmake\nmake installmake的过程可能需要3分钟，这样BDB就会被安装在/usr/local/BerkeleyDB.5.1目录下了。最后要把BDB的可执行文件加入环境变量，随意你使用什么方式，这里采用bashrc：vi ~/.bashrc\n#加入\nexport PATH=$PATH:/usr/local/BerkeleyDB.5.1/bin\n#生效\nsource ~/.bashrc（3）安装openLDAP解压openLDAP源码、进入目录，执行configure：./configure CPPFLAGS=\"-I/usr/local/BerkeleyDB.5.1/include\" LDFLAGS=\"-L/usr/local/BerkeleyDB.5.1/lib\" LD_LIBRARY_PATH=\"/usr/local/BerkeleyDB.5.1/lib\" --prefix [自定义目录]其中--prefix可以安装到指定目录，如果不指定的话，默认安装到/usr/local。然后提示要make depend：make depend接着：make\nmake test这就说明make对了，最后执行安装：make install4、配置（1）配置openLDAPvi /usr/local/etc/openldap/slapd.conf修改这两行，这是设置管理员帐号密码的：我修改为了：suffix      \"dc=bewindoweb,dc=com\"\nrootdn      \"cn=Manager,dc=bewindoweb,dc=com\"\nrootpw     **********密码可以使用工具来生成高强度密码，比如对123456进行加密：slappasswd -s 123456\n&#123;SSHA&#125;VuxpAZ3Dt8Hwasb/eHJHh3CkkCg1qdEF然后重启slapd：/usr/local/libexec/slapd可能会提示错误：libdb-5.1.so: cannot open shared object file: No such file or directory，原因是找不到这个库，其实这个库在BDB目录下的，建立一个硬链接：ln -s /usr/local/BerkeleyDB.5.1/lib/libdb-5.1.so /usr/lib/libdb-5.1.so就不报错了。最后增加一个用户：vi /usr/local/etc/openldap/bwb.ldif\n#根据前面对应的配置加入这些\ndn:dc=bewindoweb,dc=com\nobjectclass:dcObject\nobjectclass:organization\no:bewindoweb company\ndc:bewindoweb\n\n\n\ndn:cn=Manager,dc=bewindoweb,dc=comobjectclass:organizationalRolecn:Manager然后加入数据库：# -x：简单认证\n-D：指定服务器Dn-w：绑定dn的密码-f：使用LDIF文件进行条目添加ldapadd -x -D “cn=Manager,dc=bewindoweb,dc=com” -W -f bwb.ldif会提示输入密码，输入之前配置的密码即可。验证一下是否加入成功：ldapsearch -x -b 'dc=bewindoweb,dc=com'5、使用phpLDAPadmin进行可视化apt-get install phpldapadmin注意会安装php5和apache2，如果你已经有网站项目在上面比如php7，那么就要考虑一下怎么处理了。修改配置文件：vi /etc/phpldapadmin/config.php\n//$servers-&gt;setValue(‘server’,’base’,array(‘dc=example,dc=com’));$servers-&gt;setValue(‘server’,’base’,array(‘dc=bewindoweb,dc=com’));\n//$servers-&gt;setValue(‘login’,’bind_id’,’cn=admin,dc=example,dc=com’);$servers-&gt;setValue(‘login’,’bind_id’,’cn=Manager,dc=bewindoweb,dc=com’);访问界面：http://xxx.xxx.xxx.xxx/phpldapadmin/如果发现访问不了，除了检查phpLDAPadmin，也别忘了检查服务器是否开了端口（默认ldap都在389端口）：查看端口：lsof -i:389在线端口扫描6、使用Apache Direcotry Studio进行可视化安装在windows上后，点击菜单：Window → Open Perspective →  LdapWindow → Show View → Connection右键新建一个连接：由于不支持直接输入ip，修改本地的hosts文件C:\\Windows\\System32\\Drivers\\etc\\hosts：（为了不影响bewindoweb.com的正常访问，这里写成了testbewindoweb.com）106.12.129.65 testbewindoweb.com然后填入服务器信息，点击Check Network Parameter可以测试TCP连接是否成功：填入管理员帐号，测试是否可以验证成功：然后就可以愉快地使用了：总结目前Confluence、Grafana、禅道、YAPI等等非常多的软件都已集成LDAP，掌握LDAP的原理、安装和使用有利于以后的更加透彻理解。                \n","categories":["转载"],"tags":[]},{"title":"php匹配HTML标签","url":"http://tanqingbo.cn/2019/10/06/php匹配HTML标签/","content":"\nhttp://www.bewindoweb.com/176.html前言php经常需要去匹配html标签，然而由于html标签可能有很多个重复的，甚至可能含有一些嵌套，因此匹配困难。一、php正则问号的用法1、只想匹配字符“？”需要进行转义，即\\?2、用于非贪婪匹配即最近匹配：【贪婪】\n模式：a.*c\n字符串：abcabc\n匹配结果：abcabc\n【非贪婪】\n模式：a.*?c\n字符串：abcabc\n匹配结果：abc常用：（1）*? 重复任意次，但尽可能少（2）+? 重复1次或更多次，但尽可能少（3）?? 重复0次或1次，但尽可能少（4）&#123;n,m&#125;? 重复n到m次，但尽可能少（5）&#123;n,&#125;? 重复n次以上，但尽可能少3、不捕捉模式?:意思就是对于不想要用（）捕捉到的数据，加一个?:即可，例如：模式：(?:aaa)(bbb)\n匹配结果: $1=bbbaaa不会被$1捕捉到二、php匹配任意字符（含换行符）的bug1、[.\\n]*?完全不行……原因未知2、.*?可以，需要在后面加/s，复习：（1）i 不区分大小写（2）s 模式中的.匹配所有字符，包括换行符3、(.|\\n)*?感觉上是可以的，但是对于很长很长的字符串，比如文章《三国高级辅助_v1.0》的内容，就不行，没匹配完就结束了，导致文章无法显示。据《关于php中正则匹配包括换行符在内的任意字符的问题总结》说，是和php所绑定的PCRE库版本有关，可我用得是php7.0啊……4、[\\s\\S]*?最佳匹配方式，这里的（1）\\s 匹配任意空白字符，包括换行符， 等价于[\\f\\n\\r\\t\\v]（2）\\S匹配任意非空白字符，等价于 ^[\\f\\n\\r\\t\\v]合起来就是匹配所有字符。三、匹配HTML标签：pre code需要匹配&lt;pre&gt;&lt;code&gt; &nbsp;&lt;/pre&gt;&lt;/code&gt;，只要文本不出现这个标签，就可以这样匹配：/&lt;pre&gt;&lt;code&gt;([\\s\\S]*?)&lt;\\/code&gt;&lt;\\/pre&gt;/i                \n\n\n","categories":["转载"],"tags":[]},{"title":"top工具的正确打开方式","url":"http://tanqingbo.cn/2019/10/06/top工具的正确打开方式/","content":"\nhttp://www.bewindoweb.com/264.html一、top经典界面参数含义1、系统状态top - 21:36:59 up 13 days, 45 min,  1 user,  load average: 0.35, 0.12, 0.04现在的系统时间：21:36:59系统已经启动了：13天45分钟用户数量：1个系统平均负载1分钟、5分钟、15分钟：0.35、0.12、0.04系统平均负载指的是，在特定时间间隔内运行队列中的平均进程数。一个进程通常会在没有等待I/O操作、没有主动进入等待状态、没有被中止的情况下处于运行态。Top的这个系统平均负载是每隔5秒检查一次活跃进程数计算得到的，如果这个数值除以逻辑CPU的数量：&lt;0.70：正常0.70~1.00：有一些负荷了，需要检查1.00~5.00：刚好1个CPU处理1个进程，但占用了全部的CPU资源，应该马上检查进程是否有问题&gt;5.00：系统超负荷运转2、进程总体状态Tasks:  85 total,   1 running,  84 sleeping,   0 stopped,   0 zombie一共有85个进程，1个处于运行态，84个处于睡眠态，0个处于僵尸态3、CPU状态%Cpu(s):  0.2 us,  0.1 sy,  0.4 ni, 99.2 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 stus（user）：运行未调整优先级的用户进程的CPU时间所占的百分比sy（system）：运行内核进程的CPU时间所占的百分比ni（niced）：运行已调整优先级的用户进程的CPU时间所占的百分比id：（idle）CPU空闲时间所占的百分比wa（IO wait）：执行过程中用于等待IO完成的CPU时间所占的百分比hi（Hardware IRQ）：处理硬件中断的CPU时间所占的百分比si（Software Interrupts）：处理软件中断的CPU时间所占的百分比st（steal）：虚拟CPU等待实际CPU时间所占的百分比我们知道程序在进行系统调用（比如read等函数）、发生异常（比如缺页异常）、外围设备中断等操作陷入内核代码后，进程会从用户态进入系统态。当us值过高，表示运行的应用消耗掉了大部分CPU，在这种情况下就要去找程序中消耗CPU线程所执行的代码，对java程序而言，可以去查看JVM是否频繁GC和因为什么频繁GC当sy值过高，表用运行的应用过于频繁地进行线程上下文切换，线程不断地处于阻塞（锁等待、IO等待）和执行的状态变化过程中，对java程序而言，需要查看是否启动的线程太多，是否有并发锁竞争的问题。通常，除了百分比的值，us比sy应该小于3:1~4:1才比较合理。ni值可以用于观察调整过优先级的进程所占用CPU百分比。比如原本两个优先级为0的进程A和B，分别分配1时间片，提高B的优先级到-19后，A仍然1时间片，B分配1.5时间片，那么B多占了(1.5-1)/1.5+1=20%的CPU时间，这就是ni值。ni值越高说明调整后的进程抢占了其他进程越多的CPU资源。如果不是自己调的，一定要注意检查是否被入侵了，比如被挂了挖矿进程。id值表明CPU空闲时间，我的服务器99.2%，说明没跑啥大程序，大部分CPU都浪费了……st是被偷走的CPU时间，通常为0，这里的虚拟CPU指的不是逻辑CPU，而是整台服务器是运行在物理机上的虚拟机，那么st就是当CPU被分配给相同物理机的另一台虚拟机的时候，本虚拟机的虚拟CPU等待的时间。这个值越高，说明其他虚拟服务器占用的CPU越多，供应商过量地出售了虚拟云服务器，需要联系云服务器供应商扩容。4、内存状态KiB Mem:   1024052 total,   945656 used,    78396 free,   187356 buffers\nKiB Swap:        0 total,        0 used,        0 free.   359120 cached Mem第一行是物理内存，全部有1G内存（1024052字节），使用中的内存有0.9G左右，空闲内存0.1G左右，有0.17G（187356字节）的缓冲第二行是虚拟交换内存，全部有0字节，使用中的有0字节，可用的有0字节（没有设置虚拟交换内存），有0.34G（359120字节）的缓存缓冲（buffer）主要用于块设备的读写，缓存（cache）主要存储频繁访问的数据空闲内存指的是完全没有被利用的内存，所以剩余的内存可用量并不是空闲内存，而是空闲内存+缓冲+缓存，比如这里就是0.1G+0.17G+0.34G=0.61G，还有一半内存可用呢。要注意虚拟内存的used数值是否频繁变化，如果频繁变化，说明在不断地进行内存和虚拟内存的数据交换，这是内存不够用了的表现。5、进程详细状态PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND                                                                            \n1 root      20   0   28900   5248   3148 S  0.0  0.5   0:12.74 systemdPID（Process Id）：进程IDUSER（User Name）：进程所有者的用户名PR（Priority）：进程的动态优先级，“rt”代表实时态，取值0~39NI（Nice Value）：进程的静态优先级，取值-20~19VIRT（Virtual Image）：进程所用虚拟内存总量，单位KBRES（Resident Size）：驻留内存大小，单位KBSHR（shared Memory）：共享内存大小，单位KBS（Process State）：进程状态%CPU（CPU Usage）：上次更新到现在的CPU时间占用百分比%MEM（Memory Usage RES）：进程使用的物理内存百分比（RES）TIME+（CPU Time，hundredths）：启动后到现在使用的全部CPU时间，精确到1/100秒COMMAND（Command Name/Line）：运行进程使用的命令Linux一共有0~139共140个实际进程优先级，数字越小优先级越高，0~99是实时进程优先级，100~139是非实时进程优先级，系统会优先运行实时进程，只有实时进程让出CPU后才会运行非实时进程。所有新的非实时进程初始Nice值都是0，初始的实际优先级是（140 - 40/2）=120，所以可以通过-20~19的Nice值的调整来将实际优先级在100~139范围内调整。而实时进程的优先级都是根据指定策略动态变化的，实际优先级是看不见的，所以显示为“rt”，而普通非实时进程实际优先级可以通过PR+100=120+NI算出。例如：PR=20，NI必定为0，实际优先级100+20或120+0为120；PR=0，NI必定为-20，实际优先级100+0或120-20为100；PR=rt，实际优先级必定在0~99之间，是实时进程。所以PR主要用来判断是否是实时进程，NI主要用来判断非实时进程设置的优先级是多少。VIRT是进程需要的虚拟内存大小，包括库、代码、数据等，如果进程申请了200M内存，只用了10M，但这个值也会是200M，VIRT=SWAP+RES；RES是进程当前使用的内存大小，如果加载了库，只会统计加载的库文件所占内存大小，如果进程申请了200M内存，只用了10M，那么这个值就是10M，RES=CODE+DATA；SHR是共享内存大小，如果只用了库的几个函数，也会包含整个共享库的大小。S是进程的状态，包括：R（Running） - 运行态S （Sleep）- 休眠态D（UnInterruptable） - 不可中断的休眠态T（Stopped or Traced） - 跟踪态或停止态Z（Zombie） - 僵尸态X（Exit）- 退出态有关进程的状态后面可以再开一篇文章讲解，大部分进程都处于运行态和休眠态，这两个状态肯定是很好理解的，运行态可以去抢CPU，休眠态可能在等待某事件发生（比如信号量）。%CPU是CPU占用率，如果CPU是多核，并且进程开了多个线程抢CPU，那么可能CPU的占用率会超过100%，最大为核心数*100%，例如4核最大占用率为400%Time+的读法是按位的，单位分别是：1分钟、10秒、1秒、1/10秒、1/100秒，比如0:12.74就是0*1分钟+1*10秒+2*1秒+7*1/10秒+4*1/100秒。二、top的调用方法1、top参数运行（1）top -cCOMMAND一列将会显示详细的启动命令，而不是只有命令名称：（2）top -b以批处理的方式运行。也就是刷新界面不是原地刷新，而是作为历史记录上移，这样可以将历史top信息保存起来便于查看变化过程。（3）top -S累积模式，会将已完成或消失的子进程的CPU Time也累积起来。（4）top -n [次数]在刷新打印n次之后退出top。配合top -c可以查看指定几次的变化，比如：top -n 2 -b &gt; top.log（5）top -d [刷新间隔时间]指定刷新间隔时间，默认是3秒（6）top -p [PID]只显示指定进程的信息，另外我尝试了一下用逗号分隔多个pid，发现真的可以展示多个：这样只想看指定的多个进程就很方便了。（7）top -s安全模式，将不能使用交互式命令。（8）top -i不显示任何闲置（idle）或僵尸（zombie）进程。比如用了这个参数，就只有真的在跑的进程显示了：对比一下普通的top，有大量的非活跃进程：（9）top -u或-U [用户名或UID]可以只查看某个用户的进程。2、top交互式命令交互式指的是，进入top界面后，再按键。按h就可以看到了详细交互命令帮助了：这里介绍几个常用的：（1）E、e切换显示单位E控制的是上面的内存信息单位，从KB到EB：e控制的是下面的进程数据单位，从KB到PB：（2）l、t、ml：显示或隐藏第1行信息 topt：显示或隐藏第2~3行信息 Tasks、%CPU(s)m：显示或以藏第4行信息 Mem、Swap（3）1显示CPU详细信息，每核显示一行（4）d/s修改刷新频率（5）n指定显示行数，0表示无限制（6）q退出top（7）M根据驻留内存大小（RES）排序，这样能看到哪个进程占用内存大（8）P根据CPU使用百分比大小排序，能检查占用CPU多的进程（9）T根据时间/累积时间进行排序（10）x加亮排序列，可以看到当前是按照哪一列在排序打开后可以配合shift+&lt;或shift+&gt;调整排序列（11）y加亮运行态（R）进程（12）cCOMMAND列会显示详细的启动命令（13）kkill一个进程（14）rrenice，调整一个进程的静态优先级（15）W将当前弄好的配置写入~/.toprc配置文件中，这样下次启动就不会变啦。（16）最重要的F可以选择排序列，可以选择当前显示的列有哪些：更多的命令已经放到wiki上供查阅。                \n\n\n","categories":["转载"],"tags":[]},{"title":"ubuntu下安装VTK","url":"http://tanqingbo.cn/2019/10/06/ubuntu下安装VTK/","content":"\nhttp://www.bewindoweb.com/186.html一、操作环境vmware 10ubuntu-14.04.2-desktop-amd64二、具体操作1、安装Cmake安装方法参看《ubuntu下安装ITK》安装版本：3.7.02、下载和编译VTK安装openGL环境：sudo apt-get install freeglut3-dev安装Qt4.x环境：sudo apt-get install qt4-default下载VTK（VTK官网）cd /home/bwb\nwget \"https://www.vtk.org/files/release/6.3/VTK-6.3.0.tar.gz\"\nmkdir VTK\ncd VTK\ntar -zxvf ../VTK-6.3.0\nmkdir build编译VTKcd build\nccmake ../VTK-6.3.0\nc c #按c配置，再按c确定配置\ng #按g生成\nmake \nsudo make install\n配置注意这些：BUILD_EXAMPLES &nbsp; *OFFBUILD_TESTING &nbsp; &nbsp; *OFFVTK_Group_Qt &nbsp; &nbsp; &nbsp; *ONVTK_RENDERING_BACKEND &nbsp; &nbsp; *OpenGL三、测试VTK修改CMakeLIst.txt文件cd /home/bwb/VTK/VTK7.7.0/Examples/Tutorial/Step1/Cxx\nsudo gedit CMakeList.txt把findpacakge内容注释掉，改为NO_MODULE：#find_package(VTK COMPONENTS\n#  vtkFiltersSources\n#  vtkInteractionStyle\n#  vtkRendering$&#123;VTK_RENDERING_BACKEND&#125;\n#)\nfind_package(VTK 6.3 REQUIRED NO_MODULE)进行编译sudo cmake .\nsudo make\n./Cone会显示一个快速横向旋转的圆锥体，表明安装成功四、遇到的坑1、提示Could NOT find OpenGL (missing: OPENGL_gl_LIBRARY...没有安装OpenGL依赖库sudo apt-get install freeglut3-dev2、提示requires Qt 4.x没有安装Qt 4.xsudo apt-get install qt4-default3、测试时报错vtkRendering不可用CMakeLists.txt的第11行处的find_package出错，因为例子程序没有跟上版本更新，把11行的find_package注释掉，改为：find_package(VTK 7.0 REQUIRED NO_MODULE)\n4、提示X Error：GLXBadFBConfigX Error of failed request:  GLXBadFBConfig\nMajor opcode of failed request:  150 (GLX)\nMinor opcode of failed request:  34 ()\nSerial number of failed request:  39\nCurrent serial number in output stream:  40原因在于VTK7.0以上版本默认采用OpenGL2进行编译，然而又没有兼容好。解决方法��重新编译和安装一遍VTK，编译参数选择OpenGL。4、编译的时候cannot find -lvtkRenderingOpenGL2/usr/bin/ld: cannot find -lvtkRenderingOpenGL2  \n/usr/bin/ld: cannot find -lvtkglew  \n/usr/bin/ld: cannot find -lvtkRenderingVolumeOpenGL2  \n/usr/bin/ld: cannot find -lvtkDomainsChemistryOpenGL2  \n/usr/bin/ld: cannot find -lvtkRenderingGL2PSOpenGL2  \n/usr/bin/ld: cannot find -lvtkRenderingContextOpenGL2原因是在第一遍安装的时候，选择了OpenGL2；然后发现不对，又重新安装了一遍OpenGL编译的VTK，但是它不会删除OpenGL2相关的东西，所以发生了冲突。网上提供的解决方法是：&nbsp;（1）删除/usr/local/lib中所有涉及到OpenGL2的lib（注意别删除了其他的lib，那是其他程序的）&nbsp;（2）删除/usr/local/include中的vtk文件夹&nbsp;（3）删除/home/bwb/build文件夹下编译好的所有文件&nbsp;（4）重新编译vtk，编译的时候选择OpenGL然而我用了这个方法也不行，最后干脆直接用低版本的vtk6.3。五、参考文献1、《Ubuntu下安装cmake，配置ITK 和 SimpleITK, VTK(已测试可执行)》2、《vtkRenderWindow problem》3、《GLXBadFBConfig on switching from VTK6 to VTK7》4、《每日积累（20161209-day-15）(VTK7.1编译OpenGL&amp;OpenGL2 PCL1.8)》5、《 Requested modules not available: vtkRendering问题解决方法》6、《[QT][?] Found unsuitable Qt version \"5.0.2\" from /usr/bin/qmake, this code requires Qt 4.x》7、《CMake could not find OpenGL in Ubuntu》                \n\n\n","categories":["转载"],"tags":[]},{"title":"ubuntu下安装ITK","url":"http://tanqingbo.cn/2019/10/06/ubuntu下安装ITK/","content":"\nhttp://www.bewindoweb.com/184.html一、操作环境vmware 10ubuntu-14.04.2-desktop-amd64二、具体操作1、安装Cmake（1）安装curses库，这个库可以让cmake运行成GUI界面，生成ccmakesudo apt-get install libncurses5-dev\nsudo apt-get install cmake-curses-gui（2）安装cmake，这里一定要手动选择安装3.7.0的cmake，而不是apt-get install，否则会是问题很多的2.8.12cd /home/bwb #进入你自己的目录\nwget \"https://cmake.org/files/v3.7/cmake-3.7.0.tar.gz\"\ntar zxvf cmake-3.7.0.tar.gz\ncd cmake-3.7.0\nsudo su #一定要加这句话root，否则下面语句会没有权限\n./bootstrap &amp;&amp; make &amp;&amp; make install（3）验证安装cmake --version\nccmake --version2、安装编译ITK（1）下载4.10.1版本的ITK，需要自己用浏览器下载，因为并不是文件地址，而是一个下载服务的网页\"https://sourceforge.net/projects/itk/files/itk/4.10/InsightToolkit-4.10.1.tar.gz/download\"下载文件InsightToolkit-4.10.1.tar.gz放入/home/bwb（2）建立目录，解压cd /home/bwb\nmkdir ITK\nmkdir ITK/build\ntar -zxvf ../InsightToolkit-4.10.1.tar.gz #把/home/bwb下的压缩文件解压到/home/bwb/ITK里（3）编译cd /home/bwb/ITK/build\nccmake ../InsightToolkit-4.10.1（4）出现了GUI界面，按c键配置。然后会提示一些设置，但其实根本不用设置，注意下这两个选项是不是OFF就行，不是OFF改成OFF：BUILD_EXAMPLES  *OFF\nBUILD_TESTING     *OFF更改的方法是，光标上下选择，回车修改，回车保存（5）继续按c键配置，提示成功，然后按g生成编译文件。（6）makemake三、测试ITK1、建立目录cd /home/bids/ITK\nmkdir test       //工程文件\nmkdir test/src   //存放源代码\nmkdir test/bin    //示例编译目标\nmkdir test/src/HelloWorld //项目名称\nmkdir test/bin/HelloWorld //项目名称2、拷贝官方的HelloWorld程序cp /home/bwb/ITK/InsightToolkit-4.10.1/Examples/Installation/* /home/bwb/ITK/test/src/HelloWorld\n\n\n\n会有两个文件：CMakeLists.txt、HelloWorld.cxx3、进入bin目录，编译src的文件cd /home/bwb/test/bin/HelloWorldccmake /home/bwb/ITK/test/src/HelloWorld可能会出现错误：ITK_DIR_NOTFOUND同样用箭头上下选择，回车修改保存，改为ITK的目录：/home/bwb/ITK/build重新按c配置，按g生成编译文件4、makemake   //生成 HelloWorld 可执行文件./HelloWrold  //执行最终结果：ITK Hello World！5、Helloworld的CMakeList.txt解释#最低cmake版本要求cmake_minimum_required(VERSION 2.8.9)\nif(COMMAND CMAKE_POLICY)  cmake_policy(SET CMP0003 NEW)endif()\n#项目名称project(HelloWorld)\n#ITK依赖的包的路径，include进来find_package(ITK REQUIRED)include($&#123;ITK_USE_FILE&#125;)\n#把HelloWorld.cxx源文件编译成HelloWorld可执行程序add_executable(HelloWorld HelloWorld.cxx )\n#指定编译参数target_link_libraries(HelloWorld $&#123;ITK_LIBRARIES&#125;)四、安装过程中出现的坑1、出现undefined reference to symbol ‘pthread_create’&lt;h1pingfang sc’,=”” ‘microsoft=”” yahei’,=”” simhei,=”” arial,=”” simsun;=”” margin:=”” 0px;=”” padding:=”” 0px=”” 29px;=”” font-weight:=”” 700;=”” box-sizing:=”” border-box;=”” word-break:=”” break-all;=”” word-wrap:=”” break-word;=”” color:=”” rgb(44,=”” 48,=”” 51);=”” font-size:=”” 24px;=”” line-height:=”” 38px;=”” font-style:=”” normal;=”” font-variant:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” 0px;”=””&gt;&nbsp;&lt;divhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;h1pingfang sc’,=”” ‘microsoft=”” yahei’,=”” simhei,=”” arial,=”” simsun;=”” margin:=”” 0px;=”” padding:=”” 0px=”” 29px;=”” font-weight:=”” 700;=”” box-sizing:=”” border-box;=”” word-break:=”” break-all;=”” word-wrap:=”” break-word;=”” color:=”” rgb(44,=”” 48,=”” 51);=”” font-size:=”” 24px;=”” line-height:=”” 38px;=”” font-style:=”” normal;=”” font-variant:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” 0px;”=””&gt;明显是多线程模块没有正确加载。&lt;divhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;divhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;h1pingfang sc’,=”” ‘microsoft=”” yahei’,=”” simhei,=”” arial,=”” simsun;=”” margin:=”” 0px;=”” padding:=”” 0px=”” 29px;=”” font-weight:=”” 700;=”” box-sizing:=”” border-box;=”” word-break:=”” break-all;=”” word-wrap:=”” break-word;=”” color:=”” rgb(44,=”” 48,=”” 51);=”” font-size:=”” 24px;=”” line-height:=”” 38px;=”” font-style:=”” normal;=”” font-variant:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” 0px;”=””&gt;检查一下ubuntu有没有安装pthread：&nbsp;&nbsp;&lt;h1pingfang sc’,=”” ‘microsoft=”” yahei’,=”” simhei,=”” arial,=”” simsun;=”” margin:=”” 0px;=”” padding:=”” 0px=”” 29px;=”” font-weight:=”” 700;=”” box-sizing:=”” border-box;=”” word-break:=”” break-all;=”” word-wrap:=”” break-word;=”” color:=”” rgb(44,=”” 48,=”” 51);=”” font-size:=”” 24px;=”” line-height:=”” 38px;=”” font-style:=”” normal;=”” font-variant:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” 0px;”=””&gt;bwb@ubuntu:~$ man -k pthread_createpthread_create (3)   - create a new thread&lt;h1pingfang sc’,=”” ‘microsoft=”” yahei’,=”” simhei,=”” arial,=”” simsun;=”” margin:=”” 0px;=”” padding:=”” 0px=”” 29px;=”” font-weight:=”” 700;=”” box-sizing:=”” border-box;=”” word-break:=”” break-all;=”” word-wrap:=”” break-word;=”” color:=”” rgb(44,=”” 48,=”” 51);=”” font-size:=”” 24px;=”” line-height:=”” 38px;=”” font-style:=”” normal;=”” font-variant:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” 0px;”=”” style=”line-height: normal;”&gt;安装了的，如果没有安装则安装：sudo apt-get install glibc-docsudo apt-get install manpages-posix-dev&lt;h1pingfang sc’,=”” ‘microsoft=”” yahei’,=”” simhei,=”” arial,=”” simsun;=”” margin:=”” 0px;=”” padding:=”” 0px=”” 29px;=”” font-weight:=”” 700;=”” box-sizing:=”” border-box;=”” word-break:=”” break-all;=”” word-wrap:=”” break-word;=”” color:=”” rgb(44,=”” 48,=”” 51);=”” font-size:=”” 24px;=”” line-height:=”” 38px;=”” font-style:=”” normal;=”” font-variant:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” 0px;”=”” style=”line-height: normal;”&gt;&lt;h1pingfang sc’,=”” ‘microsoft=”” yahei’,=”” simhei,=”” arial,=”” simsun;=”” margin:=”” 0px;=”” padding:=”” 0px=”” 29px;=”” font-weight:=”” 700;=”” box-sizing:=”” border-box;=”” word-break:=”” break-all;=”” word-wrap:=”” break-word;=”” color:=”” rgb(44,=”” 48,=”” 51);=”” font-size:=”” 24px;=”” line-height:=”” 38px;=”” font-style:=”” normal;=”” font-variant:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” 0px;”=”” style=”line-height: normal;”&gt;修改了一下CMakeLists.txt：target_link_libraries(HelloWorld $&#123;ITK_LIBRARIES&#125;)改为target_link_libraries(HelloWorld $&#123;ITK_LIBRARIES&#125; -lpthread)解决了。2、报错undefined reference to ‘itksys::SystemTools….’&nbsp;没有相关的资料，唯一在google查到的资料是一段邮件对话：他说问题在cmake：These messages indicate possible issues with the CMake configuration.\nFor more information, see the “Configuring and Building ITK” sectionof the ITK Software Guide:\n  https://itk.org/ITKSoftwareGuide/html/Book1/ITKSoftwareGuide-Book1ch2.html#x22-130002\nand find a downloadable HelloWorld example that includes the CMakeconfiguration here:\n  https://itk.org/ITKExamples/src/Core/Common/BuildAHelloWorldProgram/Documentation.html\nHope this helps,Matt我用的2.8.12，是ITK最新版本的最低要求，所以我直接换用更高版本cmake和更低版本ITK了，才解决了，否则怎么改makefile文件都会报这个错。五、参考文献1、《Ubuntu下安装cmake，配置ITK 和 SimpleITK, VTK(已测试可执行)》2、《ubuntu12.04 64位系统下 下安装itk和vtk》3、《邮件对话》4、《ubuntu 下没有pthread库 怎么办？��六、ITK配准分割简明教程1、终于找到了一本用ITK进行配准和分割的入门教程《(ITK实现 全2册)》，还是咱大成电出版的哦，写得非常详细，入门很有帮助。百度网盘下载&nbsp;（密码：ocue）2、ITK官方的代码例子解释，不过是全英文的，稍微入门后可以继续看这个深入。页面地址                \n","categories":["转载"],"tags":[]},{"title":"《医学图像分割与配准(ITK实现)》阅读笔记（正在写）","url":"http://tanqingbo.cn/2019/10/06/《医学图像分割与配准(ITK实现)》阅读笔记（正在写）/","content":"\nhttp://www.bewindoweb.com/192.html一、图书信息【书名】《医学图像分割与配准(ITK实现)》上下册【作者】周振环 王安明 王京阳 赵明【出版社】电子科技大学出版社【其他】百度网盘下载（密码：ocue）二、阅读笔记1、ITK基本数据类型图像Image、网格Mesh2、ITK通过管道处理数据shrink-&gt;SetInput(random-&gt;GetOutput())3、ITK配准要素（1）空间变换①刚性（线性）变换刚体变换：位移（水平、垂直）、旋转仿射变换：放缩+平移+旋转投影变换：变形（但直线投影仍然为直线）②非线性变换：变形（直线变为曲线）例如FEM、FFD、B样条形变（2）灰度插值（插值器）①最近点插值：距离加权赋值②线性：周围像素的均值（3）相似性测度①灰度平均差②正则化相关尺度③梯度微分④互信息度量（4）配准参数优化搜索①Powell：极值②梯度下降法③遗传算法【问题】配准完了灰度值不就很相似了吗，那原来有肿瘤会配没吗？【解答】（@todo）4、（@todo，这是什么意思？）（1）ITK类通过对象工厂实例化：静态类New()，构造和析构是private（2）使用itk:ObjectFactoryBase登录一个或多个工厂来控制类的实例（3）工厂用CreateInstance（类名）来创建类实例（4）工厂主要用于put/output(IO)类，平时New()5、Image类基本操作（1）首先必须包含图像头文件：#include \"itkImage.h\"（2）创建图像指针：typedef itk::Image&lt;unsigned short, 3&gt; ImageType;\nImageType::Pointer image = ImageType::New();（3）图像区域分类LargePossibleRegion：完全图像BufferedRegion：内存中的部分图像RequestedRegion：滤波要求的图像（4）创建图像区域并分配内存：ImageType::IndexType start = &#123;&#123;0,0,0&#125;&#125;;\nImageType::SizeType size = &#123;&#123;200,200,200&#125;&#125;;\nImageType::RegionType region;\nregion.SetSize(size);\nregion.SetIndex(start);\nimage.SetRegions(region);\nimage.Allocate();（5）从文件中读取图像#include \"itkImageFileReader.h\"\n\n\n\ntypedef unsigned char PixelType;const unsigned int Dimension = 3;typedef itk::Image&lt;PixelType , Dimension&gt; ImageType;//定义Reader指针typedef itk::ImageFileReader&lt;ImageType&gt; ReaderType;ReaderType::Pointer reader = ReaderType::New();//Reader指针更新数据const char* filename = argv[1];reader-&gt;SetFileName(filename);reader-&gt;Update();//Image指针获取数据ImageType::Pointer image = reader-&gt;GetOutput();（6）原点和间距//设置间距ImageType::SpacingType spacing = &#123;&#123;0.33,0.33,1.20&#125;&#125;;image-&gt;SetSpacing(spacing);//返回FixedArrayconst ImageType::SpacingType&amp; sp = image-&gt;GetSpacing();std::cout&lt;&lt; \"spacing = \" &lt;&lt; sp[0] &lt;&lt;\",\"&lt;&lt;sp[1]&lt;&lt;\",\"&lt;&lt;sp[2]&lt;&lt;std::endl;//设置原点ImageType::PointType origin=&#123;&#123;0.0 , 0.0 , 0.0&#125;&#125;image-&gt;SetOrigin(origin)const ImageType::PointType&amp; orgn = image-&gt;GetOrigin();std::cout&lt;&lt;\"Origin:\"&lt;&lt;orgn[0]&lt;&lt;\",\"&lt;&lt;orgn[1]&lt;&lt;\",\"&lt;&lt;orgn[2]&lt;&lt;std::endl;【提醒】C++需要复习的东西：指针、STL迭代器、vector、T模板6、滤波（1）二值门限处理（分割的最后一步——标记）#include \"itkBinaryThresholdImageFilter.h\"\ntypedef unsigned char InputPixelType;typedef unsigned char OutputPixelType;\ntypedef itk::Image&lt;InputPixelType,2&gt; InputImageType;typedef itk::Image&lt;OutputPixelType,2&gt; OutputImageType;\n//二值滤波器typedef itk::BinaryThresholdImageFilter&lt;InputImageType,OutputImageType&gt; FilterType;\n//读图文件指针类型typedef itk::ImageFileReader&lt;InputImageType&gt; ReaderType;//写图文件指针类型typedef itk::ImageFileWriter&lt;OutputImageType&gt; WriterType;\n//读图文件指针ReaderType::Pointer reader = ReaderType::New();//过滤器管道FilterType::Pointer filter = FilterType::New();filter-&gt;SetInput(reader-&gt;GetOutput());\n//设置亮度值filter-&gt;SetOutsideValue(outsideValue);filter-&gt;SetInsideValue(insideValue);\n//设置阈值filter-&gt;SetLowerThreshold(lowerThreshold);filter-&gt;SetUpperThreshold(upperThreshold);\n//更新filter-&gt;Update();（2）（@todo）ThresholdBelow()ThresholdAbove()ThresholdOutside()7、线性映射（归一化）【Filtering/CastingImageFilters.cxx】（1）RescaleIntensityImageFilter 最小最大归一化rescaleFilter-&gt;SetInput(reader-&gt;GetOutput());rescaleFilter-&gt;SetOutputMinimun(10);rescaleFilter-&gt;SetOutputMaximum(250);（2）ShiftScaleImageFilter 根据缩放因子归一化（@todo）（3）NormalizeImageFilter 均值0方差1归一化（@todo）8、中值滤波器：用于保护边缘信息的平滑【Filtering/MedianImageFilter.cxx】#include \"itkMedianImageFilter.h\"//像素类型typedef unsigned char InputPixelType;typedef unsigned char OutputPixelType;//图像类型typedef itk::Image&lt;InputPixelType ,2&gt; InputImageType;typedef itk::Image&lt;OutputPixelType,2&gt;OutputImageType;\ntypedef itk::MedianImageFilter&lt;InputImageType,OutputImageType&gt; FilterType;FilterType::Pointer filter = FilterType::New();\n//设置中值滤波的模板InputImageType::SizeType indexRadius;indexRadius[0] = 1;indexRadius[1] = 1;filter-&gt;SetRadius(indexRadius);9、重采样图像滤波器【Filtering/ResampleImageFilter.cxx】输入：图像、变换、校对机#include \"itkResampleImageFilter.h\"#include \"itkAffineTransform.h\"#include \"itkNearestNeighborInterpolateImageFunction.h\"\nconst unsigned int Dimension=2;\n//像素类型typedef unsigned char InputPixelType;typedef unsigned char OutputPixelType;//图像类型typedef itk::Image&lt;InputPixelType ,Dimension&gt; InputImageType;typedef itk::Image&lt;OutputPixelType,Dimension&gt;OutputImageType;//重采样滤波器typedef itk::ResampleImageFilter&lt;InputImageType,OutputImageType&gt; FilterType;FilterType::Pointer filter = FilterType::New();\n//变换，这里采用默认变换typdef itk::AffineTransform&lt;double,Dimension&gt;TransformType;TransformType::Pointer transform = TransformType::New();filter-&gt;SetTransform(transform);\n//最近邻校对机typdef itk::NearestNeighborInterpolateImageFunction&lt;InputImageType,double&gt;InterpolatorType;InterpolatorType::Pointer interpolater = InterpolatorType::New();filter-&gt;SetInterpolator(interpolator);filter-&gt;SetDefaultPixelValue(0);//范围外的默认值\n//设定原点间距double spacing[Dimension];spacing[0] = 1.0;spacing[1] = 1.0;filter-&gt;SetOutputSpacing(spacing);double origin[Dimension];origin[0] = 0.0;origin[1] = 0.0;filter-&gt;SetOutputOrigin(origin);\n//设定重采样范围InputImageType::SizeType size;size[0] = 300;size[1] = 300;filter-&gt;SetSize(size);\nfilter-&gt;SetInput(reader-&gt;GetOutput());writer-&gt;SetInput(filter-&gt;GetOutput());writer-&gt;Update();【问题】重采样后，原来如果有gt图像，采样后的gt标记该怎么办？【解答】（@todo）【问题】重采样需要考虑各向同性的问题吗？如果不同性会有什么后果？【解答】（@todo）【问题】如何设置变换？【解答】设置一个-30，-50的平移变换TransformType::OutputVectorType translation;translation[0] = -30;translation[1] = -50;transform-&gt;Translate(translation);                \n","categories":["转载"],"tags":[]},{"title":"【LeetCode】第3题 最长无重复字母子串（三.J，四）","url":"http://tanqingbo.cn/2019/10/06/【LeetCode】第3题 最长无重复字母子串（三.J，四）/","content":"\nhttp://www.bewindoweb.com/155.html\n一、题目描述题目NO.3 最长无重复字母子串（Longest Substring Without Repeating Characters）给定一个字符串，找出最长的没有重复字母的子字符串的长度。样例输入输出和结果说明1、【输入】abcabcbb【输出】3【说明】最长的子串是abc。2、【输入】bbbbb【输出】1【说明】最长的子串是b。3、【输入】pwwkew【输出】3【说明】最长的子串是wke，注意必须要连续，是子串不是子序列。相关信息做题时间&nbsp;难度&nbsp;AC / submit&nbsp;2018/03/01&nbsp;中&nbsp;442.6K / 1.8M二、解题思路解题思路两侧各放一个指针，一旦遇到重复的值，则移动指针到新的位置，并一直记录最大值。在判定重复上面，直接使用桶排序的思想。注意到char最大255，因此桶取1000一定没问题。桶中-1表示没用过，&gt;=0的数字表示其在s中出现的位置。遇到的WA原因1、没有考虑到backres的更新backres每次都应该被更新为最大值，解决：backres = backres&gt;res ? backres : res;//记录最大数2、没有考虑到指针的移动fp指针如果不移动，哪怕遇到重复的也会一直累加，答案会加到很大的错误值。3、没有考虑到不止有a-z的字母样例：abcd*!-=解决：将a[26]改为a[1000]三、C和JAVA代码Cint lengthOfLongestSubstring(char* s) &#123;\n  int fp = 0;\n  int rp = 0;\n  int i, num, len, res = 0, backres = 0;\n  int a[1000];\n\n  len = strlen(s);\n  for (i = 0; i&lt;1000; i++) //重复桶，存储位置\n  a[i] = -1;\n  while (rp&lt;len){\n  num = s[rp];\n  if (a[num] == -1)&#123;//没有被使用\n      a[num] = rp;\n      res += 1;\n  &#125;\n  else&#123;//被使用了，存储一个备份\n      backres = backres&amp;gt;res ? backres : res;//记录最大数\n      res = res - (a[num] - fp + 1) + 1;//res减去让出来的，再把新的放进去\n      for (i = fp; i&amp;lt;=a[num]; i++)//先把前面的桶让出来\n          a[s[i]] = -1;\n      fp = i;//fp更新\n      a[num] = rp;//存储当前的\n  &#125;\n  rp++;\n  }  return backres&gt;res ? backres : res;}JAVA的四、有趣的题解和思维的五、相关链接1、本题链接                \n\n\n","categories":["转载"],"tags":[]},{"title":"【LeetCode】第4题 两个有序数组的中位数（三.J 四）","url":"http://tanqingbo.cn/2019/10/06/【LeetCode】第4题 两个有序数组的中位数（三.J 四）/","content":"\nhttp://www.bewindoweb.com/156.html\n一、题目描述题目NO.4 两个有序数组的中位数（Median of Two Sorted Arrays）有两个排好序的数组nums1和nums2，分别长m和n。找到两个有序数组的中位数，时间复杂度要求O(log(m+n))样例输入输出和结果说明1、【输入】nums1 = [1,3]，nums2 = [2]【输出】2.0【说明】mid [1,2,3] = 2.02、【输入】nums1 = [1,2]，nums2=[3,4]【输出】2.5【说明】(2+3)/2 = 2.5相关信息&nbsp;做题时间难度&nbsp;AC / submit&nbsp;&nbsp;2018/3/4难&nbsp;237.4K / 1M&nbsp;二、解题思路解题思路如果要求O(m+n)，那么两个指针顺序扫描即可；要求O(log(m+n))，需要进行二分查找。遇到WA的原因1、边界条件考虑了，但是代码写错了。边界条件肯定有一个空数组，但是C语言的除法是整除，在下标计算中出错了，解决：直接用除法而不是ceil。考核知识点边界条件、二分查找。三、C和JAVA代码C（时间O(m+n)，32ms，AC）double findMedianSortedArrays(int* nums1, int nums1Size, int* nums2, int nums2Size) &#123;\n  int mid;\n  int p1, p2;\n  int count;\n  int val[2];\n\n  if (nums1Size &lt;= 0)&#123;\n  if (nums2Size % 2)\n      return nums2[(nums2Size / 2)];//注意这里是整除 1/2 = 0\n  else\n      return 1.0*(nums2[(nums2Size / 2)-1] + nums2[(nums2Size / 2)])/2; // 2/2=1  2/2\n  }  else if(nums2Size &lt;= 0){\n  if (nums1Size % 2)\n      return nums1[(nums1Size / 2)]; // 3/2=1 \n  else\n      return 1.0*(nums1[(nums1Size / 2)-1] + nums1[(nums1Size / 2)])/2;\n  }\n  p1 = 0;  p2 = 0;  count = 0;  val[1] = 0;  mid = (nums1Size + nums2Size) / 2 + 1;//奇(2+1)/2 +1 = 1+1 =2  偶(2 + 2) / 2 + 1 = 3;\n  while (count &lt; mid){\n  if (p2 == nums2Size || p1 &amp;lt; nums1Size &amp;amp;&amp;amp; nums1[p1] &amp;lt; nums2[p2])&#123;\n      val[0] = val[1];\n      val[1] = nums1[p1];\n      p1++;\n  &#125;\n  else&#123;\n      val[0] = val[1];\n      val[1] = nums2[p2];\n      p2++;\n  &#125;\n  count++;\n  }\n  if ((nums1Size + nums2Size) % 2)\n  return val[1];\n  else\n  return 1.0*(val[0] + val[1])/2;\n}C（O(log(m+n))）的JAVAJAVA code四、有趣的题解和思维的五、相关链接1、本题链接                \n\n\n","categories":["转载"],"tags":[]},{"title":"【LeetCode】第5题 最长回文子串（三.J）","url":"http://tanqingbo.cn/2019/10/06/【LeetCode】第5题 最长回文子串（三.J）/","content":"\nhttp://www.bewindoweb.com/160.html\n一、题目描述题目NO.5 最长回文子串（Longest Palindromic Substring）给定一个字符串s，找出s中最长的回文子串，s最大长度不超过1000。样例输入输出和结果说明1、【输入】\"babad\"【输出】\"bab\"【说明】\"bab\"、\"aba\"都是正确答案。2、【输入】\"cbbd\"【输出】\"bb\"相关信息&nbsp;做题时间难度&nbsp;AC / submit&nbsp;&nbsp;2018/3/9中292K / 1.2M&nbsp;二、解题思路解题思路字符串长度不大，指定p为当前位置、q为末尾位置，扫描全字符串，每次q先向前-1直到和p指向的字符相等，然后p从当前位置向后+1，q继续向前-1，直至相遇或位置上的字符不相等：（1）如果一直到相遇，则说明是个回文，记录下两端的指针，记录下最大长度；（2）如果字符不相等，那么重置p，且q=末尾-1，开始又重新再扫描一遍。遇到WA的原因1、输出为null因为LeetCodeOJ似乎在退出函数后，就不再保留局部字符串空间了，解决：进行动态内存的分配：char as[1001];\n改为\nchar *as;\nas = (char*)malloc(1001 * sizeof(char));2、Runtime Error没有给字符串末尾加入'\\0'导致字符串没有结束。考核知识点字符串，回文三、C和JAVA代码Cchar* longestPalindrome(char* s) &#123;\n  int i, j;\n  int len,maxlen;\n  char *as;\n  int p, q, ap, aq, sp, sq;\n\n  as = (char*)malloc(1001 * sizeof(char));  len = strlen(s);  maxlen = 0;  for (i = 0; i &lt; len; i++)&#123;\n  p = i;\n  q = len;\n  sp = p;\n  sq = q;\n  while (q &amp;gt;= p)&#123;\n      if (s[q] == s[p])&#123;\n          p++;\n          q--;\n      &#125;\n      else&#123; // 回文中断\n          p = i;\n          q = sq - 1;\n          while (s[q] != s[p] &amp;amp;&amp;amp; q &amp;gt;= p)\n              q--;\n          sp = p;\n          sq = q;\n      &#125;\n  &#125;\n  if (sq - sp +1&amp;gt; maxlen)&#123;\n      ap = sp;\n      aq = sq;\n      maxlen = sq - sp +1;\n  &#125;\n  }  j = 0;  for (i = ap; i &lt;= aq; i++){\n  as[j] = s[i];\n  j++;\n  }  as[j] = ‘\\0’;  return as;}JAVAJAVA code四、有趣的题解和思维思路一 （一般）O(n^2)最长公共子串【关键】逆转字符串，找到合适的最长公共子串将字符串S逆转为S’，然后求LCS(S，S’)，注意看下标是否对齐，例如：S = ‘abacdxxxxdcaba’，S’ = ‘abacdxxxxdcaba’，LCS = ‘abacd’，然而它并不是一个回文。思路二 （差）O(n^3)Brute Force暴风算法【关键】遍历，根本不是算法暴风算法其实就是遍历……找到所有子串，然后看是不是回文……肯定很慢很慢的呀。思路三 （好）O(n^2)动态规划【关键】利用已有的回文初始状态，定义P（i，j）为：那么，状态转移方程：思路四 （好）O(n^2)扩展中心【关键】抓住回文特征：中心向外扩展一共有2*n-1个中心（注意不是n个中心，因为中心可能会有两个字符组成，例如“abba”，中心是“bb”）思路五 （好）O(n)manacher算法【关键】manacher算法可以达到O(n)的复杂度，但是理解很困难具体算法和AC代码见《Manacher算法：最长回文子串》五、相关链接1、本题链接                \n\n\n","categories":["转载"],"tags":[]},{"title":"一致性Hash","url":"http://tanqingbo.cn/2019/10/06/一致性Hash/","content":"\nhttp://www.bewindoweb.com/253.html前言一致性Hash是分布式架构最重要最基础的东西，这里以分布式图片缓存服务器为例进行讲述。原始问题：假设我们需要对一堆图片做缓存，缓存的图片放在了2台服务器上，当到来一个请求，应该如何知道请求的图片在哪台上面呢？暴力遍历就不要去想了，否则缓存就没有意义了。一个自然的想法就是根据图片的名字做一个映射（Hash），将图片名字映射到0，1两个数字上面，例如有这样的映射函数：f(图片名称) = md5(图片��称) % 2md5是一个典型的哈希函数，会产生128bit的值，模2后只可能是0或1，那么我们就根据这个值把图片存入0、1两台服务器，当请求过来，根据图片名称计算出值，就可以知道图片缓存放在第几号服务器了：但假设现在我们图片太多了，需要再增加一台服务器分担压力，哈希函数必须更改成0、1、2映射，我们改为：f(图片名称) = md5(图片名称) % 3理论上讲，会有(N-1)/N的缓存会失效，其中N是服务器的数量，例如上述图片缓存，除了0图片、1图片，其余图片的存放位置都变了，失效的缓存有 2/3 * 6 = 4张图片：减少图片服务器数量造成的后果亦是如此——在同一个时刻将会有大量缓存同时失效，称为“缓存雪崩”。失效了就会直接去后端服务器取，大量的请求直接透过缓存打到后端服务器，后端服务器极有可能承受不住压力而接连崩溃，最终造成整个系统瘫痪。所以出现进阶问题：当缓存服务器数量发生变���时，如何尽可能避免大量缓存同时失效？答案就是一致性Hash。一、一致性Hash原理1、放置服务器我们将服务器像图片一样也进行哈希，服务器的“图片名称”一般就使用固定IP地址，Hash取模也不再是服务器数量，而是2^32，Hash的方法也不局限于md5，用一个抽象的函数表示：f(服务器IP地址) = Hash(服务器IP地址) % 2^32于是服务器被放置到了0~2^32-1某个数字对应的位置上去：这里0~2^32-1是顺时针放置还是逆时针放置，网上的说法不一，虽然不影响算法，但统一会更好。我在原论文《Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web》中没有找到相应的描述，于是采用了网上的主流选择：顺时针放置0~2^32-1。为什么是2^32-1呢？因为第一次提出一致性Hash的论文是1997年发表的，那时候32位机器还是主流，2^32-1是最大的Integer。而现在64位早就普及了，完全可以将这个值扩大到2^64-1。&nbsp;&nbsp;2、放置数据我们将数据也按照相同的方式放到0~2^32-1的某个数字上去：f(图片名称) = Hash(图片名称) % 2^32&nbsp;&nbsp;3、把数据放到服务器上对于每个数据，从映射的位置开始，顺时针行走，放置到碰到的第一个服务器上。例如3、230将会放到0号图片服务器，232将会放到1号图片服务器，4175556547将会放到2号图片服务器：这样一致性Hash就完成了。查找数据也是先映射、再顺时针行走找到第一台服务器。二、一致性Hash如何缓解数据失效问题假设现在1号服务器崩溃，图片232找不到1号服务器，顺时针行走的第一台服务器是2号服务器，于是232的缓存位置发生了改变，变为了2号：而对于其他图片来说，缓存位置并没有发生变化，影响的数据量从（N-1）/ N 降为了 M，其中M是0号图片服务器到1号图片服务器之间的图片数量。需要重新获取的缓存数据量降低了，雪崩问题自然也就能够得到缓解。三、Hash环偏斜和虚拟节点前面讨论得太理想了，实际的服务器分布和数据分布很可能是这样的：0、1、2三台服务器并没有均匀分布在环上，大量的图片数据都被放到了0号服务器上，而很少数据放到1、2号等其他图片服务器上，这种情况称之为Hash环偏斜。如果存放的是缓存则0号服务器崩溃就会引起缓存雪崩，如果存放的是数据则0号服务器就可能单点故障。很自然可以想到，增加多台服务器就好了嘛。我们在Hash环上生成0、1、2三台服务器的虚拟节点：具体的做法是，在服务器IP后面增加编号，每一台服务器产生多个Hash值，就能放置在0~2^32-1的多个位置上了。这样一来，顺时针行走能找到不同的服务器概率将会大大提高，避免了偏斜问题。虚拟的服务器节点数越多，偏斜出现的概率就越低。通常都需要设置32或以上的虚拟节点数目，我见过甚至有���置500的。                \n\n\n","categories":["转载"],"tags":[]},{"title":"中毒！HTML文件末尾被自动添加VBS的脚本","url":"http://tanqingbo.cn/2019/10/06/中毒！HTML文件末尾被自动添加VBS的脚本/","content":"\nhttp://www.bewindoweb.com/140.html前言最近发现电脑变慢，并且html文件末尾被自动添加VBS脚本。开始还以为是编辑器添加的，后来在今日头条上看到一篇文章介绍才知道是病毒。用360扫描，1W多个文件都被感染，包括DLL、HTML、EXE。怪不得每次打开迅雷的时候360就会报毒，原来是DLL文件被感染了。添加的脚本如下：&lt;SCRIPT Language=VBScript&gt;&lt;!--\n\n\n","categories":["转载"],"tags":[]},{"title":"为什么用MQTT不用TCP长连接透传","url":"http://tanqingbo.cn/2019/10/06/为什么用MQTT不用TCP长连接透传/","content":"\nhttp://www.bewindoweb.com/266.html前言在接触到MQTT之后，总是会有疑问，为什么用MQTT不用TCP长连接透传？看起来【TCP长连接+私有协议透传】和【MQTT+业务主题】似乎都能达到同样的目的，甚至用MQTT会使得设备端逻辑实现、APP端逻辑实现、云端架构实现更加复杂。那么为什么物联网还要使用MQTT协议呢？一、MQTT相比于TCP长连接的优势1、协议更标准MQTT是标准的RFC协议，相比于私有协议而言更加标准。好处在于：（1）协议非常完整，能够马上用于生产。各端实现同一套协议之后，就能进行通信；私有协议还需要进行大量的验证，看有无缺陷或欠考虑的地方等。（2）协议的标准化带来大量的开源组件，降低开发难度。随着物联网+5G生态越来越好，开源组件越来越多，可以减少重复编码量。（3）标准协议利于第三方接入。当第三方设备、平台想要对接的时候，拿出一套标准的MQTT协议拍在他们脸上，再也没人有理由要求改接口了。2、MQTT协议制定好了很多利于物联网的功能当然TCP自己开发协议也能做到，但MQTT都已经把功能做好了，自己开发协议反而增加难度。有利的功能包括：（1）心跳机制。不需要自己做业务协议层的心跳了。（2）遗嘱消息。这对于经常掉线的物联网设备而言非常有用。（3）QoS质量等级+离线消息。持久会话离线的消息也能接收到，对于网络不稳定但要求必须送达的物联网场景很有用。（4���异步机制。MQTT将消息以QoS1/2发送出去后，设备端就不需要再管了，一切由云端负责失败重传。（5）订阅发布机制。一次发布，多个客户端订阅，这对于M2M场景很省电、省流量。（6）主题和安全。可以用主题来方便地控制客户端权限。以上的功能基于TCP自己开发也能做到，如果自己都开发了，不就是实现了应用层的MQTT协议了吗3、理解数据内容，用数据产生价值IoT目前主流设计有两部分：（1）设备影子价值微软Azure叫设备孪生（Device Twins），亚马逊AWS叫设备影子（Device Shadow），阿里云叫设备影子（Device Shadow），腾讯云叫设备影子（Device Shadow），百度云叫物影子（Shadow）。为什么这么多大厂都要开发这个概念呢，设备影子包含了设备的状态，不用一个一个透传查询设备，直接在云端访问设备影子就能够得到当前所有设备的状态数据，这蕴含着巨大的利益，比如统计数据用于引导开发新产品和功能、统计数据用于修复bug等等。（2）规则引擎价值AWS、阿里云、腾讯云、百度云，都叫规则引擎（Rule Engine）。由于MQTT细分了具体的主题，当业务以主题区别的时候，直接将对应主题的数据通过规则引擎配置的规则自动分发给其他的数据接收者，比如阿里云可以发送给：关系数据库RDS，进行普通存储时序数据库TSDB，可用于时序分析存储桶Bucket，当文件存储消息队列MQ，可以转发给多个其他服务函数计算，无服务器地处理某项工作实时流，实时地发送给某些对时间敏感的服务另一个主题，可以实现M2M通信这些都可以有很多操作空间，随便举个例子，把所有的天猫精灵的语音数据发送到MQ，然后用后端服务慢慢分析，利用机器学习算法研究出什么样的用户群体喜欢使用什么样的功能，好针对性地卖产品，比如阉割一些功能，卖“青春版”天猫精灵，或者增加一些高端功能，卖“商务版”天猫精灵。这些都是TCP透传这种云不理解业务数据内容做不到的（不要说TCP也可以解包然后分析业务数据然后转发，这样不就是变相地实现了MQTT了吗）。二、选择MQTT还是TCP长连接透传这需要看具体的业务场景。1、原始的业务场景MQTT之所以叫做“消息队列遥测传输”协议，就是因为最开始是用来将无人看管的石油天然气管道数据通过卫星链路上报给数据中心，当时的需求在于：（1）石油天然气管道大多处于无人区，更不可能有基站了，只能通过偶尔覆盖的卫星来通信。卫星通信极其不稳定，很容易频繁断开连接。（2）数据采集频率不高，且数据量小。（3）有的消息很重要，需要有质量保证，比如石油泄漏，即使想发送的时候断网了，也应该在断网后能够传出去，且传出去必须要保证送达。（4）采集设备都是嵌入式设备，要求低功耗。这不就是MQTT的“会话机制”、“异步机制”、“QoS机制”等功能的体现吗。2、端对端M2M场景——无人汽车有的业务是不需要APP的，只有云和设备端，并且消息从一个设备端发到另一个设备端，这个时候用MQTT再合适不过了，因为一个设备如果想要发给多个设备消息，考虑到嵌入式资源有限一次只能保持一条TCP SSL连接，采用TCP透传必然要频繁建立TCP连接，这对低功耗的设备是致命的；而用MQTT，由云端负责转发就非常方便。3、APP控制设备端场景——智能家居、智能快递柜其实采用TCP透传和MQTT都可以，如果MQTT只订阅一个主题，只发布一个主题，payload填业务数据，不就退化成TCP长连接透传了吗。有的可能已经有私有协议了，如果想要把IoT做大，可以考虑MQTT协议；如果想减少成本尽快上线，用TCP透传也可以。4、其他场景MQTT还可以用于其他场景，比如APP消息推送（知乎网关），游戏数据长连接，网络聊天等等，都存在真实案例。他们不用TCP长连接的理由会有很多，比如知乎是为了复用同一套长连接系统，解耦业务数据，保证消息质量等。总结当别人问为什么要用MQTT不用TCP长连接透传的时候，要先体会MQTT的好处，然后结合自己的业务分析是否真的有必要上MQTT（毕竟MQTT整套下来成本比TCP高不少）。当然还有其他协议，比如室外的智能路灯由于只能通过基站上网，因此可以用插SIM卡的CoAP协议；一些总是插电的资源很多的设备如路由器，甚至可以用HTTP协议。在纠结MQTT协议的时候，这些都是可以考虑的方向。                \n\n\n","categories":["转载"],"tags":[]},{"title":"从CDN莫名301跳转源站看回源Host","url":"http://tanqingbo.cn/2019/10/06/从CDN莫名301跳转源站看回源Host/","content":"\nhttp://www.bewindoweb.com/254.html前言由于3月初七牛云的云存储的CDN回源流量开始收费，穷困的我准备放弃使用七牛云存储，只使用CDN（研究后发现七牛云的0.15/GB已经是业界很低的价格了，如果有条件还是可以支持的）。于是我在3月初重新配置了一次CDN，可这次配置导致了一个奇怪的现象，那就是无论我如何设置CDN，访问的cdn.bewindoweb.com的时候总是产生一个HTTP 301永久跳转，跳转回了www.bewindoweb.com，再HTTP 200下发数据：访问CDN就相当于只多了一层跳转，数据还是从网站服务器拿到的，完全没有CDN的作用……最近发现越来越卡，图片的流量挤爆了我的1M小水管，网站打开一直转圈圈，于是下定决心要弄好为止。一、查找表面原因百度了半天CDN跳转301回源站，出来的都是不相关的信息，所以我打算从七牛的监控来看。打开七牛云融合CDN的监控，调取近一个月的状态码，发现自从改了之后，以前的命中200全部变成了永久跳转301：仔细地对比2月份和3月份的数据：可以确定一定有哪里出问题了，注意到3月份还是有200的，于是去看看200是些什么数据，把日志下载下来，发现200是直接访问cdn.bewindoweb.com的，而301全是图片URL：HIT 18 [10/Mar/2019:04:21:53 +0800] \"GET http://cdn.bewindoweb.com/uploadpic/fedd9da8584c1430eaa23b6e1abc6c2e.png HTTP/1.1\" 301 \nHIT 73 [10/Mar/2019:04:56:28 +0800] \"GET http://cdn.bewindoweb.com/ HTTP/1.1\" 200 修改了很多地方，包括重新使用七牛云存储、修改防盗链Refer，都不行，说明是CDN的设置问题。实在是不了解为什么跳转，于是提交了工单，和客服小哥哥聊天，其实现在回去翻记录，小哥哥在第一句话就指出了问题所在：你好，\n您设置源站为 www.bewindoweb.com，测试您的测试资源是301跳转到您的源站url：\n您这边源上是否有设置了跳转我当然不知道，于是继续聊，他也在测试，测试后发现当源站域名和回源Host这样配置的时候，能够成功获取到数据：类目&nbsp;数值&nbsp;&nbsp;源站域名www.bewindoweb.com&nbsp;&nbsp;回源Host&nbsp;www.bewindoweb.com而我是这样设置的：类目&nbsp;数值&nbsp;&nbsp;源站域名www.bewindoweb.com&nbsp;&nbsp;回源Hostcdn.bewindoweb.com当我把回源host修改成www了之后发现，部分图片URL的CDN可以正常访问了。当我用七牛云提供的刷新预取功能重置了CDN有关图片的缓存后，全站CDN可以正常访问了。二、解决办法所以解决办法就是将回源Host从cdn.bewindoweb.com改为www.bewindoweb.com，重新刷新CDN缓存，就可以正常使用了。三、探究回源Host为什么这样配置就好用了呢，仔细理解回源Host的定义：回源 HOST ：是指 CDN 节点在回源过程中，在源站访问的站点域名。具体地说：源站：源站决定了回源时，请求到哪个 IP 。&nbsp;回源 HOST ：回源 HOST 决定回源请求访问到该 IP 上的哪个站点。画出来访问过程就是，CDN发生回源的时候，先用源站域名找到IP地址，在访问这个IP的时候携带回源Host，来表明自己要访问这台机器上的哪个站点。为什么要携带Host呢，因为一台机器可能会部署多个子站点，比如图片用img、文件用file，网站服务器可以根据不同的Host进行对应的处理。再来思考为什么我用cdn.bewindoweb.com作为回源Host不行呢？由于我只缓存图片，所以设置成了cdn，按理来说应该可以，于是回去检查nginx配置，发现：if ($host != 'www.bewindoweb.com')&#123;\n          rewrite ^/(.*)$ http://www.bewindoweb.com/$1 permanent;\n      &#125;终于找到301跳转的原因，我自己配置的……这是很久以前，我为了防止直接通过IP地址访问的时候，URL前面是IP，或者用www.bewindoweb.cn访问的时候，URL前面是cn，用nginx强制给替换成.com了。而发布的站点就只有www一台，所以用www做回源域名可以访问到数据，用cdn做回源域名被301跳转到www。最开始小哥哥就说了是不是我自己设置了跳转，我根本想不起来这件事，现在终于理解了原因。所以我百度的问题就错了，因为根本不会有其他的人碰到这种问题，重新百度“回源Host配置”，大量的正确解答出来了，比如《【CDN 常见问题】CDN回源Host的意义》中的这段话：举例说明，如下是一段nginx配置server的常用配置方法，从该配置上我们可以查看到该服务器上配置一个名为www.aliyun.com的站点监听服务器的80端口，并设置了该站点的根目录路径。server {&nbsp; &nbsp;listen 80; #default_server;&nbsp;&nbsp; &nbsp;server_name www.aliyun.com;&nbsp;&nbsp; &nbsp;location / {&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;root /alidata/www/www-aliyun-com/;&nbsp; &nbsp;}&nbsp;}然后创建cdn加速域名cdntest1.aliyun.com，设置其源站为www.aliyun.com，并设置回源端口为80端口。此时如果设置回源host为关闭或者设置为cdntest1.aliyun.com时，将导致CDN回源时到源站查找server_name为cdntest1.aliyun.com的站点，而由于源站配置配置对应的站点导致出现4XX的错误了。因此此时正确的配置应该将回源host改成www.aliyun.com，这样才可以找到对应的server并到其location目录中查找对应的文件返回给CDN节点。这个4xx找不到的理由不就和我3xx跳转一样嘛！总之问题解决、原因找到了，很开心。七牛的服务态度真的特别好，我刚提交工单很快就回复了，哪怕我是免费用户……不像阿里或者腾讯服务器，提交半天没人理……以后多支持吧。                \n\n\n","categories":["转载"],"tags":[]},{"title":"似乎百度云加速是免费的","url":"http://tanqingbo.cn/2019/10/06/似乎百度云加速是免费的/","content":"\nhttp://www.bewindoweb.com/114.html记录一下，以后试试。http://su.baidu.com/product/cdn.html配置：正确开启……-------------------------------- 2017.12.3更新&nbsp;--------------------------------&nbsp;用了一下根本不行……感觉没有加速的效果……本来是想把下载的带宽从站内分离出去，后来觉得用CDN应该不行，要用阿里的OSS+CDN，一个网盘+一个分发应该才行。然而OSS需要钱……并木有钱，所以暂时搁置吧。另外CDN是无法重命名的，php可以写重命名：//打开文件\n$file = fopen ( $file_dir . $file_name, \"r\" );\n//输入文件标签\nheader ( \"Content-type: application/octet-stream\" );\nheader ( \"Accept-Ranges: bytes\" );\nheader ( \"Accept-Length: \" . filesize ( $file_dir . $file_name ) );\nheader('Content-Length: ' . filesize ( $file_dir . $file_name ));\nheader ( \"Content-Disposition: attachment; filename=\" .$newname);\n//输出文件内容\n//读取文件内容并直接输出到浏览器\necho fread ( $file, filesize ( $file_dir . $file_name ) );\nfclose ( $file );\nexit();然而CDN只会直接输出链接没查到处理文件名的方式。                \n\n\n","categories":["转载"],"tags":[]},{"title":"免费一年的亚马逊服务器","url":"http://tanqingbo.cn/2019/10/06/免费一年的亚马逊服务器/","content":"\nhttp://www.bewindoweb.com/229.html前言最近想了解一下亚马逊服务器相关的东西，比如EC2、Lambda等等不同的云产品到底有些什么特性，主要用来做什么的，所以需要注册帐号。问了下在亚马逊做市场的大佬同学，才知道新账号可以免费一年（但其实很多人都知道，只是我孤陋寡闻而已……）。一、需要材料邮箱（QQ邮箱即可）手机号国际信用卡（Master、Visa），是国际的哦，美元支付的那种二、注册过程1、进入亚马逊AWS官网：2、注册海外服务器（点击立即注册按钮）千万别弄国内的，国内还需要申请，还需要是法人，真是睿智：点击右边的立即注册按钮后是这样的，直接就可以注册：3、填写一些个人信息提示填写一系列的个人信息。手机号一定要是真实的，信用卡一定要是真实的，而且注意设置过期时间哦：4、选择支持计划当然选免费啦。5、填写验证码会有电话打给你手机，然后语音播报4位数字（填手机号填了+86中国，就会用中文跟你讲的），填上数字，注册就好了。6、信用卡验证然后亚马逊会扣信用卡1美元来验证信用卡是否有效，据同学说这1美元后面会归还的，就算不归还7块多而已。7、享受服务亚马逊官网，中国区官网：简直不要太爽哦。值得注意的是：（1）750小时=31.25天，也就是可以一个月一台EC2一直开着；如果你同时开启2台EC2实例全天候运行，只能用15天，超过时间的部分是要算钱的……（2）时间计算是以1小时算的，哪怕是在几分钟开闭几次，也会算成几小时……（3）还有就是，12个月后是不会停的，需要你手动停（和大部分免费套路一样，只管开不管停），否则也是要算钱……最后，这里列一些具体的免费体验内容（12个月）：服务类型&nbsp;产品名称&nbsp;免费使用量&nbsp;&nbsp;存储和内容分发&nbsp;Amazon S3&nbsp;5 GB 存储&nbsp;计算&nbsp;Amazon EC2&nbsp;750 小时/月&nbsp;存储和内容分发&nbsp;Amazon EFS&nbsp;5 GB 存储&nbsp;数据库&nbsp;Amazon RDS&nbsp;750 小时/月&nbsp;物联网&nbsp;AWS IoT&nbsp;250K 条消息/月&nbsp;计算&nbsp;Amazon Elastic Container Registry&nbsp;500 MB 存储/月&nbsp;计算&nbsp;Elastic Load Balancing&nbsp;750 小时/月&nbsp;存储和内容分发&nbsp;Amazon CloudFront&nbsp;50 GB 数据传出量&nbsp;存储和内容分发&nbsp;Amazon Elastic Block Storage&nbsp;30 GB 硬盘容量&nbsp;数据库&nbsp;Amazon ElastiCache&nbsp;750 小时&nbsp;分析&nbsp;AWS Data Pipeline&nbsp;3 （低频前提条件）&nbsp;身份、安全性与合规性&nbsp;Amazon Cloud Directory&nbsp;1 GB 存储/月&nbsp;分析&nbsp;Amazon Elasticsearch Service&nbsp;750 小时/月&nbsp;开发人员工具&nbsp;AWS Trusted Advisor&nbsp;4 次性能和安全检查&nbsp;应用程序服务&nbsp;Amazon API Gateway&nbsp;1 百万 API调用次数/月&nbsp;媒体服务&nbsp;Amazon Elastic Transcoder&nbsp;20 分钟音频转码时长&nbsp;人工智能&nbsp;Amazon Rekognition&nbsp;5000&nbsp; 张图像/月&nbsp;人工智能&nbsp;Amazon Lex&nbsp;10,000 次文本请求/月&nbsp;&nbsp;人工智能&nbsp;Amazon Polly&nbsp;5 百万 字符/月&nbsp;管理工具&nbsp;AWS OpsWorks for Chef Automate&nbsp;7500 节点小时/月&nbsp;移动服务&nbsp;Amazon Pinpoint&nbsp;5,000 免费目标用户数/月&nbsp;视频游戏服务器&nbsp;Amazon GameLift&nbsp;125 小时/月，50GB /月&nbsp;联络中心&nbsp;Amazon Connect&nbsp;90 分钟/月物联网&nbsp;&nbsp;AWS Greengrass&nbsp;3 台设备                \n\n\n","categories":["转载"],"tags":[]},{"title":"八大排序基础算法（未完成）","url":"http://tanqingbo.cn/2019/10/06/八大排序基础算法（未完成）/","content":"\nhttp://www.bewindoweb.com/116.html一、概述八大排序分别是：直接插入排序、希尔排序、简单选择排序、堆排序、冒泡排序、快速排序、归并排序、基数排序。性能比较：                \n\n\n","categories":["转载"],"tags":[]},{"title":"利用extundelete找回rm-rf彻底删除的文件","url":"http://tanqingbo.cn/2019/10/06/利用extundelete找回rm-rf彻底删除的文件/","content":"\nhttp://www.bewindoweb.com/207.html前言被布置了几个写linux内核设备驱动的作业，周末断断续续写了两天，也付出了不少精力。当我想在Makefile里面的clean多写点东西，把该删除的都删除了，想删除一个.mod.c的文件，一不小心直接写了个.c把c文件也一起删了……：clean:\n$(shell rm -f *.bak *o *.ko *.c *.order *.symvers)呆呆地望着剩下的Makefile，欲哭无泪……于是赶紧查了查有没有补救方案，果然查到了extundelete这款软件可以恢复，尝试了一下，成功了。一、使用条件extundelete只适用于ext3、ext4文件系统，vmware虚拟机的硬盘大多都挂在/dev/sda1上，ubuntu常用的都是ext4。你可以通过以下命令查看操作系统和linux版本：uname -a\nLinux ubuntu 3.16.0-30-generic #40~14.04.1-Ubuntu SMP Thu Jan 15 17:43:14 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux你可以通过以下命令查看分区格式：df -hT\nFilesystem     Type      Size  Used Avail Use% Mounted on\n/dev/sda1      ext4       46G   13G   31G  30% /\nnone           tmpfs     4.0K     0  4.0K   0% /sys/fs/cgroup\nudev           devtmpfs  2.0G  4.0K  2.0G   1% /dev\ntmpfs          tmpfs     395M  3.5M  392M   1% /run\nnone           tmpfs     5.0M     0  5.0M   0% /run/lock\nnone           tmpfs     2.0G  152K  2.0G   1% /run/shm\nnone           tmpfs     100M   60K  100M   1% /run/user二、安装过程1、下载extundelete可以从extundelete官网的Download the latest version中的链接进行下载，这里提供一个v0.2.4版本，百度网盘（密码&nbsp;tft3）。2、安装——configuresudo ./configure这里configure可能会遇到问题：Configuring extundelete 0.2.4 \nconfigure: error: Can't find ext2fs library说是找不到ext2fs库，解决办法是：sudo apt-get install e2fslibs-dev e2fslibs-dev再配置就不会有问题了，就会提示成功：Configuring extundelete 0.2.4\nWriting generated files to disk3、安装——makesudo make &amp;&amp; make install注意一定要用root权限，否则安装出错。可能会提示警告信息，不过可以无视它：make -s all-recursive\nMaking all in src\nextundelete.cc: In function ‘ext2_ino_t find_inode(ext2_filsys, ext2_filsys, ext2_inode*, std::string, int)’:\nextundelete.cc:1272:29: warning: narrowing conversion of ‘search_flags’ from ‘int’ to ‘ext2_ino_t &#123;aka unsigned int&#125;’ inside &#123; &#125; [-Wnarrowing]\n  buf, match_name2, priv, 0&#125;;\n                           ^4、检查是否安装成功sudo extundelete --help会出现帮助信息：Usage: extundelete [options] [--] device-file\nOptions:\n--version, -[vV]       Print version and exit successfully.\n--help,                Print this help and exit successfully.\n--superblock           Print contents of superblock in addition to the rest.\n                       If no action is specified then this option is implied.\n--journal              Show content of journal.\n--after dtime          Only process entries deleted on or after 'dtime'.\n--before dtime         Only process entries deleted before 'dtime'.\nActions:\n--inode ino            Show info on inode 'ino'.\n--block blk            Show info on block 'blk'.\n--restore-inode ino[,ino,...]\n                       Restore the file(s) with known inode number 'ino'.\n                       The restored files are created in ./RECOVERED_FILES\n                       with their inode number as extension (ie, file.12345).\n--restore-file 'path'  Will restore file 'path'. 'path' is relative to root\n                       of the partition and does not start with a '/'\n                       The restored file is created in the current\n                       directory as 'RECOVERED_FILES/path'.\n--restore-files 'path' Will restore files which are listed in the file 'path'.\n                       Each filename should be in the same format as an option\n                       to --restore-file, and there should be one per line.\n--restore-directory 'path'\n                       Will restore directory 'path'. 'path' is relative to the\n                       root directory of the file system.  The restored\n                       directory is created in the output directory as 'path'.\n--restore-all          Attempts to restore everything.\n-j journal             Reads an external journal from the named file.\n-b blocknumber         Uses the backup superblock at blocknumber when opening\n                       the file system.\n-B blocksize           Uses blocksize as the block size when opening the file\n                       system.  The number should be the number of bytes.\n--log 0                Make the program silent.\n--log filename         Logs all messages to filename.\n\n–log D1=0,D2=filename   Custom control of log messages with comma-separated   Examples below:       list of options.  Dn must be one of info, warn, or   –log info,error      error.  Omission of the ‘=name’ results in messages   –log warn=0          with the specified level to be logged to the console.   –log error=filename  If the parameter is ‘=0’, logging for the specified                         level will be turned off.  If the parameter is                         ‘=filename’, messages with that level will be written                         to filename.   -o directory          Save the recovered files to the named directory.                         The restored files are created in a directory                         named ‘RECOVERED_FILES/‘ by default.三、恢复文件过程1、找到删除的那个文件的Inode编号列出/dev/sda1硬盘上的根节点inode信息：sudo extundelete --inode 2  /dev/sda1可能会提示你警告信息，可以无视，输入y就行了：NOTICE: Extended attributes are not restored.WARNING: EXT3_FEATURE_INCOMPAT_RECOVER is set.The partition should be unmounted to undelete any files without further data loss.If the partition is not currently mounted, this message indicatesit was improperly unmounted, and you should run fsck before continuing.If you decide to continue, extundelete may overwrite some of the deletedfiles and make recovering those files impossible.  You should unmount thefile system and check it with fsck before using extundelete.Would you like to continue? (y/n)y得到的结果：File name                                       | Inode number | Deleted status.                                                 2..                                                2lost+found                                        11etc                                               524289media                                             655361bin                                               1966081boot                                              262145dev                                               2883585home                                              1703937lib                                               786433lib64                                             1048577mnt                                               2359297opt                                               1835009proc                                              2097153root                                              2228225run                                               917505sbin                                              1179649srv                                               393217sys                                               1310721tmp                                               1572865usr                                               2490369var                                               2621441vmlinuz                                           12initrd.img                                        13cdrom                                             1441793RECOVERED_FILES                                   1441794我的文件在home，进入home，home的inode编号为1703937，继续搜索：sudo extundelete --inode 1703937 /dev/sda1得到的结果：File name                                       | Inode number | Deleted status.                                                 1703937..                                                2bwb                                               1703938就这样一直搜索下去，直到找到删除的文件：我希望恢复那个c文件，编号是2247885，用小本本记下来。2、恢复文件sudo extundelete --restore-inode 2247885 /dev/sda12247885是刚刚那个Inode的编号，操作过后查看根目录，会发现多了一个RECOVERED_FILES目录：ls /bin    dev   initrd.img  lost+found  opt              root  srv  usrboot   etc   lib         media       proc             run   sys  varcdrom  home  lib64       mnt         RECOVERED_FILES  sbin  tmp  vmlinuz然后查看一下：bwb@ubuntu:/RECOVERED_FILES$ lsfile.2247885这个file.2247885就是那个.c文件的内容了。QAQ终于救回来了。四、参考资料1、《误用rm -rf *文件修复及修改rm指令为mv》2、extundelete官网3、《configure 配置 extundelete-0.2.0的时候发现提示 没有找到 ext2fs 库的解决办法》4、bwbwiki：extundelete官网文档中文翻译                \n","categories":["转载"],"tags":[]},{"title":"利用搬瓦工一键科学上网","url":"http://tanqingbo.cn/2019/10/06/利用搬瓦工一键科学上网/","content":"\nhttp://www.bewindoweb.com/147.html一、前言因为毕业设计某些资料需要去外网查询，之前自建的Strongswan搭建的VPS效果并不太理想，毕竟只是照着教程做，没有时间去深入理解原理。由于需要科学上网，听说搬瓦工很好用，希望能用到我有空去研究的时候……二、注册和购买的闲谈进入搬瓦工官网搬瓦工的官方地址已经被GFW墙了，只有搭梯子才能看到，然而我们现在正是没梯子需要搭梯子的阶段……还好据说官方又出了一个备用地址可以直连，最开始我还以为是钓鱼网站，后来发现浏览器也没有报钓鱼，并且多篇帖子都说是官方的，因此就当作是官方的吧，哪怕被骗钱，事实上真的是官方的。官方地址（被墙）：https://bandwagonhost.com备用地址（推荐）：https://bwh1.net/官方地址（被墙，aff是我的推广参数）：https://bandwagonhost.com/aff.php?aff=27230备用地址（推荐，aff是我的推广参数）：https://bwh1.net/aff.php?aff=27230长这样：解决搬瓦工无法注册的问题进入后发现哪怕是备用网址，都注册不了。原因在于搬瓦工的验证码调用的google的API，而google……所以没法看到验证码，无法注册。真心是不科学的验证码……正常情况（搭梯子访问）：异常情况（直连）：所以没个梯子连梯子都搭不了……幸运的是，可以在购买的时候直接填入信息来变相注册，这是不需要验证码的，因此直接购买想要的服务器，顺便填上信息就好了：推荐购买的便宜服务器注：购买链接加入了我的推广参数机型&nbsp;内存&nbsp;CPU&nbsp;硬盘&nbsp;流量/月&nbsp;价格&nbsp;机房&nbsp;购买链接&nbsp;KVM V3512MB1核10GB500GB$29.99/年CN2购买VZ512MB1核10GB500GB$19.99/年OVZ购买CN2有什么好处好处就是快。CN2全名为中国电信下一代承载网（China Net Next Carrying Network），遍布全球，相当于国外服务器直接拉了根网线到国内，不需要中间的路由多跳，节省了很多时延。同时搬瓦工的LOS ANGELES - CN2（推荐的第一款服务器）明确写明：所以中国电信和中国联通的用户用这个服务器速度和上百度一样。购买折扣优惠代码类似于优惠券代码，购买服务器的时候可以用：优惠码折扣&nbsp;BWH1ZBPVK&nbsp;6%BWH1XZOBK&nbsp;5.5%支付宝付款和费用统计最后付款的时候可以用支付宝了！点击checkout后，账单可以选择Alipay，就是国内常见的弹出一个二维码支付宝扫描付款，我买的第一款，$29.9约为191块钱，汇率大概在6.1左右，然后加上6%的折扣，只花了179.6块，相当于15块钱一个月……QQ充个钻的钱……真是便宜死了……速度看个1080P视频都是基础功能，开启BBR拥塞控制的话能看4K不卡……默认是安装的Centos 6 x86 bbr三、快速搭建手册选择推荐的服务器打开网址https://bwh1.net/aff.php?aff=27230&amp;pid=56选择喜欢的机房加入购物车填写6%折扣码并验证折扣码折扣码：BWH1ZBPVK&nbsp;点击checkout在Your Details填写个人信息并点击update相当于注册了，所有格子都要填哦。选择Alipay，勾选我同意，付款进入服务器控制面板回到搬瓦工首页，网址为https://bwh1.net，此时已经是登录状态，未登录的话登录即可，拉到最下面Client Area，选择My Services点击KiwiVM安装ShadowsocksR Server选择ShadowsocksR Server，点击Install按钮，一键自动安装，然后点击go back。这里推荐SSr，不推荐SS。下载对应的软件使用即可四、参考网址1、《搬瓦工最新全部购买方案》2、《搬瓦工VPS》讲解了很多相关东西，分享了很多相关资源3、《傻瓜式安装搬瓦工》4、《搬瓦工美西CN2线路VPS入手评测》                \n\n\n","categories":["转载"],"tags":[]},{"title":"原来学校的EDU邮箱是终身的……","url":"http://tanqingbo.cn/2019/10/06/原来学校的EDU邮箱是终身的……/","content":"\nhttp://www.bewindoweb.com/168.html今天想去尝试搭建一个JetBrains全家桶授权服务器（对不起对不起我以后挣钱会买的）……意外地看到可以用学生邮箱去得到激活码……《申请JetBrains学生免费注册码》然后继续百度，发现有人自己买个EDU域名来做邮箱，然而现在已经无法访问了（应该是服务器资源分配完了）还有人说，学校不是有终身免费的EDU邮箱吗？于是……发现了尘封多年的电子科大EDU邮箱……壮哉我大成电！！！打开邮箱，发现了一片垃圾邮件……当然也有正常邮件……哇……我自从借了编译器这两本书，就看了第一章……不管怎么样，咱大成电的邮箱是终身制的，很好哦，么么扎~再看看哈工大是不是也有邮箱，果然也有！然而……还真是……方便……吶……有学校的EDU邮箱，用着看起来还是很舒服的！嘻嘻。                \n\n\n","categories":["转载"],"tags":[]},{"title":"发现阿里云0.9元买2年的CDN，每月20GB","url":"http://tanqingbo.cn/2019/10/06/发现阿里云0.9元买2年的CDN，每月20GB/","content":"\nhttp://www.bewindoweb.com/119.html&nbsp;记录一下：https://common-buy.aliyun.com/?commodityCode=cdnforpack#/buy温馨提醒：1、本次活动所购买CDN流量包总量为480G，每月返20G，分2年返还完毕；2、CDN流量返还时间为每月1日；3、订购成功后，每月所返20GCDN流量中，若有未使用的部分则当月失效；4、每个用户仅可以参与一次此优惠活动；&nbsp;我怎么总去找这种免费的东西233333，当然是因为穷啊。                \n\n\n","categories":["转载"],"tags":[]},{"title":"如何从50亿个QQ号中查询某个QQ号是否存在","url":"http://tanqingbo.cn/2019/10/06/如何从50亿个QQ号中查询某个QQ号是否存在/","content":"\nhttp://www.bewindoweb.com/202.html前言这是一个比较经典的笔面题，在面试的时候被问到过，在做工大研究生复试志愿者的时候也看到过面试题有类似的题目。我每次总是理解别人说过的东西，下一次就会忘记，也不知道其中还有什么坑没踩过。所以这次我想实际地动手做一做。一、题目描述【标准描述】如果给你一个含50亿无序的QQ号的文件，每个QQ号都是一个无符号整型，现在用户查找某个QQ号，如何快速判断这个QQ号是否存在？内存限制4G。【其他相关的题目】1、设计数据结构，使其能够快速返回0~10亿哪些数存在或者不存在。2、给你一个含有1亿个QQ号码的文件，如何快速地查找某个QQ号码？3、给40亿个不重复的无序的无符号整数，给定一个无符号整数，如何快速判断这个数是否存在于40亿个数之中？二、思路分析无符号整数、内存、并行查找、分布式查找、字典树，最后再讲位图（@todo）三、实现代码和分析                \n\n\n","categories":["转载"],"tags":[]},{"title":"将图片文件部署到七牛CDN上去","url":"http://tanqingbo.cn/2019/10/06/将图片文件部署到七牛CDN上去/","content":"\nhttp://www.bewindoweb.com/112.html一、教程内容1、七牛CDN的部署2、nginx的ngx_http_substitutions_filter_module模块二、具体操作引言本来一开始只想做简单的博客，可以看到到今天为止（2017.11.25）“首页”连一张图片都没有（又想哭穷了，此站为最便宜的1M带宽50G存储……）。后来由于自己需求太多，做了大量有图片的网页，网页的加载速度可想而知，于是开始想用知名已久的免费CDN：七牛云存储，来将图片引流。配置七牛CDN骚操作1、进入七牛官网。这里介绍一下CDN的策略。众所周知，访问网页觉得慢，肯定不仅仅是这些HTML、JS、CSS代码传给你慢，而是占用带宽的大头，一些图片资源、音视频资源、下载的资源之类，因此就诞生了CDN。CDN会帮你将一些静态资源比如HTML、JS、CSS、图片、音视频、下载文件等等分发到它在各地部署的服务器上，这样你如果想要取这个资源，它会直接就近将资源发给你，这样当然是最快的啦。以前的CDN总是全站拷贝，直接将域名解析到他们的CNAME就可以了，这样的好处是省事，坏处是动态页面会遇到问题。而七牛的存储策略则是自建一个空间，然后将CDN解析到上面去，这样只需要把静态资源如图片放上去就可以了，动态的如PHP仍然通过源站访问。2、注册 → 验证个人站长身份（大概1小时）。3、单击左侧的对象存储，然后创建一个存储空间，这个空间可以任意命名，以后你的所有文件都会放到这个空间里去。4、单击左侧的融合CDN，然后新建一个加速域名这里要填写的重要信息：&nbsp;名称说明&nbsp;举例&nbsp;&nbsp;域名类型&nbsp;选普通域名&nbsp;&nbsp;加速域名&nbsp;你要添加的二级域名，后缀一定要是你的网站cdn.bewindoweb.cn&nbsp;&nbsp;源站配置&nbsp;选择你刚才建立的存储空间&nbsp;5、回到对象存储，空间概览，右侧的融合CDN加速域名，会发现你的二级域名正在配置中，一会过后会变成等待CNAME，然后点击右边的CNAME图标，就会弹出这样一个域名。6、这时候我们需要去自己网站解析地址的地方配置一下二级域名的CNAME，比如我服务器是腾讯云，腾讯云帮我解析的，我就去腾讯云，在云解析→管理→域名解析里面，添加一条这样的CNAME：&nbsp;其中关键信息如下：&nbsp;名称说明&nbsp;举例&nbsp;&nbsp;主机记录&nbsp;刚才填的二级域名的前缀&nbsp;比如cdn.xxx.cn就填cdn&nbsp;记录类型&nbsp;填CNAME&nbsp;&nbsp;记录值&nbsp;填入刚才七牛弹出来的域名&nbsp;注意填完com后会加个点，不要去改它7、等待10-20分钟，七牛会显示成功。8、点击镜像存储，绑定你的网站，保存。9、内容管理里面，将外链默认域名选为你自己建立的二级域名，七牛CDN就配置好啦。懒人站长如何使用CDN从这里开始，网上的内容大多都教如何配置wordpress的后台，然后添加CDN功能，直接填个网址完事，这里保留个链接以备不时之需吧。可是这个网站是我自己写的啊！我也想能填个网址了事……而且我也不想修改关键的内容，一是考虑到CDN是免费的，万一崩了呢？二是我不想去每个地方改php代码，不然所有的网页都得改一遍，到时候维护起来超级无敌宇宙大麻烦。我想到是用nginx进行的反向代理php-fpm解析的，那在nginx解析的时候，直接把字符串替换过去不就完事啦~果然真的有……http_substitutions_filter_module配置CDN这里参考的是Nginx内容替换模块http_substitutions_filter_module及实用案例分享，由于没有使用过ngxin自带的subs_filter，所以也不知道这两个的区别利弊，当然直接用最新的好啦。1、编译集成ngx_http_substitutions_filter_module（1）下载ngx_http_substitutions_filter_module模块文件后解压，[root@MyServer ~]# wget -O ngx_http_substitutions_filter_module-master.zip https://github.com/yaoweibin/ngx_http_substitutions_filter_module/archive/master.zip\n[root@MyServer ~]# unzip ngx_http_substitutions_filter_module-master.zip\n[root@MyServer ~]# cd ngx_http_substitutions_filter_module-master &amp;&amp; pwd \n/root/ngx_http_substitutions_filter_module-master（2）服务器上执行nginx -V ���看编译参数[root@MyServer ~]# /usr/local/nginx/sbin/nginx  -V\nTengine version: Tengine/2.1.2 (nginx/1.6.2)\nbuilt by gcc 4.8.5 20150623 (Red Hat 4.8.5-4) (GCC) \nTLS SNI support enabled\nconfigure arguments: --prefix=/usr/local/nginx --with-http_v2_module --with-http_ssl_module --with-http_gzip_static_module --with-http_realip_module --add-module=../ngx_cache_purge-2.3 --with-http_sub_module（3）加上模块参数，重新编译nginx./configure [+原有参数+] --add-module=/root/ngx_http_substitutions_filter_module-master/（4）平滑升级nginx参考这篇文章，我没有尝试过所以不写。这里我在第2步编译的时候卡壳了，我当时是apt-get install nginx安装的nginx……版本是nginx/1.12.1，我的编译参数是：--with-cc-opt='-g -O2 -fstack-protector-strong -Wformat -Werror=format-security -D_FORTIFY_SOURCE=2' --with-ld-opt='-Wl,-z,relro -Wl,-z,now' --prefix=/usr/share/nginx --conf-path=/etc/nginx/nginx.conf --http-log-path=/var/log/nginx/access.log --error-log-path=/var/log/nginx/error.log --lock-path=/var/lock/nginx.lock --pid-path=/run/nginx.pid --modules-path=/usr/lib/nginx/modules --http-client-body-temp-path=/var/lib/nginx/body --http-fastcgi-temp-path=/var/lib/nginx/fastcgi --http-proxy-temp-path=/var/lib/nginx/proxy --http-scgi-temp-path=/var/lib/nginx/scgi --http-uwsgi-temp-path=/var/lib/nginx/uwsgi --with-debug --with-pcre-jit --with-http_ssl_module --with-http_stub_status_module --with-http_realip_module --with-http_auth_request_module --with-http_v2_module --with-http_dav_module --with-file-aio --with-threads --with-http_addition_module --with-http_geoip_module=dynamic --with-http_gunzip_module --with-http_gzip_static_module --with-http_image_filter_module=dynamic --with-http_secure_link_module --with-http_sub_module --with-http_xslt_module=dynamic --with-stream=dynamic --with-stream_realip_module --with-stream_geoip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-mail=dynamic --with-mail_ssl_module --add-dynamic-module=/usr/src/builddir/debian/modules/nginx-auth-pam --add-module=/usr/src/builddir/debian/modules/nginx-dav-ext-module --add-module=/usr/src/builddir/debian/modules/nginx-echo --add-module=/usr/src/builddir/debian/modules/nginx-upstream-fair --add-module=/usr/src/builddir/debian/modules/ngx_http_substitutions_filter_module --add-module=/usr/src/builddir/debian/modules/nginx-cache-purge然后按照教程做了后报错：./configure: error: no /usr/src/builddir/debian/modules/nginx-dav-ext-module/config was found用which，whereis也找不到这个叫nginx-dav-ext-module的插件，于是乎我开始准备一个一个查找这些--add-module增加的插件是否有用，每想到找着找着找到了这个：--add-module=/usr/src/builddir/debian/modules/ngx_http_substitutions_filter_module呀，这不是我们要加的插件吗，原来在这个版本已经集成了，那就不用那么麻烦升级了……于是跳过了所有的步骤……进入使用阶段。2、配置nginx，替换字符串。ngx_http_substitutions_filter_module的github文档用法说明：* subs_filter_types\nsubs_filter_types 语法： subs_filter_types mime-type [mime-types]\n默认： subs_filter_types text/html\n适用： http， server， location\nsubs_filter_types 是用来指定替换文件类型的 默认仅仅替换text/html类型的文件。\n\n\n\nsubs_filtersubs_filter 语法： subs_filter source_str destination_str [gior]默认： none适用： http，server，locationsubs_filter 是用来替换文本的，可以使用正则g（默认）：替换匹配项。i  ：区分大小写的匹配o : 只匹配发现的第一个。r  : 正则匹配（默认是字符串匹配）。于是在ngxin的xxx.conf下，配置我的cdn：subs_filter http://www.bewindoweb.cn/([^&quot;\\&#39;]*?)\\.(jpg|png|js|css|jpeg|bmp|gif) http://cdn.bewindoweb.cn/$1.$2 igr;这里注意，我对php进行了php-fpm的配置，所以在location /下配置这一句是无效的，要在location php的下面才有效哦。最后的效果：图片加载速度快得让人想哭呢……                \n\n","categories":["转载"],"tags":[]},{"title":"布隆过滤器","url":"http://tanqingbo.cn/2019/10/06/布隆过滤器/","content":"\nhttp://www.bewindoweb.com/267.html                \n\n\n","categories":["转载"],"tags":[]},{"title":"开启头条号之旅","url":"http://tanqingbo.cn/2019/10/06/开启头条号之旅/","content":"\nhttp://www.bewindoweb.com/214.html今天开始逐渐搬运博客文章到今日头条的头条号“三颗豆子分裂中”上去，让更多人能够和我一起分享经验的同时，能够检验自己的文章的正确性如何、有哪些没有考虑到的地方、有什么更新奇的解决思路之类的。博客阅读量和头条阅读量真的是不能比的：2018年8月5日发的博客，到现在83个人阅读：今天2018年9月16日搬运到今日头条，一天的时间3625个阅读，750的收藏……可以看到很多有趣的评论，增加了好多关注，好有成就感，也有继续写博客的动力了~这个头条号和博客的内容一致，都是一些关于DIY小项目的奇奇怪怪的东西，系统的知识都会搬到wiki上面去。至于为什么我的博客这么惨淡……估计是没做SEO优化+128kb/s的打开网速+冗长的没有cdn的CSS/JS……1M小水管受制于经济能力估计没办法，不过其他的可能会在下个版本迭代更新……吧……还有很多工作想要做，还有很多有意思的世界想去看，加油~                \n\n\n","categories":["转载"],"tags":[]},{"title":"摩尔斯电码对照表","url":"http://tanqingbo.cn/2019/10/06/摩尔斯电码对照表/","content":"\nhttp://www.bewindoweb.com/117.html一、简介摩尔斯电码（又译为摩斯密码，Morse code）是一种时通时断的信号代码，通过不同的排列顺序来表达不同的英文字母、数字和标点符号。它发明于1837年，发明者有争议，是美国人塞缪尔·莫尔斯或者艾尔菲德·维尔。 摩尔斯电码是一种早期的数字化通信形式，但是它不同于现代只使用零和一两种状态的二进制代码，它的代码包括五种： 点、划、点和划之间的停顿、每个字符间短的停顿（在点和划之间）、每个词之间中等的停顿以及句子之间长的停顿。二、码表基本码表英语字母&nbsp;MC&nbsp;英语字母&nbsp;MC&nbsp;数字MC&nbsp;A&nbsp;. _&nbsp;N&nbsp;_ .1. _ _ _ _&nbsp;B&nbsp;_ . . .&nbsp;&nbsp;O&nbsp;_ _ _2. . _ _ _&nbsp;C_ . _ .&nbsp;&nbsp;P&nbsp;. _ _ .3. . . _ _&nbsp;D&nbsp;_ . .&nbsp;Q&nbsp;_ _ . _4. . . . _&nbsp;E&nbsp;.&nbsp;R&nbsp;. _ .5. . . . .&nbsp;F&nbsp;. . _ .&nbsp;S&nbsp;. . .6_ . . . .&nbsp;G&nbsp;_ _ .&nbsp;T&nbsp;_7_ _ . . .&nbsp;&nbsp;H&nbsp;. . . .&nbsp;U&nbsp;. . _8_ _ _ . .&nbsp;I&nbsp;. .&nbsp;V&nbsp;. . . _9_ _ _ _ .&nbsp;J&nbsp;. _ _ _&nbsp;W&nbsp;. _ _0_ _ _ _ _&nbsp;K&nbsp;_ . _&nbsp;X&nbsp;_ . . _&nbsp;L&nbsp;. _ . .&nbsp;Y&nbsp;_ . _ _&nbsp;M&nbsp;_ _&nbsp;Z&nbsp;_ _ . .增加码表&nbsp;标点符号&nbsp;MC数字&nbsp;MC简码&nbsp;&nbsp;句号&nbsp;. _ . _ . _&nbsp;1&nbsp;. _&nbsp;逗号&nbsp;_ _ . . _ _&nbsp;2&nbsp;. . _&nbsp;重点号或除号&nbsp;_ _ _ . . .&nbsp;3&nbsp;. . . _&nbsp;问号&nbsp;. . _ _ . .&nbsp;4&nbsp;. . . . _&nbsp;省略号&nbsp;. _ _ _ _ .&nbsp;5&nbsp;. . . . .&nbsp;连接号或减号&nbsp;_ . . . . _&nbsp;6&nbsp;_ . . . .&nbsp;左括号&nbsp;_ . _ _ .&nbsp;7&nbsp;_ . . .&nbsp;右括号&nbsp;_ . _ _ . _&nbsp;8&nbsp;_ . .&nbsp;斜线或除号&nbsp;_ . . _ .&nbsp;9&nbsp;_ .&nbsp;双线或等于号&nbsp;_ . . . _&nbsp;0&nbsp;_&nbsp;正号或加号&nbsp;. _ . _ .&nbsp;&nbsp;&nbsp;双引号&nbsp;. _ . . _ .&nbsp;&nbsp;&nbsp;乘号&nbsp;_ . . _&nbsp;&nbsp;三、释疑1、SOS是怎么来的？SOS并不是任何求救英文的缩写，而是因为在摩尔斯电码中，S为. . .，O为_ _ _，所以SOS对于发报方是最容易发出的信号，对于接收方是最容易识别的信号，因此国际无线电报公约组织于1908年正式将它确定为国际通用海难求救信号。2、摩尔斯电码会有歧义吗？如果不做处理当然会有。例如，M是_ _，E是.，而G是_ _ .，如果直接进行读取，就有ME和G两种解释。因此，表达ME时，需要加入字母间短间隔，发为_ _ / .，/代表时间上停顿一下。标准的间隔时间为：点，1t；划，3t；点划间，1t；字符间，3t；字间，7t。当然，新手可以直接间隔更长，体现出分隔的感觉，无非就是发报时间更长一点。3、摩尔斯电码如何记忆？摩尔斯密码树记忆字母笔画记忆（按正常笔画顺序）                \n\n\n","categories":["转载"],"tags":[]},{"title":"有关事务的冲突类型","url":"http://tanqingbo.cn/2019/10/06/有关事务的冲突类型/","content":"\nhttp://www.bewindoweb.com/194.html前言最近在看《Servlet/JSP深入详解》，毕竟马上要做这方面的工作了，得复习一下。又看到了事务处理的问题，把以前上数据库课的一些有意思的问题又回忆了起来，记录一下。有关脏读脏读是最简单的一种冲突类型。【定义】A事务访问并修改了数据，但未提交；B事务读取了A事务修改后的数据，发生了脏读。【隐患】若A回滚，则B所做的一切操作都是错的。【举例】对同一账户的存取款，A为取款事务，B为转账事务，操作时间片如表所示。时间片&nbsp;取款事务A&nbsp;转账事务B&nbsp;&nbsp;T1&nbsp;START&nbsp;&nbsp;T2&nbsp;&nbsp;START&nbsp;T3&nbsp;查询余额为1000元&nbsp;&nbsp;T4&nbsp;准备取走300元，修改余额为700元&nbsp;&nbsp;T5&nbsp;&nbsp;查询余额为700元&nbsp;T6&nbsp;机器没钱了，ROLLBACK，恢复余额为1000元&nbsp;&nbsp;T7&nbsp;&nbsp;汇入100元，修改余额为600元&nbsp;T8&nbsp;&nbsp;COMMIT预期结果：1000+100=1100元实际结果：600元问题出在T5时刻B发生了脏读。有关不可重复读这个冲突很有意思。【定义】A事务访问一条数据后，B事务修改了这条数据，A事务再次访问这条数据发现前后两次相同的读取操作结果不一致。【讨论】在实际使用中，会有谁在一个事务中写前后两次去访问同一条数据这样的睿智的操作呢？在我看来，有一种说法是认可的。就是这种可重复读的属性保证的是在一个事务执行的过程中，所使用的查询过的数据都是不会改变的，否则它所做的所有操作都是错误的。但这和丢失更新不是一样了吗。也有人说，是用于主从同步的，这里我还没能理解。同一个任务两次 select 本身就是多余的。mysql 默认 rr 主要是为了主从同步时，采用逻辑 sql 同步时的一致性，因为主库的 sql 是并发执行的，会有两个事务一起再跑，从库同步是单线程的，不会有两个事务同时在跑，如果不是 rr，出现楼主的栗子说的情况时，主从数据就不一致了有关幻读【定义】A事务读取了满足条件的所有行后，B事务插入了一行数据，当A事务再次读取同样条件的数据时，发现多出了一条数据。【讨论】又会有哪个睿智两次去读同样条件的数据呢？实际上，第二次读都不是指真的读，“插入”操作也会先“读”一下是不是已经存在条目了。【举例】正常A事务的目的是，查询一次是否存在条目，若不存在，则插入条目；干扰B事务的目的是，直接插入条目。时间片&nbsp;正常事务A&nbsp;干扰事务B&nbsp;&nbsp;T1&nbsp;START&nbsp;&nbsp;T2&nbsp;&nbsp;START&nbsp;T3&nbsp;查询是否存在条目item&nbsp;&nbsp;T4&nbsp;&nbsp;插入条目item&nbsp;T5&nbsp;&nbsp;COMMIT&nbsp;T6&nbsp;插入条目item&nbsp;&nbsp;T7&nbsp;失败，ROLLBACK&nbsp;这就是幻读真实的例子，正常的事务在读取条目item后，发现不存在条目item，而在它插入的时候，却发现已经存在条目item，前后两次“读取”不一致，原因是事务B插入了一条item。这个事情造成的后果是，A事务的正常执行逻辑被干扰了。                \n\n\n","categories":["转载"],"tags":[]},{"title":"查看和解决搬瓦工VPS是否被Wall的方法","url":"http://tanqingbo.cn/2019/10/06/查看和解决搬瓦工VPS是否被Wall的方法/","content":"\nhttp://www.bewindoweb.com/200.html前言搬瓦工推出了一个走CN2电信线路的VPS，一直都用得很好。昨天突然连接不上了，我以为服务器出问题了。上服务器更换密码、更换端口、重新安装某软件、重新启动机器，折腾半天都不行，Ping了一下，却发现能Ping通。原来这都是套路……PING (Packet Internet Groper)因特网包探索器，发送的是ICMP(Internet Control Messages Protocol）因特网信报控制协议，Wall对这种流量是放行的，让你误以为是通畅的……而所有TCP端口的流量都给你拦住……我真的是用来学习的啊……在搞清楚为什么被检测到之前暂时不用了。如何检查是否被X？1、判断国内是否能扫到开放的端口用站长工具的端口扫描去测试服务器的端口是否打开，如果能打开，说明你软件有问题；如果不能打开，说明可能是被X了。测试的端口是你那个软件开放的端口。我开的80端口，测试是关闭的。2、判断国外是否能扫到开放的端口用某个在线端口扫描器扫一次。如果发现是开着的，说明国外能上，国内不能上，100%被X；如果关闭的，说明你的服务器软件有问题。我开的80端口，测试是开启的……GoodGame……如何解决被X问题？每10周（2个半月）可以免费更换一次IP先打开搬瓦工的KiwiVM控制面板，然后把地址栏中的：https://kiwivm.64clouds.com/main.php改为：https://kiwivm.64clouds.com/main-exec.php?mode=blacklistcheck它会自动检测你的IP是否已经被X，如果被X，会提供一个免费更换IP的按钮。点击后你的IP就会被更换。付费更换IP还未尝试，先加个参考链接《搬瓦工怎么换 IP，被X后购买新 IP 地址教程》参考文章1、《2018 年判断搬瓦工 IP 是否被X的最新方法及相应解决方案》2、《好消息：搬瓦工 / BandwagonHOST 支持每 10 周免费更换 IP 一��》                \n\n\n","categories":["转载"],"tags":[]},{"title":"毕业论文整理（一）：CT图像和邻域近似随机森林","url":"http://tanqingbo.cn/2019/10/06/毕业论文整理（一）：CT图像和邻域近似随机森林/","content":"\nhttp://www.bewindoweb.com/226.html前言开始整理研究生毕业论文，再过不久就会忘掉我读过研究生了，但是数理统计考100也是不容易的，还是希望记录一下…现在的小学弟们早就开始各种开源平台用得贼溜了，他们都从开始就做卷积神经网络和深度学习；我一直做的是传统的树模型，虽然不如其他算法模型那么有用，但是研究得多了也会有一些心得，下面开始叙述。课题要求使用树模型分割彩色图像中的目标。主要改进了邻域近似随机森林（Neighbourhood Approximation using Randomized Forests，NAFs），还使用了依赖树（Approximating Discrete Probability Distributions with Dependence Trees，CLT）。邻域近似随机森林NAFsNAFs的原论文是用于医学图像分割的，它是一个框架不是一个模型，主要作用是对任意距离定义的近似最近邻检索（approximate nearest neighbour retrieval for arbitrary distances），解决的问题类似于：给定一组带Ground Truth的灰度人体侧面CT图片去训练NAFs，然后对于一幅新的CT图片（out of samples），给出CT图像中各个内脏边缘的3D分割结果。医学图像简介我们平时拍的CT（计算机断层扫描技术，Computed Tomography）图片原始数据并不是平面的2D图像数据，而是3D的。它是利用精准的X射线和探测器对人体的某一部位做逐层的断面扫描，采集人体截面结构的信息，再通过重建（Reconstruction）来获得数值，最后通过一定显示手段去可视化。你可以想象成CT图像会一片一片地采集2D图像，再组装成3D的。每一片图像都会有一个“厚度”，由于是物理设备，是以毫米（mm）为单位的。在这个厚度的某个像素（实际是一个小方块）里面，很可能包含不止一种组织，那么它的取值通常是这些组织取值的平均数。还有一个概念是“层距”，相邻两片的距离如果太大，就可能不是连续的影像。又因为设备的不同，每个CT图像的层厚和层距取值可能会不同，那么如果要进行机器学习，我们需要对这些图像进行配准（Register），就是把所有的CT图像数据都转换到同一个世界坐标系XYZ下，如果多了就删去，如果少了就插入，如果坐标系不一样就旋转等等，有相应的算法可以处理。最后我们规定图像像素的大小应该是几mm厚，把CT扫描的“强度值”作为“像素值”来使用，就得到了灰度图像。灰度图像的数值通常是在-2048到2048之间的，如果要可视化，需要转为0~256，因为1000和1001的灰度你是看不出来区别的。CT图像通常以DICOM（Digital Imaging and Communications in Medicine）格式存储，分辨率为4096级���我录制了一个gif来直观地感受一下（MITK workbench打开DICOM文件）：Patches简介看到这里显然有一个疑问，树模型不是一直都用来分类的吗，怎么可以用来分割呢？答案是作者通过巧妙的方式把分类转换为了分割。我们称2D图像中的像素点叫做Pixel，那么3D图像中的像素体就叫做Voxel（体像素），由一堆Voxel组成的小立方体就是Patches（块像素）。那么将40张CT图像分割成30000重叠的块像素，每个块像素提取1400个特征，训练NAFs进行分类，类别是块像素中占比多的那个内脏：对于一幅新输入的待分割CT图像，我们也切分成重叠的块像素，提取同样的特征，遍历NAFs，每棵树都会找到很多30000训练patches中的“最近邻”patches，并且根据概率有一个相似度。我们只选择相似度最高的前20个最近邻patches。对这20个最近邻Patches，创建一个搜索窗，用归一化积相关算法(NCC)进行相似度匹配，得分最高的Patches就会被选为候选Patches（candidate patches）。这样每一个voxel都会被若干候选Patches覆盖，他们的投票值最高的标签就作为这个Voxel的标签，这样一来就用Patches的分类完成了Voxel分割：NAFs原理整个分割过程大致有了了解，关键点有两个：如何构建随机森林去近似邻域？如何处理特征？我们定义整个图像集为I，每张图像I∈I，一个图像子集为{Ip}p∈[1,P]，两幅图像之间的距离定义为ρ(·, ·)，具体数值为ρ(I, J)，J为新输入的图像。NAF就是寻找k个和J最相似的I∈I，也就是使得ρ(I, J)最小的k个I，定义这个最近邻图像集合为N_kρ(J)。可以想象直接搜索这个\n\n\n\nN_kρ(J)&nbsp;是��分费时间的，而且如果采用“年龄”来定义距离，新图像是没有“年龄”这种属性的，所以距离根本不可测。NAF就是通过构建随机森林来近似这种邻域关系，相当于把这种距离保存在了树的结构里，只需要遍历森林测试特征就可以了，完全不需要去计算距离。NAFs树的测试过程NAF的树是二叉决策树，给定一幅图像J，它会依次遍历每棵树，从根节点s0开始一直找到叶节点，叶节点里保存着训练图像ID，如果新图像和那些叶节点都走了相似的路径，那说明它们本身也是相似的，这就是最近邻图像集合。我们把单棵树产生的最近邻图像集合定义为N_T(ρ)(J)，也就是新图像J按照ρ定义遍历第T棵树产生的Neighbours。论文的示意图很容易看懂，就是简单的决策树测试而已：NAFs树的训练过程——特征降维定义图像I的特征向量为f(I)∈R^Q，因为是图像，所以f非常可能是一个高维的特征向量，例如Q=10000。那么必须得降维，否则就当场去世了。随机森林的随机是一个又鲁棒又能降维的东西，我们先随机挑选特征f_T(I)∈R^q，q&lt;Q，f_T(I)∈f(I)，这样既降低了维度，又使得每棵树更加独立。然后在每棵树训练期间节点分叉的时候，我们总是再次从f_T(I)中随机挑选M个特征进行遍历来做出二分抉择，M&lt;=q，f_MT(I) ∈f_T(I)。两次降维已经够了。我们定义节点的图像集合为I_S，分叉后左节点图像集合为I_SL，右节点图像集合为I_SR，那么对于图像In∈I_S来说，分叉条件为：f_mT(In)指的是In这个图像的第m个特征值。我们的目标就是优化参数m和τ，使得划分得最开，很明显要使用熵了。但这里的距离ρ不是传统的距离，可能是语义距离，所以这里的熵需要进行特殊定义。我们首先定义集合A的空间紧凑性为：很容易理解，两两距离求和再平均，如果这个值越小，说明两两之间距离越小，那么就越紧凑（图像越相似），所以定义熵为：根节点的紧凑性减去分叉后的紧凑性的加权，反映了按照当前m和τ划分子树根节点的紧凑程度，熵越大，划分也就越好，所以整个问题变成了求最优化解：其中Δ是树的停止条件之一，也就是叶节点必须要有的最小图片数目。求解的过程就是对于每个m取值，我们遍历所有的τ划分点取值，求得使得熵G取到最大值的m和τ，虽然前面两次降维，但这个遍历过程仍然是一个很费时的操作。训练树的停止条件：树的深度、最小样本数Δ、G&lt;0。前两个就是决策树的基本停止条件，G&lt;0意味着划分下去反而变得不紧凑了（图片之间相似程度更低了），所以还不如不要分直��停止生长。NAFs的测试过程对于给定的图像J，测试每棵树，找到叶节点最近邻图像集合N_T(ρ)(J)，我们给这些图像计数，那么得分最高的前k个显然是整个森林都认为很相似的最近邻图像了。定义1A(x)为sign函数，若x∈A则1A(x)=1，否则1A(x)=0，那么测试的计数得分用数学公式表示为：也就是新图像J在距离ρ的定义下，森林F中各棵树T判断是否和训练图像In相似的求和值。NAFs参数调整NAF有很多参数：（1）叶节点最小图像数目ΔΔ越大，划分越粗糙，降低KNN精确度；Δ越小，越容易过拟合。（2）最大树深树深越小，划分越粗糙，降低KNN精确度；树深越大，对内存和算法性能要求就越高。（3）树的数目刚开始增加明显提升精确度；当树的数目达到一定程度后，精确度就不会有明显提升了。（4）特征空间大小Q和降维q、Mq/Q越大，那么树的独立性越小，都训练出一样的树那还要森林有什么用呢。q/Q通常根据具体的Q值来确定，例如Q=10000，则q/Q取0.1，q=1000；Q=3000，则q/Q取1/3，q=1000。M同理，可以根据机器性能和期望的邻域近似准确度去调整。NAFs优势和劣势从前面可以看出，整个分割过程其实就是一个寻找KNN的过程，不过NAFs的好处在于，它不需要进行配准（因为使用块像素的相似来进行分割的，而不是建立严格的数学模型），并且它可以用于“语义距离”。举个例子，我们要对脑部CT图像进行分类，判断这个人是多少岁，通常定义的距离都是这两幅图像的相似程度，比如欧式距离，而NAFs可以将“年龄”这个语义属性作为两幅图像的距离，也就是年龄差作为图像距离。这个和图像的像素值一点关系也没有，只和图像属性有关系。同时，因为构建了随机森林来保存这种块像素之间的近似相似性，所以搜索的速度非常快，不需要每个块像素去单独比对，只需要遍历NAFs即可。使用随机特征和树模型，能够很好地避免过拟合。然而，如果Patches很多，那么整个训练过程会异常缓慢，并且需要巨量的内存和硬盘；并且这种方法只能适用于图像非常近似的分割（比如CT图像几乎变化不大），不能用于图像变化剧烈的，那种剧烈的还是老老实实使用神经网络吧。使用树模型，要调整的参数非常多。                \n","categories":["转载"],"tags":[]},{"title":"毕业论文整理（三）：AdaBoost和概率提升树","url":"http://tanqingbo.cn/2019/10/06/毕业论文整理（三）：AdaBoost和概率提升树/","content":"\nhttp://www.bewindoweb.com/233.html��率提升树前言这是本科毕设用到的树，概率提升树（Probabilistic Boosting-Tree, PBT）是Tu在2005年《Probabilistic Boosting-Tree: Learning Discriminative Models for Classification, Recognition, and Clustering》中提到的分层分类框架。AdaBoostPBT的实质是对Adaboost的改进，首先回顾一下Adaboost：&nbsp; Adaboost是针对二分类问题设计的，核心点是关注那些被错误分类的训练样本，通过多轮弱分类器的训练逐渐提高被错分样本的权重，对每个弱分类器根据分类精度给一个权重，然后将所有弱分类器用加权的方式制作一个强分类器来达到分类的目的。算法如下：【输入】n个训练样本特征向量及其类别(x1,y1),...,(xn,yn)，其中xi∈R^m，yi∈{-1,+1}1) 初始化训练样本分布：D1(i) = 1/n&nbsp;&nbsp;// 初始的权重是平均的2)&nbsp;FOR&nbsp;t = 1..T&nbsp;DO&nbsp;&nbsp;// 训练T轮，T个弱分类器3)&nbsp; &nbsp; &nbsp; &nbsp; 使用分布Dt训练弱分类器ht：R^m → Y&nbsp;&nbsp;// 就是训练一个假设：看到这个特征向量→应该判别为什么类别4)&nbsp; &nbsp; &nbsp; &nbsp; 获得这个假设的加权分类误差：&nbsp;// 也就是把分类错了的权重累加起来。5)&nbsp; &nbsp; &nbsp; &nbsp; 计算这个假设（弱分类器）的权重：6)&nbsp; &nbsp; &nbsp; &nbsp; 更新训练样本分布：&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 其中，7)&nbsp;END FOR【输出】最终的假设（强分类器）：有关误差上下界的数学推导和为什么选取α为这个式子，可以参看《Boosting Methods for Automatic Segmentation of Focal Liver Lesions》。我们从结果来分析算法中各个参数的性质和作用：1) 我们知道弱分类器错误率（加权分类误差）θ≤0.5（不可能大于0.5比随机猜测更差，否则取反就能得到&lt; 0.5的分类器了）2) αt≥0（因为(1-θ)/θ ≥ 1），且其随着错误率的减小而增大，说明错误率越小的弱分类器被看得越重要。3) 对于一个被错误分类的样本，必有真实类别≠弱分类器判别的假设类别，也就是yi≠ht(xi)，那么e^-(αt × yiht(xi))必然大于1，反之分对的样本e^-(αt × yiht(xi))必然小于1，当对下一轮的样本分布权重进行归一化之后，被错分的样本权重必然提高，被正确分类的样本权重降低。4) 如此一来，一旦被错分的样本再次被错分，会造成θ错误率的巨额提升，弱分类器肯定会尽力去避免这样的高错误率，也就是被错分的样本被弱分类器更多地当作考虑因素考虑进去了。举个实际的应用例子，我们想用决策桩（就是阈值判别器）去划分平面上红色、蓝色小球，初始状态是这样的：然后第一个桩分类器竖着划分，错分了两个：于是在重新计算分布后，它们的权重变大了：第二个分类器更多的考虑了被错分的样本，然而第一次被分对的样本又被分错了两个：于是再次进行权重调整：第三次继续划分：第三次权重调整+第四次继续划分：最后得到强分类器的决策平面：当然这是理想情况，实际中不应该划分到这么细，否则会对训练样本产生过拟合。概率提升树PBT通常来说，我们希望建立的模型都是生成式模型（generative model），也就是输入考虑的多种因素，输出一个完整的模型，我们可以提取里面任意的信息。举个例子，我想判断一个动物是不是“斑马”，那么我希望建立一个模型，包含“体型”、“花纹”、“生活习性”、“饮食习惯”、“眼睛大小/颜色/花纹”等等，然后输入这些数值，就能够知道它是不是斑马了。从数学上来说，就是求取整体联合分布P(X)，代入数值，得到结果，也就是我们希望知道p(x|y)。常见的生成式模型有隐马尔科夫模型HMM、朴素贝叶斯模型、高斯混合模型GMM、LDA。实际中，考虑完所有的东西是不现实的（因此通常都是估计），并且会带来庞大计算量，更多的算法采用了判别式模型（discriminative model），输入特征，输出yes或者no或者其他类别，也就是对后验概率p(y|x)建模。常见的判别式模型有线性回归、支持向量机SVM、神经网络。Adaboost和PBT都是判别式模型。然而Tu发现，Adaboost具有一些缺点：1) 需要大量的弱分类器，这带来了庞大计算量2) 没有提取特征向量中的语义信息3) 更新权重的过程可能导致被分对的样本再次被分错4) 只适用于二值分类，多类别分类会非常艰难作者还顺便踩了一脚Grossmann提出的AdaTree，说PBT是对后验概率建模，AdaTree只是在剪枝；PBT每个节点都是强分类器，AdaTree知识把弱分类器放在树结构上而已……下面只讨论PBT的二值分类，多值分类可以转换为二值分类处理。PBT的二值分类过程我们知道，Adaboost错误率上限是（这里更换了字母，含义和前面一致）：ϵt很快地接近了0.5，然而收敛得非常慢，还造成了反复波动。所以PBT采用分治策略，划分样本空间，当错误率达到一定程度就提前结束Adaboost的训练。Friedman等人在论文《Additive Logistic Regression:A Statistical View of Boosting》已经证明过，Adaboost在用这样的逻辑��归式去求取后验概率p(y|x)：其中y∈{-1,+1}。于是可以得到估计的后验概率：然后根据这个估计的后验概率，创造一个极小的控制变量ε，PBT可以对样本空间进行划分：1) 样本算得q(+1|x)&gt; 0.5+ε，则划分到正样本空间；2) 样本算得q(-1|x) = 1-q(+1|x) &gt; 0.5+ε，则划分到负样本空间；3) 样本算得q(±1|x)∈[0.5-ε, 0.5+ε]，则是疑例，同时分配到两个空间。随着树的生长，样本空间就越来越纯净，所构建的Adaboost强分类器也就越来越好，并且越来越快，无需从头对整个样本空间进行划分。ε 的作用原文说是为了防止过拟合，通常来说取0.1是合适的。另外，还限制了每个Adaboost节点的错误上限，当超过上限直接停止生成新的弱分类器，通常来说取0.45是合适的。整个PBT的图像类似于：我们来描述一下PBT的训练算法：【输入���训练集 S={(x1,y1,w1),…,(xn,yn,wn)} ，其中 ，其中x为特征向量， y∈{-1,+1 }，且 Σwi=1。1) 计算并存储经验分布 qc(y)=Σ(yi=i)wi2) 用 Adaboost 在节点 在节点c处根据当前样本训练强分类器 Hc，当错误率大于θ=0.45 的时候提前退出3)&nbsp;IF&nbsp;达到最大树深 L&nbsp;THEN4)&nbsp; &nbsp; &nbsp; &nbsp;return5)&nbsp;ELSE6)&nbsp; &nbsp; &nbsp; &nbsp;新建空集Sleft和Sright&nbsp;7)&nbsp; &nbsp; &nbsp; &nbsp;FOR&nbsp;all xi∈Sc&nbsp;DO8)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;用gc(x)计算 q(±1|xi)9)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;IF&nbsp;q(+1|xi) &gt; 0.5+ε&nbsp;THEN10)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;将样本(xi,yi,1)加入右子树11)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;ELIF&nbsp;q(-1|xi) &gt; 0.5+ε&nbsp;THEN12)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;将样本(xi,yi,1)加入左子树13)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;ELSE14)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;将样本(xi,yi,q(+1|xi))加入左子树&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 将样本(xi,yi,q(-1|xi))加入左子树15)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;ENDIF16)&nbsp; &nbsp; &nbsp;&nbsp;ENDFOR17)&nbsp; &nbsp; &nbsp; 将左子树权值归一化，继续训练左子树18)&nbsp; &nbsp; &nbsp; 将右子树权值归一化，继续训练右子树19)&nbsp;ENDIF【输出】训练好的PBT测试算法：【输入】特征x，训练好的PBT1) 用节点c的强分类器Hc，计算 q( ±1|x)2) IF c是叶子节点3)&nbsp; &nbsp; &nbsp; &nbsp;IF y == 14)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;return q(+1|x)5)&nbsp; &nbsp; &nbsp; &nbsp;ELSE6)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;return q(-1|x)7)&nbsp; &nbsp; &nbsp; &nbsp;ENDIF8) ENDIF9) IF q(+1|x)&gt;0.5+ε THEN10)&nbsp; &nbsp; &nbsp; return q(-1|x)q^_cleft(y) + q(+1|x)p_cright(y|x)11) ELIF q(-1|x)&gt;0.5+ε THEN12)&nbsp; &nbsp; &nbsp; &nbsp;return q(-1|x)p_cleft(y|x)+q(+1|x)q^_cright(y)13) ELSE&nbsp;14)&nbsp; &nbsp; &nbsp; &nbsp;return q(-1|x)p_cleft(y|x)+q(+1|x)p_cright(y|x)15) ENDIF【输出】近似的后验概率pc(y|x)其中，p是Adaboost给出的概率，q是PBT训练过程中计算的概率，q^是训练时得到的先验估计（因为数据没有被分配到那个分支去）。这样一棵完整的PBT流程就走完了，我们分析一下它的参数：参数名称&nbsp;参数符号&nbsp;参数推荐值&nbsp;参数说明&nbsp;&nbsp;调整值ε&nbsp;&nbsp;0.1&nbsp;越小样本空间划分越开，越过拟合&nbsp;Adaboost错误率上限θ&nbsp;&nbsp;0.45&nbsp;越小Ada停止越快，精度越低&nbsp;PBT的最大树深L&nbsp;-&nbsp;越小PBT停止越快，精度越低&nbsp;Adaboost最大训练轮数T&nbsp;&nbsp;-&nbsp;越小弱分类器越少，精度越低最后再欣赏一下PBT的结构：                \n\n\n","categories":["转载"],"tags":[]},{"title":"毕业论文整理（二）：用依赖树近似离散概率分布","url":"http://tanqingbo.cn/2019/10/06/毕业论文整理（二）：用依赖树近似离散概率分布/","content":"\nhttp://www.bewindoweb.com/232.html��赖树论文背景前言《Approximating Discrete Probability Distributions with Dependence Trees》是一篇1968年的经典论文了，即使在2018年也有28次的引用量：是由两位IEEE大牛C.K. CHOW和C.N.LIU所写，所以通常都被称为“Chow-Liu Tree”、“周刘树”、“CLT”，或者叫“依赖树”。整篇论文一共就6页，虽然是6页，刚开始看得真的头大，完全不知道在讲什么，更别说用了，百度一下啥都不知道，最后到外网才找到一些资料。我本科也是做这个相关的内容，当时连分类和分割的区别都不懂，也没有人讲解强行上手，真是被坑哭了。本科大四的时候每天早上起来就硬盯着一遍一遍地重复看，终于才慢慢理解。举个例子：Abstract —— A method is presented to approximate optimally an n-dimensional discrete probability distribution by a product of second-order distributions, or the distribution of the first-order tree dependence.什么叫做second-order distribution，翻译成英文就得花费几倍的时间从公式反推才知道这是指的“二维分布”或者叫“二阶分布”而不是在讲“第二个顺序的分布”：可是为什么要同时用两种表达n-dimensional和second-order还是没去深究，说不定会有概念的细微差异，不过能用就行。另外等看明白之后，发现这篇文章其实现现在通常都被用作找寻依赖关系，比如用于特征选择，或者单词之间的关联程度，根本不适合于现代图像分割，然而老板的要求必须要做啊，不行也得行。CLT要解决的事情对于很多模式识别、学习系统来说，一个很重要的事情就是根据有限的数据集来估计整体n维联合概率分布。举个例子，有两个特征（花颜色、叶子密度），采集了一些数据集：（红色、密）→ 果实好吃，（黄色，稀）→ 果实好吃……，那么我想知道当花是什么颜色、叶子是什么密度，果实会好吃，如果估计出整体的二维联合概率分布，把公式一套进去，就能知道好吃的概率多大了。根据文章《A class of nonlinear recognition procedures》我们将联合概率分布估计为：其中，(m1, ... , mn)是未知的整数1到n的排列，P(xi | x0)定义为P(xi)，具备上述式子的概率分布我们称之为一阶树依赖概率分布。由集合x={xi | i = 1,2,...,n}和映射j(i)组成的结构我们称之为这个分布的依赖树。以后都将会简写x_mi为xi。由于一共有n(n-1)/2个二阶近似乘积项，只有n-1个会被选择，所以如何选择出使得整体最逼近的乘积项就是CLT的核心问题。举个例子，一个联合概率分布P(x1,x2,x3,x4,x5)可以被近似为：现在的问题就是要求得最佳的排列m=（1,2,3,4,5），使得整个的一阶二阶乘积估计最逼近整体联合概率分布Pt。CLT将这个数学问题计算机化，把这个乘积式子按照如下规则转为了树：1) 每个变量xi代表树的一个节点2) 如果有乘积项P(xa|xb)，则画一条从a指向b的箭头3) 如果有乘积项P(xc)，则没有从c节点出去的箭头这样的依赖树有n-1条边，例如上述的依赖树应该画为：寻找最优依赖树我们设原始概率分布为P(x)，估计的概率分布为Pa(x)，x是n维离散变量(x1,x2,...,xn)，那么要想知道估计逼近的程度，很容易用一个距离去度量两棵树的近似程度，CLT使用了前人使用过的相对熵（Relative Entropy）的概念。相对熵，也叫KL散度（Kullback-Leibler Divergence, KLD），经常被用来描述两个分布的差异。于是P和Pa的差异可以定义为：熵的值越小说明分布越接近，那么整个问题变为了：给定一个n维概率分布P(x1,x2,...,xn)，xi是离散的，我们希望找到这个概率分布的依赖树Pτ(x1,x2,...,xn)使得对任意的t∈Tn， I(P,Pτ) ≤ I(P,Pt)。其中Tn是所有可能的依赖树，这个τ就被成为最优依赖树。对于n个节点来说，一共可能产生n^n-2棵不同的树，就不要妄想去遍历了。CLT做了两个定义。【定义一】对于变量xi和xj来说，互信息I(xi, xj)定义为：这是互信息的一个普遍定义，互信息值非负。然后CLT将这个互信息作为节点之间的权重赋予在每个分支上面。【定义二】对于Tn中全部的依赖树t'，一棵最大权值依赖树是符合如下条件的依赖树：很容易理解这就是一个贪心，详细的证明在原论文上给出了，我也推导过一次。用这两个定义，通过一系列的变换，熵被变换为了：后两项是独立于依赖树的常量，因此要想使得分布越逼近，就要使得熵最小；要想使得熵最小，就要使得依赖树的权值和最大，也就是寻找一棵以互信息为权值、变量为节点的最大生成树作为依赖树。这就可以借鉴像Kruskal之类的最小生成树的算法了。依赖树寻找实例考虑如下二值四维联合概率分布：x1 x2 x3 x4&nbsp;P(x1,x2,x3,x4)&nbsp;p(x1)p(x2)p(x3)p(x4)&nbsp;&nbsp;0000&nbsp;0.100&nbsp;0.046&nbsp;0001&nbsp;0.100&nbsp;0.046&nbsp;0010&nbsp;0.050&nbsp;0.056&nbsp;0011&nbsp;0.050&nbsp;0.056&nbsp;0100&nbsp;0.000&nbsp;0.056&nbsp;0101&nbsp;0.000&nbsp;0.056&nbsp;0110&nbsp;0.100&nbsp;0.068&nbsp;0111&nbsp;0.050&nbsp;0.068&nbsp;1000&nbsp;0.050&nbsp;0.056&nbsp;1001&nbsp;0.100&nbsp;0.056&nbsp;1010&nbsp;0.000&nbsp;0.068&nbsp;1011&nbsp;0.000&nbsp;0.068&nbsp;1100&nbsp;0.050&nbsp;0.068&nbsp;1101&nbsp;0.050&nbsp;0.068&nbsp;1110&nbsp;0.150&nbsp;0.083&nbsp;1111&nbsp;0.150&nbsp;0.083表的含义是，当P(x1=0, x2=0, x3=0, x4=0) = 0.100。我们通过累加来求得一阶和二阶边缘概率分布，例如P(x1=0) = P(x1=0, x2,x3,x4)：&nbsp;0&nbsp;1&nbsp;00&nbsp;01&nbsp;10&nbsp;11&nbsp;P(x1)0.450&nbsp;0.550&nbsp;&nbsp;-&nbsp;-&nbsp;-&nbsp;-P(x2)0.4500.550&nbsp;-&nbsp;-&nbsp;-&nbsp;-P(x1, x2)-&nbsp;&nbsp;-0.3000.150&nbsp;0.150&nbsp;0.400&nbsp;然后根据互信息公式计算互信息，例如：于是得到了：互信息&nbsp;值&nbsp;&nbsp;I(x1, x2)0.079&nbsp;&nbsp;I(x1, x3)0.00005&nbsp;I(x1, x4)&nbsp;0.0051&nbsp;&nbsp;I(x2, x3)&nbsp;0.189&nbsp;I(x2, x4)&nbsp;0.0051&nbsp;&nbsp;I(x3, x4)&nbsp;0.0051我们只需要选择4-1=3条边，就能把4个节点连起来了，按照从大到小排序（x2→x1）、（x3→x2）必选，剩余三条边都是相同的权值，会按照一些排序算法随机地选择剩余的3条中的一条，生成的依赖树如图：实现代表真实选择，虚线代表可能替换选择，灰色代表不选择。&nbsp;&nbsp;于是整体分布可能被估计为：P(x1, x2, x3, x4) = P(x1)P(x2|x1)P(x3|x2)P(x4|x1)，我们可以去计算它的概率分布值，例如：得到如下三种方案的对比表：x1x2x3x4&nbsp;P(x1,x2,x3,x4)&nbsp;x4|x1&nbsp;x4|x2&nbsp;x4|x3&nbsp;&nbsp;0000&nbsp;0.100&nbsp;0.130&nbsp;0.104&nbsp;0.104&nbsp;0001&nbsp;0.100&nbsp;0.104&nbsp;0.130&nbsp;0.130&nbsp;0010&nbsp;0.050&nbsp;0.037&nbsp;0.030&nbsp;0.037&nbsp;0011&nbsp;0.050&nbsp;0.030&nbsp;0.037&nbsp;0.030&nbsp;0100&nbsp;0.000&nbsp;0.015&nbsp;0.015&nbsp;0.012&nbsp;0101&nbsp;0.000&nbsp;0.012&nbsp;0.012&nbsp;0.015&nbsp;0110&nbsp;0.100&nbsp;0.068&nbsp;0.068&nbsp;0.068&nbsp;0111&nbsp;0.050&nbsp;0.054&nbsp;0.055&nbsp;0.055&nbsp;1000&nbsp;0.050&nbsp;0.053&nbsp;0.052&nbsp;0.052&nbsp;1001&nbsp;0.100&nbsp;0.064&nbsp;0.065&nbsp;0.065&nbsp;1010&nbsp;0.000&nbsp;0.015&nbsp;0.015&nbsp;0.018&nbsp;1011&nbsp;0.000&nbsp;0.018&nbsp;0.019&nbsp;0.015&nbsp;1100&nbsp;0.050&nbsp;0.033&nbsp;0.040&nbsp;0.032&nbsp;1101&nbsp;0.050&nbsp;0.040&nbsp;0.032&nbsp;0.040&nbsp;1110&nbsp;0.150&nbsp;0.149&nbsp;0.182&nbsp;0.182&nbsp;1111&nbsp;0.150&nbsp;0.178&nbsp;0.146&nbsp;0.146三种方案的熵都是0.094，几乎接近于0，已经非常近似了。边缘概率分布的近似上面的例子先给出联合概率分布，再去求的边缘概率。实际中我们本来要求的就是联合概率分布，所以只能利用样本去近似边缘概率。很容易想到计数的方法：n_uv是xi=u,xj=v的样本简单计数，就能够得到互信息的估计了，由于熵公式只是对互信息线性求和，所以直接用这个估计替代互信息即是熵的估计了。在实际操作中还会遇到问题，那就是样本量为0的时候会发生除以0的情况，这时候需要预处理样本，所有取值样本数+1，这样不会影响整体分布，又避免了除以0的问题。我在另外的算法里看见过这种处理，因此沿用了过来。模式识别实例我们采集了19000张手写数字0-9图片，将其图像数据二值化，希望通过计算机模式识别输入图像输出数字到底是几：一共有c=10个类别，假设用ai标记第i个类别，p=(p1,...,pc)表示先验概率分布，先验概率可以通过计数简单地进行估计；对于输入的二值特征向量x=(x1,x2...,xn)，如果一个样本的特征向量符合：那么就判别这个样本为第k个类别。问题的关键转变为求条件概率P(x|ai)的分布。按照字面理解，就是在0-9的数字出现的条件下， 特征向量x出现的概率有多大。于是我们的问题可以化为求解：也就是求在给定ai类别下，特征向量取值的联合概率分布函数，这个分布函数就用CLT来求解，最后的数字“4”的CLT图像是这样的：整个流程就走通了。NAFs如何结合CLT说实话，无法结合……CLT需要离散的特征，标题都已经明确说discrete了，而图像数据通常是不连续的，要想利用CLT，就必须要离散化特征值，离散化特征值，就必然丢失特征精度，得到的效果就变差。所以为了交差，只能将其作为“粗分割”，也就是先用CLT进行一次“粗分割”，确定大致边界，再利用NAFs去精细分割。                \n\n\n","categories":["转载"],"tags":[]},{"title":"毕业论文整理（五）：Haar像素值特征","url":"http://tanqingbo.cn/2019/10/06/毕业论文整理（五）：Haar像素值特征/","content":"\nhttp://www.bewindoweb.com/235.html前言Haar特征是我用得最多的一个特征了。Haar特征的鲁棒性并不好，它常常用于颜色或者轮廓较为明显的、波动不大的图像，比如人脸识别中识别眼睛、鼻子的位置。尽管如此，用Haar特征处理一般图像分割已经足够使用了。Haar特征设计思想Haar特征(Haar-like Feature)的名称来源于Haar小波(Haar Wavelet)变换，最早由Papageorgiou在论文《A General Framework for Object Detection》中提出。那个时期，用RGB图像像素值来处理特征会产生很大的计算量，Papageorgiou等人就提出了用Haar小波变换来处理特征的想法。在2001年，Viola和Jones在论文《Rapid Object Detection using a Boosted Cascade of Simple Features》中基于这个想法进一步提出Haar特征，产生了很大的影响。他们注意到人的面部是可以用一些矩形特征进行描述的，比如对于浅色皮肤的人来说，鼻梁两侧的颜色比鼻梁的颜色要深一些，眼睛、嘴巴等地方的颜色都比周围面部皮肤的颜色要深。因此，可以用矩形像素变化来表现颜色深浅，这就是Haar特征的来源。Haar特征描述Haar特征主要分为4大类，分别是边缘特征、线性特征、中心特征和对角线特征，本质就是用下图的各类特征模板中黑色矩形的所有像素值减去白色矩形的所有像素值的和（为了像素数目平衡，颜色块少的一项将乘以系数），能够反映出不同方向上一些物体轮廓、灰度变化的情况。Haar特征计算方法很简单，黑色区域像素值和减去白色像素值的和，如果色块数目不一样，用加权保持一致：例如白-黑-白模板，Haar=2*黑-1*白。然而由于Haar特征可以更改模板类型、模板大小、模板位置，仅一幅图像就有不计其数的Haar特征，比如Viola提出的基本特征模板，在24×24像素的窗口中任意排列可以产生180000个特征。如果要从头开始逐一计算，性能代价将是巨大的。Viola和Jones提出了快速计算Haar特征的方法：积分图(Integral Image，II)，解决了这个难题，将Haar特征计算的时间复杂度降低到了常数。积分图算法积分图算法其实是动态规划，只需要遍历一次图像，遍历过程中保存图像上每个点左上角所有点像素值的和的矩阵，当计算特征的时候，通过简单的容斥加减运算就能够以O(1)的时间复杂度得到Haar特征值。先举个实际的例子：第一个矩阵原始图像像素值；第��个矩阵是行累加和s矩阵，最左边是辅助的0保证不越界，保存从左到右扫描的像素值和，例如11=3+1+7；第三个矩阵是积分图，保存着左上角的像素值和，计算方式是上一行+s矩阵值，例如46=35+11=(3+8+9+6+7+2)+3+1+7，黑色线框部分是Haar模板区域，这里使用白-黑模板；第四个矩阵中阴影部分是“黑色矩形像素”周围的积分图点。如果要计算黑色阴影的像素和，只需要进行简单的容差计算：&nbsp;∑PixelB&nbsp;= II(C) - II(B) - II(D) + II(A)&nbsp;= (红+蓝+绿+黄) - (红+绿) - (红+蓝) + (红)= 黄= 92 - 30 - 66 + 21= 17= 4 + 3 + 3 + 2 + 3 + 2这样，任意要求解的区域像素值和都可以通过加减得到。积分图算法描述如下：1) 用s(i,j)表示行方向累加和，初始化s(i,-1) = 02) 用ii(i,j)表示积分图，初始化(-1,i)=03) 从上到下，从左到右，逐行扫描图像，递归计算每个像素(i,j)行方向的累加和，s(i,j)和积分图像ii(i,j)的值，直到扫描到右下角停止：4) 设原始图像如图所示，需要计算D区域的像素和，则计算公式为：Sum = II(4)-II(2)-II(3)+II(1)如何选择Haar特征那么多Haar特征，该如何选择有效的特征呢？官方的做法是使用Adaboost。但是如果你的算法具有随机特性，可以直接随机选择模板大小、模板位置、模板类型。例如NAFs就是一个非常好的具有随机特性的算法。更多Haar特征还有很多变种，例如倾斜45°、任意旋转等模板，但是其实得不偿失，这本来就是一个简单的特征，弄得再复杂对模型的精确度提升都不大，还不如直接考虑高级的SIFT等强特征。                \n\n\n","categories":["转载"],"tags":[]},{"title":"毕业论文整理（四）：彩色图像分割的颜色空间","url":"http://tanqingbo.cn/2019/10/06/毕业论文整理（四）：彩色图像分割的颜色空间/","content":"\nhttp://www.bewindoweb.com/234.html��色空间概述入门彩色图像分割首先当然要了解一下颜色空间。RGB颜色空间RGB颜色空间的设计初衷是，用红色（Red）、蓝色（Blue）和绿色（Green）作为基础颜色，通过三基色的强弱变化组合成整个颜色空间中的各种颜色。&nbsp;如上图所示，分别以红色、绿色、蓝色分量为R轴、G轴、B轴建立坐标系，原点(0, 0, 0)代表的颜色为黑色，(1, 0, 0)、(0, 1, 0)、(0, 0, 1)分别表示红色、蓝色、绿色，构成的立方体中体对角线端点(1, 1, 1)代表的颜色为白色，而体对角线上的颜色则是由黑色过渡到白色的灰度。至此，任意一种常见颜色都可以由(R, G, B)的坐标数值表示出来。&nbsp;RGB颜色空间最开始用于彩色电视机，通过红色、绿色、蓝色发光材料的发光强度来展示彩色图像，后来在计算机显示器中被广泛使用，所以目前大多数计算机中的彩色图像都是通过保存每个像素点上的RGB三个颜色值来进行存储的。然而这种颜色空间有诸多缺点，首先，RGB是不均匀的颜色空间，两点之间的距离和对应点上的颜色差异不相符；其次，RGB的三个分量并不是独立的，每个分量上都保存了相当数量的图像信息；最后，RGB三个分量是以颜色为基础的，而没有任何的图像学意义。&nbsp;HSI颜色空间HSI颜色空间采用色调（Hue）、饱和度（Saturation）和亮度（Intensity）三个分量来描述全部色彩。色调定义了颜色的种类，反映的是颜色波长的差异，比如红色、蓝色、绿色、黄色、紫色等等；饱和度则定义了颜色的深浅，反映的是颜色鲜艳程度的差异，比如浅红色、深红色；而亮度和图像的颜色信息无关，反映了图像的明暗程度，也就是颜色之间的相对明暗程度，比如一张天空的彩色图像中，太阳给人的感觉非常明亮，而旁边的蓝天则给人感觉比较暗。HSI颜色空间如上图所示，H分量的取值范围是[0°, 360°]，从0°的红色、黄色，过渡到120°的绿色、青色，然后转为240°的蓝色、品红，最终回到360°的红色；S分量的取值范围是[0, 1]，从值为0的全白光，到值为1的纯彩色；I分量的取值范围一般为[0, 1]，从值为0的黑暗，到值为1的明亮。HSI颜色空间如图2-3所示，H分量的取值范围是[0°, 360°]，从0°的红色、黄色，过渡到120°的绿色、青色，然后转为240°的蓝色、品红，最终回到360°的红色；S分量的取值范围是[0, 1]，从值为0的全白光，到值为1的纯彩色；I分量的取值范围一般为[0, 1]，从值为0的黑暗，到值为1的明亮。人类对亮度的变化总是比对颜色的变化更为敏感，说明人的细胞会独立地反映颜色变化和亮度变化。所以HSI颜色空间非常符合人的视觉特性，将颜色变化的H、S分量和亮度变化的I分量分隔开来，并且各个分量都有明确的意义，相比于RGB颜色空间来说更加适合进行彩色图像分割。HSI被广泛地应用于各种图像处理算法，包括一些图像处理软件的功能，比如让彩色图像看起来更鲜艳一些的功能可以通过提升饱和度分量的数值来完成。但HSI颜色空间的I分量和RGB颜色空间仍有线性关系，并没有完全地脱离RGB颜色空间体系。HSV颜色空间HSV颜色空间采用色调（Hue）、饱和度（Saturation）和明度（Value），和HSI颜色空间非常类似，模型呈现一个倒圆椎体，如下图所示。&nbsp;HSV和HSI的H分量的含义相同，都表示颜色种类，其定义和数值几乎相同，HSI的H分量表示波长的变化，而HSV的H分量是人工定义的红色、绿色、蓝色分别对应角度0°、120°、240°，其间的颜色均匀变化。HSV和HSI的S分量、I分量、V分量的含义、定义、数值均完全不同。HSI的S分量表示颜色的深浅，它与颜色加入白光的程度成反比，和鲜艳程度成正比，也可以称为纯度；而HSV的S分量则反映颜色的浓淡，它对应于画家配色的方法，饱和度为100%的颜色通常纯度并没有达到100%。HSI的I称为亮度，最高的亮度达到了白光的强度，而HSV的V分量反映了明度，最高的明度达到了中度灰的亮度。所以，图像的冷暖、明暗受到HSV颜色空间的S分量和V分量共同控制，而HSI颜色空间的S分量和I分量则是相对独立的。&nbsp;Lab颜色空间Lab颜色空间是由国际照明委员会制定的设备无关、基于人类视觉感知的颜色系统，L表示亮度（Luminosity），a表示从红色到绿色，b表示从黄色到蓝色，如下图所示为Lab颜色空间模型，L取值范围为[0, 100]，从值为0的黑色变化到值为100的白色；a的取值范围为[-128, 127]，从值为-128的绿色逐渐过渡到值为127的红色；b的取值范围也是[-128, 127]，从值为-128的蓝色逐渐过渡到127的黄色。&nbsp;Lab在功能上来说几乎是完美的颜色空间：首先，它比RGB色域、CMYK色域、甚至人类视觉色域所能涵盖的颜色数量都还要多。其次，Lab非常符合人类视觉特性，将亮度和颜色作为不同分量区分开来，有利于图像处理。同时Lab解决了之前很多颜色空间的“色彩不均匀”问题，比如RGB颜色空间中，红色到绿色之间缺少黄色等过渡色，绿色到蓝色之间的过渡色又过多了，Lab可以称得上是目前最均匀的色彩空间。而且Lab并不是基于光学、颜料调色等基础理论产生的，因此不依赖于任何设备。&nbsp;但是Lab颜色空间也有比较多令人遗憾的部分。目前来说计算机存储的图像文件通常都是基于RGB颜色空间的，然而RGB颜色空间并不能直接转换到Lab颜色空间，需要经过一次XYZ颜色空间的过渡转换，公式非常复杂，极其耗时。同时Lab并没有区分开色调和饱和度，这对彩色图像处理是比较不利的。&nbsp;颜色空间用于图像分割的比较RGB颜色空间是大部分计算机中彩色图像的存储方式，但是由于其各个分量并没有明确含义，而彩色图像分割算法通常都是基于单通道的，因此不用它来进行图像分割，而是用来输入和输出图像。HSI颜色空间被很多图像处理论文所使用，如果使用I分量，那么和处理灰度图像没有任何区别，大量的彩色图像信息被丢弃，所以大部分彩色图像分割工作者都会使用H分量、或者H分量和S分量结合。考虑到H分量很好地反映了图像的颜色变化，涵盖了彩色图像的大部分信息，而S分量反映了颜色的深浅，但一般无论是深色的草地和浅色的草地都会被分割成草地，而绿色的草地和蓝色的天空才会被分割成两类不同的物体，因此可以只使用H分量来进行彩色图像分割。对于HSV颜色空间来说，并没有HSI颜色空间分得那么开，不过由于只提取H分量，因此也是可以考虑的，大量的论文也都使用了HSV颜色空间。Lab颜色空间功能非常完美，但是计算非常耗时，色调和饱和度也没有区分开，这对于需要处理大量样本的KNN基础分类模型来说并不是件好事。RGB转HSI的公式比较在彩色图像分割之前，需��将RGB颜色空间的输入图像转换到HSI颜色空间。目前有许多种RGB颜色空间到HSI颜色空间的转换算法，主要包括几何推导算法、坐标变换算法、分段定义算法、Bajon近似算法，标准模型算法等等，详细的转换公式如下表所示。其中，M=max(R, G, B)，m = min(R, G, B)。几何推导和坐标变换中，色调公式实质上是等价的，而Bajon近似算法则是为了加快运行速度提出的，会损失掉一些细节。经过不同型号计算机和大量的实验测试后发现，几何推导算法对颜色特征保留完整，分辨力很高，适合用作特征分析；坐标变换的RGB到HSI对应关系比较准确；坐标变换和标准模型转换后的颜色值分布相对更均匀一些；而后三种算法的运行速度比前两种算法的运行速度更快；前三种算法从HSI空间反变换回RGB空间所求得的值和与原RGB值更加接近。\n综合考虑精准度、速度、均匀程度等等方面的特性，几何推导是不错的方式。                \n\n\n","categories":["转载"],"tags":[]},{"title":"毕业设计整理（六）：LBP纹理特征","url":"http://tanqingbo.cn/2019/10/06/毕业设计整理（六）：LBP纹理特征/","content":"\nhttp://www.bewindoweb.com/236.html前言局部二值模式（Local Binary Pattern，LBP）是一种用来描述图像局部纹理特征的算法，反映的是图像像素点周围纹理变化情况，具有旋转不变性、灰度不变性（光照变化无影响）、计算复杂度低等优点，1994年首次由Timo Ojala, Matti Pietikainen等人提出，用于纹理特征提取。2002年论文《Multiresolution gray-scale and rotation invariant texture classification with local binary patterns》进行了归纳总结，2018年该论文引用量154次，累计9832次。LBP特征描述原始LBP特征使用3×3矩形模板，从上到下，从左到右逐行扫描，模板中心像素值为gc，从右侧中间像素点开始编号gp(p=0,...,7)。每次周围像素与中心像素比较：得到二值图像，将二值图像值从右侧中间像素点逆时针排列，得到8位二进制数，转为10进制数，就是该中心点gc的LBP特征值：一幅图像的LBP特征如果用灰度图形化显示出来就是这样的：你可以用lbp的官方matlab代码|百度网盘（密码：3yzp） 去测试和实际使用：lbp.m - LBP returns the local binary pattern image or LBP histogram of an image.getmapping.m - GETMAPPING returns a structure containing a mapping table for LBP codes.cont.m - C computes the VAR descriptor.详细描述和样例在头部注释里都有，这里给出我上面测试的例子：function lbptest\n   I=imread('rice.png');\n   SP=[-1 -1; -1 0; -1 1; 0 -1; -0 1; 1 -1; 1 0; 1 1];\n   I2=lbp(I,SP,0,'i');\n   subplot(1,2,1)\n   imshow(I)\n   title(\"rice.png\")\n   subplot(1,2,2)\n   imshow(I2)\n   title(\"lbp特征\")\nendLBP的���体思想非常简单，计算复杂度很低，反映的特征较好，但是有两个明显问题：1) 3×3邻域模板过小，无法捕获大尺度纹理结构2) 矩形模板是具有旋转不变性的因此很多人开始改进。圆形LBP特征：Circle LBP在论文的2.1 Achieving Gray-Scale Invariance中，Ojala等人提出了圆形邻域系统，如下图所示，定义中心点为gc，从最右中间点开始计数g0-gP-1共P（P&gt;1）个点，它们等角均匀地分布在半径为R（R&gt;0）的圆周上。以gc为原点（0, 0），圆周上的点gp坐标为(-Rsin(2πp/P), Rcos(2πp/P))，如果点没有落到像素中心，则采用插值的方式进行估计近似，通常来说使用双线性插值。这样就可以通过改变P的值在圆上添加任意多个点，也可以通过改变R的值任意改变模板大小，记这样的LBP算子为：然而圆形LBP依然不具有旋转不变性。旋转不变LBP特征：LBPROT我们总是选择最右中间点作为起始点g0，所以当LBP算子旋转的时候，g0会发生变化，这样即使是同一个模板、同一个位置、同样的P、R，计算得到的LBP特征值都是不同的。为了消除这种旋转差异，在论文的2.2 Achieving Rotation Invariance中，作者重新定义了LBP计算方式：其中ROR(x,i)指的是对p位数字x进行i次循环右移。也就是说，从各个旋转的LBP二进制串中，找到最小的值，作为这个模板的LBP特征。举个例子，假设P=8，R=1（8个点，半径1），那么对于4个连续的1，4个连续的0（00001111）来说，可以旋转的有：显然最小的是15，所以这个模板的值就是15。看起来圆形LBP很完美，但实际使用发现LBPROT并不具有很好地辨别力，因为随着采样点数的增加，二进制模式会急剧增多，会使得数据量过大，直方图过于稀疏，不能很好地反映图像特征。等价LBP特征：Uniform LBP针对圆形LBP缺点，作者在2.3 Improved Rotation Invariance with \"Uniform\" Patterns and Finer Quantization of the Angular Space中进一步提出等价LBP特征，利用等价模式来对LBP模板种类进行降维。我们首先定义“跳变”为二进制串中\"01\"、\"10\"这样的变化，定义等价量度（Uniformity measure U(\"pattern\")）为二进制串中的跳变次数。Ojala等人发现，大部分图像中都只包含两次跳变，于是可以保持跳变次数小于等于2的模式不变， 大于2的模式笼统归为归为一类。定义LBP：其中，例如，(00000000)2 等价于 (11111111)2，他们的等价量度U都是0，没有跳变，它们都是小于等于2的等价模式类；而(10101010)2含有8次跳变（注意是循环计数的，头和尾的差异也算跳变），属于混合模式类。我们以P=8，R=1来仔细分析，本来应该有2^8 = 256个模式，这样一划分就变成了：等价量度&nbsp;模式个数&nbsp;等价量度&nbsp;模式个数&nbsp;U=0&nbsp;2个&nbsp;U=1&nbsp;0个&nbsp;U=256个U=30个U=4140个U=50个U=656个U=70个U=82个&nbsp;&nbsp;共9种跳变，那么小于2次的共58种LBP模式，将其编码为1-58；其余的混合模式类统一编码为0，如果用灰度值图像展示等价LBP会发现这种LBP特征值图像偏暗，因为大部分不重要的特征像素都被编码为0=黑色了。等价LBP将原来2^P指数个模式变为了P(P-1)+2多项式个模式，大大减少了内存占用，并且特征维度的降低可以减少高频噪声带来的影响。等价LBP不具有旋转不变特性。旋转不变等价LBP特征将旋转不变的圆形LBP和等价LBP结合起来，就构成了最强功能的旋转不变等价LBP特征。将旋转不变LBP进一步分成P+1类均匀旋转不变模式和1类非均匀模式。实验表明，旋转不变均匀LBP具有最低特征维数，保持鉴别力的同时具有良好的旋转不变性和灰度不变性，是LBP中最好的特征了。LBP特征提取方法1) 提取整幅图的LBP特征2) 将特征按相同规则转为向量，例如按行拼接，就能够进行后续处理了。参考资料1、《LBP(局部二进制模式)》2、《LBP原理介绍以及算法实现》3、《LBP特征原理及代码实现介绍》                \n\n\n","categories":["转载"],"tags":[]},{"title":"深圳后台开发岗位要求（持续）","url":"http://tanqingbo.cn/2019/10/06/深圳后台开发岗位要求（持续）/","content":"\nhttp://www.bewindoweb.com/131.html前言用于随时检视自己知识面是否满足岗位需求，技术能否达到要求，有没有新的知识需要学习。一、大疆创新后台开发工程师（JAVA）相关链接【工作职责】 &nbsp;1. 独立完成模块需求分析和模块设计；&nbsp;2. 按照项目计划，按时提交高质量代码，完成开发任务；3. 规范文档的编写、维护；4. 新人指导及Code Review，技术难题研究，提升团队技术水平。【任职要求】 &nbsp;1. 计算机或相关专业，3年以上java实际项目开发经验；2. JAVA基础扎实，精通多线程模型及异步网络编程，深度理解io、集合等基础框架，熟练掌握各类常用数据结构和相关算法 ；&nbsp;3. 熟悉主流开源应用框架，如Spring及Springboot、iBatis、Velocity、XML、JSON、Maven等开发技术；&nbsp;4. 熟悉网络通信协议（UDP/TCP、HTTP/HTTPS），熟悉大数据相关技��（如Hadoop、Hive、Spark、ElasticSearch等），熟悉关系型数据库（MySQL、Oracle等）以及相应数据库调优、SQL优化，熟悉Redis、Elasticsearch、MongoDB等NOSQL；5. 熟悉分布式系统的设计和应用，分布式、缓存、消息、负载均衡等机制和实现者优先考虑；&nbsp;6. 有良好的学习能力、团队协作能力和沟通能力，善于思考、能独立分析和解决问题，热爱技术，对技术有不懈的追求，喜欢研究开源代码者优先考虑。后台开发工程师（PHP）相关链接【工作职责】1. 完成系统代码的实现，编写代码注释和开发文档；&nbsp;2. 辅助进行系统的功能定义，程序设计；&nbsp;3. 根据设计文档或需求说明完成代码编写，调试，测试和维护；4. 分析并解决软件开发过程中的问题；&nbsp;5. 配合项目经理完成相关任务目标。【任职要求】1. 至少三年以上PHP开发经验；&nbsp;2. 掌握Smart、Cache等常用PHP技术，可以独立完成上级下发的任务；3. 熟悉数据库的常用操作，数据库性能优化者优先；&nbsp;4. 有安全意识，熟悉常用的网站安全防护技术；&nbsp;5. 有质量意识，可编写测试代码者优先；&nbsp;6. 拥有良好的代码习惯，要求代码结构清晰，命名规范，逻辑性较强，代码冗余率等；&nbsp;7. 工作积极主动有担当，有一定的抗压能力。                \n\n\n","categories":["转载"],"tags":[]},{"title":"灰度发布、滚动发布、蓝绿部署和两种测试方法","url":"http://tanqingbo.cn/2019/10/06/灰度发布、滚动发布、蓝绿部署和两种测试方法/","content":"\nhttp://www.bewindoweb.com/231.html��言在软件上线之前，不可避免地要对软件的正确性、可靠性进行测试，又最好不要停机维护、不要影响用户体验，并且在新版本出现问题的时候能够及时回退。所以，需要有一套完整的部署方案，灰度发布、滚动发布、蓝绿部署都是常见的手段，而A/B测试则是对用户体验进行调查的测试手段，这里一并学习。一、灰度发布定义灰度发布又叫做金丝雀发布，以前矿工下矿洞前，会放一只金丝雀去试探是否有瓦斯（金丝雀对瓦斯很敏感），映射到这里就是先发布一小部分来试探整体是否能够正常运行，如果能正常运行则进行完全部署的发布方式，目前仍然是不少成长型技术组织的主流发布方式。操作描述（1）当前版本为V1，替换服务器集群中的一小部分（比如1台）为新版本V2。（2）如果正常运行，则把剩余V1版本全部升级为V2；如果运行失败，所有服务器回退到V1。特点分析（1）流量趋势图绿色为旧流量，黄色为新流量。（2）优点用户体验影响小，发布过程中出现问题只影响一部分用户。（3）缺点自动化程度不够，发布期间可能会引发服务中断。二、滚动发布定义滚动发布（Rolling Update Deployment）是在灰度发布上的改进，先发布一小部分，然后逐步增加新版本的数量，直到服务器都升级为新版本。自动化程度较高，用户体验平滑，是目前成熟型技术组织所采用的主流发布方式。操作描述（1）先发布小比例新版本，类似金丝雀。（2）如果验证成功，按照一定比例替换新版本，直到所有版本都升级为新版本，例如1台，10%，50%，100%。（3）一旦失败，将所有新版本应用替换回旧版本应用。特点分析（1）流量趋势图绿色为旧流量，黄色为新流量。（2）优点用户体验影响小，体验平滑。（3）缺点发布和回退时间缓慢。发布工具复杂，NLB需要平滑的流量摘除和拉入能力。三、蓝绿部署定义蓝绿部署（Blue Green Deployment）是一种可以保证系统在不间断提供服务的情况下上线的部署方式，它以可预测的方式发布应用，减少发布过程中服务停止的时间。操作描述（1）准备两个相同的应用运行环境，命名为蓝色环境、绿色环境，刚开始，蓝色环境和绿色环境都运行着相同的应用版本V1，只有蓝色环境对外提供服务。（2）我们开发了一个新版本V2，那么放到绿色环境上进行反复的测试、修改、验证，确定达到上线标准后，利用负载均衡器/反向代理/路由等手段将对外服务切换为绿色环境。（3）一段时间后，如果发生故障，那么迅速切换回蓝色环境V1；如果运行没有异常，那么蓝色环境更新版本到V2，版本再次一致。（4）当需要开发下一个版本V3，重复前面的步骤，蓝色绿色相互切换相互备份。特点分析（1）流量趋势图绿色为旧流量，黄色为新流量。（2）特点蓝色绿色环境相同，但硬件可以不同，例如蓝色和绿色环境分别是两台独立的机器。蓝色绿色环境都会在上线版本、旧版本（用于回滚）和新版本（用于上线前测试）之间循环。如何保证数据库的事务在切换、回退过程中不受影响是很重要的事情，一般来说可以在切换过程中设置为“只读”，或者设计回馈机制，将事务同时反馈到两个环境。（3）优点不停机更新。遇到问题能及时回退到正确版本。（4）缺点需要的硬件成本和软件服务倍增了。数据库同步非常困难。如果需要同时处理“微服务架构应用”和“传统架构应用”，当协调不好的时候还是可能出现服务停止的。在非隔离基础架构（VM、Docker）上执行蓝绿部署，蓝绿色环境都有被摧毁的可能。四、双服务器发布蓝绿发布就是双服务器发布中的蛮力发布法（强行切换），而利用相同的双服务器发布模式可以进行灰度、滚动发布。五、测试方法前面的所有都是发布方法，旨在发现bug、隐患。测试方法则是效果测试，关注的是旧版本和新版本的效果好坏，比如流量转化率、用户体验等等。A/B测试A/B测试指的是同时上线V1和V2版本，根据一定条件将流量分别导入V1和V2版本，收集感兴趣的数据，来对比产品功能的效果。影子测试影子测试主要用于语言切换，比如从JAVA项目迁移到.NET项目，准备两个完全相同的环境，将流量同时导入两个环境，比对输出的响应，来判断是否逻辑等价。这种测试可能需要几周，也可能长达半年。总结部署方式&nbsp;零停机&nbsp;生产流量测试&nbsp;机器成本&nbsp;回退速度&nbsp;对用户的影响&nbsp;复杂度&nbsp;&nbsp;灰度发布&nbsp;？&nbsp;√&nbsp;低&nbsp;慢&nbsp;一般&nbsp;低&nbsp;滚动发布&nbsp;√&nbsp;√&nbsp;低&nbsp;慢&nbsp;低&nbsp;低&nbsp;双服务器组——蓝绿&nbsp;√&nbsp;×&nbsp;高&nbsp;快&nbsp;一般&nbsp;一般&nbsp;双服务器组——灰度&nbsp;√&nbsp;√&nbsp;高&nbsp;快&nbsp;小&nbsp;一般&nbsp;双服务器组——滚动&nbsp;√&nbsp;√&nbsp;高&nbsp;快&nbsp;小&nbsp;一般参考资料1、《蓝绿部署、A/B测试以及灰度发布》2、《蓝绿部署、金丝雀发布（灰度发布）、A/B测试的准确定义》3、《微服务部署：蓝绿部署、滚动部署、灰度发布、金丝雀发布》4、《金丝雀发布、滚动发布、蓝绿发布到底有什么差别？关键点是什么？》                \n\n\n","categories":["转载"],"tags":[]},{"title":"物联网、MQTT协议和MQTT Broker","url":"http://tanqingbo.cn/2019/10/06/物联网、MQTT协议和MQTT Broker/","content":"\nhttp://www.bewindoweb.com/242.html��、物联网和MQTT随着各家嵌入式产品越来越多，技术也越来越成熟，大家都开始想要随便搭载一个AI算法，然后声称为人工智能产品去售卖，像天猫精灵、小米智能音箱之类。这些产品大多都是嵌入式设备，例如小米出了很多传感器，可以用手机APP控制。这就是万物联结的网络，称为物联网（Internet of Things，IoT）。一个很重要的功能当然是通信了，以前的想法就是，要么用Wifi连上家里的路由器，然后搭建一台HTTP服务器来提供服务就好；要么直接用蓝牙等近场通信方式，手机直接和设备交换数据。无论哪种，对嵌入式设备的电量消耗都是巨大的，而且操作的体验并不好，就好像你用蓝牙还得凑近它10米以内。于是人们开始寻找更好的替代方式，1999年IBM开发的MQTT协议重新出现在舞台上。MQTT全称是消息队列遥测传输（Message Queuing Telemetry Transport），是一种专为计算能力低的客户端设计的基于发布/订阅（Publish/Subscribe）模式的“轻量级”通讯协议。先来了解一下MQTT的基本设计思路：1）发布、订阅模式这是一个很经典的一对多消息发布模式了，像Redis就具有发布订阅功能。举一个具体的例子，我们有一个漫画家、有很多想看漫画的肥宅，先约定一个共同的主题叫做\"连载漫画专栏\"，肥宅们非常想看下一期漫画，于是“订阅”了这个专栏，并一直\"监听\"着是否有新漫画到达。每当漫画家“发布”一期新漫画到这个专栏，所有的肥宅都能“消费”相同的下一期“漫画”，漫画家只需要往这个主题“连载漫画专栏”里面发布漫画，无需关心是哪些肥宅在看；肥宅们只需要订阅和监听“连载漫画专栏”，就能够第一时间得到最新漫画内容。回到物联网，有非常多这种一对多消息发布的需求。例如一台温度传感器上传了温度数据，监控日志面板服务希望得到数据好去绘图、温度异常服务希望感知温度异常好做相应操作、手机推送服务希望能够及时地获取最新温度好呈现给手机端展示，这就是一对多的典型需求。相比于一个一个地主动投递消息，发布订阅这种被动获取减少了生产者的负担，解除了耦合，提高了消息传输效率。2）MQTT的工作层MQTT工作于应用层，是基于TCP/IP之上的可靠连接，当然也有UDP版本叫做“MQTT-SN”，通常使用的都是TCP版。3）MQTT轻量级的体现MQTT的报文头部只有2字节，它一开始就假设了客户端是计算能力低需要节省资源的设备，用约定好的二进制位来传递控制消息，省电省流量。4）MQTT的三种消息发布服务质量【QoS0】最多一次，不管成功与否这是最省电但最不可靠的方式，完全依赖底层TCP/IP网络，可能会发生消息丢失和重复。通常应用于物联网设备上报最新数据，例如温度传感器不断地上传最新温度，这次的数据丢了马上又会有下一次，所以丢失无所谓；由于只是修改状态，具有幂等性，无论重复传输多少次，结果都是一样的，所以重复也无所谓。【QoS1】至少一次，保证消息到达，可能重复在QoS0之上保证了消息一定会送到，重复无所谓（通常重复的概率很低），但必须要让消费者看见这条消息，这是最常用的服务质量��应用于手机推送消息等各项服务的数据生产消费。假设你的温度传感器监控到温度异常可能着火了，手机APP收到多条着火消息和一条着火消息都收不到，当然是收到多条着火消息更好了。【QoS2】只有一次，保证消息只到达一次这种当然是最好的情况，但这也是最费电、流程最复杂的情况，大部分物联网大厂都不支持QoS2，因为根本没有这种需求。通常QoS2用于支付，如果支付的数据丢失、或者多次重复支付，都是很难容忍的。或者用于手机聊天消息，手机APP只能接收到一条聊天消息推送，消息的丢失和重复都是不可以的，这种场景直接用HTTP服务器就好了啊，大家都是强大的手机又不是低功耗嵌入式设备。5）MQTT的心跳和连接MQTT维护了双工长连接，通过心跳机制来判断是否掉线。不要担心心跳机制给嵌入式设备带来的负担，通常这个心跳间隔都设置得很长，例如60秒。6）MQTT的主题MQTT的主题长这个样子：“/mydevice/abc”、\"/mydevice/+/confs\"、\"mydevice/qwer/#\"。第一个是最普通的精确主题，用斜杠分隔主题层级。第二个是通配符主题，“+”只能匹配一层的主题，例如“/mydevice/123/confs”是可以匹配的，\"/mydevice/123/aaa/confs\"是无法匹配的。第三个是通配符主题，\"#\"可以匹配多层，但只能在末尾，例如\"mydevice/qwer/aaa/123\"是可以匹配的。7）MQTT的保留消息MQTT设置了一个保留消息（Retain Message），这是基于主题的，每个主题可以有一条保留消息，如果有新的订阅者订阅了该主题，就需要将这条保留消息推送给它，通常用于新订阅主题的设备初始化。8）MQTT的遗嘱MQTT设置了一个遗嘱消息（Will Message），这是基于客户端的，每个客户端在连接的时候可以保留一条遗嘱消息，当连接异常断开（例如网络中断、客户端崩溃、心跳信息没有发送）没有发送正常的DISCONNECT报文的时候，会将这条消息分发给订阅了这个遗嘱消息的客户端，其他客户端就知道它发生问题了，从而做相应的处理，通常用于设备的异常通知，例如当设备正常退出，手机APP需要显示设备正常退出，当设备异常退出，手机APP需要报警，那么手机APP只需要订阅设备的遗嘱消息，就能够知道它断开时是正常的还是异常的了。9）MQTT的常用版本最常用的是三个版本，MQTT3.1、MQTT3.1.1、MQTT5.0。MQTT3.1.1是最常见的，是MQTT服务器至少应该支持的版本。MQTT3.1是早期版本，为了兼容性可以去支持。MQTT5.0是最新版本（3.1.1的下一版本是直接跳到5.0的），性能会有提升，如果设备也能采用MQTT5.0，那么服务器支持MQTT5.0是很好的决定，对于普通开发者，只需要支持MQTT3.1.1即可。10）相比于HTTP，MQTT有哪些优势？MQTT更加适合嵌入式设备：对比项&nbsp;MQTTHTTP&nbsp;报文长度&nbsp;小，省电省流量，头部二进制大，头部是明文订阅发布（多播）支持不支持QoS等级支持不支持双向通信支持用Websocket才行&nbsp;保留消息、遗嘱消息支持不支持二、MQTT Broker 消息代理刚接触物联网的同学应该经常看到这个名词，中文翻译得最准确的就是亚马逊AWS IoT的中文文档——“消息代理”。通常代理都是Proxy，这里换了一个词叫Broker（中间人、代理人），Kafka的订阅发布代理也叫做Broker。为什么要叫消息代理呢，因为所有的MQTT的转发都是由它在中间来代为协调的。Broker所做的事情就是，替客户端维护所有MQTT订阅信息，提供发布订阅的QoS保证。客户端毕竟是嵌入式设备，没有那么强大的能力，那就让服务器来替代它完成消息的推送任务。设计Broker有很多困难的地方，目前开源的Java编写的MQTT Broker没一个能满足所有需求的，很气……                \n\n\n","categories":["转载"],"tags":[]},{"title":"用EDU邮箱免费注册JetBrains全家桶","url":"http://tanqingbo.cn/2019/10/06/用EDU邮箱免费注册JetBrains全家桶/","content":"\nhttp://www.bewindoweb.com/169.html前言由于JetBrains开始封禁一些很多人用的注册服务器域名（比如idea.imsxm.com），因此注册服务器不可用了（当然也可以自己重新搭建，另外成都没有派对提供了一个紧急车：http://idea.yangyusb.com，亲测可用），其实可以用EDU邮箱来免费获取注册码的（对不起以后挣钱了自己买……）一、具体方法1、EDU邮箱获取【方法1】一般学校都会有终身的EDU邮箱，不管毕不毕业，不管是本是硕是博，是可以一直使用的。【方法2】自己搭建或者淘宝一个EDU冷门域名邮箱……比如xxx.edu.lv，缺点是有些网站不会承认这种可以购买的EDU域名2、填写官网学生信息进入学生信息页面，填写如下信息，Email地址必须是edu邮箱。3、收到确认请求邮件进入edu邮箱，确认4、再收到一条激活码获取邮件5、下载离线激活码下载一个txt文档，里面是离线激活码。6、激活软件JetBrains任何软件，点击菜单栏Help→Register→Activation Code，粘贴txt文档里的激活码进去，点击OK，激活成功，右下角会弹出一个框。注意：激活码只有一年使用权哦。二、参考文档1、《申请JetBrains学生免费注册码》2、《JetBrains 授权服务器》                \n\n\n","categories":["转载"],"tags":[]},{"title":"用Python爬取双色球开奖信息（升级版）","url":"http://tanqingbo.cn/2019/10/06/用Python爬取双色球开奖信息（升级版）/","content":"\nhttp://www.bewindoweb.com/196.html前言在《用Python简单爬取双色球开奖信息》中，完成了初始的爬取工作，但定时爬取的方法会爬取很多重复的数据，我们希望更精准更自动地去爬取。通过研究发现，中国福利彩票双色球每周二、四、日21:15开奖，中国体育彩票超级大乐透每周一、三、六21:30开奖，那么这次升级版的目标就是：1、自动完成安装工作2、在周二、四、日的晚上23:00爬取中国福利彩票双色球开奖数据，在周一、三、六的晚上23:00爬取中国体育彩票超级大乐透开奖数据。二、工具python2.7一台debian 8.2的服务器三、具体方法1、使用python2.7编写爬取脚本这里除了正常的爬取操作，还增加了独立的参数设定。如果没有参数，爬取的数据就在当前目录下；如果有参数，可以设定保存目录、保存文件名后缀。这样的话，这个脚本既可以单独使用，也可以配合sh定时任务使用。双色球爬取代码grab500_ssq.py内容：# -*- coding:utf-8 -*-\nimport re\nimport urllib\nimport time\nimport sys\n\n\n\ndatapath = sys.path[0]datasuffix = ‘txt’if (len(sys.argv)&gt;1):    datapath = sys.argv[1]    datasuffix = sys.argv[2]\ndef getHtml(url):    html = urllib.urlopen(url)    return html.read()\nhtml = getHtml(“http://zx.500.com/ssq/&quot;)\nreg =  [‘&lt;dt&gt;([0-9]\\d*).&lt;/dt&gt;’]reg.append(‘&lt;li class=”redball”&gt;([0-9]\\d)&lt;/li&gt;’)reg.append(‘&lt;li class=”blueball”&gt;([0-9]\\d*)&lt;/li&gt;’)\noutstr = “”;for i in range(len(reg)):    page = re.compile(reg[i])    rs = re.findall(page,html)    for j in range(len(rs)):        outstr+= rs[j] + “,”\n#print time.strftime(‘%Y-%m-%d’,time.localtime(time.time()))+”:”+outstr[:-1]\nwith open(datapath+’/lot_500_ssq.’+datasuffix, ‘a’) as f:    f.write(time.strftime(‘%Y-%m-%d’,time.localtime(time.time()))+”:”+outstr[:-1]+’\\n’)大乐透爬取代码grab500_dlt.py内容：# -- coding:utf-8 --import reimport urllibimport timeimport sys\ndatapath = sys.path[0]datasuffix = ‘txt’if (len(sys.argv)&gt;1):    datapath = sys.argv[1]    datasuffix = sys.argv[2] \ndef getHtml(url):    html = urllib.urlopen(url)    return html.read()\nhtml = getHtml(“http://zx.500.com/dlt/&quot;)\nreg =  [‘&lt;dt&gt;([0-9]\\d*).&lt;/dt&gt;’]reg.append(‘&lt;li class=”redball”&gt;([0-9]\\d)&lt;/li&gt;’)reg.append(‘&lt;li class=”blueball”&gt;([0-9]\\d*)&lt;/li&gt;’)\noutstr = “”;for i in range(len(reg)):    page = re.compile(reg[i])    rs = re.findall(page,html)    for j in range(len(rs)):        outstr+= rs[j] + “,”\n#print time.strftime(‘%Y-%m-%d’,time.localtime(time.time()))+”:”+outstr[:-1]\nwith open(datapath+’/lot_500_dlt.’+datasuffix, ‘a’) as f:    f.write(time.strftime(‘%Y-%m-%d’,time.localtime(time.time()))+”:”+outstr[:-1]+’\\n’)2、编写一个执行的sh���本我们需要编写执行python的sh脚本bwb_lottery_everyday.sh，要注意的是sh的date获取的星期天值是0而不是7，而crontab则可以设定0或者7。#!/bin/shbasepath=$(cd dirname $0; pwd)                #shell's dirdatapath=$basepath'/lotterydata'                #shell's datadirdatasuffix='txt'                                #datasuffix\na=date -d &quot;$&#123;date&#125;&quot; +%wif [ $a -eq 1 ] || [ $a -eq 3 ] || [ $a -eq 6 ]; then    python “${basepath}/grab500_ssq.py” $datapath $datasuffixelif [ $a -eq 2 ] || [ $a -eq 4 ] || [ $a -eq 0 ]; then    python “${basepath}/grab500_dlt.py” $datapath $datasuffixfi3、编写一个主sh脚本编写一个主要的sh脚本bwb_lottery_main.sh，执行清理和设定的工作。需要注意的是，这里直接使用了系统的/etc/crontab文件来达到周期执行的目的，其实并不太好，但crontab -e的方法很难自动化，所以只能设定为系统任务。#!/bin/shcronfile=\"/etc/crontab\"                     #debian cronfilebasepath=$(cd dirname $0; pwd)            #shell's dirdatapath=$basepath'/lotterydata'                #shell's datadirdatasuffix='txt'                                #datasuffixcrontaskname=\"bwb_lottery_everyday.sh\"           #shell's namecrontasktime=\"0 23\\t* * 1-4,6-7\"         #crontab task run time,default everyday except friday 23:00\necho “checking…”if [ ! -f ${cronfile} ]; then    echo “crontab file $cronfile doesn’t exsits.\\nplease check file or modify shell setting and run shell again.”    exit 1fi\npyver=python -V 2&amp;gt;&amp;amp;1|awk &#39;&#123;print $2&#125;&#39;|awk -F &#39;.&#39; &#39;&#123;print $1&#125;&#39;if [ $pyver != ‘2’ ]; then    echo “python2(.7) is needed.”    exit 1fi\necho “writing crontab file…”if [ grep -c &quot;$&#123;crontaskname&#125;&quot; $&#123;cronfile&#125; -eq ‘0’ ]; then    echo “${crontasktime}\\troot\\t${basepath}/${crontaskname}”&gt;&gt;${cronfile}else    sed -i “s#^.${crontaskname}.#${crontasktime}\\troot\\t${basepath}/${crontaskname}#” ${cronfile}fi/etc/init.d/cron restart\necho “making data dir…”if [ ! -d “${datapath}” ]; then    mkdir ${datapath}else    if [ ! -d “${datapath}/bak” ]; then        mkdir “${datapath}/bak”    else        mv ${datapath}/*.${datasuffix} ${datapath}/bak/ 2&gt;/dev/null    fifi\necho “changing permission…”chmod +x “$basepath/$crontaskname”chmod +w -R $datapath\necho “finished!”我们最后只需要执行这个主脚本，就能一键自动完成彩票爬虫的布置。四、其他完整的项目代码lotterygrabber已经上传到github上去了，欢迎提交watch、star、fork素质三连和提交issue。                \n","categories":["转载"],"tags":[]},{"title":"用Python简单爬取双色球开奖信息","url":"http://tanqingbo.cn/2019/10/06/用Python简单爬取双色球开奖信息/","content":"\nhttp://www.bewindoweb.com/166.html一、前言很多以前的双色球信息都不能看了，因此可以每2天爬取一次双色球信息，保存下来，以后使用。二、工具python2.7一台debian 8.9的服务器三、具体方法1、使用python2.7编写爬取脚本这里爬取的是彩票500网站的信息，步骤如下：（1）抓取网页html（2）编写正则（3）匹配网页html和需要的正则信息，提取信息保存为字符串（4）把结果写入文件（你也可以写入数据库）# -*- coding: utf-8 -*-\nimport re\nimport urllib\nimport time\n\n\n\ndef getHtml(url):    html = urllib.urlopen(url)    return html.read()\n#获取网页html内容html = getHtml(“http://zx.500.com/ssq/&quot;)\n#比对需要的信息reg =  [‘&lt;dt&gt;([0-9]\\d*).&lt;/dt&gt;’]#期数reg.append(‘&lt;li class=”redball”&gt;([0-9]\\d)&lt;/li&gt;’)#红球reg.append(‘&lt;li class=”blueball”&gt;([0-9]\\d*)&lt;/li&gt;’)#蓝球\noutstr = “”;for i in range(len(reg)):    page = re.compile(reg[i])#生成正则    rs = re.findall(page,html)#匹配网页中的正则字符串    for j in range(len(rs)):#获得结果        outstr+= rs[j] + “,”\n#print time.strftime(‘%Y-%m-%d’,time.localtime(time.time()))+”:”+outstr[:-1]#把结果写入文件with open(‘lot_500_ssq.txt’, ‘a’) as f:    f.write(time.strftime(‘%Y-%m-%d’,time.localtime(time.time()))+”:”+outstr[:-1]+’\\n’)编写完成后，保存为/home/lottery/grab500_ssq.py2、编辑一个sh脚本注意这里的cd /home/lottery是必须的，是你python文件存在的位置，如果不写这个，crontab执行不了这个python文件，因为在它的目录找不到。#!/bin/shcd /home/lotterypython grab500_ssq.py保存为 /home/lottery/main.sh3、设置crontab定时执行参考《Debian 8下定时自动备份Mysql数据库》：（1）修改sh文件权限为可执行（否则会报permission deny错误）：chmod 755 /home/lottery/main.sh（2）编辑crontabvi /etc/crontab设置内容为：每2天晚上的22点14分执行一次main.sh14 22 */2 * * root /home/lottery/main.sh（3）重启crontab使命令���效/etc/init.d/cron restart提示：[ ok ] Restarting cron (via systemctl): cron.service.四、结果每隔2天，就会进行一次爬取：cat lot_500_ssq.txt2018-03-14:18028,03,08,11,14,18,23,16时间：期数，红球，蓝球。同样的方法可以爬取体彩的大乐透。                \n","categories":["转载"],"tags":[]},{"title":"用QQ机器人筛选想买的淘宝群商品","url":"http://tanqingbo.cn/2019/10/06/用QQ机器人筛选想买的淘宝群商品/","content":"\nhttp://www.bewindoweb.com/215.html前言由于博主的贫穷，加入了很多淘宝群：虽然QQ通过不断地迭代，已经出了最好用���“接受但不提醒”的群信息接受模式，不会被群打扰日常生活，但是并没有筛选群信息的功能。每个人都有自己不同的需求，比如我特别喜欢买一些抽纸、垃圾袋、A4纸、签字笔等生活用品，绝对不会去买零食、衣服，因为这种低价的零食和衣服一般都是劣质的并夕夕同款……然而由于每个群主都会有自己的喜好，比如我见过有的群主整天发自热火锅，恨不得凉粉也能出自热款……我实在是不感兴趣，为了筛选想要的东西我经常需要花费1个小时来爬楼。所以想着如果可以自动筛选商品就好了，就想到了使用QQ聊天机器人。注意到群主也都是使用类似的工具来发群里的，发送的商品信息都有固定的格式：原价XXX元……【券后XXX元】……[淘宝链接]……[淘口令]那么一个想法就是，用一个QQ加入全部淘宝群，然后接受到含有指定内容的商品信息（比如9.9包邮），就把这条商品信息转发给我的大号，完成了筛选，bingo！暂且命名为BWBBOT~一、需要用到的工具首先，你需要这些东西：（1）花一个月混熟淘宝群。你首先需要去混熟淘宝群，了解大概会发布哪些商品，哪些是你需要的东西，都有什么固定的文本格式等等。（2）一个小号QQ。注册现在都要手机号了哦，不过一个手机号每天都可以注册很多个QQ。（3）一个群。把大号和小号都拉进来。（4）一台服务器。用的是我之前抢购的年中优惠百度云服务器，安装的操作系统是debian 8（64位）二、开始实现1、选择合适的QQ聊天机器人程序我在github上随便搜索的一个python开发的基于WebQQ的聊天机器人开源代码（MIT协议，可以免费复制修改甚至商用）：pandolia/qqbot2、python环境配置（1）检查服务器（debian 8，后续不再提示）上的python环境。一般的环境都是自带的python2.7，建议再装一个python3：安装完python3后不要删除python2.7，因为可能系统有的包还依赖于python2.7。QQ聊天机器人作者建议使用python2.7以上版本、python3.4以上版本。（2）安装pipapt-get通常都装不了pip，需要这样安装：wget https://bootstrap.pypa.io/get-pip.py\npython3 get-pip.py\npip -V　　#查看pip版���安装结果：注意这里的pip一定要是安装到python3的路径下哦。3、安装QQ聊天机器人pip install qqbot一键就完成了。然后输入qqbot就可以运行qqbot了：qqbot默认会弹出一个图片的二维码，然而这并不是好的选择，通常服务器都是没有gnome界面的。我们接下来会进行一些配置来解决这类问题，修改的都是这个文件：vi ~/.qqbot-tmp/v2.3.conf4、配置qqbot登录用过webqq的都知道，以前的webqq都是用户名+密码登录的，后来改为账密/扫码二选一，现在改为了只能通过手机扫描二维码登录……心累，而且这个登录的cookie是有时间限制的，通常来说在1~2天的时间后就会强制下线QQ，那么我们必须每次都手动重新登一次，做这个机器人的意义就削减很多了。为了尽可能地减少麻烦，我们只有尽可能地去减少重登的步骤。qqbot提供了四种登录方法：【GUI模式】 在 GUI 界面中自动弹出二维码图片&nbsp;【邮箱模式】 将二维码图片发送到指定的邮箱&nbsp;【服务器模式】在一个 HTTP 服务器中显示二维码图片&nbsp;【文本模式】在 Term 中以文本形式展示二维码(需要自行安装 pillow 和 wcwidth 库)GUI和文本模式就不用考虑了，邮箱模式和服务器模式是可以共存的。当只设置邮箱的时候，会不断地往你邮箱里发送二维码，每次二维码失效就重发一封邮件：万一我没在有网的环境，邮箱就爆炸了……所以可以设置邮箱+服务器共存，会只发送一封邮件：每次重新打开这封邮件，里面的二维码会更新，或者访问服务器的地址刷新一下，二维码也会更新，这就科学多了。（1）获取邮箱授权码打开大号QQ邮箱→设置：点击生成授权码：就得到了邮箱授权码。（2）修改配置我们来修改配置文件~/.qqbot-tmp/v2.3.conf：把somebody替换成你喜欢的名字，比如bwb；qq里面填的是小号的QQ，mailAccount填的是大号QQ邮箱，mailAuthCode填的是刚刚得到的授权码。5、Hello qqbot来编写一个helloworld。（1）修改备注名由于qqbot目前已经获取不到真实的QQ号了（腾讯关闭了相关接口），只能通过名字搜索，而这些淘宝群的名字可能随时更改，我们提前给它们设置备注名，“淘宝1”，“淘宝2”……然后把大号QQ也设置为备注名“大号”，就不怕更改啦。（2）在/root/.qqbot-tmp/plugins目录下建立一个taobaobargains.py文件，你可以试着参考sampleslots.py来填入以下内容：# -*- coding: utf-8 -*-\n\n\n\ndef onQQMessage(bot, contact, member, content):    if contact.mark == ‘淘宝1’:        recver = getRecvQcontact(bot)        bot.SendTo(recver,content)\ndef getRecvQcontact(bot):    return bot.List(‘buddy’,’大号’)[0]contact是一个Qcontact对象，包含一个QQ对象的信息，比如它可能是个群、可能是个好友、可能是讨论组。content是这个contact对象发送给你的消息。mark的含义是“备注名”，更多信息参考qcontact-attr.md（3）把编写的插件加入配置里面# 启动时需加载的插件        \"plugins\" : [            'taobaobargains',        ],（4）启动qqbotqqbot -u bwb在通过之前的扫码登录之后，就可以得到信息啦：并且你的大号QQ也会接收到相同的信息。6、实现过滤在/root/.qqbot-tmp/plugins目录下编写更具体的带测试的插件taobaobargains.py：# -- coding: utf-8 --import re\ndef onQQMessage(bot, contact, member, content):    if contact.mark == ‘淘宝1’:        recver = getRecvQcontact(bot,2)        if isTargetKeyword(content) or isTargetPrice(content):            bot.SendTo(recver,content)    elif contact.mark == ‘淘宝2’:        recver = getRecvQcontact(bot,2)        if isTargetKeyword(content) or isTargetPrice(content):            bot.SendTo(recver,content)    elif contact.mark == ‘淘宝3’:        recver = getRecvQcontact(bot,2)        if isTargetKeyword(content) or isTargetPrice(content):            bot.SendTo(recver,content)\ndef getRecvQcontact(bot,num):    if (num == 1):        return bot.List(‘buddy’,’大号’)[0]    elif (num == 2):        return bot.List(‘group’,’自聊群’)[0]\ndef isTargetKeyword(content):    keywords = [‘清风’,’维达’,’垃圾袋’,’A4纸’]    for kw in keywords:        if kw in(content):            return True    return False\ndef isTargetPrice(content):    prices = re.findall(u”(\\d*.*\\d+)元”,content)    if len(prices) &gt; 0:        for price in prices:            if float(price) &lt; 10:                return True    return False\nif name == ‘main‘:    str = [‘券后0.9元’,’0.9yuan’,’原价19.9元’,’券后1元’,’券后9.9元’,’清风抽纸’,’维达抽纸’,’1元神车’,’苏宁红包’,’60个垃圾袋’]    for item in str:        if isTargetPrice(item):            print(item)    print(“—-“)    for item in str:        if isTargetKeyword(item):            print(item + “yes”)        else:            print(item)当然在搜索价格的时候，你也可以通过re.search来搜索，这都是python相关的了，你想怎么写都可以。价格设定为10元以下。我没有把消息发给大号QQ，因为QQ好友是不具有“接受但不提醒”功能的，所以用了很多年前自己建立的一个跟自己聊天的群……（我以前经常跟自己在线表演精分现场……），群是可以“接受但不提醒”的。然后你重启qqbot就只会在群里收到符合需求的信息啦，节省了大量精力，开心：7、一些收尾工作（1）后台运行当你退���命令行界面的时候，所有相关进程都会退出。所以我们需要开启daemon模式来后台运行qqbot，在退出以后仍然能运行，修改配置文件：这里还开启了掉线重启、读取后才启动两个选项。当你重新运行的时候，就会提示：所有的输出会被重定向到/.qqbot-tmp/daemon-[qq号].log这个文件里去。如果要退出的话，kill掉就好了：（2）定时重启前面提到由于腾讯的新机制，webqq的cookie在12天后会过期，过期就需要手动重新扫码，但是这个过期时间不固定，导致随时担心扫码。我们设定每天固定时间来强行重启qqbot即可，每天扫一次，保证稳定运行（其实还是感觉很累，不太科学，后续看能不能自己开发一下）：# 启动时需加载的插件        \"plugins\" : [            'taobaobargains',            'qqbot.plugins.schedrestart'        ],\n    # 插件的配置（由用户自定义）\n    &quot;pluginsConf&quot; : &#123;\n        &#39;qqbot.plugins.schedrestart&#39;: &#39;23:00&#39;,\n    &#125;,&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;每天的23:00差不多该做的做完了，又没有睡觉，正好可以扫码。注意，我尝试过修改这里的默认全局配置，但是发现无效，所以还是需要在用户自定义配置那里去修改，然后把全局配置给注释掉：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;zoompic&quot; src=&quot;http://cdn.bewindoweb.com/uploadpic/8e12f6706eb3f88d76b63dabc324d075.png&quot; style=&quot;max-width:100%;&quot;&gt;&lt;/p&gt;&lt;p&gt;后来注释掉发现&lt;span style=&quot;font-weight: bold;&quot;&gt;每天8:00仍然重启&lt;/span&gt;……原因还是这个默认配置不生效，看来是v2.3版本的bug，我已经&lt;a href=&quot;https://github.com/pandolia/qqbot/issues/367&quot; target=&quot;_blank&quot;&gt;提交issue&lt;/a&gt;了。临时的解决方法是：&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;prettyprint lang-bsh linenums&quot;&gt;# 1、找到这个文件：\nfind -name “schedrestart“\n2、删除缓存并移动了这个文件，把它作为用户插件：rm ./usr/local/lib/python3.4/dist-packages/qqbot/plugins/pycache/schedrestart.cpython-34.pycmv ./usr/local/lib/python3.4/dist-packages/qqbot/plugins/schedrestart.py /root/.qqbot-tmp/plugins/\n3、修改了用户配置：    # 启动时需加载的插件\n    &quot;plugins&quot; : [\n        &#39;schedrestart&#39;\n    ],\n\n    # 插件的配置（由用户自定义）\n    &quot;pluginsConf&quot; : &#123;\n        &#39;schedrestart&#39;: &#39;23:00&#39;,\n    &#125;,&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这样它到时间就会出现：&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;zoompic&quot; src=&quot;http://cdn.bewindoweb.com/uploadpic/916c31a975e012f1f410a1be47b4f49d.png&quot; style=&quot;max-width:100%;&quot;&gt;&lt;/p&gt;&lt;p&gt;不断地重新发送二维码直至登录成功：&lt;/p&gt;&lt;p&gt;&lt;img class=&quot;zoompic&quot; src=&quot;http://cdn.bewindoweb.com/uploadpic/c9f70af7cd93a6c543db85ec3ba1e55d.png&quot; style=&quot;max-width:100%;&quot;&gt;&lt;/p&gt;&lt;h1&gt;三、缺点分析&lt;/h1&gt;&lt;p&gt;（1）每天扫码不方便，不是一个优雅的解决方式。为了让机器人稳定运行，每天都扫码登录，真是一个睿智的行为……&lt;/p&gt;&lt;p&gt;（2）仍然可能获取到一些无用信息，比如很多群主喜欢发：&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;prettyprint lang-txt linenums&quot;&gt;平均一件不到4元 → 【4元】但是总价很高好嘛！\n领取红包群里购物直接抵现，可以0元撸！→【0元】但是根本撸不了好嘛！每天领红包，搜索xxxxxx →【红包】我想要的不是花呗红包……是苏宁30-30这种红包啊这就需要取舍权衡“丢弃部分商品，非常严格筛选，节约时间”和“保留大多数商品，放宽筛选条件”了。四、值得继续深入玩一玩的地方（1）持续长期登录（2）利用QQ机器人，测试自己的AI算法                \n","categories":["转载"],"tags":[]},{"title":"用pythonGUI上传文件到AWS S3","url":"http://tanqingbo.cn/2019/10/06/用pythonGUI上传文件到AWS S3/","content":"\nhttp://www.bewindoweb.com/265.html前言经常会遇到在windows上上传文件到AWS S3的需求，由于某些原因不方便直接使用AWS提供的HTTP界面去上传文件，只好用脚本上传。在windows上更多的是编译好了一个程序想放到AWS的机器跑一跑，用S3做文件中转。直接用脚本的话，每次都要输入对应的文件路径，比较麻烦，更想有个GUI界面选择文件后自动把路径填上去，AWS提供了boto3这个库，支持java、python等等，我们用python3来做这件事。一、前期准备（1）IDE：推荐使用PyCharm，方便的是当有库没有安装时会提示你Alt+Enter快速安装（2）Python：3.6+（3）python库安装：用pip3 install提前安装好所有的库aws库：boto3，官方文档和示例python打包成EXE库：pyinstallerpythonGUI库：tkinter（之前的版本叫Tkinter）解析INI配置文件库：configparser（之前的版本叫ConfigParser）二、预览最终效果本地文件路径：要上传的本地文件路径，在”选择文件“后会自动添加S3文件名：上传到S3后的文件名，默认用原文件名aws_kid：AWS Access Key ID, IAM生成的密钥IDaws_sak：AWS Secret Access Key，IAM生成的密钥，和密钥ID是成对分配的region_name：区域，例如ap-south-1，详细的区域可以看区域列表中S3部署的区域桶（bucket）：你建立的S3桶的名称键（key）：这里指的是前缀，例如填入myfolder，S3文件名为xxxx.jpg，那么S3上存储的路径就会变为myfolder/xxxx.jpg，在S3的界面上直观看是一个文件夹叫myfolder，里面放了xxxx.jpg这个文件点击保存配置后，可将配置保存到同目录下的config.ini文件中；点击选择文件会GUI选择文件，选择完毕会将路径和文件名填入“本地文件路径”和“S3文件名”中；点击上传文件到S3会将文件上传到S3，且会看到实时的上传进度条以及百分比数字，如果出错会提示出错。三、分解步骤1、熟悉boto3的上传操作boto3的上传代码：session = boto3.Session(\n          aws_access_key_id = xxxx,\n          aws_secret_access_key = xxxx,\n          region_name = xxxx)\ns3 = session.resource('s3')\ns3.meta.client.upload_file(srcPath, bucket, destPath)其实就几行，建立一个boto3的Session对象，初始化为's3'服务，然后调用上传文件的函数，填入源文件名、桶的位置、目的文件名，就可以传上去了。2、熟悉python tkintertkinter是python经典的GUI框架。（1）布局布局包括3种，pack、place、grid：pack：比较简单的相对布局，适合初学place：绝对布局grid：类似CSS分格子的布局，适合仔细研���和生产开始我尝试了pack，发现不满足需求，组件必须放在Frame上，我想要分成多行，每行一个标签和一个文本框，就需要每行构建一个Frame，太麻烦，grid又需要仔细学，因此直接用了place绝对布局，规定在哪个像素显示就会在哪里显示，虽然不像grid一样适合后面扩展，但由于只是小工具不需要扩展，所以使用比较方便。（2）常用组件和对应方法把常用的例子列出来：from tkinter import *\nfrom tkinter.filedialog import askopenfilename\nfrom tkinter import messagebox\n\n\n\n1. 创建容器window = Tk()window.title(“s3文件上传工具”)window.geometry(‘600x320’) # 设置绝对宽高window.wm_resizable(False,False) # 不允许调整宽高\n2. Label标签place绝对布局，10px，10px，且x横向放置在0.07*600的位置，通过调整这个数字就可以调整位置untitle_label = Label(window, text=’本地文件路径’).place(x=10, y=10, relx=0.07) \n3. 可动态设置内容的Label标签建立一个变量，并绑定到容器var_upload_percentage = StringVar(window, “”)\nLabel绑定这个变量，标签会显示为这个变量的值untitle_label = Label(window, textvariable=var_upload_percentage).place(x=140, y=300)\n改变变量的值就能改变标签值var_upload_percentage.set(“”)\n4. Text文本框text_filepath = Text(window, width=50, height=1)\ninsert可以追加文本（不清空）text_filepath.insert(INSERT, “��上传文件…”)text_filepath.place(x=140, y=15)\nget可以获取第0行从第0个字符到末尾的文本末尾的:-1是去掉最后一个字符，因为获取的文本总会带换行符\\nfilepath = text_filepath.get(0.0, END)[:-1]\n清空和追加=重置text_filepath.delete(0.0, END)text_filepath.insert(INSERT, “xxxxxx”)\n5. 普通按钮点击就会调用save_config函数save_button = Button(window, text=”保存配置”, command=save_config)save_button.place(x=140, y=225)\n6. 可更改按钮内容的按钮（和前面一样的方法）var_upload_botton = StringVar(window, “上传文件到s3”)upload_button = Button(window, textvariable=var_upload_botton, command=fileupload)upload_button.place(x=300, y=225)\n7.按钮的禁用、启用upload_button.configure(state=’disable’)upload_button.configure(state=’active’)\n8.Canvas画布创建一个画布canvas_width = 350canvas = Canvas(window, width=canvas_width, height=22, bg=”white”)canvas.place(x=140, y=270)\n绘制一个矩形，左上角1.5px 1.5px，宽度current/total*canvas_width，高度23，填充为绿色绘制完之后一定要刷新容器，否则不会显示canvas.create_rectangle(1.5, 1.5, current/total*canvas_width, 23, fill=”green”)window.update()\n清空画布内容canvas.delete(ALL)\n9. 提示框messagebox.showerror(“上传结果”, “文件上传失败！请检查请求参数和网络连接”)messagebox.showinfo(“上传结果”, “文件上传成功！”)\n10. 最后一句话，就能显示这个GUI界面了mainloop()3、利用boto3的回调制作上传进度条原理：boto3的upload_file有一个可选的参数CallBack，上传时会定时调用这个函数，并提供当前传送的数据量、总数据量、百分比等数据；利用前面的画布，根据百分比绘制对应宽度的矩形，由于被定时调用，看起来就像进度条在往前走一样。这里一定要注意使用多线程，否则GUI会卡死。相关代码：class ProgressPercentage(object):\ndef __init__(self, filename):\n    self._filename = filename\n    self._size = float(os.path.getsize(filename))\n    self._seen_so_far = 0\n    self._lock = threading.Lock()\n\ndef __call__(self, bytes_amount):\n    # To simplify, assume this is hooked up to a single filename\n    with self._lock:\n        self._seen_so_far += bytes_amount\n        percentage = (self._seen_so_far / self._size) * 100\n        sys.stdout.write(\n            &quot;\\r%s  %s / %s  (%.2f%%)&quot; % (\n               self._filename, self._seen_so_far, self._size,\n               percentage))\n        sys.stdout.flush()\n        try:\n            progress(self._seen_so_far, self._size)\n        except:\n            print(&quot;出错&quot;)\ndef fileupload():    filepath = text_filepath.get(0.0, END)[:-1]    filename = text_filename.get(0.0, END)[:-1]    bucket = text_bucket.get(0.0, END)[:-1]    key = text_key.get(0.0, END)[:-1]    aws_access_key_id = text_aws_access_key_id.get(0.0, END)[:-1]    aws_secret_access_key = text_aws_secret_access_key.get(0.0, END)[:-1]    region_name = text_region_name.get(0.0, END)[:-1]    print(“文件路径=” + filepath +          “\\n新文件名=” + filename +          “\\n桶=” + bucket +          “\\n键=” + key +          “\\nawskid=” + aws_access_key_id +          “\\nawssak=” + aws_secret_access_key +          “\\n区域=” + region_name + “\\n”)    t = threading.Thread(target=s3upload,                         args=(filepath, aws_access_key_id, aws_secret_access_key, region_name, bucket, key, filename))    t.setDaemon(True)    t.start()    var_upload_botton.set(“正在上传”)    upload_button.configure(state=’disable’)def clear_progress(canvas):    canvas.delete(ALL)    var_upload_percentage.set(“”)    var_upload_botton.set(“上传文件到s3”)    upload_button.configure(state=’active’)\ndef progress(current, total):    # 填充进度条    canvas.create_rectangle(1.5, 1.5, current/totalcanvas_width, 23, fill=”green”)    window.update()    # 填写进度    var_upload_percentage.set(str(round(current/total100, 2)) + “%”)\nif name == ‘main‘:    var_upload_botton = StringVar(window, “上传文件到s3”)    upload_button = Button(window, textvariable=var_upload_botton, command=fileupload)    upload_button.place(x=300, y=225)    untitle_label = Label(window, text=’上传进度’).place(x=10, y=270, relx=0.11)    canvas_width = 350    canvas = Canvas(window, width=canvas_width, height=22, bg=”white”)    canvas.place(x=140, y=270)    var_upload_percentage = StringVar(window, “”)    untitle_label = Label(window, textvariable=var_upload_percentage).place(x=140, y=300)4、增加配置文件希望能够自己添加配置文件，因此本地保存一个INI就可以了，然后启动时读取，点击“保存配置”按钮时写入。def save_config():    bucket = text_bucket.get(0.0, END)[:-1]    key = text_key.get(0.0, END)[:-1]    aws_access_key_id = text_aws_access_key_id.get(0.0, END)[:-1]    aws_secret_access_key = text_aws_secret_access_key.get(0.0, END)[:-1]    region_name = text_region_name.get(0.0, END)[:-1]    print(aws_access_key_id, aws_secret_access_key, region_name, bucket, key)    try:        conf.set(\"aws_account\", \"aws_kid\", aws_access_key_id)        conf.set(\"aws_account\", \"aws_sak\", aws_secret_access_key)        conf.set(\"bucket_info\", \"region_name\", region_name)        conf.set(\"bucket_info\", \"bucket\", bucket)        conf.set(\"bucket_info\", \"key\", key)        conf.write(open(cfgpath, \"w+\")) #w是替换，r+是修改    except:        messagebox.showerror(\"配置保存结果\", \"保存失败！\")        return False    else:        messagebox.showinfo(\"配置保存结果\", \"保存成功！\")\nif name == ‘main‘:    # 读取配置    curpath = os.path.dirname(os.path.realpath(file))    cfgpath = os.path.join(curpath, “config.ini”)    conf = configparser.ConfigParser()    conf.read(cfgpath, “utf-8”)    aws_kid = conf.get(“aws_account”, “aws_kid”)    aws_sak = conf.get(“aws_account”, “aws_sak”)    region_name = conf.get(“bucket_info”, “region_name”)    bucket = conf.get(“bucket_info”, “bucket”)    key = conf.get(“bucket_info”, “key”)\nsave_button = Button(window, text=&quot;保存配置&quot;, command=save_config)\nsave_button.place(x=140, y=225)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;配置文件config.ini类似这样：&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;prettyprint lang-txt linenums&quot;&gt;[aws_account]\naws_kid = A****aws_sak = o******\n[bucket_info]region_name = **bucket = *key = *5、文件选择框文件选择框调用一个函数即可，底层库帮我们做复杂的GUI操作。def filefound():    filepath= askopenfilename()    if (filepath != \"\"):        (filename_prefix, filename) = os.path.split(filepath)        text_filepath.delete(0.0, END)        text_filepath.insert(END, filepath)        text_filename.delete(0.0, END)        text_filename.insert(INSERT, filename)6、打包成EXE利用pyinstaller命令：pyinstaller -w main.py-w：启动时不显示命令行窗口-F：打包成一个独立的EXE文件。不推荐这样做，因为这样会在启动的时候慢慢释放那些依赖库，导致启动缓慢，启动一次要10秒不能忍受-D（默认）：打包成一个文件夹，含有依赖库，启动快。还有其他参数，例如设置图标等，可以查pyinstaller的API。打包下来有50M左右，还是很大，只是一个小程序。四、总结这个脚本的适用性不广，但是熟悉了很多python的库，而且也方便我平时使用。如果习惯命令行的，可以直接写个windows批处理程序；还可以扩展诸如选择文件夹上传、多文件上传、日志查看等，这里我不需要所以不继续做了。完整代码和可执行文件：AwsS3WindowsUploder                \n","categories":["转载"],"tags":[]},{"title":"用百度翻译快速阅读大量英文文献","url":"http://tanqingbo.cn/2019/10/06/用百度翻译快速阅读大量英文文献/","content":"\nhttp://www.bewindoweb.com/193.html前言对于一些引用的英文文献，我们需要快速地了解整篇文献讲了什么内容，来判断是否可以作为“国内外研究现状”来进行详细分析。通常文献都是CAJ或者PDF格式的，这样格式文献的缺点在于，复制粘贴后会产生断行，例如完整的一段“摘要”在复制粘贴后变成了一行一行的：We are interested in a general alpha matting approach\nfor the simultaneous extraction of multiple image layers;\neach layer may have disjoint segments for material matting\nnot limited to foreground mattes typical of natural image\nmatting. The estimated alphas also satisfy the summation\nconstraint. Our approach does not assume the local color-\nline model, does not need sophisticated sampling strategies,\nand generalizes well to any color or feature space in any\ndimensions. Our matting technique, aptly called KNN matting\n, capitalizes on the nonlocal principle by using K near-\nest neighbors (KNN) in matching nonlocal neighborhoods,\nand contributes a simple and fast algorithm giving compet-\nitive results with sparse user markups. KNN matting has\na closed-form solution that can leverage on the precondi-\ntioned conjugate gradient method to produce an efficient\nimplementation. Experimental evaluation on benchmark\ndatasets indicates that our matting results are comparable\nto or of higher quality than state of the art methods.原因在于PDF排版的时候添加了这样的换行符，这样带来的后果是百度翻译把每一行当作单独的一句话，造成歧译、错译、漏译，或者完全不是一句话：我们感兴趣的是一般的alpha抠图方法。\n用于同时提取多个图像层；\n每一层可能有材料拼接的不相交段。\n不局限于前景的自然图像典型\n席子估计的Alpas也满足求和。\n约束。我们的方法不假设局部颜色-\n线模型，不需要复杂的采样策略，\n并推广到任何颜色或特征空间。\n尺寸。我们的抠图技术，恰当地称为KNN抠图。\n利用k近邻利用非局部原理\nEST邻居（KNN）在非局部邻域匹配中的应用\n并给出了一个简单快速的算法\n具有稀疏用户标记的正确结果。KNN抠图\n一个可以在前提条件下使用的封闭形式的解决方案\n用共轭梯度法产生一个有效的方法\n实施。基准试验评价\n数据集表明，我们的抠图结果是可比的。\n比现有技术更高的质量。可以看到，…… K near-\nest neighbors ……被翻译成了：……k近邻……\nEST邻居…………上一行通过猜测得到了正确翻译，下一行误以为EST是一个专有名词，所以需要想办法解决这个问题。用WORD去掉换行符，愉快地翻译当然，一种方法是手动地去掉换行符，我试过，手很累，心更累。正确姿势是用WORD替换：【第一步】复制PDF中的文字【第二步】粘贴到word文档中，按CTRL+H呼出替换界面【第三步】&lt;替换&gt;选项中，查找内容设置为^p，替换内容为一个空格【第四步】点击全部替换【第五步】复制到百度翻译，正确地翻译，然后一行一行地看大概意思（百度翻译得并不好）如果有条件上外网，可以用Google翻译，毕竟是Google翻译是神经网络，效果好得多。（根据2018年7月11日网友乐小飞同学的信息，国内的translate.google.cn是不需要梯子的，国外的translate.google.com是需要梯子的）todo做一个复制后转换回车并且调用百度翻译接口的网页。                \n\n\n","categories":["转载"],"tags":[]},{"title":"百度云服务器双11优惠","url":"http://tanqingbo.cn/2019/10/06/百度云服务器双11优惠/","content":"\nhttp://www.bewindoweb.com/218.html前言百度云、腾讯云、阿里云服务器在双11又搞活动啦，仔细分析后总结一句话就是：【百度云】便宜又好用【腾讯云】土豪专场 —— 小伙子该充Q币啦~【阿里云】学霸专场 —— 最终的优惠价格是：112+(291/(10*30%)+187*10 + 25- (192*0.1))&nbsp;百度云服务器活动信息【活动地址】购买页面【活动对象】百度云实名认证用户且首次购买（BCC、BCH、CDN、BOS）产品的用户【活动时间】2018年10月24日~11月30日（每日9:30开启秒杀）；【活动内容】活动期间，同一百度云用户可以购买每款秒杀活动产品套餐各1次（同一手机号、同一认证证件、同一account ID 或经百度云排查多个账户为同一实际控制人的均被视为同一用户）【产品限额】每款产品每日限量提供(BCC:1核1G产品每日限量200台，1核2G产品每日限量100台、2核4G产品每日限量50台，4核8G产品每日限量30台；各款BCH每日限量200台；CDN流量包每日限量50个；BOS存储包每日限量50个)，先抢先得，以用户下单成功的时间顺序为准好价产品（1）两款云服务器入门型云服务器：1核/1G内存/1M带宽/40G硬盘，88一年。基础型云服务器：1核/2G内存/1M带宽/40G硬盘，128一年。对比我年中抢购的百度云服务器：2核/4G内存/2M带宽/40GB内存，6个月，花费139元，从性价比上看，这次的活动相当于性能折半+价格折半。而相比于我腾讯云服务器：1核1G1M带宽50GB硬盘，一模一样的配置还打折，都花费了326元。所以抢百度云这个服务器赚翻了好吗！为什么这么便宜呢？因为百度云是后面起来的，当年腾讯云刚出的时候，100块钱左右能买到三年的服务器。不要怕每天200台抢不到，我之前年中抢购百度云服务器的时候，很容易就抢到了。&nbsp;&nbsp;（2）域名.cn域名是28元（新老用户）；.com域名是新用户25元，老用户49元。之前在腾讯云续费.com域名同样是28元，所以中规中矩。                \n\n\n","categories":["转载"],"tags":[]},{"title":"百度区块链试水：百度莱茨狗","url":"http://tanqingbo.cn/2019/10/06/百度区块链试水：百度莱茨狗/","content":"\nhttp://www.bewindoweb.com/148.html一、免费领养步骤1、进入网址：https://pet-chain.baidu.com/chain/splash2、登录自己的百度帐号，点击免费领养3、免费领取后，将会获得1000微积分。二、最新活动安装百度全家桶领狗狗（已经结束）https://pet-chain.baidu.com/chain/personal签到领积分（已经结束）https://pet-chain.baidu.com/chain/personal繁殖功能（即将到来）https://pet-chain.baidu.com/chain/personal二、莱茨狗是什么明显这名字和套路就是在参考创世猫，谐音“Let's GO”，无聊的谐音。目前是百度试水区块链的一个项目，处于内测阶段，每个帐号可以免费领养一只。莱茨狗有8个外貌特征，每个特征有两种不同的属性，稀有和普通：&nbsp;外貌特征&nbsp;属性&nbsp;&nbsp;体型&nbsp; 稀有、普通 &nbsp;&nbsp;眼睛&nbsp;\n\n\n\n&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 28px;=”” orphans:=”” auto;=”” text-align:=”” left;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;稀有、普通 &nbsp;&nbsp;嘴巴&nbsp;\n&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 28px;=”” orphans:=”” auto;=”” text-align:=”” left;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;稀有、普通 &nbsp;&nbsp;身体色&nbsp;\n&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 28px;=”” orphans:=”” auto;=”” text-align:=”” left;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;稀有、普通 &nbsp;&nbsp;花纹&nbsp;\n&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 28px;=”” orphans:=”” auto;=”” text-align:=”” left;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;稀有、普通 &nbsp;&nbsp;眼睛色&nbsp;\n&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 28px;=”” orphans:=”” auto;=”” text-align:=”” left;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;稀有、普通 &nbsp;&nbsp;肚皮色&nbsp;\n&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 28px;=”” orphans:=”” auto;=”” text-align:=”” left;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;稀有、普通 &nbsp;&nbsp;花纹色&nbsp;\n&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 28px;=”” orphans:=”” auto;=”” text-align:=”” left;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;稀有、普通 &nbsp;通过这些属性决定狗狗的稀有等级：&nbsp;稀有等级&nbsp;普通&nbsp;稀有&nbsp;&nbsp;卓越&nbsp;史诗&nbsp;神话&nbsp;传奇例如我领养的狗狗：三、微积分与狗狗买卖微积分……这个名字真是欺骗没上过大学的……就是积分而已，微只是和微信的微一样的含义，并不是数学的微积分。免费领养后就会赠送1000微积分，现在可以用微积分去狗市购买狗狗，也可以卖出自己的狗狗赚取微积分，不过每次买卖都会有5积分的手续费。低价的狗狗根本抢不到，一出来就会被那些脚本抢掉……四、应用前景最贵的一只创世猫以246.95个以太币的价格成交，约为11.7万美金，77万人民币，所以……五、参考资料百度官方文章《我是谁？你要怎么玩儿？开发团队》                \n","categories":["转载"],"tags":[]},{"title":"素数的世界","url":"http://tanqingbo.cn/2019/10/06/素数的世界/","content":"\nhttp://www.bewindoweb.com/206.html前言素数现在在各个算法里应用非常广泛，而且各种简单的机考题总会涉及素数相关的问题。每次我都百度一下就糊弄过去了，下一次仍然离线自己写，只会写一个“不能被2到n-1除尽”或者优化到根号的垃圾算法，甚至在NOIP那场考试中用到了素数，我打的表……那么，好好地来研究一下吧。一、素数是什么来自百度汉语的解释，是数学课本上的解释，也是我们通常的理解：素数曾称质数。一个大于1的正整数，如果除了1和它本身以外，不能被其他正整数整除，就叫素数。来自维基百科的解释：素数是一个比1大的，并且不能由两个比它小的自然数乘积构成的自然数。例如，5不能被因式分解成两个比5小的自然数的乘积。二、素数有哪些特点1、任何大于1的自然数，要么本身是质数，要么可以分解为几个质数的乘积，并且这种分解是唯一的。2、质数有无限多个。3、如果n为正整数，那么在n^2到(n+1)^2之间至少有一个质数。比如n=5，那么在25到36之间必有质数；比如n=1，那么在1和4之间必有质数。4、如果n为大于等于2的正整数，那么在n到n!之间至少有一个质数。比如n=2，那么在2到2之间必有质数；比如n=4，那么在4到24之间必有质数。5、如果质数p为不超过n(n ≥ 4)的最大质数，那么p&gt;n/2。比如n=10，p则为7，7是一定大于10的一半5的；比如n=4，p则为3，3&gt;2。6、所有大于10的质数中，个位数只有1，3，7，9。哇，这是一个非常有用而且很少提及的特性。其证明在陈景润的《大偶数表为一个素数及一个不超过二个素数的乘积之和》。​​7、如果一个数n是素数，那么它的最小质因数一定小于等于它的开方√n。这实际上就是一个废话，一个数如果被分解为两个因子，那么两个因子肯定不会比它的开方大，分解的因子越多，因子的值越小。比如n=10，那么最小质因数2≤√10≈3.16。不过这个特性实际中很有用处。8、大于等于5的素数一定和6的倍数相邻。这个特性超级好用，比如5、7、11、13、17、19。【证明】设x≥1，那么大于等于5的自然数可以表示为：6x-1，6x，6x+1，6x+2，6x+3，6x+4，6x+5，6(x+1)，6(x+1)+1，6(x+1)+2……即不与6的倍数相邻的数��：6x+2，6x+3，6x+4 (x≥1)，观察这些数，可因式分解为2(3x+1)，3(2x+1)，3(2x+2)，它们必是合数。三、判断一个数为素数的各种算法1、定义法（试除法）。复杂度O(n)。根据定义去判断，找2到n-1之间有没有能够整除它的。注意先判断是否为&gt;1的正整数。2、根号法（改进的试除法）。复杂度O(√n)。判断n是否能被2到√n之间的数整除。原理是特性7，如果根号这边的数找不到约数，那么另一侧的数也肯定不会找到约数的。3、步进法（超级改进的试除法）。复杂度O(√n/3)。利用性质8，可以知道n一定是6x-1、6x+1 (x≥1，n≥5)的形式，且一定是奇数（这点可以从这个形式或者从性质6得到）。如果n能被6x、6x+2、6x+4整除，那么n必须为偶数，矛盾；如果n能被6x+3整除，那么n一定能被3整除，有6x是能被3整除的，故能得知与6x相邻的6x-1、6x+1不能被3整除，矛盾。所以，让x从1开始，每次检查6x-1、6x+1是否能被n整除，直到6x-1大于√n。当然更快的做法是让i从5开始，每次步进6，检查i和i+2是否能被n整除，直到i大于√n。这种做法比算法2少找了2/3的数字，理论上复杂度也减少了2/3。四、素数能干什么用五、素数相关的OJ@todo，以后补充。                \n\n\n","categories":["转载"],"tags":[]},{"title":"网易云音乐ncm文件格式解析","url":"http://tanqingbo.cn/2019/10/06/网易云音乐ncm文件格式解析/","content":"\nhttp://www.bewindoweb.com/228.html前言做了好久的心理建设鼓起勇气花了8块钱充了网易云音乐一个月会员，准备下载一些歌到ipod上听，下下来的却是：喵喵喵？充钱下了个加密文件，是心梗的感觉，参考知乎《如何评价网易云音乐的ncm格式？》。开始搜转码吧，可是总会好奇到底是怎么转的，所以一步一步debug，下载各种工具去查看，大概弄懂了一些。而且和实习的时候研究的网易云音乐前端JS加密一样，猪厂真的很喜欢用AES和RSA加密方式，而且很喜欢对数据加密之后再把它的密钥给加密……首先贴上代码和软件，如果不感兴趣可以直接去下载使用就好了：（1）anonymous5l / ncmdump&nbsp;（C++，MIT协议）基于openssl库编写，所以速度非常快，而且又好。（2）nondanee / ncmdump&nbsp;（python，MIT协议）依赖pycryptodome库、mutagen库，比较完善了。（3）lianglixin / ncmdump（python，MIT协议）fork的nondanee作者的源码（开始没有注意以为是独立提交的），修改了依赖库依赖pycrypto库，会有一些安装和使用问题：（4）windows GUI 直接运行的EXE文件：项目名和源码下载地址百度云下载地址&nbsp;说明yoki123 / ncmdump点此下载（提取码：92ib）批量的anonymous5l / ncmdump-gui点此下载（提取码：\n\n\n\nfffn）&nbsp;大佬原生程序&nbsp;未知点此下载（提取码：\nxmd9）只需要把ncm拖进main.exe就可以了写到这里，默默大喊一句，开源大法好！NCM文件格式和解密代码分析由于第一个搜索到的项目是lianglixin / ncmdump，所以我们以lianglinxin作者的python代码为基础来进行分析，参考nondanee作者的代码注释来理清思路。测试的ncm文件是郭顶 - 水星记.ncm（提取码：5ua0），字节查看器为UltraEdit。整个文件��一个函数dump(file_path)，下面进行分段分析。core_key = binascii.a2b_hex(\"687A4852416D736F356B496E62617857\")meta_key = binascii.a2b_hex(\"2331346C6A6B5F215C5D2630553C2728\")unpad = lambda s : s[0:-(s[-1] if type(s[-1]) == int else ord(s[-1]))]f = open(file_path,'rb')header = f.read(8)assert binascii.b2a_hex(header) == b'4354454e4644414d'定义了core_key和meta_key，binascii.a2b_hex的意思就是把这个字符串按照十六进制反解析为二进制字节序列（bytes类型），可以用ascii字符来表示，b2a则进行相反操作。如果对ascii码不熟悉可以查表，比如0x68=h，0x7A=z，所以：core_key = b’hzHRAmso5kInbaxW’meta_key = b”#14ljk_!\\]&amp;0U&lt;’(“然后定义了一个lamda表达式（内嵌函数）unpad。打开了ncm文件并读取了8个字节，确认这8个字节是否是字节序列b’4354454e4644414d’，用UltraEdit查看ncm文件，发现这些字节是’CTENFDAM’，0x43=C，说明这些就是ncm独有的文件标记，就是通俗所谓的magic。f.seek(2, 1)然后从当前位置跳过了2个字节，这两个字节是0x01 0x70，而且打开几个ncm文件都是一样的值，为什么它不能直接读10个字节的magic呢？可能代表不同的含义吧，暂时不管。key_length = f.read(4)key_length = struct.unpack('&lt;I', bytes(key_length))[0]key_data = f.read(key_length)key_data_array = bytearray(key_data)for i in range (0,len(key_data_array)): key_data_array[i] ^= 0x64key_data = bytes(key_data_array)cryptor = AES.new(core_key, AES.MODE_ECB)key_data = unpad(cryptor.decrypt(key_data))[17:]key_length = len(key_data)获取了4字节的key长度，并且按照小端（&lt;）的方式（高字节保存在内存的高地址中，而数据的低字节保存在内存的低地址中，也就是反序）转为整型（I）。这4个字节是：0x80 0x00 0x00 0x00，所以反序再转换就是0x00000080 = 128。读取128个字节的key数据，并转为字符数组，每个字节和0x64进行异或，还不清楚这个异或是为了什么目的。然后用之前的core_key创建了AES_ECB（Electronic Codebook Book，电码本模式）的解密器。ECB模式是将整个明文分成若干段相同的小段，然后对每一小段进行加密，如果不足则会进行补足。cryptor.decrypt(key_data)解析出来的是：b’neteasecloudmusic10073261712832E7fT49x7dof9OKCgg9cdvhEuezy3iZCL1nFvBFd1T4uSktAJKmwZXsijPbijliionVUXXg9plTbXEclAE9Lb\\r\\r\\r\\r\\r\\r\\r\\r\\r\\r\\r\\r\\r’&nbsp;&nbsp;而应用unpad的lamda表达式之后，末尾的\\r就去掉了，并且去掉了开头的标记符号，NCM的大名Netease Cloud Music：key_data = b’10073261712832E7fT49x7dof9OKCgg9cdvhEuezy3iZCL1nFvBFd1T4uSktAJKmwZXsijPbijliionVUXXg9plTbXEclAE9Lb’&nbsp;&nbsp;&nbsp;在最后更新了一下key的长度，更新为了128-13-17=98。key_data = bytearray(key_data)key_box = bytearray(range(256))c = 0last_byte = 0key_offset = 0for i in range(256):    swap = key_box[i]    c = (swap + last_byte + key_data[key_offset]) &amp; 0xff    key_offset += 1    if key_offset &gt;= key_length: key_offset = 0    key_box[i] = key_box[c]    key_box[c] = swap    last_byte = c上面这部分是标准RC4-KSA算法（Key-scheduling algorithm）去计算S-box。meta_length = f.read(4)meta_length = struct.unpack('&lt;I', bytes(meta_length))[0]meta_data = f.read(meta_length)meta_data_array = bytearray(meta_data)for i in range(0,len(meta_data_array)): meta_data_array[i] ^= 0x63meta_data = bytes(meta_data_array)meta_data = base64.b64decode(meta_data[22:])cryptor = AES.new(meta_key, AES.MODE_ECB)meta_data = unpad(cryptor.decrypt(meta_data)).decode('utf-8')[6:]meta_data = json.loads(meta_data)这部分和前面的key很相似，读取4字节长度，然后把数据进行异或，注意这里异或的是0x63，这个值怎么来的也不清楚。接着发现meta_data的值是这样的：b”163 key(Don’t modify):L64FU3W4YxX3ZFTmbZ+8/fOGFX4ZDFzRxiE6WTSCw8Wbw8yYSVQFmAmCHw9A96ZnO0UOuMsVWYFWvoqD0/YcH3r7VAGU8B3l+FBJm4JL6is23S2yXChnSbfLIksnEUcTC7JtrA1JAoR0GVnz+OT3hGTJRsjGIVQXg2yide/YKBACffE+oYBApqZ5Isq0n7h/MlBnjn6ihuSlIl5V2rXEjSISQr031eSBdEVJ/JcwttzLafIPBh2FQfaVd/U0inWY5jxCXZCw/jxcIdGmGH/0Oft3UlNPt2kDBrsivoVuD03tMWL6A5Flg/jCbofSOblHFC79oU3WF9doUjD24BXuu6K7wyoWkgyG7SJu8tk72hkGw3rLK1nbTHsSEIPjocC6Ba9mzF48SB087MFTSn+9PXPZIboMXFXGI3TpMj4rR6cD+6CEWS7EoZrUC1cipi/A0jT/rFtAirM4hmkbrvslJumMHDJz1q9o6t3XRWydyoIaC3ktXuesyV8sbuoQ+Y/EMWNZRN3KhGR/jnnQPBtseQ==”前面有22位的“163 key(Don’t modify):”，去掉之后用base64解码，并同样地通过AES_ECB和meta_key进行解密：b’music:{“musicId”:441491828,”musicName”:”\\xe6\\xb0\\xb4\\xe6\\x98\\x9f\\xe8\\xae\\xb0”,”artist”:[[“\\xe9\\x83\\xad\\xe9\\xa1\\xb6”,2843]],”albumId”:35005583,”album”:”\\xe9\\xa3\\x9e\\xe8\\xa1\\x8c\\xe5\\x99\\xa8\\xe7\\x9a\\x84\\xe6\\x89\\xa7\\xe8\\xa1\\x8c\\xe5\\x91\\xa8\\xe6\\x9c\\x9f”,”albumPicDocId”:2946691248081599,”albumPic”:”https://p4.music.126.net/wSMfGvFzOAYRU_yVIfquAA==/2946691248081599.jpg&quot;,&quot;bitrate&quot;:320000,&quot;mp3DocId&quot;:&quot;668809cf9ba99c3b7cc51ae17a66027f&quot;,&quot;duration&quot;:325266,&quot;mvId&quot;:5404031,&quot;alias&quot;:[],&quot;transNames&quot;:[],&quot;format&quot;:&quot;mp3&quot;}\\r\\r\\r\\r\\r\\r\\r\\r\\r\\r\\r\\r\\r&#39;于是这个作者去掉了前面的“music:”，然后转为了json字典：crc32 = f.read(4)crc32 = struct.unpack('&lt;I', bytes(crc32))[0]f.seek(5, 1)这是CRC32校验码，以及5个不知道为什么跳过的字符。image_size = f.read(4)image_size = struct.unpack('&lt;I', bytes(image_size))[0]image_data = f.read(image_size)这是封面的图像数据。file_name = meta_data['musicName'] + '.' + meta_data['format']    m = open(os.path.join(os.path.split(file_path)[0],file_name),'wb')    chunk = bytearray()    while True:        chunk = bytearray(f.read(0x8000))        chunk_length = len(chunk)        if not chunk:            break        for i in range(1,chunk_length+1):            j = i &amp; 0xff;            chunk[i-1] ^= key_box[(key_box[j] + key_box[(key_box[j] + j) &amp; 0xff]) &amp; 0xff]        m.write(chunk)    m.close()    f.close()这部分是用修改后的RC4-PRGA算法（Pseudo-random generation algorithm）进行还原并输出成文件，这是MP3的原本数据。原本故事到这里就结束了，然而发现输出的文件和另一个用GUI程序输出的文件不一样呢：竟然木有封面……用MP3tag比较一下，其他信息都全，就是图片没有啊：于是用eyed3库添加image_data进去，查了半天源码，终于找到合适的方法：audiofile = eyed3.load(u\"E:\\CloudMusic\\3.mp3\")audiofile.tag.images.set(0x06, image_data, 'image/jpeg')audiofile.tag.save()这样就有封面啦。nondanee/ncmdump作者也发现了这个问题，并且也是手动添加的image_data的tag数据：不过python还是很慢的，以后还是用C++那个程序比较好。附录1、安装pycrypto报错unable to find vcvarsall.batpycrypto对于python3.5要求VS2015的库，我只安装了VS2013，所以需要下载新版的库，大概3G，强制占用C盘嘤嘤嘤……2、eyed3路径不支持中文名这是bug……而且trick方法是修改magic.py文件（是库文件），我试过确实可以，但是这个方法并不好，在230行左右：if is_unicode:    return filename.encode('utf-8'）else:    return filename改为：if is_unicode:        import locale        lan, encoding = locale.getdefaultlocale()        return filename.encode(encoding)else:        return filename很明显可以参考nondanee/ncmdump作者采用mutagen库，放弃eyed3。3、ASCII 十进制、十六进制、字符对照表4、unpack()参数含义5、AES五种加密模式                \n","categories":["转载"],"tags":[]},{"title":"网易区块链试水：星球基地","url":"http://tanqingbo.cn/2019/10/06/网易区块链试水：星球基地/","content":"\nhttp://www.bewindoweb.com/149.html2月9日，网易上线了内测的星球APP，号称是一款区块链产品。然而股票在暴涨600%后因为被抓住收集用户隐私而暴跌……其实通过他的说明基本上就有收集用户信息去卖的感觉了，毕竟是网易金融推出来的，不赚钱谁干。不过我还是来试一试吧~一、下载APP一个谜之下载链接：https://163.lu/GTe6P3，实在是搞不懂为什么要用这么一个非官方.com的看起来极像钓鱼网站的山寨网址来内测，查了下域名：好吧，就用这个下载吧。二、注册进入后的界面是这样的：除了上面那个公告，其他的看起来很官方。点了我的基地后，可以注册，需要填写一个邀请码，随便百度一下就有了。另外，发送的短信验证也是网易发过来的，所以这个APP还是可信的，可是，可是，可是！！！！下一步，竟然要我输入身份证……喵喵喵？？？实在是不能理解，一个去中心化的区块链竟然要实名制？掌握这么多信息干什么？我在这一步就停止了，再观望吧。                \n\n\n","categories":["转载"],"tags":[]},{"title":"网站变化记录","url":"http://tanqingbo.cn/2019/10/06/网站变化记录/","content":"\nhttp://www.bewindoweb.com/139.html一、最近更新的1、将【一枚萌新】的友链移动到了导航栏，不然隐藏太深了看不见。2、【一枚萌新】的背景图替换成去免费高清大图网站找的星空图了，非常好看：利用到的【嗖嗖搜】的工具：3、增加了【一枚萌新】的赞助支持方式：4、为了节约带宽，【1010】不再提供本地下载，将下载功能转移到了百度云盘：5、做了一直不想动的【存推】页面，只对【音乐推荐】做了后台：用到的【嗖嗖搜】的工具：二、需要更新的1、首页虽然无图加载很快，但是很难吸引人看下去，还是要配图在简介里面。2、存推的后台3、友链的页面4、写文章的草稿箱5、写文章的HTML功能6、附件系统7、嗖嗖搜的侧边栏8、页面的静态化9、日志的可视化10、文章的分享功能根本做不完啊……                \n\n\n","categories":["转载"],"tags":[]},{"title":"网站过渡到2.0版本","url":"http://tanqingbo.cn/2019/10/06/网站过渡到2.0版本/","content":"\nhttp://www.bewindoweb.com/201.html前言博客网站过渡到2.0版本，暂时不会有太大的变化了，开始囤文章积累知识，这里记录一下发生的变化。改动增加自适应标题栏的自适应：文章标题的自适应：文章推荐的自适应：其他的不再列图：嗖嗖搜 / 友链增加两个文章的缩略图为了让文章吸引人，增加了一个260×190像素的缩略图，以及文章中1190×300像素的标题背景图。如果暂时没有图，会默认显示两幅星空图。增加评论系统表情以OwO插件为基础进行的改进增加文章的【持续更新】属性修改了【一枚萌新】的内容增加了后台的浏览器缓存功能这样失误按到鼠标侧键浏览器前后翻页造成写一半的文章丢失的情况就不会再出现啦~而且同时不会增加服务器负担，因为缓存是以Cookie的形式保存在浏览器端的。增加了草稿箱功能这样就不会再有（正在写）这种写一半的文章发布了。服务器迁移到广东买了一年1M小水管，以后还会换吧估计。增加.com域名.com和.cn都能访问博客了。移除所有的生活文章移除所有的工具文章出错解决手册之类的文章移到wiki了。优化博客的CSS显示比如调整一些字体颜色、按钮颜色、触发特效。增加图片放大功能图片可以放大查看了。下一个版本的工作将其他的功能自适应化1010、零度燃烧、存推优化加载速度比如压缩CSS、合并JS，CDN分发CSS、JS。搭建本地修改平台当访问量多了之后，就不太好直接在线修改网站造成访问错误、或者泄漏一些信息了，搭建一个本地平台修改完再推上去。优化手机端浏览文字的包裹都是div造成手机端浏览时候解析字体大小很难看，最好都修改为标准的标签。增加php缓存输送内存太小，每次都解析一次php速度太慢。优化文章中【打赏】功能直接弹出窗口而不是跳转网页，尽管也没人打赏……开始考虑浏览器的支持搜狗和Chrome是没问题的                \n\n\n","categories":["转载"],"tags":[]},{"title":"计网必问经典问题：输入网址之后发生了什么","url":"http://tanqingbo.cn/2019/10/06/计网必问经典问题：输入网址之后发生了什么/","content":"\nhttp://www.bewindoweb.com/129.html一、问题输入网址后到页面显示出来，中间发生了什么？二、解答1、查询DNS，获取域名对应的IP。（1）检查本地hosts文件是否有这个网址的映射，如果有，就调用这个IP地址映射，解析完成。&nbsp;（2）如果没有，则查找本地DNS解析器缓存是否有这个网址的映射，如果有，返回映射，解析完成。&nbsp;（3）如果没有，则查找填写或分配的首选DNS服务器，称为本地DNS服务器。服务器接收到查询时：如果要查询的域名包含在本地配置区域资源中，返回解析结果，查询结束，此解析具有权威性。&nbsp;如果要查询的域名不由本地DNS服务器区域解析，但服务器缓存了此网址的映射关系，返回解析结果，查询结束，此解析不具有权威性。（4）如果本地DNS服务器也失效： &nbsp;如果未采用转发模式（迭代），本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后，会判断这个域名（如.com）是谁来授权管理，并返回一个负责该顶级域名服务器的IP，本地DNS服务器收到顶级域名服务器IP信息后，继续向该顶级域名服务器IP发送请求，该服务器如果无法解析，则会找到负责这个域名的下一级DNS服务器（如baidu.com）的IP给本地DNS服务器，循环往复直至查询到映射，将解析结果返回本地DNS服务器，再由本地DNS服务器返回解析结果，查询完成。如果采用转发模式（递归），则此DNS服务器就会把请求转发至上一级DNS服务器，如果上一级DNS服务器不能解析，则继续向上请求。最终将解析结果依次返回本地DNS服务器，本地DNS服务器再返回给客户机，查询完成。2、客户机发送HTTP请求报文：（1）应用层：客户端发送HTTP请求报文（2）传输层：切分长数据，并确保可靠性。（3）网络层：进行路由（4）数据链路层：传输数据（5）物理层：物理传输bit3、服务器端经过物理层→数据链路层→网络层→传输层→应用层，解析请求报文，发送HTTP响应报文。4、客户端解析HTTP���应报文5、浏览器开始显示HTML6、浏览器重新发送请求获取图片、CSS、JS的数据。7、如果有AJAX，浏览器发送AJAX请求，及时更新页面。                \n\n\n","categories":["转载"],"tags":[]},{"title":"设置Visual Studio2013的TAB键为4个空格","url":"http://tanqingbo.cn/2019/10/06/设置Visual Studio2013的TAB键为4个空格/","content":"\nhttp://www.bewindoweb.com/213.html前言在实际的工程里也是这么要求的，原因在于虽然都是TAB键，但在不同的系统中可能会有不同的呈现，有的4个空格，有的8个空格。因此直接将TAB制表符替换为4个空格，就避免了所有的问题。一、设置Visual Studio2013的TAB键为4个空格工具 → 选项\n→ 文本编辑器\n→&nbsp;所有语言\n→&nbsp;制表符，更改：（1）制表符大小：4（2）勾选插入空格二、替换已有的文件中的制表符网上查了好多教程，都到这里为止了。但是一般来说，当发现这个问题的时候，都已经写了很多代码了，如何更改已有代码的TAB制表符呢？在编辑→高级里面，有一个将选定行中的制表符替换为空格，似乎是很方便。然而真实测试发现，这个功能只会替换一行开头的制表符，而在行中、行末的制表符是不会被替换的，也就是像这样（编辑→高级→查看空白，就能看到空白符了，点表示空格，箭头表示制表符）：所以，我们来解决这个问题。删除空白符选中所有代码，先使用编辑→高级→删除水平空白：自动美化格式使用编辑→高级→设置选定内容的格式：可以发现下部分的格式已经自动美化了，但是对于#define这种来说没有办法。手动调整#define部分只有手动调整了，在设置完TAB变4空格后，这里可以随意按TAB键来调整格式，并且VS会智能地根据上一行的格式自动给你匹配到底要几个空格，而不是限定死一个TAB=4个空格，所以很快也能调整好：这样的话在编写一些博客的时候，复制代码就不会有不对齐的情况啦：                \n\n\n","categories":["转载"],"tags":[]},{"title":"证书授权机构CA和数字证书","url":"http://tanqingbo.cn/2019/10/06/证书授权机构CA和数字证书/","content":"\nhttp://www.bewindoweb.com/274.html��、引言1.1 问题的引入客户端A、B、C都想要下载服务器S的某个文件，但文件传输过程中会经过许多不可靠的节点，应该如何保证A、B、C的请求不被篡改，且保证A、B、C收到的是没有被篡改的文件呢？1.2 第一次解决——加密服务器S做了一对密钥，私钥自己保留，并把公钥发送给客户端A、客户端B、客户端C保存。这样，客户端A可以用公钥对请求进行加密，密文为““&amp;A2*XVqzp346(??=””；服务器S收到后用私钥解密，明文为“客户端A想要下载资源文件”；中间节点没有私钥，无法解密这个请求，也就无法篡改了。此时，服务器S需要把资源文件传给客户端A，需要保证安全性，于是服务器S决定使用“数字签名（Digital Signature）”：将资源文件用Hash函数生成“摘要（Digest）”，然后用私钥对这个摘要加密，生成数字签名。中间节点一旦修改任意的数据，摘要就会发生变化，而新的摘要需要用私钥加密，中间节点无法生成新的摘要，也就无法篡改了。例如服务器S生成摘要“MD5-1234567”，加密后为数字签名“Xzpqp190&amp;)DVsz”；将资源文件和数字签名一起发给客户端，客户端收到后用资源文件生成摘要“MD5-1234567”，用公钥解密数字签名，得到服务器S发送的摘要“MD5-1234567”，如果两个摘要一样，则文件确实是服务器S发出的。1.3 加密存在的问题不可靠节点U通过某种方式去掉了服务器S的真公钥，并自己生成了一对假公钥，把假公钥发送给客户端A。当服务器S传递文件的时候，不可靠节点U解开资源文件，并加入木马病毒，重新用自己的私钥签名，发送给客户端A。客户端A用U的假公钥解开验证，一切正常，误以为是服务器S传递过来的真文件。1.4 第二次解决——证书授权中心服务器S去一个权威机构“证书授权中心（Certificate Authority）”，将服务器的信息、服务器S的公钥一起用CA私钥加密，生成“数字证书（Digital Certificate）”。服务器S把通过认证的证书发给客户端，客户端用CA公钥解密和验证后得到服务器S公钥，保证服务器S公钥不会被篡改。二、数字签名 Digital Signature数字签名（Digital Signature），就是只有信息的发送者才能产生的别人无法伪造的一段数字串。常见的数字签名手段就是Hash算法，如MD5、SHA256，原理也很简单，将数据通过哈希函数映射到一段字符串上，一旦改动了数据，字符串也会变化，不产生变化的概率极低，也就是所谓的“不可抵赖性”。MD5在我中学时期很火，各大下载站为了保证自己的下载内容没有被注入木马，通常都会在网站上挂着MD5校验值。现在木马已经很少了，而且SHA256更安全用得更多一些。三、证书授权中心 CA证书授权中心（Certificate Authority，CA），���为一个受信任的第三方，承担公钥合法性校验的责任。3.1 证书链&nbsp;Certificate ChainCA如果直接颁发数字证书，一旦CA的私钥泄漏，所有的证书都将无效。因此CA设立了三级证书，分别是根证书（Root Certificates）、中间证书（Intermediates Certificates）、终端用户证书（End-user Certificates）。根证书的私钥通常存放在断网的环境里，隔离保护；根证书通常除了提供官方下载渠道下载，还会和其他厂商合作，比如Windows操作系统，Chrome浏览器，让其内置这张证书。中间证书可能会有多级，比如二级中间证书、三级中间证书等。终端用户证书只能由这些二级CA、三级CA颁发，这样一旦某个中间CA的私钥泄漏，根CA重新颁发一张证书即可。中间CA的私钥一旦泄漏，也意味着各大浏览器都会标记这家CA颁发出的终端用户证书不安全，这家公司将会倒闭。终端用户证书则是我们平时使用到的服务器证书。剩下的问题就是这么多级证书如何做校验？根证书-中间证书-终端用户证书形成了证书链（Certificate Chain），当校验的时候，根据颁发机构ID一级一级往上提取证书，然后一级一级根据公钥校验证书合法性。我们可以看看比较出名的公司使用的什么证书（通过点击浏览器小绿锁就可以看到了）：百度用的Globalsign根CA。中国建设银行用的DigiCert。github用的DigiCert。google用的GlobalSign。3.2 自建CA问题如果只是自己使用，当然可以自己搭建CA给自己签发证书，但浏览器一般都会提示“不安全”，因为这个证书不是权威机构颁发的。四、证书类型证书一共有三种类型：域名型证书DV（Domain Validation SSL Certificate）、企业组织型证书OV（Organization Validation SSL Certificate）、增强型证书EV（Extended Validation SSL Certificate）。&nbsp;对比项&nbsp;&nbsp;DV&nbsp;&nbsp;OV&nbsp;&nbsp;EV&nbsp;&nbsp;审核内容&nbsp;域名&nbsp;域名、组织信息&nbsp;域名、组织信息、第三方数据库&nbsp;&nbsp;签发周期&nbsp;几分钟~几小时&nbsp;2~5天&nbsp;&nbsp;5~7天&nbsp;赔付保障&nbsp;少&nbsp;一般&nbsp;多&nbsp;浏览器表现&nbsp;绿锁&nbsp;绿锁&nbsp;&nbsp;绿锁+组织信息&nbsp;&nbsp;证书详情&nbsp;显示域名&nbsp;&nbsp;显示组织名&nbsp;&nbsp;显示组织名&nbsp;用途&nbsp;个人站点&nbsp;一般企业网站&nbsp;金融等要求较高的企业网站&nbsp;收费&nbsp;千元级&nbsp;万元级&nbsp;万元级例如，随便找的一个个人博客的DV��书：百度的OV证书：随便找的一个EV证书网站，会在浏览器显示公司信息：参考资料1、《【web安全】X.509数字证书的结构与解析》2、《证书链-Digital Certificates》3、《What is the SSL Certificate Chain?》4、《域名型(DV),企业型(OV),增强型(EV)三种SSL证书之间的区别》5、《DV型和OV型证书的区别》                \n\n\n","categories":["转载"],"tags":[]},{"title":"软件工程中的UML图","url":"http://tanqingbo.cn/2019/10/06/软件工程中的UML图/","content":"\nhttp://www.bewindoweb.com/227.html一、UML简介UML（Unified Modeling Language，统一建模语言）是一种构建软件系统和文档的通用可视化建模语言，体现了实践面向对象方法的最好经验。UML能表达系统的静态结构和动态信息，并能管理复杂的系统模型，便于软件团队之间的合作开发。UML不是编程语言，但支持UML语言的工具可以提供从UML到编程语言的代码生成，也可以实现从现有程序逆向构建UML模型。UML由视图（Views）、图（Diagram）、模型元素（Model Elements）、通用机制（General Mechanism）组成。1、视图每个视图显示系统的一个特定方面，分别从不同的视角做出描述。视图由图组成，一个视图对应一个或多个图。（1）用例视图——静态建模作用：描述系统的外部功能。对应：用例图（2）逻辑视图——静态建模作用：表达系统的基本逻辑结构，也称为静态视图。采用类图描述对象的静态结构，采用对象图来显示类的实例以帮助理解该类对应：类图、对象图（3）行为视图——动态建模作用：表达系统的动态行为 采用顺序图、协作图、活动图及状态图描述对应：状态图、活动图、顺序图和协作图（4）组件视图——物理架构作用：表达软件组织结构。采用组件图描述系统的软件组件或模块及它们的依赖关系对应：组件图（5）配置视图——物理架构作用：表达物理结构。采用配置图来描述系统中的节点和节点的连接关系，以及软件对象在节点的分布情况对应：配置图2、图例如用例图：3、模型元素可以在UML图中使用的概念统称为模型元素，也就是图中的元素，例如类、节点、组件：4、通用机制为图做进一步的补充说明，如注释、元素的语义说明。                \n\n\n","categories":["转载"],"tags":[]},{"title":"5分钟学会利用python库爬取双色球历史数据","url":"http://tanqingbo.cn/2019/10/06/5分钟学会利用python库爬取双色球历史数据/","content":"\nhttp://www.bewindoweb.com/208.html\n前言在之前《用Python爬取双色球开奖信息（升级版）》中已经介绍了简单的urllib+re正则的方式来提取每天的双色球数据，当然这是有用的，虽然数据量少，但是可以用来做一些比如“买了股票自动比对中奖情况然后推送”这一类程序或网页。但这种爬取方式仍然存在问题：容易被网站的反爬虫或者反作弊发现。也就是说，你爬取这些接口，那边的服务器系统会有日志的，并且有自动处理程序，甚至会有机器学习的程序。尽管这种数据没有什么敏感性，根本不会来封你的IP，不过也要养成良好的爬虫习惯，至少——在爬取的时候加个header，不要被一句简单的awk命令就给筛选出来安排得明明白白了（我在实习的时候经常一句awk就筛出那些刷金币刷花接口的小同学，尽管大佬们提供了svm机器学习模型来自动处理）。注意到有的网站提供了大量的历史开奖数据，比如500彩票网双色球历史数据、中彩网双色球历史数据，我们可以都爬下来，然后自行对比使用，一个可能的用途是用机器学习去预测走势（虽然国内的双色球……em……每天停售后两个小时才开奖……可以做很多事……而且如果完全公正了，从概率上来说机器学习学出的中奖概率是一样的……），用来玩玩吧。运行环境解释器：python3.5.2IDE：Pycharm 2016.3.2浏览器：Chrome爬取500双色球的历史数据500彩票网的网页比较规矩，没有什么花里胡哨的东西。1、进入网页，查看接口用Chrome浏览器进入500双色球历史数据网页，然后右键→检查，翻到Network→XHR的一栏。网页上随便选择期数，点击查看，就能看到网页异步获取数据的接口了：点进去看一看，非常简单的get请求：翻看一下Response，竟然直接���回的HTML而不是JSON……2、分析数据这就比较烦了，需要解析html了，首先分析一下彩票数据html的数据结构：&lt;tbody id=\"tdata\"&gt;\n  &lt;tr class=\"t_tr1\"&gt;\n      &lt;!--&lt;td&gt;2&lt;/td&gt;--&gt;\n      &lt;td&gt;18092&lt;/td&gt;\n      &lt;td class=\"t_cfont2\"&gt;06&lt;/td&gt;\n      &lt;td class=\"t_cfont2\"&gt;10&lt;/td&gt;\n      &lt;td class=\"t_cfont2\"&gt;16&lt;/td&gt;\n      &lt;td class=\"t_cfont2\"&gt;19&lt;/td&gt;\n      &lt;td class=\"t_cfont2\"&gt;24&lt;/td&gt;\n      &lt;td class=\"t_cfont2\"&gt;33&lt;/td&gt;\n      &lt;td class=\"t_cfont4\"&gt;16&lt;/td&gt;\n      &lt;td class=\"t_cfont4\"&gt;&nbsp;&lt;/td&gt;\n      &lt;td&gt;921,043,817&lt;/td&gt;\n      &lt;td&gt;1&lt;/td&gt;\n      &lt;td&gt;10,000,000&lt;/td&gt;\n      &lt;td&gt;95&lt;/td&gt;\n      &lt;td&gt;269,198&lt;/td&gt;\n      &lt;td&gt;318,819,890&lt;/td&gt;\n      &lt;td&gt;2018-08-09&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr class=\"t_tr1\"&gt;\n      &lt;!--&lt;td&gt;2&lt;/td&gt;--&gt;\n      &lt;td&gt;18091&lt;/td&gt;\n      &lt;td class=\"t_cfont2\"&gt;06&lt;/td&gt;\n      &lt;td class=\"t_cfont2\"&gt;11&lt;/td&gt;\n      &lt;td class=\"t_cfont2\"&gt;13&lt;/td&gt;\n      &lt;td class=\"t_cfont2\"&gt;17&lt;/td&gt;\n      &lt;td class=\"t_cfont2\"&gt;25&lt;/td&gt;\n      &lt;td class=\"t_cfont2\"&gt;32&lt;/td&gt;\n      &lt;td class=\"t_cfont4\"&gt;07&lt;/td&gt;\n      &lt;td class=\"t_cfont4\"&gt;&nbsp;&lt;/td&gt;\n      &lt;td&gt;854,322,188&lt;/td&gt;\n      &lt;td&gt;4&lt;/td&gt;\n      &lt;td&gt;8,999,907&lt;/td&gt;\n      &lt;td&gt;81&lt;/td&gt;\n      &lt;td&gt;246,907&lt;/td&gt;\n      &lt;td&gt;315,853,082&lt;/td&gt;\n      &lt;td&gt;2018-08-07&lt;/td&gt;\n  &lt;/tr&gt;\n&lt;/tbody&gt;非常完整标准的表格结构，这里要注意几个细节：（1）中间有一栏是&amp;nbsp，也就是空格，这一栏的体现是一个名为快乐星期天的属性。快乐星期天是指开出两个蓝球，第一个正常开，该中啥中啥；第二个蓝号中了，并且前面红号任意中5个，就能得到固定的3000元奖金。这里由于只是一个活动，不清楚以后是否会用，而且快乐星期天数据格式有：空格（&amp;nbsp，unicode显示为\\xa0）；0；1个数字；3个逗号分隔的数字，因此可以考虑把这个属性变为用“-”连接的字符串，如果以后有需要可以自行处理，如果不需要可以直接略过整个属性。（2）数字采用了银行的那种逗号分隔的格式，这是方便浏览的格式；同时我们想做的也是用逗号分隔，这会产生歧义，并且我们需要的是存储使用而不是观看，所以需要在采集的时候把逗号去掉。（3）多测几次数据，会发现500没有对数据进行分页，这对爬取来说非常有利。3、开始爬取那么，这次我们使用python强大的库吧，这里使用的是用于请求数据的requests以及用于解析HTML的HTMLParser。 &nbsp;requests的用法非常简单，注意编码格式不要中文乱码即可：def getHtml(url, method='get', headers=&#123;&#125;, params=&#123;&#125;):\n  if method == 'get':\n      html = requests.get(url, headers=headers,  params=params)\n      html.encoding = 'utf-8' #html.apparent_encoding\n  else:\n      html = requests.post(url, headers=headers, data=params)\n      html.encoding = 'utf-8'\n  return html.textheader和params都是这样的字典：headers:\n&#123;\n          \"Host\": \"datachart.500.com\",\n          \"Connection\": \"keep-alive\",\n          \"Accept\": \"*/*\",\n          \"X-Requested-With\": \"XMLHttpRequest\",\n          \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.\"\n                        \"0.3202.94 Safari/537.36\",\n          \"Referer\": \"http://datachart.500.com/ssq/history/history.shtml\",\n          \"Accept-Encoding\": \"gzip, deflate\",\n          \"Accept-Language\":\"zh-CN,zh;q=0.9\",\n          \"Cookie\":\"ck_RegFromUrl=http%3A//www.500.com/; sdc_session=1533916356798; _jzqy=1.1528606472.1533916357.1.\"\n                   \"jzqsr=baidu.-; _jzqckmp=1; seo_key=baidu%7C%7Chttps://www.baidu.com/link?url=MQcB3-er5rK249eCQNw\"\n                   \"G8A4N-hontstLi8HIy9E7H_q&amp;wd=&amp;eqid=fec80b7400019715000000035b6db4d7; bdshare_firstime=15339164028\"\n                   \"59; WT_FPC=id=undefined:lv=1533916553308:ss=1533916402791; _qzja=1.190448226.1533829920533.15338\"\n                   \"29920534.1533916402865.1533916409059.1533916553371.0.0.0.5.2; _qzjc=1; _jzqa=1.20620370185900751\"\n                   \"00.1533829921.1533829921.1533916357.2; _jzqc=1; Hm_lvt_4f816d475bb0b9ed640ae412d6b42cab=15338299\"\n                   \"21,1533916357; Hm_lpvt_4f816d475bb0b9ed640ae412d6b42cab=1533916554; __utma=63332592.612539621.15\"\n                   \"33916358.1533916358.1533916358.1; __utmc=63332592; __utmz=63332592.1533916358.1.1.utmcsr=baidu|u\"\n                   \"tmccn=(organic)|utmcmd=organic; CLICKSTRN_ID=123.98.36.94-1533829945.911636::415C872F9F26292A610C\"\n                   \"843E6BD7FEB2; motion_id=1533920615560_0.37147948464863223\",\n&#125;\nparams:\n&#123;\n         'start':'1',\n         'end':'18092'\n&#125;start和end就是那个get请求的URL携带的参数啦，就是彩票期数。Cookie可以直接加在header里面发送，也可以单独地作为参数：requests.get(url, headers=headers, cookies=cookies, params=params)前面提到，爬下来是一个网页，需要解析，我们构建一个HTMLParser的处理类：class Parser500ssq(HTMLParser):\n  flag_tbody = False # 定义一些变量\n  flag_tr = False\n  flag_td = False\n  linedata = []\n  result = []\n\n  def handle_starttag(self, tag, attrs):     # 匹配开始标签\n  if (str(tag).startswith(&quot;tbody&quot;)):     # 比如匹配tbody \n      for k,v in attrs:                  # 遍历tbody标签中的属性\n          if k == &#39;id&#39; and v == &#39;tdata&#39;: # 如果匹配到指定属性\n              self.flag_tbody = True     # 设置一个flag，表明匹配到了开始工作啦\n              return\n  elif (self.flag_tbody == True):        \n      if (str(tag).startswith(&quot;tr&quot;)):\n          self.flag_tr = True\n      if (str(tag).startswith(&quot;td&quot;)):\n          self.flag_td = True\n  def handle_endtag(self, tag):             # 匹配结束标签 \n  if (self.flag_tbody == True):         # 如果在tbody标签里面\n      if (str(tag).startswith(&quot;tr&quot;)):   # 如果是&amp;lt;/tr&amp;gt;，说明行结束了，提交一波数据\n          self.result.append(self.linedata)\n          self.linedata = []\n          self.flag_tr = False\n      elif (str(tag).startswith(&quot;td&quot;)): # 如果是&amp;lt;/td&amp;gt;，说明一个属性结束了，关掉flag \n          self.flag_td = False\n      elif (str(tag).startswith(&quot;tbody&quot;)):\n          self.flag_tbody = False\n  def handle_data(self, data):              # 处理&lt;xx&gt;data&lt;/xx&gt;里面的数据\n  if (self.flag_td == True):            # 如果是在处理&amp;lt;td&amp;gt;内的数据\n      if &#39;\\xa0&#39; in data:\n          self.linedata.append(&quot;-&quot;.join(data.replace(u&#39;\\xa0&#39;, u&#39;&#39;).split(&quot;,&quot;))) # 空格特殊处理\n      else:\n          self.linedata.append(&quot;&quot;.join(data.split(&quot;,&quot;))) # 数字去掉逗号\n‘’’  def handle_startendtag(self, tag, attrs): # 匹配开始和结束标签，用不到\n  print(&#39;&amp;lt;%s/&amp;gt;&#39; % tag)\n  def handle_comment(self, data):           # 匹配&lt;!–&gt;comment&lt;–!&gt;这样的注释，用不到\n  print(&#39;&amp;lt;!--&#39;, data, &#39;--&amp;gt;&#39;)\n  def handle_entityref(self, name):         # 匹配特殊字符，比如&amp;nbps，用不到\n  print(&#39;&amp;amp;%s;&#39; % name)\n  def handle_charref(self, name):           # 匹配特殊字符串，比如&amp;#，用不到\n  print(&#39;&amp;amp;#%s;&#39; % name)\n‘’’思路很简单，匹配到了开始符就设置flag，然后就开始收集数据，匹配到了结束符就存一波数据，这样数据就会被以列表的结构存在result里面。那么我们简单定义一个处理函数，就能够把它打入文件保存了。用feed给这个parser类喂数据，用with...as的结构来写文件：def parse500ssq(html,datapath):  print(\"start grabbing...\")  parser = Parser500ssq()  parser.feed(html)  print(parser.result)  with open(BASEPATH + datapath, 'w') as f:\n  for line in parser.result:\n      print(line)\n      f.write(&quot;,&quot;.join(line))\n      f.write(&quot;\\n&quot;)\n  print(“finished.”)得到的结果是这样的：['18092', '06', '10', '16', '19', '24', '33', '16', '', '921043817', '1', '10000000', '95', '269198', '318819890', '2018-08-09']['11025', '08', '25', '26', '31', '32', '33', '09', '0', '310916704', '4', '8040679', '80', '228050', '335345846', '2011-03-06']['06050', '02', '06', '12', '15', '25', '31', '07', '09-14-05', '138448657', '1', '5000000', '39', '148511', '94915860', '2006-05-02']['03001', '10', '11', '12', '13', '26', '28', '11', '10', '2097070', '0', '0', '1', '898744', '10307806', '2003-02-23']爬取中彩网双色球的历史数据1、进入网页，查看接口进入中彩网双色球往期查询页面，相同的方法，随便选择期数，点击查询，观察XHR。然而XHR没有任何变化……检查查询按钮的HTML，是一个调用js函数search()的input元素：网页上右键，查看网页源代码，ctrl+f搜索search()，竟然没搜到……仔细观察发现是加载了一个iframe：&lt;iframe src=\"http://kaijiang.zhcw.com/lishishuju/jsp/ssqInfoList.jsp?czId=1&quot; id=\"frmdetail\" name=\"frmdetail\" width=\"100%\" frameborder=\"0\" onload=\"this.height = 20+document.getElementById('frmdetail').contentDocument.body.offsetHeight; delNode('loading');\"&gt;&lt;/iframe&gt;进入这个网址，是一个纯净的数据表HTML，赛高~再次点击查询，观察XHR，仍然没有数据……调整到All，原来它是直接跳转的网页而不是异步刷新数据：那么，又要解析html了………………2、分析数据仍然是标准的html表格：&lt;tbody&gt;  &lt;tr&gt;\n  &amp;lt;td&amp;gt;1&amp;lt;/td&amp;gt;\n  &amp;lt;td&amp;gt;2018-08-09&amp;lt;/td&amp;gt;\n  &amp;lt;td&amp;gt;2018092&amp;lt;/td&amp;gt;\n  &amp;lt;td class=&quot;kaiHao&quot;&amp;gt;06 10 16 19 24 33 &amp;lt;span&amp;gt;16&amp;lt;/span&amp;gt;&amp;lt;/td&amp;gt;\n  &amp;lt;td&amp;gt;318,819,890&amp;lt;/td&amp;gt;\n  &amp;lt;td&amp;gt;1&amp;lt;/td&amp;gt;\n  &amp;lt;td&amp;gt;10,000,000&amp;lt;/td&amp;gt;\n  &amp;lt;td&amp;gt;95&amp;lt;/td&amp;gt;\n  &amp;lt;td&amp;gt;269,198&amp;lt;/td&amp;gt;\n  &amp;lt;td&amp;gt;882&amp;lt;/td&amp;gt;\n  &amp;lt;td&amp;gt;3,000&amp;lt;/td&amp;gt;\n  &amp;lt;td&amp;gt;921,043,817&amp;lt;/td&amp;gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n  &amp;lt;td&amp;gt;2&amp;lt;/td&amp;gt;\n  &amp;lt;td&amp;gt;2018-08-07&amp;lt;/td&amp;gt;\n  &amp;lt;td&amp;gt;2018091&amp;lt;/td&amp;gt;\n  &amp;lt;td class=&quot;kaiHao&quot;&amp;gt;06 11 13 17 25 32 &amp;lt;span&amp;gt;07&amp;lt;/span&amp;gt;&amp;lt;/td&amp;gt;\n  &amp;lt;td&amp;gt;315,853,082&amp;lt;/td&amp;gt;\n  &amp;lt;td&amp;gt;4&amp;lt;/td&amp;gt;\n  &amp;lt;td&amp;gt;8,999,907&amp;lt;/td&amp;gt;\n  &amp;lt;td&amp;gt;81&amp;lt;/td&amp;gt;\n  &amp;lt;td&amp;gt;246,907&amp;lt;/td&amp;gt;\n  &amp;lt;td&amp;gt;1107&amp;lt;/td&amp;gt;\n  &amp;lt;td&amp;gt;3,000&amp;lt;/td&amp;gt;\n  &amp;lt;td&amp;gt;854,322,188&amp;lt;/td&amp;gt;\n  &lt;/tr&gt;&lt;/tbody&gt;这里要注意：（1）设计了分页，所以表面上是三个参数：参数名&nbsp;参数值&nbsp;czId&nbsp;1&nbsp;beginIssue2018091endIssue2018092实际上还有一个参数：参数名&nbsp;参数值&nbsp;&nbsp;currentPageNum&nbsp;1（2）蓝球是在span标签里面的，而不是td（3）数字依然有逗号分隔3、开始爬取首先需要处理翻页的问题，观察到下一页翻到最后尾页是相同的，没有价值，我们可以比对上一页和尾页，如果上一页和尾页的差距在一页以上，就说明没爬完，需要进行翻页。举个例子，当前页数为1，上一页为0，尾页为2，一共有2页。那么当上一页为0的时候，所在页为1，需要翻页；上一页为1的时候，和尾页差距为1，这时候所在页为2，已经爬取完了。而翻页的方式仅仅需要修改提交请求的参数，很容易写出这样的代码：class ParserZhcwssq(HTMLParser):  flag_tbody = False  flag_tr = False  flag_td = False  flag_ballnum = False  flag_nextpage = False  linedata = []  result = []  url_nextpage = []\n  def reset_attr(self):\n  self.flag_tbody = False\n  self.flag_tr = False\n  self.flag_td = False\n  self.flag_ballnum = False\n  self.flag_nextpage = False\n  self.linedata = []\n  self.result = []\n  self.url_nextpage = []\n  def handle_starttag(self, tag, attrs):    # start tag\n  if (str(tag).startswith(&quot;tbody&quot;)):\n      self.flag_tbody = True\n  elif (self.flag_tbody == True):\n      if (str(tag).startswith(&quot;tr&quot;)):\n          self.flag_tr = True\n      elif (str(tag).startswith(&quot;td&quot;)):\n          self.flag_td = True\n          for k,v in attrs:\n              if k == &#39;class&#39; and v == &quot;kaiHao&quot;:\n                  self.flag_ballnum = True\n  elif self.flag_nextpage == True and str(tag).startswith(&quot;a&quot;):\n      self.url_nextpage.append(attrs[0][1].split(&quot;PageNum=&quot;)[1])\n  def handle_endtag(self, tag):             # end tag\n  if (self.flag_tbody == True):\n      if (str(tag).startswith(&quot;tr&quot;)):\n          self.result.append(self.linedata)\n          self.linedata = []\n          self.flag_tr = False\n      elif (str(tag).startswith(&quot;td&quot;)):\n          self.flag_td = False\n          self.flag_ballnum = False\n      elif (str(tag).startswith(&quot;tbody&quot;)):\n          self.flag_tbody = False\n  def handle_data(self, data):              # &lt;xx&gt;data&lt;/xx&gt;\n  if (self.flag_td == True):\n      if self.flag_ballnum == True:\n          self.linedata.extend(data.rstrip().split(&quot; &quot;))\n      else:\n          self.linedata.append(&quot;&quot;.join(data.split(&quot;,&quot;)))\n  def handle_comment(self, data):  # &lt;!–&gt;comment&lt;–!&gt;\n  if(data.strip() == &#39;分页条&#39;):\n      self.flag_nextpage = True\n\n\ndef parseZhcwssq(html,datapath,htmlurl,method,headers,params):    print(“start grabbing…”)    parser = ParserZhcwssq()    wmode = ‘w’    while(1):        parser.feed(html)        print(parser.result)        with open(BASEPATH + datapath, wmode) as f:            for line in parser.result:                f.write(“,”.join(line))                f.write(“\\n”)        if int(parser.url_nextpage[1]) != int(parser.url_nextpage[3]) - 1:            print(“grabbing nextpage…”)            wmode = ‘a’            params[‘currentPageNum’] = parser.url_nextpage[2].strip()            html = getHtml(htmlurl, method, headers,params)            parser.reset_attr()        else:            print(“finished.”)            break爬取结果：总结1、这次爬取的结果已经上传到github上的lotterydata上面了，可以下载来直接使用。2、完整的爬取代码上传到了github上的lotteryhistorygrabber，可以下载来学习和实践。3、数据格式：lot_500_ssq.txt：期号，红球1，红球2，红球3，红球4，红球5，红球6，蓝球，快乐星期天，奖金奖池（元），一等奖注数，一等奖奖金（元），二等奖注数，二等奖奖金（元），总投注额（元），开奖日期lot_zhcw_ssq.txt：序号，开奖日期，期号，红球1，红球2，红球3，红球4，红球5，红球6，蓝球，销售额，一等奖注数，一等奖奖金（元），二等奖注数，二等奖奖金（元），三等奖注数，三等奖奖金（元），奖池（元）4、这次的爬取总的来说还是十分简单，没有涉及到任何异步加载延迟、复杂的iframe结构、登录cookie/session、js双重加密、服务器反爬虫封IP等等问题，但是可以当做一次基本练习，爬下来的数据也是很有价值的。更加复杂爬虫的推荐使用scrapy+splash等专业爬虫平台来构建项目。talk is cheep，立刻动手，开始编写属于你的爬虫吧~                \n","categories":["转载"],"tags":[]},{"title":"API集成管理平台YAPI的搭建和使用","url":"http://tanqingbo.cn/2019/10/06/API集成管理平台YAPI的搭建和使用/","content":"\nhttp://www.bewindoweb.com/222.html前言随着API数量越来越多，wiki已经再也体现不出它的优势了。冗长的文档资料让人难以维护，稍微一点小改动就需要对很多地方进行修改。以前见到过的解决方案是，使用Confluence来进行接口管理和测试。但最近一位前端大佬推荐了YAPI这套API集成管理平台，上手后发现还挺不错的，不过也有一些不方便的地方，看完后可以根据需求选择。一、YAPI是什么YAPI简介YAPI是去哪儿网团队YMFE开发的一个开源项目，用于API开发，帮助开发者轻松创建、发布、维护 API，协议Apache 2.0，非常良心，先给出相关链接：（1）去哪儿网：和携程类似的订票网站（2）YAPI官网：YAPI的简介（3）YAPIgithub仓库：YAPI的源码（4）YAPI使用文档：YAPI安装手册、使用方法等（5）官方交流QQ群：644642474（2018年11月18日有效）官方的宣传：YAPI——高效、易用、功能强大的API管理平台，旨在为开发、产品、测试人员提供更优雅的接口管理服务。YAPI功能特性（1）强大的Mock数据功能：前端Mock数据的福音，和Mock.js类似的语法（2）多人可视化接口管理：多人协作（有修改历史记录）、可视化接口管理（树形结构、搜索等等）（3）权限管理：成熟的权限管理配置（4）兼容性：支持swagger、postman等经典接口管理工具的数据格式导入，支持markdown、json等数据格式输出（5）wiki：可以自动生成接口wiki（6）自动化测试：其实这个功能不太好用，可以基于本地或者服务器来进行自动化测试，但目前发现只能是冒烟测试。（7）插件机制：留有插件hook，可以二次开发（8）支持docker部署、内网部署二、YAPI普通方式部署和安装无论以哪种方式部署，都需要两个基本的环境：nodejs7.6+、mongodb2.6+。通常来说apt-get下来的版本都不满足要求，所以我们直接安装二进制包（如果有时间可以自己make源码）。1、基础环境搭建首先得有下载和解压工具：apt-get install wget\napt-get install xznodejs官网找到二进制包的下载地址：用wget下载到服务器，这里选择最新稳定版10.13.0，执行解压、安装：# 下载\nwget https://nodejs.org/dist/v10.13.0/node-v10.13.0-linux-x64.tar.xz\n# 解压\nxz -d node-v10.13.0-linux-x64.tar.xz\ntar -xvf node-v10.13.0-linux-x64.tar\n# 移动到合适地方\nmv node-v10.13.0-linux-x64 /usr/local/node-v10.13.0-linux-x64\n# 添加环境变量\nvi ~/.bashrc\nexport PATH=$PATH:/usr/local/node-v10.13.0-linux-x64/bin\nsource ~/.bashrc测试一下：node -v\nv10.13.0同样的方法安装mongodb：去mongodb官网，选择合适的版本，windows会是msi，Linux是tgz（用刚才加环境变量的方式安装），我们选择debian 8，是deb文件：用wget下载，用dpkg安装：wget https://repo.mongodb.org/apt/debian/dists/jessie/mongodb-org/4.0/main/binary-amd64/mongodb-org-server_4.0.4_amd64.deb\nsudo dpkg -i mongodb-org-server_4.0.4_amd64.deb但下载过于缓慢（5kb/s）,所以可以使用阿里镜像，选择适合自己系统的，这里是debian 8 amd64：wget http://mirrors.aliyun.com/mongodb/apt/debian/dists/jessie/mongodb-org/4.0/main/binary-amd64/mongodb-org-server_4.0.4_amd64.deb\ndpkg -i mongodb-org-server_4.0.4_amd64.deb\nwget http://mirrors.aliyun.com/mongodb/apt/debian/dists/jessie/mongodb-org/4.0/main/binary-amd64/mongodb-org-shell_4.0.4_amd64.deb\ndpkg -i mongodb-org-shell_4.0.4_amd64.deb\nwget http://mirrors.aliyun.com/mongodb/apt/debian/dists/jessie/mongodb-org/4.0/main/binary-amd64/mongodb-org-tools_4.0.4_amd64.deb\ndpkg -i mongodb-org-tools_4.0.4_amd64.deb顺手装了一个shell（如果不装shell，只能启动服务，不能使用mongo命令作为客户端去连接mongodb服务器），再装一个tools（包含mongodump等备份工具）只花了1.2秒。启动mongodb服务器：service mongod start用mongodb shell测试一下：mongo\n\n\n\nMongoDB shell version v4.0.4connecting to: mongodb://127.0.0.1:27017Implicit session: session &#123; “id” : UUID(“2558d8c3-4873-4c39-8a77-3a5a41d067b5”) &#125;MongoDB server version: 4.0.4Welcome to the MongoDB shell.mongodb默认是谁都可以进的（不像mysql有root用户），所以我们需要给mongodb加一个账户（密码请设置复杂点的）：mongo\n创建数据库，名字必须是yapiuse yapi\n增加一个yapi管理员账户db.createUser(&#123;    user: “yapidba”,    pwd: “123456”,    roles:[       &#123;           role:”readWrite”,           db:”yapi”       &#125;    ]&#125;)\n进入admin数据库use admin\n增加一个mongodb超级管理员账户db.createUser(&#123;    user: “mongoadmin”,    pwd: “123456”,    roles:[       &#123;           role:”userAdminAnyDatabase”,           db:”admin”       &#125;    ]&#125;)CTRL+C退出mongo，开启登录验证：vi /etc/mongod.conf\n#security:auth = true重启mongod服务：#停止当前服务service mongod stop\n创建/data/dbmkdir /datamkdir /data/db\n手工后台启动mongodmongod –auth –fork –logpath=/var/log/mongodb/mongod.log\n完整的语句是mongod –auth –dbpath=[你的db数据文件存放路径] –fork –logpath=[你的日志存放路径]注意，手工启动的话只能杀进程来退出（你也可以自己编写service脚本）：ps -aux|grep mongokill xxxxxx2、安装YAPI根据YAPI文档进行安装，官方推荐方式是图形界面方式：npm install -g yapi-cli --registry https://registry.npm.taobao.orgyapi server这里我们选择命令行方式去安装：mkdir yapicd yapigit clone https://github.com/YMFE/yapi.git vendors //或者下载 zip 包解压到 vendors 目录cp vendors/config_example.json ./config.json //复制完成后请修改相关配置然后修改这个config文件：&#123;  \"port\": \"9233\",  \"adminAccount\": \"&#x79;&#97;&#x70;&#x69;&#97;&#100;&#109;&#x69;&#x6e;&#x40;&#x62;&#x65;&#x77;&#105;&#110;&#x64;&#x6f;&#x77;&#101;&#98;&#46;&#x63;&#111;&#x6d;\",  \"closeRegister\":true,  \"db\": &#123;    \"servername\": \"127.0.0.1\",    \"DATABASE\": \"yapi\",    \"port\": 27017,    \"user\": \"yapidba\",    \"pass\": \"123456\",    \"authSource\": \"\"  &#125;,  \"mail\": &#123;    \"enable\": false,    \"host\": \"smtp.163.com\",    \"port\": 465,    \"from\": \"@163.com\",    \"auth\": &#123;      \"user\": \"@163.com\",      \"pass\": \"*****\"    &#125;  &#125;,  \"ldapLogin\":&#123;    \"enable\":true,    \"server\":\"ldap://localhost:389\",    \"baseDn\":\"cn=Manager,dc=bewindoweb,dc=com\",    \"bindPassword\":\"123456\",    \"searchDn\":\"dc=bewindoweb,dc=com\",    \"searchStandard\":\"mail\",    \"emailPostfix\":\"@bewindoweb.com\",    \"emailKey\":\"mail\",    \"usernameKey\":\"description\"  &#125;&#125;（1）adminAccount：和mongodb无关，是yapi登录使用的账号名，后缀必须是@，密码默认ymfe.org（2）closeRegister：禁止注册（3）user/pass：刚才mongodb设置的yapi的用户名和密码（4）mail：暂时关闭，设置为false（5）ldapLogin：增加ldap登录方式，利用前面《openLDAP原理、安装和使用》搭建的服务器来测试，我们把账号稍微设置得更完整：baseDn、bindPassword：用于搜索用户账号的系统账号；searchDn：搜索根目录；searchStandard：搜索条件；emailPostfix：邮箱后缀；emailKey：邮箱在LDAP账号里面的属性名称；usernameKey：用户显示名在LDAP账号里面的属性名称接着执行npm依赖安装，会生成node_module目录：cd vendorsnpm install --production --registry https://registry.npm.taobao.org这一步很容易报错，这是一个bug，如果报错，请尝试：npm install --production --registry https://registry.npm.taobao.org --unsafe-perm=true --allow-rootnpm依赖安装安装完成后执行yapi服务器安装：npm run install-server //安装程序会初始化数据库索引和管理员账号，管理员账号名可在 config.json 配置这一步如果报错说Error: 初始化管理员账号 \"yapiadmin\" 失败，则根据打印信息去找是否是mongodb设置问题、config.json设置问题，成功的显示是这样的：完成之后启动yapi：node server/app.js然后输入公网IP:9233就可以访问啦，只要你的服务器开放了这个端口。三、YAPI的使用方法1、基本界面介绍【首页】【登录/注册】如果配置了不让注册，1.3.x版本是点击注册后弹框提示不让注册，1.4.x版本是直接不让点击。&nbsp;登录有两种方式，我们前面配置的ldap和普通的mongodb数据库登录。我们尝试一下LDAP：登录成功，然后查看一下个人信息：是我们LDAP里面配置的字段，很棒。再尝试普通登录：查看一下个人信息：由于是管理员，增加了好多信息，并且普通登录支持修改用户名和密码（因为mongodb是yapi在管理）。【基本操作界面】&nbsp;【用户管理界面】（只有管理员可以看见）【系统信息界面】（只有管理员看得见）2、基本使用【权限】角色分为超级管理员&gt;组长&gt;开发者&gt;访客。目录有分组&gt;项目。每个人都可以创建分组，但只有超级管理员可以删除分组。每个人都可以创建项目，但只有超级管理员和分组组长可以删除项目。每个人都可以创建私有分组和项目，拥有完全的管理权限。更多的权限控制可自行探索：【接口编写和测试】接口支持很多功能：HTTP方法、HTTPS、标签、状态等等。请求接口支持上传文件、RAW、BODY（JSON）、query（get参数）、配置Header等，非常灵活。尝试运行（需要安装插件+chrome）：测试一下，断言返回HTTP CODE 200：【自动wiki】导出成wiki试试：四、YAPI优缺点优点颜值高；安装简便；集成WIKI、接口编写、接口自动化测试于一体，更新非常及时；支持权限管理；支持swagger等其他API管理工具的格式数据导入；支持LDAP、SSO、CAS等登录方式；支持集群。缺点（1）接口返回值只能设置一个模板有时候我们希望正确返回设置一个模板、错误返回设置一个模板，这是swagger可以做到的，而YAPI无法做到（2）接口模板必须复制粘贴不像swagger解耦合一样，一处配置处处运行，例如配置“分页模板”，然后每个分页只需要引用一下就好了，修改起来只需要修改一次。而YAPI目前只有复制粘贴。已经有人提issue了：（3）测试功能太鸡肋只能做冒烟测试，给数据、返回期望数据。无法编写测试逻辑（如果返回XX则跳到XX），无法返回多个值（如果200则XX，如果404则XX），也就无法编写单元测试了。五、其他nginx代理配置因为YAPI是基于websocket的，所以如果用了nginx反向代理转发，可以这样配置：server&#123;    listen 8081;    server_name yapi.bewindoweb.com;    location / &#123;        proxy_buffers 8 32k;        proxy_buffer_size 64k;\n    # websocket\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection &quot;upgrade&quot;;\n\n    client_max_body_size 500m;\n    proxy_pass http://localhost:9233;\n&#125;\n}然后执行：nginx -t -c [配置文件]nginx -s reloadYAPI7天备份脚本#!/bin/sh\nargsbasepath=$(cd dirname $0; pwd)datapath=$basepatholddatapath=$basepath’/backupdata7days’mdpath=”/usr/bin/mongodump”databasename=”yapi”user=”yapidba”password=”123456”hostname=”localhost”port=”27017”\nmove old data to olddatapathif [ “ls -A $&#123;datapath&#125;“ != “” ];then    mv ${datapath}’/‘${databasename} ${olddatapath} 2&gt;/dev/nullfi\ngen new backupnow=$(date +”%Y-%m-%d”)file=${datapath}’/‘${databasename}-$now${mdpath} -h${hostname}:${port} -u${user} -p${password} -d${databasename} -o${file}#echo ${mdpath} -h${hostname}:${port} -u${user} -p${password} -d${databasename} -o${file}\nclean up over 7 dayssevendays=$(date -d -7day +”%Y-%m-%d”)if [ -d ${olddatapath}’/‘$databasename’-‘$sevendays ];then    rm -rf ${olddatapath}’/‘$databasename’-‘$sevendaysfi然后使用crontab每天周期运行这个脚本：crontab -e0 2 * * * /home/yapi/backup/backup.sh                \n","categories":["转载"],"tags":[]},{"title":"EMQ源码分析（三）：Erlang所有常用语法","url":"http://tanqingbo.cn/2019/10/06/EMQ源码分析（三）：Erlang所有常用语法/","content":"\nhttp://www.bewindoweb.com/257.html前言只需要了解EMQ用到过的语法，以EMQ2.3.11为基础，有任何理解错误请指正。一、认识HelloWorld% hello world program\n\n-module(helloworld).-export([start/0]). \nstart() -&gt;   io:fwrite(“Hello, world!\\n”).%：注释-module(模块名)：定义模块，模块名必须和文件名一致（去掉后缀.erl），否则编译会出错。-export([函数名/参数个数]) ：定义外部可以调用的函数，斜杠后面是参数个数start()：一个函数，名字任意取io:fwrite：调用io模块的fwrite函数，输出消息到控制台.：语句结束符二、数据类型1、标准数据类型Erlang有7种标准数据类型，数字、原子、布尔、位字符串、元组、映射、列表1）数字 number只有两种，整数integer、浮点数float，例如：40、40.00。【进制整数】可以用数字+“#”表示2-36的进制整数，例如emqttd_session.erl第824行中16#FFFF。【整数范围】Erlang的则整数精度只受到内存限制，支持大数运算。测试：start() -&gt;  A = 1234567890*99999999999999999999,  io:fwrite(\"Bn\",[A]).\n  % 输出123456788999999999998765432110【浮点数的科学计数法】和其他语言类似，用e/E后面带+/-和指数：start() -&gt;  A = 3.468e+3,  io:fwrite(\"fn\",[A]).\n  % 输出3468.000000【ASCII】可以用$char来表达ASCII的数字，如$A值为65，$\\n值为10。2）原子 atom原子是文字，以小写字母开头，后跟字母、数字、下划线、@。也可以使用单引号，就能跟任何的字符，否则会被识别为变量编译报错：测试：start() -&gt;  A = ok,  B = error,  C = 'Error',  D = a@12_3Axf,  E = 'error ans',  io:fwrite(\"wn\",[A]).【运算】原子的意义就是文字，只支持比较和赋值运算【创建】出现即创建，除非系统重启否则不会被清除，单系统最大可用原子数1048576个。EMQ通常使用原子来定义一些字符串常量，例如emqttd.hrl第43行自定义类型时，取值只能为两个原子：-type(pubsub() :: publish | subscribe).emqttd_protocol.hrl第101行定义MQTT报文名称时，使用了原子：-define(TYPE_NAMES, [    'CONNECT',    ……emqttd_trie.erl第156行删除订阅树边时，返回的原子：delete_path([]) -&gt;    ok;emqttd_trie.erl第82行，从根节点遍历订阅树时，根节点用的原子：match(Topic) when is_binary(Topic) -&gt;    TrieNodes = match_node(root, emqttd_topic:words(Topic)),3）布尔 boolean伪数据类型，其实是两个保留原子，true、false。4）位字符串 binary二进制序列，操作二进制非常方便的数据结构。通常的二进制串是无符号8bit字节序列，但位串可以是任意bit位数。标准语法：双小于、双大于括起来，用逗号隔开。&lt;&lt;E1, ..., EN&gt;&gt;中间的Ei可以是：Value                                     % 必须是整数、浮点数或另一个位串Value:Size                             % 指定数据的二进制位数Value/TypeSpecifierList         % 指定数据的类型Value:Size/TypeSpecifierList % 指定数据的位数和类型示例1：&lt;&lt;1,2,3&gt;&gt;、&lt;&lt;12.1,44.45&gt;&gt;、&lt;&lt;$a,$b,$c&gt;&gt;、&lt;&lt;”abc”&gt;&gt;默认的Value，类型可以是整数（8bit）、浮点数（64bit）、位串，自动识别。整数如果越界（超过8bit表达的十进制数，如256、257），则和其他语言处理类似，进行高位截断（256→0）。&lt;&lt;”abc”&gt;&gt;是&lt;&lt;$a,$b,$c&gt;&gt;的语法糖，在EMQ超级常用，例如emqttd_packet.erl第34行：protocol_name(?MQTT_PROTO_V5) -&gt; &lt;&lt;\"MQTT\"&gt;&gt;.示例2：&lt;&lt;1:3, 2:4&gt;&gt;、&lt;&lt;42:12&gt;&gt;&lt;&lt;1:3, 2:4&gt;&gt;表达式中的位串位数是3+4=7位，二进制被拼接成0b0010010，所以最终得到的值是&lt;&lt;18:7&gt;&gt;。如果你用&lt;&lt;18:7&gt;&gt; == &lt;&lt;18&gt;&gt;做比较，会得到false，因为默认8位位数不同。无论&lt;&lt;1:3, 2:4&gt;&gt;还是&lt;&lt;18:7&gt;&gt;哪种表达，它们都是同一段二进制数据，只是截断的位置不一样。&nbsp;&nbsp;&lt;&lt;1,17,42:12&gt;&gt;表达式中的位串位数是8+8+12=28位，二进制高位用0填充，整个串为0b 0000 0010 1010，所以最终得到的值是&lt;&lt;2,10:4&gt;&gt;测试：start() -&gt;  A = &lt;&lt;1:3, 2:4&gt;&gt;,  B = &lt;&lt;18:7&gt;&gt;,  C = A == B,  io:fwrite(\"w ~w ~w ~n\",[A,B,C]).示例3：&lt;&lt;1024/utf8&gt;&gt;、&lt;&lt;1024:32/unsigned-little-integer&gt;&gt;、&lt;&lt;”abc”/utf8&gt;&gt; 、&lt;&lt;$a/utf8,$b/utf8,$c/utf8&gt;&gt;.TypeSpecifierList可以控制编码细节，控制参数用横杠隔开：数据类型（Type）：integer、float、bytes/binary、bits/bitstring、utf8、utf16、utf32，其中bytes是binary缩写，bits是bitstring的缩写，作用相同。符号（Signedness）：signed、unsigned，默认无符号。大小端（Endianness）：big、little、native，默认大端。单位（Unit）：unit:1256，默认整数、浮点数都是1bit为单位，位串8bit为单位。同样的，&lt;&lt;\"abc\"/utf8&gt;&gt; 是&lt;&lt;$a/utf8,$b/utf8,$c/utf8&gt;&gt;.的语法糖。我们可以用来定义常见数据类型，如：-define( UINT, 32/unsigned-little-integer).-define( INT, 32/signed-little-integer).-define( USHORT, 16/unsigned-little-integer).-define( SHORT, 16/signed-little-integer).-define( UBYTE, 8/unsigned-little-integer).-define( BYTE, 8/signed-little-integer).-define( CHAR, 1/binary-unit:8).在EMQ中通常被用来定义字符串常量，好处在于，在进行模式匹配的时候速度很快；还被用于解析一些复杂的数据，好处在于，可以控制任意位数，例如emqttd_topic.erl第112行，当在某一层中既含有字符（在validate2已经判断过了），又含有通配符时，判定是非法的格式：validate3(&lt;&lt;C/utf8, Rest/binary&gt;&gt;) when C == $#; C == $+; C == 0 -&gt;    false;5）元组 tuple将多个实体组合成一个实体，通常用于参数匹配，可以嵌套任意数据类型，包括元组。元组定义好就不变了。标准语法：A=&#123;Term1, ..., TermN&#125;.参数匹配的含义是：&#123;A, B, C, &#125;  =  &#123;apple, banana, orange, hhhhhh&#125;这样就可以将apple赋值给A、banana赋值给B，orange赋值给C，hhhhhh被丢弃。在EMQ中也被用来做参数匹配，例如：% emqttd_protocol.erl第493行，调用函数，发送参数：    case emqttd_topic:validate(&#123;name, Topic&#125;) of        true  -&gt; ok;        false -&gt; &#123;error, badtopic&#125;    end;% emqttd_topic.erl第91行，接受参数：validate(&#123;filter, Topic&#125;) when is_binary(Topic) -&gt;    validate2(words(Topic));6）映射 mapmap是k-v映射表。标准语法：% 定义mapmymap = #&#123;Key1=&gt;Value1,...,KeyN=&gt;ValueN&#125;% 获取值myvalue = maps:get(Key1,mymap)% 设置数据maps:put(Value1, Value2, ..., ValueN)% 更新数据maps:update(Value1, Value2, ..., ValueN)例如emqttd_session.erl第397行，更新订阅：maps:put(Topic, NewQos, SubMap);7）列表 list一堆任意类型的数据组合成的表，可以任意增删数据。标准语法：[Term1,...,TermN]使用频率极高，包括像helloworld里面也在使用：-export([start/0]).一个重要特性是：[Term1,…,TermN] 等价于 [Term1|[…|[TermN|[]]]]：[H|T]=[apple, banana]% H = apple% T = [banana]前一个将会匹配独立的元素apple，类型是元素类型，H可以任意取名，这里代表的是Head的含义；后一个将会匹配整个列表剩余部分（哪怕只剩一个元素），类型是列表，T可以任意取名，这里代表的是Tail的含义。通常元组被用于递归，例如emqttd_topic.erl第87行到第108行：validate(&#123;, &lt;&lt;&gt;&gt;&#125;) -&gt;    false;validate(&#123;, Topic&#125;) when is_binary(Topic) and (size(Topic) &gt; ?MAX_TOPIC_LEN) -&gt;    false;validate(&#123;filter, Topic&#125;) when is_binary(Topic) -&gt;    validate2(words(Topic));validate(&#123;name, Topic&#125;) when is_binary(Topic) -&gt;    Words = words(Topic),    validate2(Words) and (not wildcard(Words)).\nvalidate2([]) -&gt;    true;validate2([‘#’]) -&gt; % end with ‘#’    true;validate2([‘#’|Words]) when length(Words) &gt; 0 -&gt;    false;validate2([‘’|Words]) -&gt;    validate2(Words);validate2([‘+’|Words]) -&gt;    validate2(Words);validate2([W|Words]) -&gt;    case validate3(W) of true -&gt; validate2(Words); false -&gt; false end.第一个validate用元组，因为只是参数传递；第二个validate2用列表，因为在用递归去不断地匹配Topic按斜杠分割后的每一层的Token。2、高级数据类型1）记录 record记录相当于C语言中的结构体，它是一个伪数据类型，会在编译阶段被转换成元组。定义记录，通常在.hrl头文件中定义：-record(Name, &#123;Field1 [= Value1],               ...               FieldN [= ValueN]&#125;).创建记录：R = #Name&#123;Field1=Expr1,...,FieldK=ExprK&#125;更新记录（可以只更新部分值）：R2 = R#Name&#123;Field1=Expr1,...,FieldM=ExprM&#125;读取值（提取法）：#Name.Field��取值（匹配法）：terminate(_Reason, #state&#123;stats_timer = TRef&#125;) -&gt;    timer:cancel(TRef),    ekka:unmonitor(membership).在EMQ中被大量使用，定义一些数据结构：% 定义：emqttd.hrl 第148行-record(mqtt_delivery,        &#123; sender  :: pid(),          %% Pid of the sender/publisher          message :: mqtt_message(), %% Message          flows   :: list()        &#125;).\n% 创建：emqttd_pubsub.erl第89行delivery(Msg) -&gt; #mqtt_delivery&#123;sender = self(), message = Msg, flows = []&#125;.\n% 更新：eqmttd_pubsub.erl第78行dispatch(To, Delivery#mqtt_delivery&#123;flows = [&#123;route, Node, To&#125; | Flows]&#125;);\n% 读值：eqmttd_pubsub.erl第72行route([], #mqtt_delivery&#123;message = #mqtt_message&#123;topic = Topic&#125;&#125;) -&gt;    dropped(Topic), ignore;2）进程ID Pid就是进程的ID，在EMQ对应的使用：-record(mqtt_session,        &#123; client_id  :: binary(),          sess_pid   :: pid(),          clean_sess :: boolean()        &#125;).如果向某个进程发送消息，可以直接用pid+感叹号的形式，如emqttd_pubsub.erl第112行：SubPid ! &#123;dispatch, Topic, Msg&#125;;消息会放到对应的Mailbox里面。self() 可以获取自己的进程ID。3）引用 Reference引用通过make_ref/0函数来创建，引用在运行时是全局唯一的，常常在创建定时任务时返回一个引用，通过这个引用来取消定时任务。如EMQ的gen_server2.erl第821行：Tag = make_ref()4）函数&nbsp;function函数也算是数据类型，函数可以被当作参数去赋值，如EMQ中emqttd_topic.erl第184行：parse(&lt;&lt;\"$local/\", Topic1/binary&gt;&gt;, Options) -&gt;    if_not_contain(local, Options, fun() -&gt;                       parse(Topic1, [local | Options])                   end);对应接收的函数是emqttd_topic.erl第203行：if_not_contain(local, Options, Fun) -&gt;    ?IF(lists:member(local, Options), error(invalid_topic), Fun());三、运算符1、算数运算符符号&nbsp;含义&nbsp;&nbsp;+&nbsp;加&nbsp;-&nbsp;减&nbsp;*&nbsp;乘&nbsp;/&nbsp;除&nbsp;rem&nbsp;取余（模）&nbsp;div&nbsp;整除2、关系运算符符号&nbsp;含义&nbsp;备注&nbsp;&nbsp;==&nbsp;相等&nbsp;&nbsp;/=&nbsp;不等&nbsp;注意不等号&nbsp;&lt;&nbsp;小于&nbsp;&nbsp;=&lt;&nbsp;小于等于&nbsp;注意先等后小&nbsp;&gt;&nbsp;大于&nbsp;&nbsp;&gt;=&nbsp;大于等于&nbsp;&nbsp;=:=&nbsp;恒等于&nbsp;重点&nbsp;=/=&nbsp;恒不等于&nbsp;重点1）恒等于和恒不等于等于（==）只需要判断数值： 1 == 1.0 → true恒等于（=:=）除了数值还需要判断数据类型：1 =:= 1.0 → false不等于（/=）只需要判断数值：1 /= 1.0 → false恒不等于（=/=）除了数值还需要判断数据类型：1 =/= 1.0 → true测试：start() -&gt;  A = 1 == 1.0,  B = 1 =:= 1.0,  C = 1 /= 1.0,  D = 1 =/= 1.0,  io:fwrite(\"1==1.0: wn1=:=1.0: wn1/=1.0: wn1=/=1.0: wn\",[A,B,C,D]).\n% 1==1.0: true% 1=:=1.0: false% 1/=1.0: false% 1=/=1.0: true在EMQ中也被使用到，如：% emqttd_pubsub.erl第77行Node =:= node()% emqttd_trie.erl第83行Name =/= undefined2）不同数据类型做比较如果数据类型不同，按照如下的方式比较大小：number &lt; atom &lt; reference &lt; fun &lt; port &lt; pid &lt; tuple &lt; list &lt; bitstring例如，[]&gt;0 → true，因为list&gt;number3、位运算符符号&nbsp;含义&nbsp;&nbsp;band&nbsp;按位与&nbsp;bor&nbsp;按位或&nbsp;bxor&nbsp;按位异或&nbsp;bnot&nbsp;按位非4、逻辑布尔运算符符号&nbsp;含义&nbsp;&nbsp;or&nbsp;或&nbsp;and&nbsp;与&nbsp;not&nbsp;非&nbsp;xor&nbsp;异或&nbsp;andalso&nbsp;短路与&nbsp;orelse&nbsp;短路或默认逻辑运算符是不短路的，短路与和短路或在EMQ中使用得很频繁，如：% eqmttd_serializer.erl第43行：when ?CONNECT =&lt; Type andalso Type =&lt; ?DISCONNECT -&gt;% emqttd_protocol.erl第427行：when NullId =:= undefined orelse NullId =:= &lt;&lt;&gt;&gt; -&gt;四、变量变量必须以大写字母开头，例如Myvar。五、函数和递归函数和递归是Erlang最核心的部分，Erlang没有for循环，没有while循环，全靠函数和递归了。标准语法：Name [when GuardSeq1] -&gt;        Body1;...;Name [when GuardSeqK] -&gt;        BodyK.1）简单函数示例start() -&gt;  A = 1&lt;2.2）多子句函数示例子句用逗号分割，依次执行：start() -&gt;  A = 1&lt;2,  io:fwrite(\"wn\",[A]).3）带保护序列函数示例用when关键字在执行函数前判断执行条件，如果为false则这个函数不会被匹配到：add(X) when X&gt;3 -&gt;   io:fwrite(\"wn\",[X]). \nstart() -&gt;   add(4).4）匿名函数用fun关键字定义匿名函数，括号里可以带参数如fun(var1,var2)，可以被赋值给变量，例如emqttd_client.erl第259行定义了一个匿名函数，并赋值给StatFun，后面就可以把这个StatFun作为参数传递，或者后面加个括号直接作为函数调用：StatFun = fun() -&gt;                case Conn:getstat([recv_oct]) of                    &#123;ok, [&#123;recv_oct, RecvOct&#125;]&#125; -&gt; &#123;ok, RecvOct&#125;;                    &#123;error, Error&#125;              -&gt; &#123;error, Error&#125;                end             end\n% 作为参数传递：emqttd_keepalive:start(StatFun, Interval, &#123;keepalive, check&#125;)% 直接调用：StatFun()5）多函数声明执行过程示例例如EMQ中emqttd_topic.erl第97行：validate2([]) -&gt;    true;validate2(['#']) -&gt; % end with '#'    true;validate2(['#'|Words]) when length(Words) &gt; 0 -&gt;    false;validate2([''|Words]) -&gt;    validate2(Words);validate2(['+'|Words]) -&gt;    validate2(Words);validate2([W|Words]) -&gt;    case validate3(W) of true -&gt; validate2(Words); false -&gt; false end.在调用validate2之前，已经将主题”/a/b/c/+/d/#”拆分成了list[a,b,c,+,d,#]，然后调用validate2。调用的时候会去比较到底哪个函数的参数类型是匹配的（类似于方法重载的概念），就调��哪个函数。如果有多个都可能被匹配的函数，则只匹配写在最前面的第一个函数，例如：validate2(['#']) -&gt; % end with '#'    true;validate2(['#']) -&gt; % end with '#'    false.则匹配[‘#’]只会返回true。所以上述逻辑为：如果为空，返回true，合法主题，如果为”#”且是最后一个，返回true，合法主题，如果为”#”且后面还有层级，返回false，非法主题，如果为空层，继续匹配，如果为”+”，继续匹配，如果为任意字符串，则调用validate3看里面是否有通配符（如果有则是非法主题，通配符必须独占层级）。6）递归如果调用了自己，就会形成递归，例如上述validate2就调用了自己。六、宏定义宏定义(Macros)通常在include/xxx.hrl文件里，类似C语言的头文件，语法也类似。1）宏定义常量示例% -define(Const, Replacement).-define(PROTOCOL_VERSION, \"MQTT/5.0\").2）宏定义函数示例（支持函数重载）% -define(Func(Var1,...,VarN), Replacement).-define(ALLOW_DENY(A), ((A =:= allow) orelse (A =:= deny))).3）使用宏定义示例% ?Const% ?Func(Arg1,...,ArgN)compile(&#123;A, all&#125;) when ?ALLOW_DENY(A) -&gt;    &#123;A, all&#125;;4）系统预定义宏% 当前模块名?MODULE% 当前模块名，字符串格式?MODULE_STRING.% 当前模块的文件名?FILE.% 当前行号?LINE.% 当前机器名称?MACHINE.% 当前函数名称?FUNCTION_NAME% 当前函数有多少个参数?FUNCTION_ARITY% OTP版本号?OTP_RELEASE5）控制宏和C语言概念一致，多用于debug：% 如果定义了宏，则-ifdef(Macro).% 如果未定义宏，则-ifndef(Macro).% 否则-else.% 结束控制宏流程-endif.% 如果条件为真，则-if(Condition).% 否则如果条件2为真，则-elif(Condition).% 让宏表现得像没有被定义过一样-undef(Macro).七、行为 Behaviour和behaviour的英语含义一致，就是“表现、行为、外观”，类似java的抽象类，规定了共性的函数操作，所有的实现模块自己实现所有特性的函数操作。Erlang/OTP有四个经典behaviour：gen_server、gen_fsm、gen_event、supervisor，在前文《EMQ源码分析（二）：Erlang相关概念》已经描述过了：gen_server：用于实现C/S结构中的服务端gen_fsm：用于实现有限状态机gen_event：用于实现事件处理功能supervisor：用于实现监督树中的监督进程例如EMQ中emqttd_router.erl就采用了行为：-behaviour(gen_server).八、其他EMQ中常见Erlang语法1）定义模块名-module(emqttd_router).2）定义作者-author(\"Feng Lee &lt;&#x66;&#x65;&#x6e;&#x67;&#64;&#101;&#109;&#113;&#x74;&#116;&#46;&#105;&#111;&gt;\").3）引入模块或头文件这样在调用函数就不需要加前缀了。-include(\"emqttd.hrl\").4）定义函数声明在每个函数的前面用-spec编写声明，如emqttd_router.erl第93行：%% @doc Match Routes.-spec(match(Topic:: binary()) -&gt; [mqtt_route()]).match(Topic) when is_binary(Topic) -&gt;    %% Optimize: ets???    Matched = mnesia:ets(fun emqttd_trie:match/1, [Topic]),    %% Optimize: route table will be replicated to all nodes.    lists:append([ets:lookup(mqtt_route, To) || To &lt;- [Topic | Matched]]).5）自定义数据类型-type(mqtt_qos() :: ?QOS0 | ?QOS1 | ?QOS2).推荐参考资料1���《Erlang官网英文手册》2、《易百Erlang教程》                \n","categories":["转载"],"tags":[]},{"title":"Jquery使用ajax过程中禁止点a标签","url":"http://tanqingbo.cn/2019/10/06/Jquery使用ajax过程中禁止点a标签/","content":"\nhttp://www.bewindoweb.com/138.html\n一、教程内容在Jquery使用ajax更新数据的过程中，禁用a标签二、具体操作ajax判断的是整个类的标签被点击时：$('.xxxxxx').click(function()&#123;\n....\n&#125;首先���录我尝试过的东西：1、增加一个效果一模一样的类，取名为xxxxx-live，在load function中移除xxxxx增加xxxxx-live，这样保持CSS效果的同时，不会触发xxxxx的点击事件。结果：失败，仍然触发了，没有再去研究。2、利用$('#xx').removeAttr（'onclick'）移除click事件，就不会触发了。结果：不好，如果超时之类的出现了错误，移除后无法再添加（没研究如何添加）。3、添加disabled属性，$('#xx').attr('disabled',\"true\");结果：失败，只对button有效，对a标签无效。4、禁用鼠标一段时间，不准点击网页。结果：不好，体验很难受。5、采用一个遮挡蒙板，当点击后就遮挡住按钮，防止过程中点击。结果：没尝试，要写很多东西，比较懒不想写……最终采用的方法：添加全局标志变量flag，当加载时flag设置为false禁止进入ajax，success或者error时设置为true，其实就是一把锁。var flag = true;\n      $(function()&#123;\n          $('.xxxxxxxxx').click(function()&#123;\n              if(flag) &#123;\n                  flag = false;\n                  event.stopPropagation();//防止冒泡\n                  ……\n                  $.ajax(&#123;\n                      ……\n                  &#125;)\n\n              function LoadFunction() &#123;\n                  ……\n              &#125;\n\n              function erryFunction(XMLHttpRequest, textStatus, errorThrown) &#123;\n                  ……\n                  &lt;font color=&quot;#f9963b&quot;&gt;flag=true;&lt;/font&gt;\n              &#125;\n\n              function succFunction(tt) &#123;\n                 ……\n                  &lt;font color=&quot;#f9963b&quot;&gt;flag=true;&lt;/font&gt;\n              &#125;\n          &#125;\n      &#125;);\n  &#125;)&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;codebitstream vera=&quot;&quot; sans=&quot;&quot; mono&#39;,=&quot;&quot; &#39;courier=&quot;&quot; new&#39;,=&quot;&quot; courier,=&quot;&quot; monospace=&quot;&quot; !important;=&quot;&quot; font-weight:=&quot;&quot; normal;=&quot;&quot; font-style:=&quot;&quot; font-size:=&quot;&quot; 15px;=&quot;&quot; direction:=&quot;&quot; ltr=&quot;&quot; -webkit-box-shadow:=&quot;&quot; none=&quot;&quot; box-shadow:=&quot;&quot; display:=&quot;&quot; inline=&quot;&quot; color:=&quot;&quot; black=&quot;&quot; font-variant:=&quot;&quot; letter-spacing:=&quot;&quot; orphans:=&quot;&quot; auto;=&quot;&quot; text-indent:=&quot;&quot; 0px;=&quot;&quot; text-transform:=&quot;&quot; none;=&quot;&quot; white-space:=&quot;&quot; pre;=&quot;&quot; widows:=&quot;&quot; word-spacing:=&quot;&quot; -webkit-text-stroke-width:=&quot;&quot; background:=&quot;&quot; !important;&quot;=&quot;&quot;&gt;&lt;codebitstream vera=&quot;&quot; sans=&quot;&quot; mono&#39;,=&quot;&quot; &#39;courier=&quot;&quot; new&#39;,=&quot;&quot; courier,=&quot;&quot; monospace=&quot;&quot; !important;=&quot;&quot; font-weight:=&quot;&quot; normal;=&quot;&quot; font-style:=&quot;&quot; font-size:=&quot;&quot; 15px;=&quot;&quot; direction:=&quot;&quot; ltr=&quot;&quot; -webkit-box-shadow:=&quot;&quot; none=&quot;&quot; box-shadow:=&quot;&quot; display:=&quot;&quot; inline=&quot;&quot; color:=&quot;&quot; blue=&quot;&quot; font-variant:=&quot;&quot; letter-spacing:=&quot;&quot; orphans:=&quot;&quot; auto;=&quot;&quot; text-indent:=&quot;&quot; 0px;=&quot;&quot; text-transform:=&quot;&quot; none;=&quot;&quot; white-space:=&quot;&quot; pre;=&quot;&quot; widows:=&quot;&quot; word-spacing:=&quot;&quot; -webkit-text-stroke-width:=&quot;&quot; background:=&quot;&quot; !important;&quot;=&quot;&quot;&gt;&lt;codebitstream vera=&quot;&quot; sans=&quot;&quot; mono&#39;,=&quot;&quot; &#39;courier=&quot;&quot; new&#39;,=&quot;&quot; courier,=&quot;&quot; monospace=&quot;&quot; !important;=&quot;&quot; font-weight:=&quot;&quot; normal;=&quot;&quot; font-style:=&quot;&quot; font-size:=&quot;&quot; 15px;=&quot;&quot; direction:=&quot;&quot; ltr=&quot;&quot; -webkit-box-shadow:=&quot;&quot; none=&quot;&quot; box-shadow:=&quot;&quot; display:=&quot;&quot; inline=&quot;&quot; color:=&quot;&quot; black=&quot;&quot; font-variant:=&quot;&quot; letter-spacing:=&quot;&quot; orphans:=&quot;&quot; auto;=&quot;&quot; text-indent:=&quot;&quot; 0px;=&quot;&quot; text-transform:=&quot;&quot; none;=&quot;&quot; white-space:=&quot;&quot; pre;=&quot;&quot; widows:=&quot;&quot; word-spacing:=&quot;&quot; -webkit-text-stroke-width:=&quot;&quot; background:=&quot;&quot; !important;&quot;=&quot;&quot;&gt;&lt;codebitstream vera=&quot;&quot; sans=&quot;&quot; mono&#39;,=&quot;&quot; &#39;courier=&quot;&quot; new&#39;,=&quot;&quot; courier,=&quot;&quot; monospace=&quot;&quot; !important;=&quot;&quot; font-weight:=&quot;&quot; normal;=&quot;&quot; font-style:=&quot;&quot; font-size:=&quot;&quot; 15px;=&quot;&quot; direction:=&quot;&quot; ltr=&quot;&quot; -webkit-box-shadow:=&quot;&quot; none=&quot;&quot; box-shadow:=&quot;&quot; display:=&quot;&quot; inline=&quot;&quot; color:=&quot;&quot; blue=&quot;&quot; font-variant:=&quot;&quot; letter-spacing:=&quot;&quot; orphans:=&quot;&quot; auto;=&quot;&quot; text-indent:=&quot;&quot; 0px;=&quot;&quot; text-transform:=&quot;&quot; none;=&quot;&quot; white-space:=&quot;&quot; pre;=&quot;&quot; widows:=&quot;&quot; word-spacing:=&quot;&quot; -webkit-text-stroke-width:=&quot;&quot; background:=&quot;&quot; !important;&quot;=&quot;&quot;&gt;&lt;codebitstream vera=&quot;&quot; sans=&quot;&quot; mono&#39;,=&quot;&quot; &#39;courier=&quot;&quot; new&#39;,=&quot;&quot; courier,=&quot;&quot; monospace=&quot;&quot; !important;=&quot;&quot; font-weight:=&quot;&quot; normal;=&quot;&quot; font-style:=&quot;&quot; font-size:=&quot;&quot; 15px;=&quot;&quot; direction:=&quot;&quot; ltr=&quot;&quot; -webkit-box-shadow:=&quot;&quot; none=&quot;&quot; box-shadow:=&quot;&quot; display:=&quot;&quot; inline=&quot;&quot; color:=&quot;&quot; black=&quot;&quot; font-variant:=&quot;&quot; letter-spacing:=&quot;&quot; orphans:=&quot;&quot; auto;=&quot;&quot; text-indent:=&quot;&quot; 0px;=&quot;&quot; text-transform:=&quot;&quot; none;=&quot;&quot; white-space:=&quot;&quot; pre;=&quot;&quot; widows:=&quot;&quot; word-spacing:=&quot;&quot; -webkit-text-stroke-width:=&quot;&quot; background:=&quot;&quot; !important;&quot;=&quot;&quot;&gt;&lt;codebitstream vera=&quot;&quot; sans=&quot;&quot; mono&#39;,=&quot;&quot; &#39;courier=&quot;&quot; new&#39;,=&quot;&quot; courier,=&quot;&quot; monospace=&quot;&quot; !important;=&quot;&quot; font-weight:=&quot;&quot; normal;=&quot;&quot; font-style:=&quot;&quot; font-size:=&quot;&quot; 15px;=&quot;&quot; direction:=&quot;&quot; ltr=&quot;&quot; -webkit-box-shadow:=&quot;&quot; none=&quot;&quot; box-shadow:=&quot;&quot; display:=&quot;&quot; inline=&quot;&quot; color:=&quot;&quot; blue=&quot;&quot; font-variant:=&quot;&quot; letter-spacing:=&quot;&quot; orphans:=&quot;&quot; auto;=&quot;&quot; text-indent:=&quot;&quot; 0px;=&quot;&quot; text-transform:=&quot;&quot; none;=&quot;&quot; white-space:=&quot;&quot; pre;=&quot;&quot; widows:=&quot;&quot; word-spacing:=&quot;&quot; -webkit-text-stroke-width:=&quot;&quot; background:=&quot;&quot; !important;&quot;=&quot;&quot;&gt;&lt;codebitstream vera=&quot;&quot; sans=&quot;&quot; mono&#39;,=&quot;&quot; &#39;courier=&quot;&quot; new&#39;,=&quot;&quot; courier,=&quot;&quot; monospace=&quot;&quot; !important;=&quot;&quot; font-weight:=&quot;&quot; normal;=&quot;&quot; font-style:=&quot;&quot; font-size:=&quot;&quot; 15px;=&quot;&quot; direction:=&quot;&quot; ltr=&quot;&quot; -webkit-box-shadow:=&quot;&quot; none=&quot;&quot; box-shadow:=&quot;&quot; display:=&quot;&quot; inline=&quot;&quot; color:=&quot;&quot; black=&quot;&quot; font-variant:=&quot;&quot; letter-spacing:=&quot;&quot; orphans:=&quot;&quot; auto;=&quot;&quot; text-indent:=&quot;&quot; 0px;=&quot;&quot; text-transform:=&quot;&quot; none;=&quot;&quot; white-space:=&quot;&quot; pre;=&quot;&quot; widows:=&quot;&quot; word-spacing:=&quot;&quot; -webkit-text-stroke-width:=&quot;&quot; background:=&quot;&quot; !important;&quot;=&quot;&quot;&gt;&amp;nbsp;&lt;br&gt;&lt;/codebitstream&gt;&lt;/codebitstream&gt;&lt;/codebitstream&gt;&lt;/codebitstream&gt;&lt;/codebitstream&gt;&lt;/codebitstream&gt;&lt;/codebitstream&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;                &lt;/div&gt;\n\n\n","categories":["转载"],"tags":[]},{"title":"MQTT通信流程和Broker的任务","url":"http://tanqingbo.cn/2019/10/06/MQTT通信流程和Broker的任务/","content":"\nhttp://www.bewindoweb.com/243.html��、MQTT报文通信流程要做消息代理，首先需要解析协议。我们从抽象层面去考虑协议，不去更深挖到底哪个比特组合代表什么含义，这样有利于理清逻辑，而且早就有很多组件可以直接使用，只需要True和False代表什么含义，不需要知道001和010代表什么含义。以MQTT 3.1.1为例来描述细节。1、术语定义1）客户端 Client使用MQTT的程序或设备，它可以做的操作是：发布消息给其他客户端订阅主题取消订阅主题断开连接2）服务端 Server作为发送消息的客户端和请求订阅的客户端之间的中介，也就是MQTT Broker，它可以：接受网络连接接受客户端发布的应用消息处理客户端的订阅和取消订阅请求转发应用消息给符合条件的已订阅客户端3）订阅 Subscription包含一个主题过滤器（Topic Filter）、一个最大服务质量等级QoS。4）主题名 Topic Name附加在应用消息上的一个标签，也就是发布（Publish）消息所携带的主题名称。5）主题过滤器 Topic Filter订阅中包含的一个表达式，用于表示相关的一个或多个主题，可以使用通配符，也就是订阅（Subscribe）消息所携带的主题名称。6）会话 Session就和HTTP的会话概念一致，每一个会话里包含着客户端的信息、客户端订阅了哪些主题、以及一些保存的消息等等。7）控制报文 MQTT Control PacketMQTT的信息数据包，一共有14种。2、MQTT通信图客户端首先通过发包CONNECT、收包CONNACK来建立MQTT连接；然后通过发心跳包PINGREQ、收心跳包PINGRESP来建立心跳，维护通信链路。连接建立后，可以通过发包SUBSCRIBE、收包SUBACK来订阅主题，通过发包UNSUBSCRIBE、收包UNSUBACK来取消订阅主题。对于QoS0的消息，直接发送PUBLISH即可，不需要接受回包。对于QoS1的消息，发包PUBLISH、收包PUBACK，才算是消息发送成功了。对于QoS2的消息，发包PUBLISH、收包PUBREC；再次发包PUBREL，再次收包PUBCOMP，消息才发送成功。二、Broker的任务1、CONNECT/CONNACK 连接服务端1）判断是否是合法的MQTT包是否是MQTT协议：不是，断开连接。是否是支持的MQTT版本：不支持，返回CONNACK[不支持的协议级别]报文，断开连接。2）用户名和密码是否正确用户名是否合法：UTF-8、字符串，不合法，返回CONNACK[无效的用户名或密码]，断开连接。密码是否合法：0~65535字节，不合法，返回CONNACK[无效的用户名或密码]，断开连接。用户名、密码是否正确：密码完全可以不用明文密码，采用JWT等验证方式的数据，不正确，返回CONNACK[未授权]，断开连接。3）审查连接情况ClientID是否合法：必须不为空，必须是UTF-8编码、大小写字母和数字、1~23字节长（1~23个数字或字母），不合法，返回CONNACK[标识符不合格]，断开连接。【自定义】协议规定服务端可以自己设计ClientID长度、字符，可以是零字节。如果是零字节，则服务器需要辅助生成ClientID，并且只能是临时会话（Clean Session为1），因为断开后下一次服务器就不认识这个客户端了。是否已有在线连接占用了这个ClientID：MQTT要求ClientID唯一，如果占用，则踢掉旧会话，维持这个新会话。是否清理会话：① 如果不清理会话（要求持久化会话，CleanSession为False），那么服务端必须在客户端离线之后保留客户端的会话状态，包括：客户端的订阅信息已经发送给客户端，还未确认的QoS1、QoS2消息离线接收的QoS1、QoS2消息已从客户端接收，还未确认的QoS2消息可选，准备发给客户端的QoS0消息持久化Session虽然是持久化，也需要设置过期时间② 如果清理会话（临时会话，CleanSession为True），则服务端丢弃之前的所有数据，并开始一个新的临时会话。如果客户端想要清理之前的数据，重新开始一个新连接，那么需要先CleanSession=True连接一次，断开连接，再重新建立新连接。4）是否有遗嘱消息遗嘱主题是否合法：UTF-8，字符串遗嘱消息是否合法：0~65535字节遗嘱消息是否保留：如果设置了保留，服务端将为这个遗嘱主题保留这条消息。遗嘱消息会在以下情况下分发：服务端检测到I/O错误或者网络故障客户端在保持连接（Keep Alive）的时间段内未能通讯客户端没发送DISCCONECT报文强行关闭了连接由于协议错误服务端主动关闭了连接遗嘱消息会在以下情况下被清理：客户端发送了DISCONNECT报文正常退出（无论是否是持久会话）5）保持心跳Keep Alive声明了客户端想要保持的心跳间隔，以秒为单位，一共2个字节。一般是设置为60秒或几分钟，最大值为18小时12分15秒。如果值非零，服务端如果在1.5倍KeepAlive时间内没有收到任何控制报文，则视为客户端离开，需要断开连接。如果值为零，服务端不需要判断客户端是否活跃，但只要服务端认为不活跃，就可以主动断开连接。需要核查客户端声明的心跳间隔，否则如果时间过短服务端承受不了那么大的压力。6）返回CONNACK设置Session Present：如果CleanSession为0（要求持久化会话），并且服务端保存了旧会话的数据，那么必须将SessionPresent设置为1，表明服务端存在旧会话，方便客户端选择是否要使用这个旧会话。其余情况均设置SessionPresent为0。返回报文：除了明确的异常断开的情况，其他所有异常返回CONNACK[服务端不可用]。如果连接被接受，则返回CONNACK[已接受]。2、DISCONNECT 断开连接1）丢弃遗嘱消息2）断开网络连接3、SUBSCRIBE/SUBACK 订阅主题1）解析订阅请求一个SUBSCRIBE报文可以包含一系列的主题过滤器，以及对应的QoS等级。2）权限检查如果客户端没有权限订阅这个主题过滤器，则需要标记订阅失败。3）发布主题的保留消息对于设置了保留消息的主题，如果任何的主题过滤器能够匹配上，都需要将保留消息发布���该客户端。如果订阅的主题过滤器已经存在（可能QoS等级不同），那么用新的订阅替换旧订阅，并重发匹配主题的保留消息。&nbsp;&nbsp;4）回复SUBACK如果SUBSCRIBE是多个主题过滤器，那么回复也必须在一个SUBACK报文中回复全部的主题过滤器订阅结果。一个主题过滤器的订阅结果包含主题过滤器、QoS等级。如果服务端不支持这么高的服务质量，QoS等级回复支持的最大服务质量或者回复订阅失败。如果主题过滤器不合法，QoS等级则是订阅失败。4、UNSUBSCRIBE/UNSUBACK 取消订阅同样在一个报文可以包含希望取消的多个主题过滤器。在取消订阅后，已经在分发的消息仍然可以继续分发，但服务端不能在接受任何该主题的新消息了。服务端是无法清空所有订阅的，如果要清空，需要客户端准确的取消订阅所有订阅主题，或者清除服务端的Session重新连接。5、PUBLISH 发布消息1）检查主题名是否正确主题名只有一个，而且是精确的主题，不能包含任何通配符。2）检查客户端是否有权限向某个主题发布消息防止客户端非法地发布消息。3）重发标志DUP如果收到重发标志，则表明这是重发的PUBLISH报文。唯一要求重发的场景是客户端设置CleanSession为0（持久化会话）重连，服务端需要重发未确认的PUBLISH报文和PUBREL报文。这里有个疑问是，假设服务端发送了QoS1的PUBLISH报文，在一定时间内没有收到PUBACK报文，那么需要重新尝试分发吗？虽然底层是TCP保证了消息不会丢失，但可能客户端出了错或者发生了什么，导致没有回复PUBACK报文。我的理解是当然需要重发，因为在发布客户端那边，我们已经做完了QoS1通信，发布客户端会以为消息已经按QoS1送达了，而Broker转发给接受客户端这边，必须确保接收客户端收到了这条消息，所以一旦超时，必须要重发。消息排序：重发任何之前的PUBLISH报文时，必须按原始PUBLISH报文的发送顺序重发。这里不是说要等待前一条消息确认后才能下发新一条消息，否则就变成同步了效率低下，这里是说当未收到ACK需要重发的时候，需要按照相同的顺序进行重发。例如发布1、2、3、4消息，订阅者收到的可能是1、2、3、2、3、4，后面的2、3是重发的报文，必须按照2、3的顺序，整个过程也并不是同步的而是并发的，否则应该是1、2、2、3、3、4了。4）保留消息Retain一个主题的保留消息只有一条。作用：如果Retain为1��True），则服务端需要保存这条消息及其QoS，以便分发给未来的新订阅者。设置：如果Retain为1，则服务端必须丢弃之前为这个主题的保留消息，将这条消息作为最新的保留消息保存。清除：如果Retain为1且有效载荷为0字节，那么会被当做正常消息进行分发，并且该主题的保留消息会被移除，服务端不能存储零字节的保留消息。下发：如果客户端的新订阅匹配了一条保留消息，那么服务端给它发送的PUBLISH报文的Retain标志必须置为1，以提醒客户端这是来自于主题的保留消息而非正常消息。&nbsp;&nbsp;5）主题名主题名只能是精确的，不能包含通配符。那如果我们有需求是向“北京地区”的客户端分发消息应该怎么办呢？那就需要北京地区的客户端订阅通配符主题表明自己是北京地区的，而不是发送者向通配符主题发送消息。如果客户端同时订阅了通配符和精确匹配的主题，那么匹配的通配符和精确匹配的主题过滤器都将会收到消息。例如订阅了/abc/#和/abc/123，当发布/abc/123的时候，两个主题都会收到消息，哪怕它们是一个客户端订阅的。&nbsp;&nbsp;① 主题由主题层级分隔符（Topic Level Separator）斜杠“/”进行分隔，两个斜杠可以相邻，表示一个零长度的主题层级，虽然不推荐这样做。② 多层通配符（Mutil-Level wildcard）井号\"#\"可以匹配任意层级，但必须跟在主题层级分隔符之后，并且必须是最后一个字符。【非法格式】\"sport/tennis#\"是无效的，因为tennis和#处于了同一层级\"sport/tennis/#/ranking\"是无效的，因为它不是最后一个字符。\"sport/tennis/#ranking\"是无效的，因为它不是最后一个字符。&nbsp;&nbsp;【匹配策略】如果客户端订阅了\"sport/tennis/player1/#\"，那么：\"sport/tennis/player1\"可以发布消息给它；\"sport/tennis/player1/ranking\"可以发布消息给它；\"sport/tennis/player1/score/wimbledon\"可以发布消息给它；③ 单层通配符加号“+”可以匹配单层，可以放到任意位置，可以和多层通配符一起使用，但必须独占整个层级。【非法格式】\"sport+\"是无效的，因为没有独占整个层级。【匹配策略】如果客户端订阅了\"sport/tennis/+\"，那么：\"sport/tennis/player1\"可以发消息给它；\"sport/tennis/player1/ranking\"不能发消息给它，因为多了一层。&nbsp; \"sport/tennis/\"可以发消息给它，斜杠后面没有数据视为零长度的层级。④ $开头的主题通配符（#或+）不能匹配以$开头的主题，例如发布消息到\"$TEST/monitor\"，订阅\"#\"、\"+/monitor\"的主题将不会收到消息，只有“$TEST/#”等头部精确匹配的才会收到消息。通常$SYS会被用作服务器内部的统计信息主题。⑤ 主题格式规定主题名至少包含1个字符（不能为空）；主题名大小写敏感；主题名可以包含空格；只包含一个“/”的主题名是合法的，含义为[空]/[空]；主题名是UTF-8字符串，不能超过65535个字节。6）报文标识符报文标识符只会在QoS1、QoS2出现，它用来标记一对完整的通信：QoS1-PUBLISH / QoS1-PUBACKQoS2-PUBLISH / QoS2- PUBRECQoS2-PUBREL / QoS2-PUBCOMP由于发送消息不是同步等待发完一条收到回包再发下一条的，而是同时发送多条消息同时等待回包，所以通信双方通过设定的报文标识符来知道这是哪一次通信，从而去做相应处理。报文标识符范围是1~65535，注意是非零的。7）QoS的具体流程QoS0，只需要简单��接受PUBLISH报文，然后投递的时候也发送PUBLISH报文即可，不需要管回包。QoS1：&nbsp;&nbsp;1.1 发布者发布消息给Broker1.2 Broker持久化这条消息1.3 以相同packetId=12回复ACK2.1 Broker发布消息给订阅者2.2 订阅者以相同packetId=631回复ACK2.3 Broker删除持久化的消息对于Broker来说，需要关注收到消息后的操作；对于订阅者来说，当Broker未收到ACK的时候会持续重复发送Publish消息，所以可能重复但必定到达；两侧的packetId是由各自的客户端session分别维护的，没有任何关系。QoS2：&nbsp;&nbsp;1.1 发布者发布消息给Broker1.2 Broker存储消息2.1 Broker回复发布者Publish REC，此后收到任何packetId=13的Publish消息都视为重复消息进行丢弃。2.2 发布者发布Publish REL，Broker将存储的消息移动到下发队列，向订阅者下发消息2.3 Broker回复发布者Publish COMP，完成发布端的QoS2全部阶段。3.1 订阅者回复Publish REC，Broker删除存储的Publish消息（第一阶段），重新存储一个Publish REL消息并下发。3.2 订阅者回复Publish REL，Broker删除存储的Publish REL消息（第二阶段），回复订阅者Publish COMP，完成订阅端的QoS2全部阶段。订阅者此时才会向上转发消息，上层收到的QoS2消息有且只会有一条。&nbsp;&nbsp;也许你会担心例如联网的天然气灶，如果之前一直发送打开消息没有发送成功，半夜的时候突然重连上网络，接收到了打开消息怎么办！或者联网的防盗门，半夜才重连，接收到了打开消息怎么办！不用担心，一般这种消息都会带有时间戳的，完全可以在客户端上做逻辑操作，例如超时5分钟则丢弃消息；同时服务器保存的session具有过期时间，一般为2小时，过期后哪怕是持久化的会话，所有离线消息也都将被丢弃。                \n\n\n","categories":["转载"],"tags":[]},{"title":"MQTT Broker的需求和各大Broker对比","url":"http://tanqingbo.cn/2019/10/06/MQTT Broker的需求和各大Broker对比/","content":"\nhttp://www.bewindoweb.com/244.html一、MQTT Broker的需求1、基本需求1）支持 mqtt3.1 / mqtt3.1.1协议（可选 mqtt5.0）3.1和3.1.1是最常见的协议版本，几乎目前生产的IoT设备都支持，所以Broker也必须支持。至于5.0版本，目前各大Broker都在努力支持，不过还需要一些时间才会普及。2）支持QoS0、QoS1（可选QoS2）各大厂商都至少支持了QoS1，保证消息到达。一般的场景下不会用到QoS2，所以可以选择性地考虑支持QoS23）支持遗嘱消息这是必须支持的功能，通常设备断开都不是主动断开的，而是没有电了才断开，属于异常断开，需要设置遗嘱消息来通知后端服务或者其他设备进行后续处理。4）支持持久化一些数据如QoS1消息、持久Session，需要支持持久化，这是MQTT协议规定的。5）支持多种连接方式MQTT over TCP：最基础的连接方式MQTT over Websocket：在Websocket之上做MQTT封装，对APP这种客户端来说很友好MQTT over TCP/SSL：基础连接方式做通信加密，通常SSL采用TLSMQTT over Websocket/SSL：Websocket做通信加密，通常SSL采用TLS6）（可选 保留消息）保留消息的利用场景几乎可以忽略，而带来的查询成本会很高（每次订阅主题都要查一遍有没有保留消息，再加上通配符匹配，时延很高），所以不一定需要支持，具体应用具体分析。7）支持集群Broker要支持保持海量MQTT连接，需要做集群。集群的难点在于Session的持久化和集群通信。我们既要持久化Session的各项数据，例如正在发送但未收到ACK的QoS1消息，又要保证提取速度，这就是矛盾的事情。而根据订阅信息在内存中构建的订阅树，需要整个集群同步，如何做集群同步也是一个难点。任何一个简单的功能，像发现相同ClientID则踢掉旧会话，一旦做到集群里，就是不容易处理的事情。&nbsp;&nbsp;8）支持自定义验证方式验证客户端的合法性有三点：CONNECT阶段验证是否允许连接、PUBLISH阶段验证是否允许发布、SUBSCRIBE阶段验证是否允许订阅。CONNECT阶段需要验证ClientID、Username、Password、IP四项，不过大部分开源Broker都只支持Username和Password的验证。PUBLISH、SUBSCRIBE的验证的目的是防止非法客户端订阅别人的主题，向别人的主题发布消息。但每台设备每次订阅、发布都要验证一次频率巨高，所以需要设计Cache和高效查询机制。2、高级功能：支持共享订阅共享订阅的具体含义是，多个客户端订阅同一个主题，消息只会被分发给其中的一个客户端。共享订阅主要针对的是需要客户端负载均衡的场景，比如后端���务多个Worker，需要共享订阅来只让一个Worker得到数据。但仔细地想一想，后端服务一定有大量消息扇入，在Broker端用共享订阅可能会导致内存爆炸，还不如直接发到Kafka，利用Kafka的负载均衡来做。不过现在的Broker都在逐渐支持共享订阅，所以也是一个趋势吧。二、MQTT Broker官方资料官方相关链接：mqtt官方整理的开源Broker简要列表mqtt官方整理的开源Broker详细介绍mqtt官方整理的开源Broker特性和性能对比三、体验过的MQTT Broker及其对比我以为物联网已经很成熟了，事实上最近才有大量产品上线，网上可以参考的内容不多。体验了很多开源Broker，开源的Broker根本不能直接上生产环境，只有商业版的HiveMQ和商业版的EMQ才满足了所有的需求。先列个表，这些已经算是比较优秀的Broker了，分析主要特性：✔&nbsp; -&nbsp; 支持✘&nbsp; -&nbsp; 不支持？ -&nbsp; 不了解&nbsp;§&nbsp; -&nbsp; 支持但做得不好（有限制）Broker&nbsp;开源语言��接方式QoS共享订阅持久化集群mosquitto&nbsp;✔&nbsp;C/C++&nbsp;4种&nbsp;全部&nbsp;\n\n\n\n✘？✘hui6075/mosquitto&nbsp;✔&nbsp;C/C++&nbsp;4种&nbsp;全部&nbsp;\n✘？✔&nbsp;&nbsp;&nbsp;moquette0.10&nbsp;✔&nbsp;Java&nbsp;4种&nbsp;全部&nbsp;\n✘&nbsp;✔✔moquette0.12&nbsp;✔&nbsp;Java&nbsp;4种&nbsp;全部&nbsp;\n✘&nbsp;§✘EMQ2.0+&nbsp;✔&nbsp;Erlang&nbsp;4种&nbsp;全部&nbsp;\n✘&nbsp;✔✔EMQ3.0+&nbsp;✔&nbsp;Erlang&nbsp;4种&nbsp;全部&nbsp;\n✔&nbsp;✔✔EMQ PLUS&nbsp;✘&nbsp;Erlang&nbsp;4种&nbsp;全部&nbsp;\n✔&nbsp;✔✔&nbsp;&nbsp;Jmqtt1.1.0&nbsp;✔&nbsp;Java&nbsp;无SSL&nbsp;全部&nbsp;✘&nbsp;✔✘MqttWk&nbsp;✔&nbsp;Java&nbsp;4种&nbsp;全部&nbsp;✘&nbsp;§§&nbsp;&nbsp;HiveMQ&nbsp;✘&nbsp;Java&nbsp;4种&nbsp;全部&nbsp;\n✔&nbsp;✔✔1、mosquitto【简介】mosquitto是ecplise出的开源Broker，由C/C++语言编写，目前最新版v1.5.8，是一个开源MQTT Broker。【官方文档宣称的特性】协议：支持mqtt 3.1 / mqtt 3.1.1【实际的使用限制分析】“趁着年轻”大佬早在2013年就开始研究了，当时的版本是1.2.2，那时候还有一些基础的性能问题，比如用的poll而没有用epoll，内存方面没有优化，多线程主要靠加锁等等，预计可支持10W左右链接。于是大佬自己修改了一个版本kulv2012/mosquitto，优化了那些性能，这已经是五年前了……同样的，“逍遥子”2015年在CSDN上分析了mosquitto1.2的源码，指出epoll需要优化、订阅树需要优化。将订阅树改为了HASH表，直接查找，限制了通配符订阅功能但速度提升明显。mosquitto可以通过桥接的方式进行集群，桥接就是靠一个mosquitto实例去做转发，其他的broker可以转发给它而已，如果客户端切换节点，session就会消失，并且一旦中转Broker挂掉，整个集群就挂了，这是一种伪集群。“hui6075”在mosquitto上做了真集群hui6075/mosquitto-cluster，也就是自定义一些消息，session可以通过这些消息进行转移。最新版本早就没有了那些性能问题，也早就从poll改为epoll了（忘了在哪儿看到的），目前正在努力支持mqtt5，出了一个MQTT5测试版，暂时还不支持共享订阅。无论如何，总结一句话，mosquitto是为了嵌入式设备而生，正如官方的介绍，mosquitto足够轻量，可以运行在任何低功率单片机上，包括嵌入式传感器、手机设备、嵌入式微处理器，mosquitto用C语言编写、集群做的如此简单就是证明，它不适合用来做云服务的MQTT Broker。【推荐延伸阅读】mosquitto github开源代码mosquitto 官方网站趁着年轻：《Mosquitto pub/sub服务实现代码浅析-主体框架》&nbsp;&nbsp;小诺Z《Mosquitto集群搭建》逍遥子《mosquitto源码分析（一）》简介逍遥子《mosquitto源码分析（二）》数据结构逍遥子《mosquitto源码分析（三）》订阅树逍遥子《mosquitto源码分析（四）》订阅树逍遥子《mosquitto源码分析（五）》Poll和消息收发逍遥子《mosquitto源码分析（六）》日志逍遥子《Mosquito的优化——epoll优化（七）》逍遥子《Mosquito的优化——订阅树优化（八）》逍遥子《Mosquito的优化——其他优化（九）》&nbsp;2、EMQ （emqttd）【简介】EMQ是国人出产的一个开源Broker，已经用于很多企业生产了，几乎是目前的全能Broker了，文档和资料也非常齐全，但它是用Erlang语言编写的，这是一个不常见的语言。有两个版本2.0和3.0，最大的区别是3.0的集群化更好，支持集群共享订阅功能，2.0只支持本地共享订阅功能。同时3.0支持mqtt5.0，其他的都是一些性能优化。【官方文档宣称的特性】MQTT 3.1 / 3.1.1 / 5.0（EMQ3.0）完整QoS支持单节点100万连接分布式集群或桥接（还支持mosquitto桥接、rsmb桥接）、脑裂自动愈合LDAP, MySQL, PostgreSQL, Redis, MongoDB等验证插件完整连接方式支持API、Web监控界面本地共享订阅（EMQ2.0）、集群共享订阅（EMQ3.0）$SYS统计信息主题自定义插件开发【实际的使用限制分析】几乎是完美的，只有一点限制，那就是开源版本不支持消息持久化：EMQ 1.0 版本不支持服务器内部消息持久化，这是一个架构设计选择。首先，EMQ 解决的核心问题是连接与路由；其次，我们认为内置持久化是个错误设计。&nbsp;传统内置消息持久化的 MQ 服务器，比如广泛使用的 JMS 服务器 ActiveMQ，几乎每个大版本都在重新设计持久化部分。内置消息持久化在设计上有两个问题:&nbsp;1）如何平衡内存与磁盘使用？消息路由基于内存，消息存储是基于磁盘。&nbsp;2）多服务器分布集群架构下，如何放置 Queue 如何复制 Queue 的消息？&nbsp;Kafka 在上述问题上，做出了正确的设计：一个完全基于磁盘分布式 Commit Log 的消息服务器。&nbsp;EMQ 2.0 版本将发布 EMQ X 平台产品，支持消息持久化到 Redis、Kafka、Cassandra、PostgreSQL 等数据库。&nbsp;设计上分离消息路由与消息存储职责后，数据复制容灾备份甚至应用集成，可以在数据层面灵活实现。这是MQTT的标准协议规定的啊，看完源码后发现它的普通Publish消息是持久化到分布式数据库Mnesia了（但是如果节点崩得多也会丢失），而离线消息队列是基于内存的，也就是Broker一崩消息就丢失了，很多人都在寻求解决方法，都没有好的方法。还有个问题是后端服务怎么接上去，EMQ的设计根本没提到后端服务的问题。大部分的解决方法都是编写一个插件，把MQTT消息丢到Kafka，后端服务处理Kafka的数据，但是后端服务除了收还要发呀，如果直接作为客户端连上去，Broker会内存爆炸因为后端服务要发送的消息太多了。如果你有好的想法，请一定要教教我。【推荐延伸阅读】&nbsp;&nbsp;EMQ github 源码EMQ wikiEMQ 官网知乎：分布式开源物联网MQTT消息服务器EMQ怎么做数据的存储？Dr_C《EMQ集成Kafka插件编写过程 emq_plugin_kafka》响亮响亮《EMQ扩展插件-emq_plugin_kafka》无脑仔的小明《物联网架构成长之路(3)-EMQ消息服务器了解》无脑仔的小明《物联网架构成长之路(4)-EMQ插件创建》无脑仔的小明《物联网架构成长之路(5)-EMQ插件配置》无脑仔的小明《物联网架构成长之路(6)-EMQ权限控制》无脑仔的小明《物联网架构成长之路(7)-EMQ权限验证小结》无脑仔的小明《物联网架构成长之路(8)-EMQ-Hook了解、连接Kafka发送消息》无脑仔的小明《物联网架构成长之路(12)-物联网架构小结1》3、HiveMQ【简介】HiveMQ是企业级的Broker，用Java编写，代码真的赏心悦目。由于是收费的，没有公开的源码可以看，我只从一个反编译的大佬那里看到几张截图而已，只是一些截图就能够看到编写者的Java水平真的很高……【官方文档宣称的特性】MQTT 3.1 / 3.1.1 / 5.0完整QoS支持分布式集群支持持久化支持流量控制支持完整连接方式支持IPv6支持集群共享订阅$SYS统计信息主题JMX性能监控日志打印Docker部署……【实际的使用限制分析】功能上齐全得让人想哭，唯一的限制就是收费，没有任何源码可以参考。它的集群是基于Jgroups的，持久化的数据都是本地+Jgroups同步，自己编写了一套一致性Hash和VectorClock解决冲突……订阅树也是完整的订阅树，优秀的缓存和并发访问控制，集群进行数据同步。多线程和并发等用的google的guava进行防御性编程，实在是太厉害了。如果你有源码，请多发给我一份，我只是用来学习，谢谢！【推荐延伸阅读】&nbsp;&nbsp;HiveMQ官网西安PP《MQTT—HiveMQ源码详解(一)概览》西安PP《MQTT—HiveMQ源码详解(二)结构与启动》西安PP《MQTT—HiveMQ源码详解(三)配置加载》西安PP《MQTT—HiveMQ源码详解(四)插件加载》西安PP《MQTT—HiveMQ源码详解(五)Netty-启动与Listeners加载》西安PP《MQTT—HiveMQ源码详解(六)Netty-Handlers总览》西安PP《MQTT—HiveMQ源码详解(七)Netty-SSL/NoSSL》西安PP《MQTT—HiveMQ源码详解(八)Netty-WebSocket》西安PP《MQTT—HiveMQ源码详解(九)Netty-Codec》西安PP《MQTT—HiveMQ源码详解(十)Netty-Statistics》西安PP《MQTT—HiveMQ源码详解(十一)Netty-Throttling》西安PP《MQTT—HiveMQ源码详解(十二)Netty-MQTT消息、事件处理(流程)》西安PP《MQTT—HiveMQ源码详解(十三)Netty-MQTT消息、事件处理(源码举例解读)》西安PP《MQTT—HiveMQ源码详解(十四)Persistence-LocalPersistence》西安PP《MQTT—HiveMQ源码详解(十五)Persistence-Cluster/Single》西安PP《MQTT—HiveMQ源码详解(十六)TopicTree》西安PP《MQTT—HiveMQ源码详解(十七)Cluster-Consistent Hashing Ring &amp; Node Lifecycle》西安PP《MQTT—HiveMQ源码详解(十八)Cluster-kryo与Serializer》西安PP《MQTT—HiveMQ源码详解(十九)Cluster-Request/Response》西安PP《MQTT—HiveMQ源码详解(二十)Cluster-Replicate/VectorClock》西安PP《MQTT—HiveMQ源码详解(二十一)完结篇》西安PP《MQTT—HiveMQ源码详解(外传)为什么使用Xodus》4、MqttWk【简介】一个阿里大佬编写的基于 nutzboot + netty + redis + kafka 实现的MQTT服务开源broker，代码非常简洁干净，一看就懂。nutzboot是国人编写的类似于springboot的开源架构，它有一系列的产品，功能和代码外观都和spring全家桶很像，但比spring全家桶轻量。【官方文档宣称的特性】MQTT 3.1.1完整的QoS服务完整的连接方式Kafka消息转发集群功能分发重试【实际的使用限制分析】1）MessageQueue没有排序：是直接插入Redis的key-value，并不是一个队列2）消息分发重试很差：对于未确认的QoS1消息，只会在重新连接的时候下发，如果一直在线就会一直淤积3）集群功能很差：用Redis的订阅发布当作消息总线来构建集群，而且我刚熟悉的时候还有问题（1.0.7版本），提交了issue后更新到1.0.8，不过集群这块还是不太好。4）Kafka消息转发：只是单纯地转发而已，没有从后端服务接收消息的代码。而且用原始的代码去编写的转发（为了使用没有Kafka功能的nutzboot，没有用spring的Kafka相关注解）。5）主题：主题有一些限制，不能以/结尾，不支持通配符订阅+我当时还测试出了一些其他的问题，但是忘记了，而且这个项目竟然是上生产的项目……经历过2万设备连接，我在commitlog里面看到作者还写“不知道Redis会不会有性能问题”这种提交信息……不过代码真的非常非常清晰简洁，有助于理解MQTT协议交互过程。【推荐延伸阅读】&nbsp;&nbsp;MqttWk github 开源代码开源中国：MqttWk介绍MqttWk 码云 开源代码5、Jmqtt【简介】jmqtt是一个大佬对开源Broker现状不满意，自己做出来的一个开源Broker。代码思路很清晰，尤其对CONNECT做了优化，而且Session的过期处理得也很好，编写了大量多线程代码，看得出是Java多线程高手。【官方文档宣称的特性】完整的QoS等级支持MQTT、Websocket连接方式支持RocksDB进行数据本地存储【实际的使用限制分析】不支持集群，不支持共享订阅，不支持SSL，MessageQueue不是队列……但是和大佬交流得最深，教了我很多东西，很感谢。【推荐延伸阅读】jmqtt github源码jmqtt 中文自述Ciciz：《MQTT Broker选型》Ciciz：《IoT MQ设计篇：调研与协议选型》Ciciz：《IoT MQ设计篇：开源or自研，系统复杂度分析》Ciciz：《IoT MQ设计篇：基于开源项目二次开发的坑》Ciciz：《IoT MQ设计篇：最终架构与jmqtt介绍》&nbsp;6、Moquette 0.10【简介】0.10和0.12是两个核心版本，功能变化巨大，这里分开叙述。Moquette是我参考得最多的一个Broker了，它是唯一的功能齐全、Java语言编写的开源Broker，网上很多人都是以Moquette为基础进行开发的。Moquette怎么样呢，以研究HiveMQ的“西安PP”大佬的原话说——就是一个玩具项目……看和HiveMQ截图的源码成熟度对比其实我也能感觉出来。但免费的玩具只有这一个啊，没得挑。【官方文档宣称的特性】完整QoS服务完整连接认证方式多种持久化存储支持集群支持性能监控支持【实际的使用限制分析】“专注的力量”用它的代码进行压测，发现有内存泄漏问题，于是自己修复了这些东西，还支持了Redis持久化，发布了一个开源版本irubant/moquette。moquette的集群只是用了hazelcast作消息总线，不支持共享订阅，而且所有的消息都是广播的，也没有在不同Broker节点上相同clinetID相互踢下线的功能。没有消息重发机制，只会在重连的时候重发。订阅树编写得非常复杂，还不断地以CAS（比较并替换）操作在并发环境下更换根节点，会带来很多性能问题。【推荐延伸阅读】moquttte源码moquette官网专注的力量《开源MQTT中间件：moquette》袁志健《从moquette源码看IOT接入协议MQTT的实现》7、Moquette 0.12【简介】Moquette0.12将整个项目简化了，Jar包管理方式从Maven改为Gradle，不再支持集群，说是为了让人1分钟就能快速上手，放弃了Hazelcast说这种方式做集群不好，准备先支持MQTT5.0，再考虑做集群的事情。不过这个版本改进了订阅树，还支持了重发未ACK的消息，MessageQueue也采用了Queue，去掉了大部分持久化方式，只保留H2。【官方文档宣称的特性】支持完整QoS支持完整连接认证方式【实际的使用限制分析】完全地退化……不过代码更清晰一点了，各个功能模块划分得更清楚。但是单机是最大的缺陷，很难改成集群，几乎要全改。8、其他最近又出了一些新的Broker，例如基于moquette的cassandana，宣称已经用于生产，还有一些新特性，想去看看源码是怎么写的。至于Apache ActiveMQ、Apache ActiveMQ Artemis这种基于消息队列制作的MQTT Broker还没有使用过，只是看了一些文章说有性能问题。                \n","categories":["转载"],"tags":[]},{"title":"Moquette 源码分析（一）v0.10 订阅树","url":"http://tanqingbo.cn/2019/10/06/Moquette 源码分析（一）v0.10 订阅树/","content":"\nhttp://www.bewindoweb.com/269.html一、M10 简介Moquette 0.10（以下简称M10）的订阅树实现在moquette-0.10/broker/src/main/java/io/moquette/spi/impl/subscriptions，包括：SubscriptionsDirectory：订阅树的增删改查Token：片段，由topicFilter按“/”分割而成的最小字符串单位Topic：主题/主题过滤器，包含一系列方法，比如比较主题和主题过滤器是否匹配Subscription：订阅信息，{clientId, topicFilter，qos，active}TreeNode：树节点查看源码的时候应该从SubscriptionsDirectory开始阅读。二、M10 订阅树表示假设有如下订阅信息：&nbsp;节点编号&nbsp;&nbsp;订阅客户端&nbsp;&nbsp;订阅主题&nbsp;&nbsp;订阅质量&nbsp;&nbsp;N5A&nbsp;&nbsp;abc/+/123&nbsp;0&nbsp;N3B&nbsp;&nbsp;abc/#&nbsp;1&nbsp;N3A&nbsp;&nbsp;abc/#&nbsp;0&nbsp;N4B&nbsp;&nbsp;abc/def&nbsp;0&nbsp;N6B&nbsp;abc/def/123&nbsp;0&nbsp;N6C&nbsp;&nbsp;abc/def/123&nbsp;1&nbsp;N7&nbsp;D&nbsp;abc/def/456&nbsp;0则可以构建一棵典型的M10订阅树：&nbsp;变量名&nbsp;&nbsp;数据类型&nbsp;&nbsp;数据含义&nbsp;&nbsp;m_token&nbsp;&nbsp;Token&nbsp;该节点代表片段&nbsp;m_children&nbsp;List&lt;TreeNode&gt;&nbsp;子节点&nbsp;m_subscriptions&nbsp;Set&lt;ClientTopicCouple&gt;[1]&nbsp;该节点订阅信息集合&nbsp;subtreeSubscriptions&nbsp;Integer&nbsp;子树订阅信息数量和[2][1]&nbsp; ClientTopicCouple是{clientId，topicFilter}，相比Subscription少了一些字段，减少内存占用。&nbsp;[2] 不是子节点数量之和，而是本节点订阅数量与每个子节点下面的订阅数量之和（递归遍历）可以看到，M10订阅树的信息全在节点内（因为并没有所谓“边”的数据结构）。三、M10 数据结构3.1 节点 TreeNode（1）数据结构：TreeNode（2）属性值&nbsp;数据名&nbsp;&nbsp;数据类型&nbsp;&nbsp;数据含义&nbsp;&nbsp;m_token&nbsp;Token&nbsp;本节点片段，例如“abc”&nbsp;m_children&nbsp;List&lt;TreeNode&gt;&nbsp;子节点&nbsp;m_subscription&nbsp;Set&lt;ClientTopicCouple&gt;&nbsp;本节点订阅信息，例如{client123，\"+\"}（3）重要方法copy：浅拷贝，新建一个TreeNode，拷贝TreeNode的所有属性，由于m_children和m_subscription是引用，这里直接拷贝了引用。childWithToken：查询所有的子节点，找到其中具有token片段的节点，如果找不到，返回nullupdateChild：移除旧子节点，增加新子节点remove：移除本节点上特定的订阅信息matches：查询树中所有匹配某个主题Token的订阅信息。 该方法会递归比对每个Token是否和该节点上所有订阅信息的TopicToken匹配，如果匹配，加入结果。3.2 主题（主题过滤器）Topic（1）数据结构：Topic（2）属性值&nbsp;数据名&nbsp;&nbsp;数据类型&nbsp;&nbsp;数据含义&nbsp;&nbsp;topic&nbsp;String&nbsp;主题或主题过滤器&nbsp;tokens&nbsp;transient List&lt;Token&gt;&nbsp;划分的片段（不会被序列化）&nbsp;valid&nbsp;transient boolean&nbsp;是否是合法的主题（不会被序列化）（3）重要方法getTokens：生成Token列表，只会生成1次，且会判断主题是否合法，比如“/abc/#/123”是非法的&nbsp;isValid：主题是否合法&nbsp;match：返回是否匹配某个订阅主题。要求本主题不含通配符，被匹配的主题可以含通配符。asTopic：根据String生成Topic对象3.3 片段 Token（1）数据结构：Token（2）属性值&nbsp;数据名&nbsp;&nbsp;数据类型&nbsp;&nbsp;数据含义&nbsp;&nbsp;name&nbsp;String&nbsp;片段内容（3）重要方法match：两个Token是否匹配。要求本Token可以含通配符，被比较的Token不能含通配符。3.4 简要订阅信息 ClientTopicCouple（1）数据结构：ClientTopicCouple（2）属性值&nbsp;数据名&nbsp;&nbsp;数据类型&nbsp;&nbsp;数据含义&nbsp;&nbsp;topicFilterTopic&nbsp;主题过滤器&nbsp;clientID&nbsp;String&nbsp;MQTT协议的clientID，客户端ID3.5 订阅信息 Subscription（1）数据结构：Subscription（2）属性值&nbsp;数据名&nbsp;&nbsp;数据类型&nbsp;&nbsp;数据含义&nbsp;&nbsp;topicFilter&nbsp;Topic&nbsp;主题过滤器&nbsp;clientID&nbsp;String&nbsp;MQTT协议的clientID，客户端&nbsp;requestQos&nbsp;MQTTQoS&nbsp;订阅质量&nbsp;active&nbsp;boolean&nbsp;订阅是否有效，暂未使用这个字段3.6 订阅树 SubscriptionsDirectory（1）数据结构：SubscriptionsDirectory（2）属性值&nbsp;数据名&nbsp;&nbsp;数据类型&nbsp;&nbsp;数据含义&nbsp;&nbsp;subscriptions&nbsp;AtomicReference&lt;TreeNode&gt;&nbsp;根节点（3）重要方法init：从持久化存储里初始化订阅信息add：新增订阅removeSubscription：删除一个订阅removeForClient：移除一个客户端的所有订阅matches：查询一个发布主题（不含通配符）匹配的订阅信息四、M10 匹配订阅信息过程M10的订阅匹配实现是DFS的：算法4-1 递归匹配 \nFUNCTION void matches（Queue&lt;Token&gt; tokens, List&lt;ClientTopicCouple&gt; matchingSubs）\n  // 弹出队列头片段\n  t = tokens.poll()\n  // 如果已经匹配完了\n  IF t == null\n     // 说明完全匹配，加入所有的订阅信息\n     matchingSubs.addAll(m_subscriptions)\n    // 子节点如果含有通配符，也加入子节点订阅信息，因为通配符可以匹配空层，比如“/abc”是能够匹配上“/abc/#”的\n     FOR childNode IN m_children\n         IF childNode.m_token == \"#\" || childNode.m_token == \"+\"\n             matchingSubs.addAll(childNode.m_subscriptions) \n         END\n     END\n     RETURN\n  END\n\n\n\n\n// 如果本层token是通配符（对于订阅Topic来说不可能含有通配符），则加入所有订阅信息\nIF m_token == &quot;#&quot;\n    matchingSubs.addAll(m_subscriptions) \n    RETURN\nEND\n\n\n// 遍历子节点，是否有匹配的，如果匹配，递归调用\nFOR childNode in m_children\n    IF childNode.m_token matches t\n        matches(tokens, mathingSubs)\n    END\nEND\nEND例如，我们仍然保持前面的订阅，订阅树也一样：客户端X向主题abc/def/123发布消息，从根节点开始遍历：（1）进入Root，弹出第一个token“abc”，查找子节点发现N1的m_token”abc”匹配（2）进入N1，弹出第二个token“def”，发现N2的m_token“+”匹配，N3的m_token“#”也匹配，N4的m_token“def”也匹配（3.1.1）进入子节点N2，弹出第三个token“123”，发现N5的m_token”123”匹配（3.1.2）进入子节点N5，队列空，匹配完成，将N5的m_subscriptions[{A, abc/+/123}]加入订阅信息集合（3.2.1）返回节点N1，进入子节点N3，队列空，匹配完成，将N3的订阅信息{A，“abc/#”}和订阅信息｛B，“abc/#”｝加入集合（3.3.1）返回节点N1，进入子节点N4，发现子节点N6的m_token”123”匹配（3.3.2）进入子节点N6，队列空，将N6的订阅信息[{B, abc/def/123}，{C, abc/def/123}]加入集合（4）返回N1，返回Root，查找结束这样就成功匹配到了5条订阅信息：&nbsp;节点编号&nbsp;&nbsp;订阅客户端&nbsp;&nbsp;订阅主题&nbsp;&nbsp;订阅质量&nbsp;&nbsp;N5A&nbsp;&nbsp;abc/+/123&nbsp;0&nbsp;N3B&nbsp;&nbsp;abc/#&nbsp;1&nbsp;N3A&nbsp;&nbsp;abc/#&nbsp;0&nbsp;N6B&nbsp;abc/def/123&nbsp;0&nbsp;N6C&nbsp;&nbsp;abc/def/123&nbsp;1五、M10增加订阅5.1 路径重建算法 RPM10的增加订阅和取消订阅都会调用路径重建算法（recreatePath，RP）。在了解路径重建算法之前，��要知道M10订阅树一个性质：【特性1】给定一个主题，一旦发现某个token之前没有建立过节点，其后的所有token都必将建立新节点【解释】给定一个主题”abc/+/123/new1/new2/new3”，前面的token”abc”，”+”，”123”由于A客户端的订阅已经构建了对应的节点TreeNode，发现其后的第一个没有构建过的token“new1”，则其后的“new2”、”new3”都肯定没有构建过。【证明】假设后面的某个token Tn是以前建立过的，那么必然存在之前的某个订阅构建了从Root到Tn的完整路径，且当前主题S一定也遍历的这个路径（否则不会访问到Tn）；但现在已经在这条路径上遇到了一个新节点T0，矛盾，所以Tn必然不可能被建立过。&nbsp;&nbsp;RP算法如下：算法5-2 路径重建recreatePathFUNCTION NodeCouple recreatePath（Topic topic, final TreeNode oldRoot）    // 新建节点，浅拷贝子节点，增加两个指针    newRoot = oldRoot.copy()    parent = newRoot    current = newRoot    // 遍历片段    For token IN Topic       // 如果已经存在某个子节点具有这个token       IF EXIST token IN children           // 浅拷贝这个子节点，当前节点指针下移           current = matchChild.copy()           // 删掉旧子节点，增加新子节点           parrent.update(matchChild, current)           // 父节点指针下移           parrent = current       ELSE           // 新建一个子节点           matchChild = new TreeNode           matchChild.m_token = token           // 当前节点加入新子节点           current.addChild(matchChild)           // 当前节点指针下移           current = matchChild       END    END\nRETURN NodeCouple(newRoot, current)\nEND5.2 增加订阅过程举一个详细的例子，假设现在客户端F产生了一个新订阅”abc/+/123/new1/new2/new3”，我们看看是如何插入的：（1）建立初始数据结构浅拷贝的newRoot，两个指针P，C：（2）发现“abc”有子节点，浅拷贝，指针下移（3）发现“+”有子节点，浅拷贝，指针下移（4）发现“123”有子节点，浅拷贝，指针下移（5）发现“new1”没有节点了，增加节点（6）同理new2、new3（7）很明显，newRoot构建了一个新的树，包含了最新的订阅，current指向了创建的最后一个节点，我们更改颜色来更好地直观感受5.3 增加订阅剩余工作目前只做了路径重建，没有完成订阅，剩下三个工作：（1）将订阅信息加入节点\n有了current指针，就能够直接到达最后创建的节点，将订阅信息加入即可（2）重新计算订阅数量subtreeSubscriptions\n重新执行一次递归计算（耗时）（3）替换旧树根节点\n需要考虑并发，这里M10用的是经典的CAS，替换根节点，旧节点的内存回收由JAVA垃圾回收器来做。&nbsp;我们来看一下CAS的这段源码：do &#123;            oldRoot = subscriptions.get();            couple = recreatePath(newSubscription.topicFilter, oldRoot);            couple.createdNode.addSubscription(newSubscription); //createdNode could be null?            couple.root.recalculateSubscriptionsSize();            //spin lock repeating till we can, swap root, if can't swap just re-do the operation&#125; while (!subscriptions.compareAndSet(oldRoot, couple.root));当CAS替换不成功的时候（比如同时有并发的插入操作且它们执行成功导致根节点发生变化），while条件判断为true，会丢弃掉之前生成的节点，重新执行生成操作。利用这个思路可以写很多CAS的代码，例如：do &#123;    num = myAtomNum.intValue();    if (num &gt;=  maxNum) &#123;        do something 1 ……                return;    &#125; &#125; while (!myAtomNum.compareAndSet(num, num + 1));\n do something 2 ……myAtomNum是一个原子类型，我们希望当myAtomNum的值在达到maxNum后执行“do something 1”，而没有达到时正常执行“do something 2”。如果仅仅写一个if，就会有并发问题。如果像上面这样写，则保证了并发安全。假设maxNum=50，num=40，此时有2个并发线程进入，一个成功执行do something 2，一个失败循环后成功执行do something 2。假设maxNum=50，num=49，此时有2个并发线程进入，一个成功执行do something 2，一个失败循环后成功执行do something 1。假设maxNum=50，num=50，此时有2个并发线程进入，则都将执行do something 1。六、M10 取消订阅M10取消订阅同样会使用RP算法，找到这棵树的最后一个订阅节点（current指针），然后移除其中的订阅信息。例如A取消订阅“abc/+/123”，如下图所示：再进行和订阅同样的后续操作。七、总结可以发现M10的订阅树缺点：（1）只要订阅过，哪怕取消订阅后，这个订阅的节点也不会删除（2）无论通配符订阅还是非通配符订阅，都需要遍历一遍树结构。（3）每次订阅、取消订阅，递归更新订阅数量的时间耗费是很大的，但是这个“统计订阅量”的需求并不需要实时，也不是频繁发生的                \n","categories":["转载"],"tags":[]},{"title":"《Java程序设计》复习笔记（正在写）","url":"http://tanqingbo.cn/2019/10/06/《Java程序设计》复习笔记（正在写）/","content":"\nhttp://www.bewindoweb.com/182.html一、图书信息【书名】《Java程序设计》第一版【作者】江春华【出版社】电子科技大学出版社【其他】大二Java课教材二、复习笔记（仅记录不熟悉的地方）1、对System.out.println的解释 P23（1）System是一个类，存放于Java.lang包中（2）out是System类的成员变量（可以直接访问）（3）println是out的一个方法【问题】成员变量为什么会有方法？【解答】System.class全拼是java.lang.System，是java.lang包中的类；out是System.class中的静态成员变量：public static final java.io.PrintStream out;所以System.out就成了java.io.PrintStream实例的引用，可以直接调用PrintStream.class的方法（非静态方法）：public void println(String x)&#123;\n  synchronized(this)&#123;\n         print(x);\n         newLine();\n  &#125;\n&#125;\n\n\n\npublic void println(Object x)&#123;    String s = String.valueOf(x);    synchronized(this)&#123;           print(s);           newLine();    &#125;&#125;2、import和include区别 P23（1）C/C++的include做了什么？include仅仅是替换而已，把相应的文件内容替换进去，例如一个有趣的例子（pialoneCSDN）：.c文件#include &lt;stdio.h&gt;int main()&#123;    #include \"main.h\"    ++;    printf(\"Hello world! %d\\n \", A);    return 0;&#125;main.h文件int A=99;A看起来++;根本不是一条能通过编译的语句，然而却能够完美运行，因为#include”main.h”仅仅做了复制粘贴工作而已，因此变成了A++;（空格无所谓）（2）C/C++ 的include&lt;&gt;和include””include””会在当前目录下找，找不到再去系统目录下找，一般用于用户自定义的头文件，如include”my.h”；include&lt;&gt;直接去系统目录下找，用于标准库的头文件，如include&lt;stdio.h&gt;；（3）C/C++的include会使得文件变大吗？C语言的编译过程：源文件.c→预处理（复制粘贴.h文件等工作）.i→编译（编译成汇编）.s→汇编（翻译成二进制机器码）.o/.obj→链接（所有的.o文件串起来）.exe当然，源文件肯定会增大一点点，毕竟多了一些字符。因为它是复制粘贴，所以：【自己写的头文件】如果.h文件仅仅包含一些函数的声明，那么编译出的.o二进制文件基本不会变；如果包含一些其他的东西，那么生成的.o二进制文件一定会变大。【库的头文件】生成的.o文件丝毫不会多。如果是静态链接，会把库的.o文件链接进来，生成的EXE会变大，如果是动态链接，只会添加一些描述符，因此生成的.EXE文件不会有太大变化。（4）java的import做了什么import做的工作仅仅是区分是哪个包里的类而已，相当于给所有的类加了一个前缀，例如import java.lang，就可以直接用System类了，它会自动将其替换成java.lang.System。而且在编译的时候，哪怕用了import java.util.*，也仅仅会引入需要用到的包。3、Java类 P23（1）一个Java源程序中只能由一个public类（但是可以有多个类），如果其中某个类有main方法，则必须声明该类为public类。4、三目运算符 P25Java支持三目运算符?:5、字符串拼接 P25经典写法：”abcd” + str（str是int也可以）6、关键字 P26Java的关键字全部是小写的，如true、false、null7、标识符 P26-27（1）开头：数字、字母、美元符 / 中间：数字、字母、下划线、美元符（2）长度没有限制（3）经典写法【类、接口】WorldTool 大写开头【方法、变量】despositAccount() 驼峰【常量】MAX_COUNT 全大写，下划线分隔8、真假布尔变量 P31boolean = true / false ，不支持 0/非0来赋值9、各数据初始化的位置 P35数据&nbsp;初始化存放位置&nbsp;&nbsp;局部变量栈 Stack&nbsp;普通成员变量、new对象&nbsp;堆 Heap&nbsp;静态成员变量、字符串、常量数据段 Data Segment&nbsp;&nbsp;成员方法代码段 Code Segment1011、取模运算浮点数 P28Java取模可以对浮点数：37.2%10 = 7.212、&amp;&amp; || 支持判断一半 P41false &amp;&amp; ? = falsetrue || ? = true13、String的奇特赋值 P47String a = 11 + 11 + “11 “ → “2211”String a = “11” + 11 + 11 &nbsp;→ “111111”其实就是一个从左到右依次计算的梗，11+11先算造成了22，”11”+11先算造成了”1111”。14、break可以块标记 P53....    bB:&#123;            .....            bC:&#123;                   .....                  break bB;                   ...... // 不会执行            &#125;            ..... // 不会执行    &#125;.... //直接跳到这里15、continue块标记 P59同break16、数组声明 P63-68（1）[]内不能有数字（2）[]可前可后：int [] arr;int arr[];（3）实例化：arr = new int [100]; //0-99下标brr = new int [30][40];（4）声明时实例化：int [] arr = new int [30];（5）自带length属性int count[] = new int[10]; // count.length = 10char [][]ch = new char [3][5]; // ch.length = 3（6）声明时初始化：String [] colors = &#123;\"Red\",\"Green\",\"Blue\"&#125;;（7）可部分实例化：int [][] arr = new int[3][] //每一个arr[i]都是null17、String初始化 P70（1）String s = new String(“abc”);//new对象，放入堆（2）String s = “abc”;//字符串，放入DS（3）汉字和字母都只算一位（4）String.length()是方法，arr.length是属性18、变量与方法 P74（1）变量名可以和方法名相同19、常量 P74（1）经典定义 final int MAX_COUNT=12;20、构造方法 P83（1）构造方法不能有返回值（2）如果存在构造方法，那么默认构造方法会失效（需要自己重写）21、类继承 P100（1）如果没有extends，默认继承java.lang.Object（2）父类构造器不是默认时，子类构造器必须用super(xxxx)调用切放在子类构造器的第一行。22、运行时多态 P107（1）父 abc = new 子，此时只能访问父类成员，除非子类覆盖23、abstract抽象类 P108（1）抽象类中可以有非抽象方法；一个类中如果有抽象方法，就必须声明为抽象类（2）抽象方法必须被子类实现（子类可以不实现父类的非抽象方法）（3）3种不能声明抽象的方法：①构造方法 → 继承后无法调用super()②类方法（static标记的静态方法）→ 没有意义了，无法直接使用静态的类方法，继承是无法覆盖静态方法的。例子③私有方法（private控制的方法）→ 没有意义了，抽象类不能创建对象，没有对象能够调用它。抽象方法的意义在于被未来的子类覆盖实现，所以在继承或者使用会出问题的地方都不能标记为抽象。24、Object类 P109-113（1）clone方法Point p2 = p1.clone() //值复制，p1和p2指向不同的对象，不同的地址，内容相同而已。注意，需要实现接口cloneable（2）equals方法【equals】equals比较的是值是否相同（字符串）：Integer ob1 = new Integer(\"123\");Integer ob2 = new Integer(\"123\");ob1.equals(ob2);【==】==比较的是引用是否相同（字符、数字、对象）：'c' == 'c'1 == 2ob1 == ob2（3）toString方法Integer a = new Integer(10);Point p = new Point(100,200);a.toString → 10p.toString → Point@1fb8ee325、访问控制范围 P117-118&nbsp;同一类中&nbsp;同一包中&nbsp;不同包中的子类&nbsp;不同包中的非子类&nbsp;&nbsp;public&nbsp;&nbsp; &nbsp;√&nbsp;\n&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 28px;=”” orphans:=”” auto;=”” text-align:=”” left;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&nbsp;√ &nbsp;&nbsp;\n&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 28px;=”” orphans:=”” auto;=”” text-align:=”” left;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&nbsp;√ &nbsp;&nbsp;\n&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 28px;=”” orphans:=”” auto;=”” text-align:=”” left;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&nbsp;√ &nbsp;&nbsp;protected&nbsp;\n&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 28px;=”” orphans:=”” auto;=”” text-align:=”” left;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&nbsp;√ &nbsp;&nbsp;\n&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 28px;=”” orphans:=”” auto;=”” text-align:=”” left;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&nbsp;√ &nbsp;&nbsp;\n&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 28px;=”” orphans:=”” auto;=”” text-align:=”” left;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&nbsp;√ &nbsp;&nbsp;&nbsp;缺省&nbsp;\n&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 28px;=”” orphans:=”” auto;=”” text-align:=”” left;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&nbsp;√ &nbsp;&nbsp;\n&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 28px;=”” orphans:=”” auto;=”” text-align:=”” left;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&nbsp;√ &nbsp;&nbsp;&nbsp;&nbsp;private&nbsp;\n&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 28px;=”” orphans:=”” auto;=”” text-align:=”” left;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&nbsp;√ &nbsp;&nbsp;&nbsp;&nbsp;【应用】如何让类不能创建对象而且不能被继承？【解答】把构造函数设为private26、接口主要用于 P124（1）通过接口实现不相关类的相同行为，而不需要考虑类联系（2）通过接口指明多个类需要实现的方法（3）通过接口了解对象的交互界面，而不需要了解对象所对应的类。27、接口和抽象类的区别 P125（1）接口中方法都是抽象的；抽象类中可以包含非抽象方法（2）接口中的变量都是常量；抽象类中可以有一般的成员变量；（3）接口可以实现多重继承；抽象类是单一继承（4）没有联系的类可以执行相同的接口28、接口的典型定义 P126[public] interface xxx&#123;        (public final static) int MAX_NUM = 100;        (public abstract) void add(int num);&#125;29、异常处理 P142（1）throw经典语法throw new IllegalMarkException();（2）throws经典语法（作用是抛出但不处理）void exam(int mark)throws NegativeMarkException,OutofMarkException&#123;         if (mark&lt;0) throw new NegativeMarkException();         if (mark&gt;100) throw new OutofMarkExcetption();&#125;30、线程146（1）两种创建方法①生成Thread子类：class xxx extends Thread②声明和实现Runnable接口：class xxx implements Runnable（2）分别的步骤【Thread】①生成Thread类的子类：class xxx extends Thread②覆盖写public void run(){}方法③生成对象，调用start()方法：FT first = new FT();first.start();【Runnable】①声明和实现：class xxx implements Runnable&#123;        ....        public void run ()&#123;            ....        &#125;        ....&#125;②生成实例：xxx n = new xxx();③生成Thread对象：Thread th = new Thread(n);th.start();（3）Runnable注意要使用Thread.sleep();而不是直接sleep()，因为直接sleep()默认是指this.sleep()，然而并没有继承Thread()所以会出错31.1、多线程调度 P153（1）状态①Create新生态：线程对象已分配内存空间，未被调度②Ready可执行态：&nbsp; Ready就绪状态：等待CPU；&nbsp; Execute执行状态：获得CPU正在执行③Block阻塞态：线程暂停④Dead停止态：执行完毕或者调用了stop();（2）调度线程优先级1-10，默认5，先来先服务的抢占式调度；高优先级一进入，低优先级立即放弃CPU。（3）线程状态转换图（@todo转换图）31.2、线程同步 P162①同步方法synchronized void xxx()&#123;    ....&#125;②同步代码块（一定要括号对象）synchronized(this)&#123;  ....&#125;31.3、常见的线程方法辨析参考经典��章《java中yield(),sleep()以及wait()的区别》（1）sleep(int)和yield()区别sleep：由Execute→Block 睡眠时线程放弃CPU，但不会释放锁标志，此时任何优先级的任何线程都可以执行。yield：由Execute→Ready 把线程重新放在等待队列的末尾，等待下一轮执行（如果没有线程在等待则会立即执行），不会释放锁标志，让同优先级其他线程有机会执行（当然高优先级可以进行CPU抢占）。（2）suspend()和resume()&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 30px;=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&nbsp;suspend只能被resume唤醒，不会释放锁标志。&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 30px;=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;已经不建议使用了，因为它可能会造成死锁。（3）wait(int)和notify()、notifyAll()wait会释放锁标志；如果wait不带毫秒时间的参数，那么它只能被notify唤醒。必须在synchronized方法或代码块内使用，用于同步，否则会报IllegalMonitorStateException异常。32、文件类 P166（1）File 基本的文件类 P167（2）RandomAccessFile 读写文件类 P173readLine()：可以识别'\\r' '\\n' '\\r\\n' EOFwriteBytes()：每个字符占一个字节（8bit）writeChars()：每个字符占两个字节（16bit）writeUTF()：每个字符占一个字节，开头会输出两个字节表示将要写出的字节总数write(byte b[]，int offset，int length)按字节写（3）常见的数据类型长度&nbsp;基本类型字节长度&nbsp;备注&nbsp;&nbsp;byte&nbsp;&nbsp;1&nbsp;&nbsp;&nbsp;boolean&nbsp;1&nbsp;&nbsp;short&nbsp;2&nbsp;&nbsp;int&nbsp;4&nbsp;&nbsp;long&nbsp;8&nbsp;&nbsp;float&nbsp;4&nbsp;&nbsp;double&nbsp;8&nbsp;&nbsp;char&nbsp;2&nbsp;Java使用Unicode而不是ASCII33、字节流 P177-186（1）InputStream / OutputStream 顶层抽象类（2）FileInputStream / FileOutputStream 按字节读①支持追加写文件：FileOutputStream(String name，Boolean append)②判断结束的经典代码：while((c == in.read())&gt;-1)&#123;        if ((char)c == '\\n') i++;        System.out.println((char)c);&#125;（3）FilterInputStream / FilterOutputStream &nbsp;&nbsp;★★&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 30px;=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=”” style=”line-height: normal;”&gt;★&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 30px;=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;★包括了两类：BufferedInputStream、DataInputStream①【缓冲区】BufferedInputStream使用了默认2048字节缓冲区BufferedOutputStream使用了默认512字节缓冲区【经典方法】inf = new FileInputSystem(new File(args[0]));bis = new BufferedInputStream(inf);【判断结束】bis.read &gt; -1②DataInputStream与RandomAccessFile类的读写方法基本一致，适用于网络传输34、字符流 P187（1）Reader / Writer 顶层抽象类（2）BufferedReader / BufferedWriter【创建】FileWriter fw = new FileWriter(new File(args[2]));bWrite = new BufferedWriter(fw);【读】buffer = bRead.readLine(); // buffer定义：String bufferwhile (buffer != null)&#123;         buffer = bRead.readLine();&#125;【写】bWrite.write(buffer);bWrite.newLine();这里和RandomAccessFile不同的地方在于，BufferedWriter不会主动换行，而是newLine进行换行，这样好处是可以根据机器类型编写不同的换行符号。35、对象序列化 P195经典代码：Worm implements SerializableObjectOutputStream out = new ObjectOutputStream (new FileOutputStream(\"worm\"));out.writeObject(\"Worm Storage\");out.writeObject(w); // w的定义是：Worm w = new Worm(6,'a');out.close();36、网络编程 P203（1）套接字socket = 端口port，编号为0-65535。                \n","categories":["转载"],"tags":[]},{"title":"一天上手Lua脚本语言","url":"http://tanqingbo.cn/2019/10/06/一天上手Lua脚本语言/","content":"\nhttp://www.bewindoweb.com/225.html前言Lua是目前最流行的轻量级脚本语言，在很多嵌入式设备上已经广泛应用。不仅如此，某些应用程序、网页脚本、游戏开发、数据库等等都使用Lua来对功能进行扩展，比如Redis就能用Lua脚本灵活操作。记得以前博哥也提到过Lua脚本，说明Lua真的值得一学。接下来主要讲述Lua的特别之处，更加详细的语法细节已经记录在wiki上，只需用到的时候查找文档即可。推荐教程：菜鸟教程&nbsp;|&nbsp;易百教程一、Lua背景介绍Lua于1993年开发，名字的原意是“Moon”，是一个名词而不是缩写，所以作者建议写为“Lua”，不要写成“LUA”。Lua由标准C语言编写，最大的特点是轻量，在64位Linux下，Lua的解释器247K（最新的版本）、Lua库421K，所有的脚本引擎中Lua是最快的。Lua和Python很容易被拿来比较，但Lua最核心的使用方式是和其他语言配合，而不是像Python自己能完成所有的事情。Lua是开源的，使用MIT协议，你可以在官网下载Lua源码，目前最新的Lua版本是2018年6月26日更新的Lua 5.3.5。此外，Lua支持面向过程编程和函数式编程，通过闭包和table数据结构竟然可以支持面向对象编程的一些机制。而且Lua有自动内存回收机制，十分方便。二、环境搭建Debian 8 下安装Luawget http://www.lua.org/ftp/lua-5.3.5.tar.gz\ntar -zxvf lua-5.3.5.tar.gz\ncd lua-5.3.5\nmake linux test\nmake install可能会遇到：lua.c:82:31: fatal error: readline/readline.h: No such file or directory，这是因为缺少libreadline-dev依赖包，解决：apt-get install libreadline-dev再安装就好了。which lua\n/usr/local/bin/lua\nlua -v\nLua 5.3.5  Copyright (C) 1994-2018 Lua.org, PUC-RioWindows Lua IDE 环境搭建（1）安装本地Lua和Java、Python类似，下Bin包、加环境变量，lua的环境变量名字是LUA_HOME。Lua各个版本的Bin包&nbsp;sf下载&nbsp;|&nbsp;Lua 5.3.4 for win64百度云下载（密码2p0l）下载完成后解压到喜欢的位置，复制lua53.exe为lua.exe，添加用户或者系统的环境变量：测试一下：（2）配置IDE环境使用国人开发的开源插���EmmyLua for IntelliJ IDEA（Apache 2.0协议），把IDEA作为Lua的IDE。EmmyLua支持IDEA 2017.1、IDEA2017.2/IDEA2018.1、IDEA2018.2，我使用的IDEA版本是2018.1，所以下载IntelliJ-EmmyLua-1.2.6-IDEA172.zip|&nbsp;百度云下载（密码64gl），然后文件→设置→插件→Install plugin from disk，选择刚刚下载的ZIP包（不要解压），选择重启IDEA：lua环境就搭好了，新建项目里就有Lua项目了：然后来一波helloworld（如果提示lua.exe找不到的，查看环境变量是否配对+手动重启IDEA）：EmmyLua是支持断点调试、自动补全的。三、Lua主要特性1、基本信息大小写敏感、动态类型语言（值有类型，变量无类型）2、基本语法（1）格式：字母下划线开头，后跟字母数字下划线。（2）空：nil注意，判断空是要加引号作为字符串的：&nbsp;if test == \"nil\" or test == 'nil'（3）逻辑：and、or、not（4）布尔：true、false注意，0、\"\"、\"0\"都是真，只有false、nil是假。if 0 then\n  print(\"0为真\")\nend\nif \"\" then\n  print(\"\\\"\\\"为真\")\nend\nif \"0\" then\n  print(\"\\\"0\\\"为真\")\nend\nif nil then\n  print(\"nil为真\")\nend\n\n–[[0为真“”为真“0”为真–]]（5）注释普通注释：-- 我是注释段落注释：--[[&lt;html&gt;     &lt;div&gt; &lt;/div&gt;&lt;html&gt;--]]（6）数字数字的字符串看作数字，并且数字只有number（浮点数）：print(\"1\"+\"2\") -- =3.0print(\"1\" + \"test\") -- error（7）运算符多了乘幂：^，例如print(2^3)不等于：~=求长度：#，例如：a = \"aaa\"print(#a) --3（8）变量全局变量：默认全局变量，无论在哪里声明局部变量：local xxxxx（9）赋值支持连着赋值，右值少了则补nil，右值多了则忽略：a = 1b = 2a,b,c = b,aprint(a,b,c) -- 2    1    nil（10）条件判断if true then   xxxxxelse if false then   xxxxxelse  xxxxend（11）for循环for i=1,10,1 do  -- 从1到10步进1    xxxxend\nfor k,v in pairs(table) do – 遍历table的key、value    xxxxend\nfor k,v in ipairs(table) do – 从下标1开始遍历table的key、value，忽略字符串的key    xxxxend（12）其他循环while…do endrepeat… until（13）数组数组的下标是从1开始的！一维数组：array = &#123;\"Lua\", \"Tutorial\"&#125;print(array[1]) -- Lua高维数组：-- 初始化数组array = &#123;&#125;for i=1,3 do    array[i] = &#123;&#125;    for j=1,3 do        array[i][j] = i*j    endend\n– 访问数组for i=1,3 do    for j=1,3 do        print(array[i][j])    endend（14）文件IOfile = io.open(\"test.lua\", \"r\")-- 以只读方式打开文件print(file:read())-- 输出文件第一行file:close() -- 关闭打开的文件3、超强数据结构——table（1）table类似java中的Map，key-value形式。创建方式为：mytable = &#123;&#125;mytable[1] = \"hello\"mytable[2] = \"world\"-- 或者mytable = &#123;\"hello\",\"world\"&#125;-- 或者mytable =  &#123;key = \"value\"&#125;（2）table的下标是从1开始的。（3）table支持同时使用整数和字符串作为key，支持同时使用多种值类型例如：mytable=&#123;\"hello\",\"world\"&#125;mytable[\"test\"] = \"bewindoweb\"mytable[\"test2\"] = 1print(#mytable)在print上打断点就能看到：但是注意#只能识别正常的从数字1开始的数目，所以长度为2：（4）table有两种访问方式print(mytable[1])print(mytable.test)（5）table销毁mytable=nil（6）其他table支持insert、remove、sort、concat、maxn（求table中的最大值，Lua5.2后移除）4、Lua函数（1）可以返回多个值：function myfunc ()    a = 100    b = 200    return a,bend（2）可以有可变参：function average(...)    local arg=&#123;...&#125;    --&gt; arg 为一个表，局部变量end（3）可以被赋值、并作为参数传递function myprint(msg)    print(\"hello \"..msg)end\nfunction mymain(anyfunc,msg)    anyfunc(msg)end\nmyfunc = myprintmymain(myfunc,”world”)5、Lua字符串（1）三种创建方式str = \"hello\"str = 'hello'str = [[hello]]（2）字符串替换string.gsub(mainString,findString,replaceString,num)str = \"hello bwb lua bwb bwb\"print(        string.gsub(str,\"bwb\",\"world\",2))-- hello world lua world bwb    2（3）字符串查找string.find (str, substr, [init, [end]])str = \"hello bwb lua bwb bwb\"print(        string.find(str,\"bwb\",1))-- 7   9（4）缩水版正则匹配由于Lua模式匹配只用了500行代码，当然不可能实现POSIX的4000行代码的标准正则，所以只能匹配一些常见的东西（已经足够使用了）。简单列举一些有特点的（详细的见wiki）：占位符&nbsp;含义&nbsp;占位符&nbsp;含义&nbsp;&nbsp;%a所有字母&nbsp;%l所有小写字母&nbsp;&nbsp;%p所有标点符号&nbsp;%u所有大写字母&nbsp;%w所有字母和数字&nbsp;%z所有0值字符%S：所有的大写占位符都是其补集，比如%S代表非空白字符。%n：这里的 n 可以从 1 到 9； 这个条目匹配一个等于 n 号捕获物（后面有描述）的子串。%bxy：这里的 x 和 y 是两个明确的字符； 这个条目匹配以 x 开始 y 结束， 且其中 x 和 y 保持 平衡 的字符串。 意思是，如果从左到右读这个字符串，对每次读到一个 x 就 +1 ，读到一个 y 就 -1， 最终结束处的那个 y 是第一个记数到 0 的 y。 举个例子，条目 %b() 可以匹配到括号平衡的表达式。举个例子：str = \"hello bwb lua bwb bwb \\0\"s1,s2,s3,s4 = string.match(str,\"(%bbb).*(%1)%s+(%a+)%s+(%z+)$\") --print(s1,s2,s3,s4)6、模块和包（1）Lua可以定义模块（由table实现）：-- 文件名为 module.luamodule = &#123;&#125;  -- 定义一个名为 module 的模块module.constant = \"这是一个常量\" -- 定义一个常量\nfunction module.func1()  – 定义一个函数    io.write(“这是一个公有函数！\\n”)end\nlocal function func2()    print(“这是一个私有函数！”)end\nfunction module.func3()    func2()end\nreturn module（2）Lua从环境变量LUA_PATH中加载模块require(\"模块名\")require \"模块名\"（3）Lua可以加载C的库local path = \"/usr/local/lua/lib/libluasocket.so\"-- 或者 path = \"C:\\windows\\luasocket.dll\"，这是 Window 平台下local f = assert(loadlib(path, \"luaopen_socket\"))f()  -- 真正打开库7、Lua难点之一——元表元表（Metatable）是table的一个东西，初始化：mytable = &#123;&#125;                          -- 普通表mymetatable = &#123;&#125;                      -- 元表setmetatable(mytable,mymetatable)     -- 把 mymetatable 设为 mytable 的元表或者：mytable = setmetatable(&#123;&#125;,&#123;&#125;)元表的意义在于，定义了table的操作对应的一组函数，执行自己想要的逻辑，其实有点像运算符重载。举个例子，当table产生赋值操作时，发现table没有这个key，那么有两种做法，一种是直接报错，一种是新插入这个键值对。那么就可以在table的元表的__newindex元方法里面写下这些逻辑。例如用table实现一个集合Set，并带有交集和并集的方法：Set = &#123;&#125;Set.mt = &#123;&#125;   --将所有集合共享一个metatablefunction Set.new (t)   --新建一个表    local set = &#123;&#125;    setmetatable(set,Set.mt)    for _, l in ipairs(t) do set[l] = true end    return setendfunction Set.union(a,b)   --并集    local res = Set.new(&#123;&#125;)--注意这里是大括号    for i in pairs(a) do res[i] = true end    for i in pairs(b) do res[i] = true end    return resendfunction Set.intersection(a,b)   --交集    local res = Set.new(&#123;&#125;)  --注意这里是大括号    for i in pairs(a) do        res[i] = b[i]    end    return resendfunction Set.tostring(set)  --打印函数输出结果的调用函数    local s = \"&#123;\"    local sep = \"\"    for i in pairs(set) do        s = s..sep..i        sep = \",\"    end    return s..\"&#125;\"endfunction Set.print(set)   --打印函数输出结果    print(Set.tostring(set))end\nSet.mt.__add = Set.union\ns1 = Set.new&#123;1,2&#125;s2 = Set.new&#123;3,4&#125;print(getmetatable(s1))print(getmetatable(s2))s3 = s1 + s2Set.print(s3)\nSet.mt.__mul = Set.intersection   –使用相乘运算符来定义集合的交集操作Set.print((s1 + s2)*s1)8、Lua难点之二——协同程序（1）什么是协同(coroutine)？Lua 协同程序(coroutine)与线程比较类似：拥有独立的堆栈，独立的局部变量，独立的指令指针，同时又与其它协同程序共享全局变量和其它大部分东西。 协同是非常强大的功能，但是用起来也很复杂。（2）线程和协同程序区别线程与协同程序的主要区别在于，一个具有多个线程的程序可以同时运行几个线程，而协同程序却需要彼此协作的运行。 在任一指定时刻只有一个协同程序在运行，并且这个正在运行的协同程序只有在明确的被要求挂起的时候才会被挂起。 协同程序有点类似同步的多线程，在等待同一个线程锁的几个线程有点类似协同。Lua的协程在底层实现就是一个线程。（3）协程执行时间当使用resume触发事件的时候，协程create的函数就被执行了；当遇到yield的时候就代表挂起当前协程，等候再次resume触发事件。（4）一个具体的例子来看yield和resumefunction foo (a)    print(\"foo 函数输出\", a)    return coroutine.yield(2 * a) -- 返回  2*a 的值end\nco = coroutine.create(function (a , b)    print(“第一次协同程序执行输出”, a, b) – co-body 1 10    local r = foo(a + 1)\nprint(&quot;第二次协同程序执行输出&quot;, r)\nlocal r, s = coroutine.yield(a + b, a - b)  -- a，b的值为第一次调用协同程序时传入\n\nprint(&quot;第三次协同程序执行输出&quot;, r, s)\nreturn b, &quot;结束协同程序&quot;                   -- b的值为第二次调用协同程序时传入\nend)\nprint(“main”, coroutine.resume(co, 1, 10)) – true, 4print(“main”, coroutine.resume(co, “r”)) – true 11 -9print(“main”, coroutine.resume(co, “x”, “y”)) – true 10 endprint(“main”, coroutine.resume(co, “x”, “y”)) – cannot resume dead coroutine第一次resume，create的function开始执行，接受到a=1，b=10，打印1，10；进入foo函数，a’ = a+1 = 2，打印2，2*a = 4，yield返回4，所以coroutine.resume打印出来是4；然后主程序第二次resume，协程接受到参数”r”，这时候coroutine.yield的值为”r”，从foo函数的return开始执行，即 return “r”；协程继续执行，打印”r”，用yield返回a+b=11，a-b=-9；coroutine.resume打印11，-9……直到最后，协程退出，主程序还想去resume协程，已经没有协程在yield了，因此报错。整个过程就是主程序和协程在相互传递参数，在某些地方这种传递是很有用的。9、Lua难点之三——面向对象与元表（1）类的设计（用table+function实现），很容易理解：-- Meta classShape = &#123;area = 0&#125;\n– 基础类方法 newfunction Shape:new (o,side)    o = o or &#123;&#125;    setmetatable(o, self)    self.__index = self    side = side or 0    self.area = side*side;    return oend\n– 基础类方法 printAreafunction Shape:printArea ()    print(“面积为 “,self.area)end\n– 创建对象myshape = Shape:new(nil,10)\nmyshape:printArea()（2）继承和多态看似是继承和多态，其实就是一个table在模拟而已：Rectangle = Shape:new()-- 派生类方法 newfunction Rectangle:new (o,length,breadth)    o = o or Shape:new(o)    setmetatable(o, self)    self.__index = self    self.area = length * breadth    return oend\n– 派生类方法 printAreafunction Rectangle:printArea ()    print(“矩形面积为 “,self.area)end\n– 创建对象myrectangle = Rectangle:new(nil,10,20)myrectangle:printArea()10、Lua内存回收机制Lua构建了增量标记-扫描收集器，使用垃圾收集器间歇率和垃圾收集器步进倍率来控制扫描频率，两个数字都是百分比（100代表100%）。（1）间歇率表明开启新循环前需要等待多久：值越大，回收越慢值小于100，则下次循环前不会有任何等待；值等于200，则表明收集器需要等总内存使用量达到之前的2倍才开始新循环（2）步进倍率表明收集器的运作速度相对于内存分配速度的倍率：值越大，回收越快值小于100，则内存分配速度永远比回收要快，这是禁止的；默认值等于200，表明收集器以内存分配速度的2倍速工作；值非常大，则相当于暂停了应用程序的运行，进行一次完整的垃圾回收了。总结作为脚本语言，Lua并不复杂，强大的table数据结构让Lua能够实现很多功能。Lua还有一些错误处理、调试、数据库等API，平时应该不会用到，用到的时候再去查找相关资料即可。一天能学到的只是皮毛，Talk is cheap，期待有机会实践。                \n","categories":["转载"],"tags":[]},{"title":"在ubuntu16.04上安装nvidia驱动","url":"http://tanqingbo.cn/2019/10/06/在ubuntu16.04上安装nvidia驱动/","content":"\nhttp://www.bewindoweb.com/179.html前言一切的一切，只是因为我想在ubuntu上安装一个matlab跑程序……在重新启动之后，一直卡在输入账户密码这步，进不去桌面。输入正确的密码，黑屏一下，然后又会闪退回登录界面，这就是传说中的“循环登录”，其间还提示了一个：    System program problem detected\nDo you want to report the problem now？\nCancel                              Report problem...查了下，这是系统错误报告，说明系统某个地方出错了。可以关闭这个提示：sudo vi /etc/default/report\n\n\n\nset this to 0 to disable apport, or to 1 to enable ityou can temporarily override this withsudo service apport start force_start=1enabled=1把其中的enabled=1改成0就可以了，不过这个没什么意义，还是进不去的。这是实验室的服务器，里面有数据，不能重装系统……查了半天资料，查到了错误的log日志存在的地方：#进入/home目录cd ~#查看所有的文件（包括隐藏文件）ls -la#就能看到.xsession-errors文件了，而且时间还是最新的cat .xsession-errors#出来的结果是：Xlib: extension \"GLX\" missing on display \":0\".Xlib: extension \"GLX\" missing on display \":0\".....百度了下，原来是Nvidia驱动不兼容导致的，问题终于找出来了，以为马上能解决了，只是没想到这是个开头……一、Nvidia快速安装手册注意，这台机器的参数是：机器型号：Dell Precision Tower 7810（工作站）CPU：Intel Xeon(R) CPU E5-2637 v3 3.50Ghz×4显卡：nvidia gk110gl Quadro k6000操作系统：ubuntu 16.04LTS（内核：4.4.0-116-generic）进入tty命令行模式在登录界面按Ctrl+Alt+F1（F1~F6可以开启6个不同的界面）进入命令行模式；按Ctrl+Alt+F7可以返回图形界面。输入账户名和密码如果忘记了账户名，可以返回图形界面，输入密码的上面是账户名清除所有的英伟达显卡驱动程序不用担心显示的问题，最坏的情况我们也有命令行可以使用sudo apt-get purge nvidia-*更新apt的国内源默认源都是国外的服务器，很慢，更新成国内的：（1）进入清华大学开源软件镜像站，选择ubuntu 16.04LTS，增加基础源。sudo vi /etc/apt/sources.list\n默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial main restricted universe multiverse\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-security main restricted universe multiverse\ndeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-security main restricted universe multiverse预发布软件源，不建议启用deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-proposed main restricted universe multiversedeb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse（2）更新apt源sudo apt-get update注意这里的update和upgrade的区别：update更新路径，相当于找到资源存放的位置；而upgrade更新软件，相当于软件管家自动升级已经安装好的软件。如果发现都被忽略了，出现：apt-get: Could not resolve ‘mirrors.tuna.tsinghua.edu.cn’，说明它可能无法解析这个域名的IP地址：【第1步】去ChinaZ查询这个域名的服务器IP，得到IP地址为101.6.8.193【第2步】将这个IP加入hosts：#编辑sudo vi /etc/hosts#加入以下内容101.6.8.193 mirrors.tuna.tsinghua.edu.cn#立即生效sudo  /etc/init.d/networking restart​​【第3步】重新sudo apt-get update查看自己的linux内核版本uname -r4.4.0-116-generic&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;如果是116以上的，那么需要对linux内核进行降级。【第1步】搜索系统内核：sudo dpkg --get-selections | grep linux【第2步】查看是否有低版本内核（重要！）如果有低版本内核，那么卸载高版本内核后会自动退回低版本内核；如果没有低版本内核，那么卸载高版本内核后会回到BIOS界面！如果没有低版本内核，那么可以安装一个112的（没有尝试，因为有112的内核了）sudo apt-get install linux-image-4.4.0-112-generic【第3步】卸载高版本内核sudo apt-get remove linux-image-4.4.0-116-generic【第4步】重启sudo shutdown -r now【第5步】安装和内核版本对应的headers可不做，后面安装Nvidia依赖也会装一次。sudo apt-get install linux-headers-$(uname -r)然后再次uname -r查看内核版本，发现退回了112了。查看自己的显卡型号lspci  | grep -i vgavga compatible controller:Nvidia Corporation GK110GL [Quadro K6000] (rev a1)官网查找合适的nvidia驱动进入英伟达官网驱动下载，输入显卡型号，找到合适的驱动：发现是一个375.82的驱动，也就是说我们只需要安装比这个高一点版本的驱动，就应该能兼容。当然也可以直接安装这个run文件，比较复杂。选项一：直接安装run文件（1）安装受限制的驱动列表sudo apt-get insall nvidia-current nvidia-settings（2）下载驱动（.run文件）wget \"http://cn.download.nvidia.com/XFree86/Linux-x86_64/375.82/NVIDIA-Linux-x86_64-375.82.run&quot;这个下载地址只需要F12查看&lt;a href=”xxxxxx”&gt;就可以知道了（3）安装编译所需的依赖sudo apt-get install build-essential pkg-config xserver-xorg-dev linux-headers-uname -r注意看下uname -r是否已经是112了。（4）屏蔽开源驱动nouveau默认有一个开源的驱动nouveau，如果不屏蔽，在安装过程会报错。sudo vi /etc/modprobe.d/blacklist.conf加入：blacklist vga16fbblacklist nouveaublacklist rivafbblacklist nvidiafbblacklist rivatv（5）关闭图形环境否则安装过程中会报错sudo /etc/init.d/lightdm stop会提示OK（6）安装run文件sudo ./NVIDIA-Linux-x86_64-375.82.run（7）选项的选择开始��显示大量点点（……），然后进入图形化安装界面：如果提示是否接受（accept），选接受；如果提示检测到xxx不完整，是否退出安装，选不退出（continue）；如果提示有旧驱动，询问是否删除旧驱动，选Yes；&nbsp;如果提示缺少某某模块（modules），询问是否上网下载，选no；&nbsp;如果提示编译模块，询问是否进行编译，选ok；&nbsp;如果提示将要修改Xorg.conf，询问是否允许，选Yes；选项二：apt-get自动安装sudo apt-cache search nvidia*会出来很多版本，选择有的而且较高的版本：sudo apt-get install nvidia-387然后会出现和选项一一样的图形化安装界面安装结束出现这样的报告说明安装成功了，否则出错的话，出错的话log会存放在/var/log/nvidia-installer.log。查看驱动安装信息：sudo nvidia-smi然后重启，就能进去桌面了：sudo shutdown -r now二、艰辛的安装过程​噩梦的开始本来只是想安装一个matlab啊……谁会想到matlab自动安装了一个Nvidia CUDA插件……而且还是不兼容的那种……然后本来想着安装了软件之后重启一下再用，就再也进不去了……我先尝试了重启几次，重启完了之后发现显示屏不亮了，原来是显示屏接触不良了，把各个接线头都插拔了一下，搞了半小时，终于屏幕亮了。然后我开始看是什么原因导致的，首先发现的是屏幕的分辨率有问题，也没去多想。黑屏的时候出现了一些字符，但是一闪而过看不清，于是我录了视频，那一帧并不是整数……不能暂停来看……于是我不断地按着那一帧画面，频率高了和固定是一样的，发现打印的字符是：/dev/sdb1: recovering journal/dev/sdb1: Clearing orphaned inode 1179883(uid=108,gid=114,mode=0100664,size=2363).......查了查资料，发现这就是因为我在显示屏不显示东西的时候强制关机造成的，它在自动修复。看这个熟悉的操作系统的inode，就知道在修复一些文件节点了。所以，这和我进不去桌面没有任何关系……又查了下unbuntu进不去桌面，发现有人说是桌面程序崩溃了，需要在recovery模式下面去重装桌面程序：apt-get install ubuntu-desktop可是，当我进入recovery的root模式没几分钟，界面就开始乱跳……还各种#命令行出现在中间和背景进行着xor……我决定在这几分钟内搞定问题，然而我想多了，apt-get提示找不到包……于是需要重新更新apt的源。我就想几分钟肯定不行，需要在原来进不去桌面的那里用Ctrl+Alt+F1切换命令行，在那里弄，于是我shutdown -r now……然后，显示屏先是微微发蓝，然后变成蓝色，然后重启了再也没亮起来……我猜测，那个传输数据的针肯定是接触不良，所以又开始各种插拔，然后，把显示屏的数据线拔下来，插回去的时候一侧的螺丝怎么拧也拧不上了，真棒。然后再尝试了重启机器，发现显示屏亮了，我稍稍移动下显示屏，ubuntu的紫红色变成了蓝色，再稍稍移动一下，又变回了红色，再也不想去碰它了。安装apt源，却给我报了一大堆的错误，解决方法参考《ubuntu16.04出现APT的错误：Update::Post-Invoke-Success》。紧接着，查到一篇劣质文章《解决Ubuntu输入密码后无法进入桌面，一直停留在登陆界面的问题》，让我输入这样的代码：1.$ cd -2.$ sudo chown 你的用户名：你的用户名 .Xauthority3.ls .Xauthority -l你让我cd - cd到哪里去。后来猜测是cd ~，回到/home目录。进行了操作，没有任何用。继续查下去，终于发现了《Ubuntu输入密码登入黑屏后仍返回到登入界面的解决》，这个.xsession-errors记录了错误，才知道是英伟达显卡的错误，回想起matlab安装的时候，安装了一个CUDA，和显卡有关，所以推测是和显卡不兼容，想着不用N卡就行了，但是……ubuntu安装Nvidia驱动的坑我先是想直接用集成显卡好了，不用N卡，用sudo apt-get remove nvidia*卸载了所有的驱动后，重启，发现真的用了集成显卡，进去桌面了！！！然而桌面看不全，所有的界面都不能移动，强行停留在中间。我尝试调分辨率，发现分辨率已经是最高了，1024的，是因为显示屏的分辨率更高，我也没有其他的设备，也不能重装系统因为机器上有数据，很难受。好吧，还是决定重装Nvidia的显卡驱动，查到了最简单的方法：sudo apt-get install nvidia-xxx重启后发现不行，卸载了。然后查到了去下载针对显卡型号的run文件来安装，可是总提示错误：nvidia.ko模块安装有问题。找了半天，终于找到了错误日志：nvidia：version magic\"4.4.0-116-generic SMP mod_unload modversions\" should be \"4.4.0-116-generic SMP mod_unload modversions retpoline\"哇就差了一个retpoline而已啊。查了下version magic，是幻数的意思，在安装软件交叉编译的时候，会对比linux内核的幻数和软件所需要的环境的幻数是不是一致的，从而保证软件稳定。那很简单啊，删去retpoline就好了。我找到了存放Linux内核的源码：cd /usr/src/linux-headers-4.4.0-116-generic发现有人因为版本型号不同，直接改其下的include/generated里面的一些文件的数据就可以了，但是，retpoline根本没在里面出现：grep -r \"retpoline\" ./include需要修改幻数里面的文件：vi /include/linux/vermagic.h真的发现了retpoline，写的是IF具有什么功能，就”retpoline”，否则就””，所以只要把retpoline改成””就行了。然而需要重新编译内核……各种环境+3小时，根本等不了。陷入了绝境，所有的方法都不行。查了一下retpoline：《谷歌推出新的Retpoline编码技术，可避免Spectre攻击》：2018年1月5日，Google已经公布了他们工程师创建的新编码技术的详细信息，任何开发人员都可以部署和防止Spectre攻击。Google声称，这种称为Retpoline的新技术与过去几天推出的其他补丁相比，对性能的影响可以忽略不计，其他补丁在某些情况下会导致CPU性能大幅下降。Turner还向Linux内核项目提交了一个补丁，以实现Linux内核的Retpoline技术。在向其他Linux内核开发人员介绍该技术时，Turner表示，Retpoline为我们的内部工作负载添加了一个“平均总体开销”，它的范围在0-1.5％内，其中包括一些高分组处理引擎。发现事情并不是这么简单。发现了很多人提交了这个4.4.0-116版本内核的bug：2018-2-22《wifi -&gt; broadcom -&gt; update to 4.4.0-116 mismatch wl mod》2018-2-22《4.4.0-116 Kernel update on 2/21 breaks Nvidia drivers (on 14.04 and 16.04) due to outdated gcc-4.8》哇，竟然是最新���问题。那既然是新的，就退内核吧，降内核版本，终于找到了一篇优质博文《安装nvidia 390/387/384显卡驱动出现登录死循环问题的参考解决方法》，一模一样的错误，一样的内核降级思路。在买了泡面和水准备通宵的时候，终于解决了所有的问题，回去睡觉了。参考文献重要文献1、关闭错误报告&lt;a href=”https://www.linuxidc.com/Linux/2014-12/110069.htm&quot; target=”_blank” helvetica=”” neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;《手把手 教你解决Ubuntu的错误提示》2、apt源《清华大学开源软件镜像站》3、xsession-errors《Ubuntu输入密码登入黑屏后仍返回到登入界面的解决》4、安装手册维基百科《Nvidia ubuntu中文》5、Nvidia官网驱动《Nvidia驱动下载》6、坑的解决《安装nvidia 390/387/384显卡驱动出现登录死循环问题的参考解决方法》一般文献&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;1、《Ubuntu 16.04 nvidia安装》&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;2、《 Xlib: extension “GLX” missing on display “:0.0”.》&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;3、《glxgears Xlib: extension “GLX” missing on display “:0.0”》&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;4、《Ubuntu 16.04 内核降级》5、《linux下显卡信息的查看》6、《Ubuntu修改apt-get源》7、《MATLAB CUDA插件》8、《怎么使ko文件的version magic通过?》9、《谷歌推出新的Retpoline编码技术，可避免Spectre攻击》10、《4.4.0-116 Kernel update on 2/21 breaks Nvidia drivers (on 14.04 and 16.04) due to outdated gcc-4.8》11、《wifi -&gt; broadcom -&gt; update to 4.4.0-116 mismatch wl mod》12、《VirtualBox not starting after kernel upgrade》13、《Retpoline support》14、《NVIDIA Driver Installation nvidia: version magic ‘4.4.0-116-generic SMP mod_unload modversions ‘ sho…》15、《Linux中的update和upgrade分别是更新什么呀?》                \n","categories":["转载"],"tags":[]},{"title":"在wangEditor上使用Code-prettify进行代码高亮","url":"http://tanqingbo.cn/2019/10/06/在wangEditor上使用Code-prettify进行代码高亮/","content":"\nhttp://www.bewindoweb.com/172.html\n前言代码显示全部都是白色，看起来比较费时间，而且也没有行数显示，于是查到了使用Google的Code-pretty这个插件进行上色。这样上色的好处是，原来的代码不需要加入一些颜色的代码，只需要在显示的时候JS加上去就好了。而且之前看到很多博客都使用Code-pretty来上色。一、code-prettify下载code-prettifygithub：code-prettify&nbsp;| 百度网盘（密码roay）2018年6月22日版本最简单的使用demo&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n      &lt;meta charset=\"utf-8\"&gt;\n      &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\"&gt;\n      &lt;title&gt;Examples&lt;/title&gt;\n      &lt;link href=\"prettify.css\" rel=\"stylesheet\"&gt;\n      &lt;script type=\"text/javascript\" src=\"prettify.js\"&gt;&lt;/script&gt;\n  &lt;/head&gt;\n&lt;body&gt;\n &lt;pre&gt;\n      &lt;code class=\"prettyprint lang-js linenums\"&gt;\n          var a = 0;\n          alert(a);\n      &lt;/code&gt;\n  &lt;/pre&gt;\n  &lt;script type=\"text/javascript\"&gt;\n      prettyPrint();\n  &lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;引用CSS、JS，然后写一个prettyPrint()脚本。二、修改wangEditor问题变成了，如何让后台添加pre、code标签的时候，自动加入class标签，标记code的类型，方便上色。最开始，我以为code-prettify不支持pre里面含有code标签，而wangEditor的代码编辑器就是&lt;pre&gt;&lt;code&gt;的格式，需要修改wangEditor源码。注意到wangEditor的文件下面有src文件夹，因此可以尝试去修改src，然而我引用的是.min.js，所以新问题是如何在修改src后自动生成.min,js文件。搭建windows下的gulp环境注意到有一个不认识的gulpfile.js和package.json，于是百度了一下，查到gulpjs插件，是前端开发中对代码进行自动化构建的工具，能对JS/coffee/sass/less/html/image/css等文件进行测试、检查、合并、压缩、格式化，简化重复的工作。只要我搭建一样的环境，就能够修改wangEditor的源码了。1、安装node.jsgulp是基于node.js开发的，所以需要装node.js，进入node.js下载界面，下载最新的稳定版本（2018年3月19日最新稳定版本8.10.0LTS），安装到任意位置。【查看node.js版本】node -v【查看npm版本】npm -v2、安装cnpmnpm（node package manager）是nodejs的包管理器，由于源都在国外，因此淘宝开发了一个淘宝NPM镜像，每10分钟和官网同步一次。cnpm的使用方法和npm完全一样，只需要把npm替换成cnpm执行即可，win+R，输入cmd进入命令行，执行安装命令：npm install cnpm -g --registry=https://registry.npm.taobao.org【查看cnpm版本】cnpm -v注意，安装完后要关闭cmd再重新打开cmd，否则直接使用cnpm会出错。3、安装全局gulp【安装gulp】cnpm install gulp -g【查看gulp版本】gulp -v4、package.json文件这一步wangEditor作者已经写好，不需要进行。5、把gulp部署到wangEditor项目里面除了安装全局的，还需要在wangEditor项目里面装一个专门的，注意要先进入项目目录。//进入项目目录\nG:\ncd G:\\test\\plugin\\wangEditor\n//安装依赖包\ncnpm install --save-dev\n//安装gulp-less\ncnpm install gulp-less --save-dev\n//安装gulp\ncnpm install gulp --save-dev--save-dev的意思是只安装开发需要的包。完成后会在wangEditor目录下生成很深很深的node_modules文件夹。其中，less是一种CSS的生成器，wangEditor作者采用了这种生成器来写CSS。6、gulpfile.js文件这一步wangEditor作者也写好了，不需要进行。7、运行gulp打开phpstorm（我是用phpstorm开发的），注意这里有个坑，如果发现phpstorm一直在进行目录扫描，电脑非常卡，原因和解决参看《phpstorm一直扫描目录导致电脑卡》，再打开wangEditor\\gulpfile.js，在文件上右键，会发现多了一个Show Gulp Tasks。点击后，就会弹出来相关的东西，右键可以运行一个默认程序。这个程序就是更新程序，如果没有任何错误，会提示这些东西：我们修改任意src里面的js、less文件，再运行这里的gulpfile.js就会执行更新，.min,js、.min,css就会更新。但其实，只需要修改后ctrl+s保存，这个gulpfile.js就会自动执行更新，很方便。修改wangEditor源代码（错误尝试）目标是把：&lt;pre&gt;\n  &lt;code&gt;\n        xxxxx\n  &lt;/code&gt;\n&lt;/pre&gt;修改为：&lt;pre class=\"prettyprint lang-xxxx linenums\"&gt;\n   xxxxx\n&lt;/pre&gt;wangEditor的src文件夹目录结构是这样的：刚打开，就报一堆书写错误，提示“xxx definenation are not supported by current JavaScrpit version”，解决参看《phpstorm报JS书写错误》1、修改src/js/menus/code/index.js这个js写了菜单code的所有代码，先对这个进行修改。代码思路很清晰：（a）如果选中了文字，用code进行包裹，效果类似：我是被code包裹的文字（b）否则，如果光标在&lt;pre&gt;&lt;code&gt;里面，则说明要更新，调用更新的函数（c）否则，调用创建新的&lt;pre&gt;&lt;code&gt;区域函数跟着这个思路修改就行。（1）onclick里，修改编辑内容的入口参数，增加codeclass注意到源代码：if (this._active) &#123;\n          // 选中状态，将编辑内容\n          this._createPanel($startElem.html())\n      &#125; else &#123;\n          // 未选中状态，将创建内容\n          this._createPanel()\n      &#125;看到用了html()这个方法，估计这个$startElem就是指的&lt;code&gt;&lt;pre&gt;的dom，于是类似地去写，把第3行改为：this._createPanel($startElem.attr('class').split(' ')[1],$startElem.html())获取&lt;pre class=\"prettyprint lang-xxxx linenums\"&gt;中的lang-xxx（代码类别）。完整代码：onClick: function (e) &#123;\n      const editor = this.editor\n      const $startElem = editor.selection.getSelectionStartElem()\n      const $endElem = editor.selection.getSelectionEndElem()\n      const isSeleEmpty = editor.selection.isSelectionEmpty()\n      const selectionText = editor.selection.getSelectionText()\n      let $code\n\n  if (!$startElem.equal($endElem)) &#123;\n      // 跨元素选择，不做处理\n      editor.selection.restoreSelection()\n      return\n  &#125;\n  if (!isSeleEmpty) &#123;\n      // 选取不是空，用 &amp;lt;code&amp;gt; 包裹即可\n      $code = $(`&amp;lt;code&amp;gt;$&#123;selectionText&#125;&amp;lt;/code&amp;gt;`)\n      editor.cmd.do(&#39;insertElem&#39;, $code)\n      editor.selection.createRangeByElem($code, false)\n      editor.selection.restoreSelection()\n      return\n  &#125;\n\n  // 选取是空，且没有夸元素选择，则插入 &amp;lt;pre&amp;gt;&amp;lt;code&amp;gt;&amp;lt;/code&amp;gt;&amp;lt;/prev&amp;gt;\n  if (this._active) &#123;\n      // 选中状态，将编辑内容\n      this._createPanel($startElem.attr(&#39;class&#39;).split(&#39; &#39;)[1],$startElem.html())\n  &#125; else &#123;\n      // 未选中状态，将创建内容\n      this._createPanel()\n  &#125;\n  },（2）_createPanel里，增加select的内容这里有个技巧，如果option里面，有selected=selected属性，就可以让它成为select的默认选中值。_createPanel: function (codeclass,value) &#123;\n  // value - 要编辑的内容\n  codeclass = codeclass || &#39;lang-c&#39;\n  value = value || &#39;&#39;\n  const type = !value ? &#39;new&#39; : &#39;edit&#39;\n  const textId = getRandom(&#39;texxt&#39;)\n  const btnId = getRandom(&#39;btn&#39;)\n  const selectId = getRandom(&#39;select&#39;)\n  const sval = new Array(&#39;c&#39;,&#39;java&#39;,&#39;python&#39;,&#39;bash&#39;,&#39;a&#39;,&#39;b&#39;,&#39;d&#39;)\n  const stxt = new Array(&#39;C语言&#39;,&#39;Java&#39;,&#39;Python&#39;,&#39;Bash命令行&#39;,&#39;按键精灵&#39;,&#39;易语言&#39;,&#39;其他&#39;)\n  var sh = &#39;&#39;\n  for (var i=0;i&amp;lt;sval.length;i++)&#123;\n      if (codeclass === &#39;lang-&#39;+sval[i]) &#123;\n          sh += `&amp;lt;option value=lang-$&#123;sval[i]&#125; selected=selected&amp;gt;$&#123;stxt[i]&#125;&amp;lt;/option&amp;gt;`\n      &#125;else&#123;\n          sh += `&amp;lt;option value=lang-$&#123;sval[i]&#125;&amp;gt;$&#123;stxt[i]&#125;&amp;lt;/option&amp;gt;`\n      &#125;\n  &#125;\n  const panel = new Panel(this, &#123;\n      width: 500,\n      // 一个 Panel 包含多个 tab\n      tabs: [\n          &#123;\n              // 标题\n              title: &#39;插入代码&#39;,\n              // 模板\n              tpl: `&amp;lt;div&amp;gt;\n                  &amp;lt;div class=&quot;w-e-select-container&quot;&amp;gt;\n                      &amp;lt;select id=&quot;$&#123;selectId&#125;&quot; value=&quot;$&#123;codeclass&#125;&quot;&amp;gt;\n                      $&#123;sh&#125;\n                      &amp;lt;/select&amp;gt;\n                  &amp;lt;/div&amp;gt;\n                  &amp;lt;textarea id=&quot;$&#123;textId&#125;&quot; style=&quot;height:145px;;&quot;&amp;gt;$&#123;value&#125;&amp;lt;/textarea&amp;gt;\n                  &amp;lt;div class=&quot;w-e-button-container&quot;&amp;gt;\n                      &amp;lt;button id=&quot;$&#123;btnId&#125;&quot; class=&quot;right&quot;&amp;gt;插入&amp;lt;/button&amp;gt;\n                  &amp;lt;/div&amp;gt;\n              &amp;lt;div&amp;gt;`,\n              // 事件绑定\n              events: [\n                  // 插入代码\n                  &#123;\n                      selector: &#39;#&#39; + btnId,\n                      type: &#39;click&#39;,\n                      fn: () =&amp;gt; &#123;\n                          const $text = $(&#39;#&#39; + textId)\n                          let text = $text.val() || $text.html()\n                          text = replaceHtmlSymbol(text)\n                          const $codeclass = $(&#39;#&#39; + selectId)\n                          let codeclass = $codeclass.val()\n                          codeclass = replaceHtmlSymbol(codeclass)\n                          if (type === &#39;new&#39;) &#123;\n                              // 新插入\n                              this._insertCode(codeclass,text)\n                          &#125; else &#123;\n                              // 编辑更新\n                              this._updateCode(codeclass,text)\n                          &#125;\n\n                          // 返回 true，表示该事件执行完之后，panel 要关闭。否则 panel 不会关闭\n                          return true\n                      &#125;\n                  &#125;\n              ]\n          &#125; // first tab end\n      ] // tabs end\n  &#125;) // new Panel end\n\n  // 显示 panel\n  panel.show()\n\n  // 记录属性\n  this.panel = panel\n  },（3）修改_insertCode、_updateCode、_tryChangeActive// 插入代码  _insertCode: function (codeclass,value) &#123;\n  const editor = this.editor\n  editor.cmd.do(&#39;insertHTML&#39;, `&amp;lt;pre class=&quot;prettyprint $&#123;codeclass&#125; linenums&quot;&amp;gt;$&#123;value&#125;&amp;lt;/pre&amp;gt;&amp;lt;p&amp;gt;&amp;lt;br&amp;gt;&amp;lt;/p&amp;gt;`)\n  },\n  // 更新代码  _updateCode: function (codeclass,value) {\n  const editor = this.editor\n  const $selectionELem = editor.selection.getSelectionContainerElem()\n  if (!$selectionELem) &#123;\n      return\n  &#125;\n  $selectionELem.html(value)\n  $selectionELem.attr(&#39;class&#39;,&#39;prettyprint &#39;+codeclass+ &#39; linenums&#39;)\n  editor.selection.restoreSelection()\n  //BWB：特别地恢复标签：\n  },\n  // 试图改变 active 状态  tryChangeActive: function (e) {\n  const editor = this.editor\n  const $elem = this.$elem\n  const $selectionELem = editor.selection.getSelectionContainerElem()\n  if (!$selectionELem) &#123;\n      return\n  &#125;\n  //const $parentElem = $selectionELem.parent()\n  //if ($selectionELem.getNodeName() === &#39;CODE&#39; &amp;amp;&amp;amp; $parentElem.getNodeName() === &#39;PRE&#39;) &#123;\n  if ($selectionELem.getNodeName() === &#39;PRE&#39;) &#123;\n      this._active = true\n      $elem.addClass(&#39;w-e-active&#39;)\n  &#125; else &#123;\n      this._active = false\n      $elem.removeClass(&#39;w-e-active&#39;)\n  &#125;\n  }2、修改text/index.jstext控制了编辑器的操作，比如光标变化、按下键盘按键，因此需要对这里也进行修改，因为我们改变了标签。将所有的：if (selectionNodeName !== 'CODE' || parentNodeName !== 'PRE')改为：if(selectionNodeName !== 'PRE')3、修改src/less/panel.less在.w-e-panel-tab-content的.w-e-button-container:after后面增加select的CSS.w-e-select-container&#123;\n          width:120px;\n          display:block;\n          height:30px;\n          margin-bottom:10px;\n\n          select&#123;\n              background: #f2f2f2;\n              border: none;\n              padding-left: 10px;\n              width: 100%;\n              height: 30px;\n              color:#242424;\n              display:block;\n              font-size:14px;\n\n              option&#123;\n                  background:#fff;\n                  border: none;\n                  padding:0px 2px;\n              &#125;\n          &#125;\n\n      &#125;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;4、修改src/less/text.less&lt;/p&gt;&lt;p&gt;修改pre标签的CSS即可，这里由于我没有使用wangEditor自带的CSS，因此没有做。&lt;/p&gt;&lt;h2&gt;修改wangEditor源代码（正确尝试）&lt;/h2&gt;&lt;p&gt;其实呢，Code-prettify是支持&amp;lt;pre&amp;gt;&amp;lt;code&amp;gt;标签的，但是class需要写在code里面：&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;prettyprint lang-html linenums&quot;&gt;&amp;lt;pre&amp;gt;\n   &lt;code class=”prettyprint lang-xxxx linenums”&gt;   ….这种标签竟然是HTML5的，还是要多看readme文件呀，《Code-Prettify的Readme文件翻译》。因此wangEditor只需要改src/js/menus/code/index.js即可，注意这里和前面会有一点不同：onClick: function (e) &#123;\n  const editor = this.editor\n  const $startElem = editor.selection.getSelectionStartElem()\n  const $endElem = editor.selection.getSelectionEndElem()\n  const isSeleEmpty = editor.selection.isSelectionEmpty()\n  const selectionText = editor.selection.getSelectionText()\n  let $code\n\n  if (!$startElem.equal($endElem)) &#123;\n      // 跨元素选择，不做处理\n      editor.selection.restoreSelection()\n      return\n  &#125;\n  if (!isSeleEmpty) &#123;\n      // 选取不是空，用 &amp;lt;code&amp;gt; 包裹即可\n      $code = $(`&amp;lt;code&amp;gt;$&#123;selectionText&#125;&amp;lt;/code&amp;gt;`)\n      editor.cmd.do(&#39;insertElem&#39;, $code)\n      editor.selection.createRangeByElem($code, false)\n      editor.selection.restoreSelection()\n      return\n  &#125;\n\n  // 选取是空，且没有夸元素选择，则插入 &amp;lt;pre&amp;gt;&amp;lt;code&amp;gt;&amp;lt;/code&amp;gt;&amp;lt;/prev&amp;gt;\n  if (this._active) &#123;\n      // 选中状态，将编辑内容\n      this._createPanel($startElem.attr(&#39;class&#39;).split(&#39; &#39;)[1],$startElem.html())\n  &#125; else &#123;\n      // 未选中状态，将创建内容\n      this._createPanel()\n  &#125;\n  },\n  _createPanel: function (codeclass,value) {\n  // value - 要编辑的内容\n  codeclass = codeclass || &#39;lang-c&#39;\n  value = value || &#39;&#39;\n  const type = !value ? &#39;new&#39; : &#39;edit&#39;\n  const textId = getRandom(&#39;texxt&#39;)\n  const btnId = getRandom(&#39;btn&#39;)\n  const selectId = getRandom(&#39;select&#39;)\n  const sval = new Array(&#39;c&#39;,&#39;java&#39;,&#39;PHP&#39;,&#39;python&#39;,&#39;matlab&#39;,&#39;html&#39;,&#39;css&#39;,&#39;js&#39;,&#39;bash&#39;,&#39;ajjl&#39;,&#39;eyy&#39;,&#39;txt&#39;)\n  const stxt = new Array(&#39;C/C++&#39;,&#39;Java&#39;,&#39;PHP&#39;,&#39;Python&#39;,&#39;Matlab&#39;,&#39;HTML&#39;,&#39;CSS&#39;,&#39;JavaScript&#39;,&#39;Bash命令行&#39;,&#39;按键精灵&#39;,&#39;易语言&#39;,&#39;普通文本&#39;)\n  var sh = &#39;&#39;\n  for (var i=0;i&amp;lt;sval.length;i++)&#123;\n      if (codeclass === &#39;lang-&#39;+sval[i]) &#123;\n          sh += `&amp;lt;option value=lang-$&#123;sval[i]&#125; selected=selected&amp;gt;$&#123;stxt[i]&#125;&amp;lt;/option&amp;gt;`\n      &#125;else&#123;\n          sh += `&amp;lt;option value=lang-$&#123;sval[i]&#125;&amp;gt;$&#123;stxt[i]&#125;&amp;lt;/option&amp;gt;`\n      &#125;\n  &#125;\n  const panel = new Panel(this, &#123;\n      width: 500,\n      // 一个 Panel 包含多个 tab\n      tabs: [\n          &#123;\n              // 标题\n              title: &#39;插入代码&#39;,\n              // 模板\n              tpl: `&amp;lt;div&amp;gt;\n                  &amp;lt;div class=&quot;w-e-select-container&quot;&amp;gt;\n                      &amp;lt;select id=&quot;$&#123;selectId&#125;&quot; value=&quot;$&#123;codeclass&#125;&quot;&amp;gt;\n                      $&#123;sh&#125;\n                      &amp;lt;/select&amp;gt;\n                  &amp;lt;/div&amp;gt;\n                  &amp;lt;textarea id=&quot;$&#123;textId&#125;&quot; style=&quot;height:145px;;&quot;&amp;gt;$&#123;value&#125;&amp;lt;/textarea&amp;gt;\n                  &amp;lt;div class=&quot;w-e-button-container&quot;&amp;gt;\n                      &amp;lt;button id=&quot;$&#123;btnId&#125;&quot; class=&quot;right&quot;&amp;gt;插入&amp;lt;/button&amp;gt;\n                  &amp;lt;/div&amp;gt;\n              &amp;lt;div&amp;gt;`,\n              // 事件绑定\n              events: [\n                  // 插入代码\n                  &#123;\n                      selector: &#39;#&#39; + btnId,\n                      type: &#39;click&#39;,\n                      fn: () =&amp;gt; &#123;\n                          const $text = $(&#39;#&#39; + textId)\n                          let text = $text.val() || $text.html()\n                          text = replaceHtmlSymbol(text)\n                          const $codeclass = $(&#39;#&#39; + selectId)\n                          let codeclass = $codeclass.val()\n                          codeclass = replaceHtmlSymbol(codeclass)\n                          if (type === &#39;new&#39;) &#123;\n                              // 新插入\n                              this._insertCode(codeclass,text)\n                          &#125; else &#123;\n                              // 编辑更新\n                              this._updateCode(codeclass,text)\n                          &#125;\n\n                          // 返回 true，表示该事件执行完之后，panel 要关闭。否则 panel 不会关闭\n                          return true\n                      &#125;\n                  &#125;\n              ]\n          &#125; // first tab end\n      ] // tabs end\n  &#125;) // new Panel end\n\n  // 显示 panel\n  panel.show()\n\n  // 记录属性\n  this.panel = panel\n  },\n  // 插入代码  _insertCode: function (codeclass,value) {\n  const editor = this.editor\n  editor.cmd.do(&#39;insertHTML&#39;, `&amp;lt;pre&amp;gt;&amp;lt;code class=&quot;prettyprint $&#123;codeclass&#125; linenums&quot;&amp;gt;$&#123;value&#125;&amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt;&amp;lt;p&amp;gt;&amp;lt;br&amp;gt;&amp;lt;/p&amp;gt;`)\n  },\n  // 更新代码  _updateCode: function (codeclass,value) {\n  const editor = this.editor\n  const $selectionELem = editor.selection.getSelectionContainerElem()\n  if (!$selectionELem) &#123;\n      return\n  &#125;\n  $selectionELem.html(value)\n  $selectionELem.attr(&#39;class&#39;,&#39;prettyprint &#39;+codeclass+&#39; linenums&#39;)\n  editor.selection.restoreSelection()\n  },\n  // 试图改变 active 状态  tryChangeActive: function (e) {\n  const editor = this.editor\n  const $elem = this.$elem\n  const $selectionELem = editor.selection.getSelectionContainerElem()\n  if (!$selectionELem) &#123;\n      return\n  &#125;\n  const $parentElem = $selectionELem.parent()\n  if ($selectionELem.getNodeName() === &#39;CODE&#39; &amp;amp;&amp;amp; $parentElem.getNodeName() === &#39;PRE&#39;) &#123;\n      this._active = true\n      $elem.addClass(&#39;w-e-active&#39;)\n  &#125; else &#123;\n      this._active = false\n      $elem.removeClass(&#39;w-e-active&#39;)\n  &#125;\n  }最终效果：三、修改已有的文章已经写了很多文章了，都没有加入class标签，因此需要修改数据库：这里为了匹配&lt;pre&gt;&lt;code&gt;&lt;/code&gt;&lt;pre&gt;标签，费了很大的劲，有很多坑，参考《PHP匹配HTML标签》参考网页1、《用谷歌代码高亮插件code-prettify打造属于你的漂亮博文》2、《windows下Gulp入门详细教程》3、《npm install –save/–save-dev的区别》4、《关于php中正则匹配包括换行符在内的任意字符的问题总结》5、《正则表达式-问号的四种用法》                \n\n\n","categories":["转载"],"tags":[]},{"title":"基于amwiki搭建属于自己的维基百科","url":"http://tanqingbo.cn/2019/10/06/基于amwiki搭建属于自己的维基百科/","content":"\nhttp://www.bewindoweb.com/199.html前言最近突然意识到，我把过多的内容放到这个博客里面了，是时候把编程、生活日记、工具wiki三者分开了：（1）个人博客应该记录编程的内容，比如有趣的小实验、小项目、优美的算法、数学等等，它应该是以后工作的名片。（2）生活日记记录的才是自己去哪儿玩儿了，昨天做什么梦了，有啥想买想吃的东西。（3）wiki则应该记录一些常用的、系统的知识，比如快捷键、中文文档的翻译、软件程序出错解决手册。它应该是经过多次验证的工具书，不同于平时使用的印象笔记，印象笔记都是杂乱的思绪，突然想到的方法，突然想做的事情，或者在做事过程中边做边记录不需要考虑格式问题的草稿。wiki记录的则是可以快速搜索查找、具有条理的但是非常无聊、平时不会看，关键时候又需要翻一翻的东西。因此诞生了制作自己的wiki的想法。需求分析我主要有三个需求：（1）可以放在服务器上便于在任何地方查看，这需要体积小巧。（2）支持Markdown的语法，支持中文。（3）���强大的搜索功能，能够搜索内容中的关键字而不仅仅是标题。我的小伙伴钉子在《使用 TiddlyWiki 打造轻便个人 Wiki 知识库》中已经提到了用TiddlyWiki，TiddlyWiki非常有用：（1）单HTML文件，可以随时装在U盘里离线查看（2）不需要任何服务器的配置，也不需要任何安装（3）很多人使用，已经具有很多成熟的插件（4）有强大的标签和搜索功能用钉子的原话说：&nbsp;笔记软件，例如 EverNote 、 WizNote 、 OneNote 的确十分不错，但是也会带来客户端是否跨平台、启动速度是否好看甚至默认文字排版是否美观的问题；而且，常规的笔记软件也达不到 Wiki 级别方便的 Tag 标签系统。当然， Wiki 系统有经典的 MediaWiki 系统，还有许许多多的静态 Wiki 系统、 Wiki 知识库类客户端。然而， MediaWiki 庞大、复杂和丑陋； Wiki 客户端程序有好有坏，有设计简陋也有强大美观，但是最大的限制还是往往不跨平台；一些可以用 Github Pages 部署的，基于 Markdown 的 Wiki 系统尽管几乎能在功能上满足我的需求，但是每一次撰写新条目和部署的复杂度还是令人难以接受。你可能已经看出了我口味相当的刁钻和需求相当的诡异 …… 在我看来，管理以文字、代码和数学公式为主的个人知识库， TiddlyWiki 可谓是最好的选择之一。然而其实不太符合我的需求：（1）无法放到小水管服务器上。存储在单一HTML文件里，再装几个插件，写点文字，文件会原来越大，钉子的Tiddly已经到5M了，5M的东西要用1M也就是128kb/s的水管传输……而钉子的服务器是80块一个月的Linode，非常适合：（2）不支持markdown语法Tiddlywiki用的是WikiText，虽然说差不多，但是也需要学习。（3）界面凌乱由于只有一个html文件，作者编辑和读者看是一个界面，虽然读者不会保存修改操作，但看着并不会使用却放在那里的按钮很难受。（4）对浏览器的支持不太好搜狗浏览器打开：不过以后有机会还是想用一用TiddlyWiki的，比如等我租到大带宽服务器……amwiki简介在查了一些资料，并且排除了钉子所说的不太好用的那些wiki后，发现了amwiki。amwiki是国人TevinLi开发的在github���开源的wiki程序，起源也是因为觉得wiki都不太好用，于是他自己开发了一个。amwiki优点（1）支持markdown语法、支持中文。国人基于Atom开发的产物……太棒了。（2）有自动构建工具。写完markdown后只需要按一下按钮更新目录即可。（3）无需数据库。所有的markdown写完都保存为.md文件，它能够自动加载，省去了数据库的备份麻烦。（4）支持粘贴图片。非常非常实用的功能，QQ截图后在Atom里面粘贴图片，自动把图片保存到assets目录下，并且自动创建文件夹、命名，自动把markdown语句写好……无敌。（5）支持导出github wiki。因为amwiki最开始是为github项目写wiki用的。（6）支持全库搜索。支持标题搜索、支持内容搜索。（7）支持手机浏览amwiki缺点（1）没有更新了。amwiki的最后一次更新是在2018年1月3日，5个月没更新了，估计作者要弃坑了……有什么问题得自己去改。（2）不支持公式。amwiki毕竟是小项目，没有成熟的插件。（3）加载缓慢。由于没用数据库，还要在加载过程中转换为html，加载也是比较缓慢的。不过，amwiki是有缓存机制的，而且不需要像Tiddlywiki一样一次性加载完所有的文档。未来的amwiki注意到在计划中的下一个版本作者准备支持数学公式了，罒ω罒，包括评论系统，都是值得期待的，不过不知道何年何月才能等到……上手amwikiamwiki下载和安装（1）从github上点击Clone or download下载ZIP，这里提供一个百度网盘amwikiv1.2.1（密码xvnk）（2）安装Atom编辑器，安装过程是自动的，强制安装到C盘。这是一款github开发的开源免费的编辑器，amwiki是作为Atom的插件开发的。同样提供百度网盘（密码8bui）备份下载，不过注意这个文件是v1.27.2 For Windows7(64bit) or later的，我的操作系统是windows8 64位，所以如果你的操作系统不同，需要自己去官网下载对应版本。（3）将amwiki手动安装至Atom。① 进入C:\\Users\\BEWINDOWEB\\.atom\\packages文件夹，这里的BEWINDOWEB是你计算机的名字，.atom是一个隐藏文件夹。② 将amwiki的ZIP文件解压到这个文件夹，如果解压后的名字不是amWiki的话，比如是amWiki-master，需要把amWiki-master重命名为amWiki。（4）顺手装一个Atom汉化插件，同样的安装方法，下载→解压到packages目录。插件名字叫atom-simplified-chinese-menu-master，给一个百度网盘（密码qqa7）地址。（5）打开Atom，发现上面的英文菜单栏变为了中文，并且多了一个amWiki轻文库的菜单，说明安装成功了：amWiki的Hello World（1）新建一个项目文��夹。我们在喜欢的地方建立一个文件夹，比如G:\\githubWorkspace\\Helloworld\\，然后在Atom里面选择文件→添加项目文件夹→选中这个Helloworld，一个项目文件夹就建好了：（2）编写config.json。在这个Helloworld文件夹下创建一个config.json文件，写入内容：&#123;\n\"name\": \"Hello wiki\"\n&#125;（3）生成amwiki。菜单栏amWiki轻文库→通过config.json创建新文库，会在这个目录下自动生成很多文件：（4）启动本地服务器。菜单栏amWiki轻文库→启动本地静态Web服务器，可能会提示联网，允许就好了。（5）查看Hello wiki内容。① 进入library目录，选择home-首页.md：② 然后菜单栏amWiki轻文库→在浏览器中打开当前文档，Helloworld！（注意这里不能直接去打开index.html，因为会有跨域的问题，很多文件无法引用，需要从静态Web服务器来操作）修改amwiki（1）看���么都不如看官方文档，amwiki官网，amwiki文档中心。（2）修改config.json。由于amwiki是自动生成的，所以你手动去更改内容非常麻烦，一切的修改都应该基于config.json，作者提供了以下接口：&nbsp;参数名默认值&nbsp;修改示例&nbsp;作用&nbsp;nameamWiki轻文库Hello wiki&nbsp;wiki名称&nbsp;verby Tevinv0.0.1wiki版本logoamwiki/images/logo.png/assets/logo.pnglogo图片&nbsp;colour#4296eb/assets/logo界面颜色github-url无你的github项目url作为github附属wikipage-mountsfalse&nbsp;true页面挂载数据imports无assets/bwb.css引入自己的css/js &nbsp;最好的地方就是，作者允许使用自己的css/js，举个例子：① 可玩点一：修改界面样式。我希望把文库也改成类似自己博客的界面，风格统一，那么可以建立一个assets文件夹，创建文件bwb.css。在bwb.css中，通过复写元素的样式就能够覆盖，比如审查头部的背景，class名称叫header：我们编写一个：/*头部*/\n.header&#123;\nbackground-color: #242424;\nborder-top:none;\n&#125;头部就从蓝白变成了全黑：完整的界面对比和bwb.css代码如下，你可以参考：a&#123;\ncolor:#478cdc;\n&#125;\n/*头部*/\n.header&#123;\nbackground-color: #242424;\nborder-top:none;\n&#125;\n.header .logo &#123;\npadding-top: 5px;\n&#125;\n\n\n\n.header .logo img &#123;  max-height: 59px;&#125;\n.header .logo i &#123;  display:none;&#125;\n.header .logo b &#123;  height: 59px;  color:#f2f2f2;  line-height:59px;&#125;/主体背景/.container&#123;  background-color:#f1f5f8;  border: none;  border-radius: 4px;  box-shadow: 0px 0px 5px #f2f2f2;  box-sizing: border-box;  overflow:hidden;&#125;/左侧菜单/.menubar&#123;  border-right: 1px solid #eee;&#125;.menu-filter svg &#123;  color:#478cdc;&#125;.menu-search svg &#123;  color:#478cdc;&#125;.menubar h4.on svg &#123;  color:#478cdc;&#125;.menubar h4.on a &#123;  color:#478cdc;&#125;.menubar h4, .menubar h5 &#123;  border:1px solid #FFFFFF;&#125;.menu-search&#123;  border-left:none;  border-bottom: 1px solid #eee;&#125;.menu-filter&#123;  border-bottom: 1px solid #eee;  padding-left: 6px;  width: 205px;&#125;.menu-filter input &#123;  border-bottom: none;  width:170px;  text-align: left;  height:30px;&#125;.menu-filter i &#123;  line-height: 36px;  margin-top:2px;&#125;.menu-filter:hover input &#123;  border-bottom: none;&#125;.menu-filter input:focus &#123;outline: none;  border-bottom: none;&#125;.menu-filter svg&#123;  display:none;&#125;.container .nav &#123;  background-color: #ffffff;  border:none;&#125;/右侧内容/.main-inner&#123;  background-color: #ffffff;  border:none;&#125;/搜索功能/.search-update input &#123;  background-color: #eee;  font-weight: 300;  text-decoration: none;  text-align: center;  cursor: pointer;  border: none;  border-radius: 15px;  height: 30px;  line-height: 28px;  padding: 1px 10px;  width: 110px;  font-size:14px;  color: #666;&#125;.search-update input[disabled] &#123;  color: #ccc;  background: #f2f2f2;  border: #aaa 1px solid;  padding: 1px 10px;  border-radius: 15px;  cursor:not-allowed;&#125;.search-update input:hover&#123;  background-color: #f4f4f4;&#125;.search-input input[type=”button”] &#123;  font-size: 14px;  background-color: #1B9AF7;  color:#f2f2f2;  border: none;  height: 44px;  padding-left:3px;  padding-right:3px;  outline:none;&#125;.search-input input[type=”button”]:hover&#123;  background-color: #41afff;&#125;\n.search-input&#123;  padding-right: 105px;&#125;\n.search-input input[type=”text”]&#123;  border-color:#eee;  font-size: 14px;  padding:11px;&#125;.search-input input[type=”text”]:focus&#123;  border-color:#478cdc;  box-shadow: none;&#125;\n/返回顶部/aside .contents&#123;  background: #eee;  color: #666;  box-shadow: 0px 0px 5px #f2f2f2;  border: 1px solid #f2f2f2;&#125;aside .contents-list&#123;  background: #fafafa;  border: 1px solid #eee;&#125;aside .contents a&#123;  color: #444;&#125;\naside .contents a:hover&#123;  color: #478cdc;&#125;aside .contents .markdown-contents ol li&gt;i&#123;  color: #666;  background-color: #f2f2f2;  padding: 0 5px;  border-radius: 4px;  line-height: 20px;&#125;aside .back-top&#123;  background: #eee;  color: #666;  box-shadow: 0px 0px 5px #f2f2f2;  border: 1px solid #f2f2f2;&#125;\n/底部签名/.signature&#123;  display:none;&#125;\n/markdown语法/.markdown-body h1 &#123;  margin-top: 50px;  font-size: 30px;&#125;.markdown-body h2 &#123;  font-size: 26px;&#125;.markdown-body h3 &#123;  font-size: 22px;&#125;.markdown-body code, .markdown-body tt &#123;padding: 0;font-size:14px;background-color:#f1f8ff;color: #0366d6;height:20px;margin:5px 3px;padding:3px 0px;white-space: normal;line-height:2.0;&#125;.markdown-body img &#123;  text-align:center;  margin: 10px auto;  display:block;&#125;.markdown-body table &#123;  margin-left:auto;  margin-right:auto;  width:auto;  display:table;&#125;\n.markdown-body pre code &#123;    font-size:14px;&#125;\n@media screen and (max-width: 720px)&#123;  .header .logo img&#123;    display:none;  &#125;  .header .logo b &#123;      line-height:49px;      height:49px;  &#125;  .header .logo &#123;    padding-top: 0;  &#125;  .container&#123;    background-color:#f1f5f8;    border: none;    border-radius: none;    box-shadow: none;    box-sizing: border-box;    overflow:hidden;  &#125;  .container .nav&#123;    background: #242424;  &#125;  .menu-filter&#123;    width:100%;  &#125;&#125;② 可玩点二：引入一些成熟的CSS。作者只允许在config.json中引入一个CSS，其他的CSS会失效，但是我们可以在CSS里面写引入的语句。这使得功能变得强大，比如我想要使用font-awesome4.7.0的图标，百度网盘（密码vxl4），那么把font-awesome插件下载到assets目录下：再在bwb.css开头（注意是开头，写在结尾无效）写引入语句：/引入其他css/@import \"font-awesome/css/font-awesome.min.css\";就能够在markdown里面使用啦&lt;font color=\"#478cdc\"&gt;&lt;i class=\"fa fa-globe\"&gt;&lt;/i&gt;&lt;/font&gt;效果：使用amwiki的姿势（1）剪贴板功能QQ截图后，直接使用ctrl+shift+v，或者菜单栏amWiki轻文库→从剪贴板粘贴截图，就能够自动帮你保存图片并写好markdown：更好的是，它可以根据文档所在目录自动创建文件夹，让你的图片可以按文章分类。（2）善用搜索功能虽然amwiki没有标签，但是可以搜索文章内容是非常无敌的。先更新缓存到100%，再搜索：（3）手机端观看amwiki支持自适应（虽然写得并不太好），手机端也是可以浏览、搜索、查看的哦。（4）打开实时预览编写Markdown在Atom中按Ctrl+shift+m可以打开Markdown实时预览amwiki v1.2.1的bug字符被转码当输入\\n的时候会被转义为&amp;#39;。原因是这一段，来源于amWiki\\js\\amWiki.docs.js：content = content.replace(/\\(.)/g, function (m, s1) &#123;      return '&amp;#' + s1.charCodeAt(0) + ';';&#125;);看��下作者的wiki：………………目测是开发中状态，而且和作者交流后，发现作者已经用上了自己开发好了的版本了……没办法，把这段注释掉就好了，不过用不上这个新功能了。记得注释C:\\Users\\BEWINDOWEB.atom\\packages\\amWiki\\files下amWiki.docs.js中的内容，这样再次用config.json生成的时候就一直会是注释状态，否则只注释项目内的amWiki.docs.js，重新生成的时候会被重写。img.toPng() is not a functionAtom 1.28.0版本已经将Electron升级到2.0版本了。而Electron v2.0的NativeImage.toPng函数已经被移除，取而代之的是NativeImage.toPNG。所以修改这个代码即可。解决方法参见《amwiki报错：img.toPng is not a function》使用github托管wiki如果没有合适的服务器，完全可以用github来托管，和普通的上传项目的方式一致：create项目→ push本地仓库 → push到github。不过建立的项目名称必须为：username.github.io，比如我的wiki为bewindoweb.github.io，他会自动识别的，一打开就是home-首页.md的内容。赶紧尝试动手搭一个吧~你还可以通过github项目→Settings→Github Pages→Custom domain自定义其他的域名。当然，你要提前在域名解析上面添加CNAME指向wiki的地址。还能够强制启用HTTPS，不过这个证书是github的，在Chrome上会有拦截信息，这样wiki.bewindoweb.com也能访问它了。                \n","categories":["转载"],"tags":[]},{"title":"搭建strongswan服务器","url":"http://tanqingbo.cn/2019/10/06/搭建strongswan服务器/","content":"\nhttp://www.bewindoweb.com/123.html一、快速搭建strongswan（一切自动）1、购买一台Linode服务器。系统选择CentOS7，硬盘分配20244MB，交换内存分配256MB，设置相应的root密码，点击Boot启动服务器。系统：选择CentOS 7\n硬盘分配：20244MB（和那个max的数字一致）\n交换内存分配：256MB（默认即可）\nroot密码：登录这台服务器需要的密码2、用Xshell 4连接上这台服务器。【第一步】配置连接中的名称、主机、端口号。名称：随便填\n主机：服务器的ip地址（通过linode上的dashboard查看）\n端口号：22（linode一般都是22）【第二步】配置用户身份验证中的用户名和密码。用户名：root\n密码：刚才创建的时候填的密码3、自动安装strongswan【第一步】更新yum源yum –y update【第二步】安装epel源。strongSwan的发行版已包含在EPEL源中，目前的版本是5.5.3。yum -y install epel-release【第三步】安装strongswanyum -y install strongswan注意：使用yum安装，命令ipsec被替代为strongswan。可设置别名来解决这个问题： alias ipsec='strongswan'，不过这里不用设置，就用strongswan命令。记录一下，方便以后查阅。 &nbsp;【第四步】查看当前安装的strongswan版本strongswan --version\n提示：Linux strongSwan U5.5.3/K4.9.50-x86_64-linode864、使用脚本自动颁发证书【第一步】进入ipsec.d目录cd /etc/strongswan/ipsec.d【第二步】获取服务器端证书脚本wget https://raw.githubusercontent.com/michael-loo/strongswan_config/8c6721a4a49ac0382ee9d48ed99abce676bde1c0/server_key.sh【第三步】修改文件权限为可执行chmod a+x server_key.sh【第四步】执行脚本，YOUR_SERVER_IP换成你的服务器的ip地址（刚刚填过）./server_key.sh YOUR_SERVER_IP【第五步】获取客户端证书脚本wget https://github.com/michael-loo/strongswan_config/raw/8c6721a4a49ac0382ee9d48ed99abce676bde1c0/client_key.sh【第六步】修改文件权限为可执行chmod a+x client_key.sh【第七步】执行脚本，YOUR_NAME填写你的名字（任意取），YOUR_EMAIL@qq.com填写你的邮箱（任意）./client_key.sh YOUR_NAME YOUR_EMAIL@qq.com在执行的过程中，会提示你输入.p12证书文件的密码，这个密码的意思是，如果以后别人有.p12证书文件，在安装证书的时候需要输入这个密码，否则无法安装证书，这样就避免了证书泄露给别人，然后别人用证书使用你搭建的服务器的风险。Enter password to protect p12 cert for xxx\nEnter Export Password:YOUR_CERT_PASSWORD5、配置ipsec.conf【第一步】打开文件ipsec.confvi /etc/strongswan/ipsec.conf【第二步】按i键进入insert编辑模式i【第三步】删除文件中的其他文本，替换成以下内容config setup\n  uniqueids=never\n  charondebug=\"cfg 2, dmn 2, ike 2, net 0\"\n\n\n\nconn %default    left=%defaultroute    leftsubnet=0.0.0.0/0    leftcert=vpnHostCert.pem    right=%any    rightsourceip=10.0.0.0/24\nconn xauth_pubkey_ikev1    keyexchange=ikev1    fragmentation=yes    rightauth=pubkey    rightauth2=xauth    leftsendcert=always    rekey=no    auto=add\nconn xauth_psk_ikev1    keyexchange=ikev1    leftauth=psk    rightauth=psk    rightauth2=xauth    auto=add    dpdaction=hold    dpddelay=600s    dpdtimeout=5s    lifetime=24h    ikelifetime=240h    rekey=no\nconn pubkey_ikev2    keyexchange=ikev2    leftauth=pubkey    rightauth=pubkey    leftsendcert=always    auto=add\nconn eap_ikev2    keyexchange=ikev2    ike=aes256-sha1-modp1024!    rekey=no    leftauth=pubkey    leftsendcert=always    rightauth=eap-mschapv2    eap_identity=%any    auto=add【第四步】按ESC，输入冒号+wq保存修改。wq的含义是write and quit。ESC:wq6、配置strongswan.conf【第一步】打开strongswan.confvi /etc/strongswan/strongswan.conf&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 30px;=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;【第二步】编辑、保存的操作方式同5，以下是要修改的内容 &nbsp;charon &#123;    load_modular = yes    duplicheck.enable = no    compress = yes    plugins &#123;        include strongswan.d/charon/*.conf    &#125;  \ndns1 = 8.8.8.8  \ndns2 = 8.8.4.4  \nnbns1 = 8.8.8.8  \nnbns2 = 8.8.4.4  \n}include strongswan.d/*.conf7、创建VPN帐号【第一步】打开ipsec.secretsvi /etc/strongswan/ipsec.secrets【第二步】添加用户和密码，可以添加很多个。注YOUR_PSK_KEY填写一个复杂的连接VPN的密码，YOUR_USERNAME填写登录用户名，YOUR_PASSWORD填写登录密码。注意：所有的空格、引号都不能去掉！尤其是冒号左右的空格: RSA vpnHostKey.pemPSK \"YOUR_PSK_KEY\"YOUR_USERNAME %any : EAP \"YOUR_PASSWORD\"YOUR_USERNAME %any : XAUTH \"YOUR_PASSWORD\"以后如果要添加新的帐号，修改完这个文件后，要重启strongswan：systemctl restart strongswan8、打开ipv4的转发功能【第一步】打开sysctl.confvi /etc/sysctl.conf【第二步】加入ipv4转发。把以下内容写到sysctl.conf里面net.ipv4.ip_forward=1net.ipv6.conf.all.forwarding=1net.ipv4.conf.all.accept_redirects = 0net.ipv4.conf.all.send_redirects = 0【第三步】更新sysctl -p\n提示：net.ipv4_ip_forward=1……9、打开防火墙并添加ipsec服务【第一步】打开防火墙，并查看是否开启成功。systemctl start firewalld\nsystemctl status firewalld【第二步】添加ipsec服务，每执行一条就会提示一次successfirewall-cmd --permanent --add-service=\"ipsec\"  \nfirewall-cmd --permanent --add-port=4500/udp  \nfirewall-cmd --permanent --add-masquerade  \nfirewall-cmd --reload10、开启strongswan服务systemctl start strongswan  \nsystemctl enable strongswan至此，服务器搭建完成，已经可以用PSK密码+用户名+密码登录使用了。二、客户端的配置1、ios11（iphone 7 Plus）直接使用PSK+用户名+密码登录。2、ios11（ipad pro 2017）直接使用PSK+用户名+密码登录。&nbsp;3、mac OS X（mac air）&nbsp;直接使用PSK+用户名+密码登录。&nbsp;4、windows 10使用证书登录，安装证书的方法：【第一步】下载.p12证书。用Xftp 4连接上服务器，然后下载etc/strongswan/ipsec.d/YOUR_NAME.p12到本地。【第二步】win+R，输入certmgr.mscwin + R\ncertmgr.msc【第三步】导入.p12证书。个人上面点右键，所有任务，导入。选择.p12文件输入证书保护密码：YOUR_CERT_PASSWORD【第四步】移动strongswan Root CA证书到受信任的根证书颁发机构→证书里面【第五步】控制面板→网络和Internet→网络和共享中心：设置新的连接或网络→连接到工作区→配置相关信息。【第六步】进行特殊设置：《strongswan在win10上能连接但无法访问》这样就能连上strongswan服务器了。5、windows 8使用VPN Access Manager软件，用PSK+用户名+密码登录。【第一步】点击add按钮【第二步】添加如下配置：General选项卡：\n        Remote Host / Host Name or IP Address：填写你的服务器ip\n        Port：500\nClient选项卡：\n        Maximun packet size：1500\nAutheritication选项卡：\n        Authentication Method：Mutual PSK+ XAuth\n        Credentials：\n                 Pre Shared Key：YOUR_PSK_PASSWORD\nPhrase1选项卡：\n        Exchange Type：main\nPhrase2选项卡：\n        PFS Exchange：auto6、android（miui 9）无法连接上，原因是ipsec.conf有问题，暂时没时间去查找怎么改。&nbsp;任何连接的问题都可以通过tail -n40 /var/log/messages查看运行日志找到原因三、参考链接1、英语网页《Setup a IPSEC on Centos 7 using Strongswan》2、《使用strongswan搭建ipsec服务器》3、《在CentOS 7 上使用strongswan搭建Ipsec》4、��CentOS7安装strongswan配置梯子科学上网》5、《CentOS出现“FirewallD is not running”怎么办》6、《CentOS系统上安装strongswan搭建Ipsec服务器》7、《CentOS7下Strongswan架设IPSec-IKEv1, IKEv2, L2TP》8、《CentOS使用strongswan架设》9、《使用strongswan架设ipsec》10、《【译】IPSEC.CONF(5) － IPsec配置详解》11、《配置IPsec VPN（Strongswan）》12、《StrongSwan 搭建IPsec (IKEv1 and IKEv2) 实现不同局域网之间通讯》                \n","categories":["转载"],"tags":[]},{"title":"搭建自己的git服务器管理网站代码","url":"http://tanqingbo.cn/2019/10/06/搭建自己的git服务器管理网站代码/","content":"\nhttp://www.bewindoweb.com/210.html前言网站有太多的功能想加了，然而并不希望在线调试代码，所以想到了用git。当然不只是git而已，还需要能够预览修改后的效果。所以最开始准备在本地windows 8搭建一个NMP环境，其实搭建过程还好，然而在windows下安装nginx时出了问题，我使用了一个nginx插件subs_filter，在linux下可以很方便地重新编译把插件装上，但是在windows下就直接给的编译好的代码，感觉又得搭一个windows编译环境，好心累……所以放弃这个方案。第二个方案是本地采用vmware虚拟机，然后通过桥接接到主机，每次打开vmware作为本地环境来预览效果。我的计划总是那么美，实现起来总是那么困难，光是安装debian 8.2就装了好久，大概做了这些：（1）vmware 10不支持debian 8以上，需要重装vmware 14（2）安装debian的过程中总是出错，我以为是安装包有问题，换了好几个，每次都得下载一晚上（3）终于找对了方法，原来是没有安装grub引导。但是在更新APT的时候，总是连接不上服务器，又搞了好久。（4）终于差不多搞好了，一开机，中文显示方块……又用英文重装，然后再查各种办法解决中文方块的问题（至今未解决，如果你有好的办法还请评论或者邮件教教我）。于是放弃debian 8.2，转为安装ubuntu，然而，我之前写的debian下一键搭建LNMP环境脚本在ubuntu上是因为一些差异用不了的……意味着我要重新一步一步地搭LNMP……这就是我这么多天没更新文章的原因(╯°Д°)╯︵ ┻━┻我投翔，我投翔还不行吗！！！第三个方案，用之前买的其他的服务器作为“本地环境”，虽然有外网暴露降低网站权重或者出现内部错误代码给攻击机会的危险，但是只要全站反爬+神奇端口+最重要的跪求各位小伙伴不要攻击我这个菜鸡做的根本没有几个人访问的全是bug的十八线小网站，就好了吧……一、准备环境拓扑是这样的：网站服务器WS，就是你看到的本站的服务器啦。WS上我们主要需要做的是git服务器配置；开发服务器DS，就是找的其他的服务器。DS上主要做的是配置git本地环境；本地机PC，就是写代码的电脑了。也就是说，预想的正确操作是：PC用PhpStorm开发代码���用自带的ssh提交功能提交到开发服务器上，DS提供web预览，及时地预览效果，当效果稳定后，使用git提交到网���服务器，就完成了功能迭代。同时git还能够做版本控制，想想都有点小激动呢~有关如何搭建LNMP环境、如何配置PhpStorm的ssh，百度一下会出来很多资料，也可以评论和邮件我，这里不多介绍。相关的版本一览：机器软件版本WS/DS操作系统Debian 8.2&nbsp;WS/DSgit&nbsp;2.1.4二、git服务器的搭建1、WS：添加apt的163源这里的源是163提供的给Debian 8（Jessie）的源，你可以自己去寻找适合自己版本的163源、清华大学镜像站源等等。vi /etc/apt/sources.list加入：deb http://mirrors.163.com/debian/ jessie main non-free contrib\ndeb http://mirrors.163.com/debian/ jessie-updates main non-free contrib\ndeb http://mirrors.163.com/debian/ jessie-backports main non-free contrib\ndeb-src http://mirrors.163.com/debian/ jessie main non-free contrib\ndeb-src http://mirrors.163.com/debian/ jessie-updates main non-free contrib\ndeb-src http://mirrors.163.com/debian/ jessie-backports main non-free contrib\ndeb http://mirrors.163.com/debian-security/ jessie/updates main non-free contrib\ndeb-src http://mirrors.163.com/debian-security/ jessie/updates main non-free contrib2、WS：root用户下安装git和sudoapt-get install git\napt-get install sudo3、WS：root用户下添加用于git的用户adduser bwb密码一定要输哦，这个密码是登录这个账户的密码。4、WS：root用户下给bwb用户sudo权限vi /etc/sudoers添加：bwb     ALL=(ALL:ALL) ALL并使用wq!进行强制保存。5、DS：创建ssh的密钥cd ~/.ssh\nssh-keygen -t rsa会提示输入密码，这个密码是这个密钥的密码，推荐输入哦（虽然不输入也能成功）。如果没有.ssh目录的话，可以手动创建一个。6、DS→WS：拷贝id_rsa.pub可以使用类似xftp4这类ftp工具，把生成的id_rsa.pub从DS拷贝到WS上。如果使用xftp4的话，注意通过菜单栏的工具→选项，勾选“显示隐藏的文件”来看到.ssh这个隐藏目录。7、WS：配置好ssh从root用户进入（或者直接从bwb用户进入）：su bwb\nsudo mkdir ~/.ssh\nsudo cd ~/.ssh\nsudo cat id_rsa.pub &gt;&gt; authorized_keys\nsudo service ssh restart（1）如果没有.ssh才创建.ssh（2）这里的id_rsa.pub注意填为你拷贝的文件路径。（3）配置好后，你可以在DS上通过：touch test.txt\nscp -r test.txt bwb@xxx.xxx.xxx.xxx:/home/bwb来观察test.txt有没有拷贝到WS上的/home/bwb目录下。这里的xxx.xxx.xxx.xxx是WS的IP，当然你也可以填网址域名。8、WS：bwb用户下配置git服务器我们全程假设web工程的目录为/home/testweb。（1）进入目录cd /home/testweb（2）初始化空仓库git init会提示：初始化空的 Git 版本库于 /home/testweb/.git/（3）修改configvi .git/config加入：[receive]\n      denyCurrentBranch = ignore（4）修改hook新建一个hookvi .git/hooks/post-receive加入：#!/bin/sh\nGIT_WORK_TREE=/home/testweb  git checkout -f（5）加入README.mdtouch README.md（6）加入工程下的所有的文件到gitgit add .注意后面的点哦。（7）提交到本地仓库git commit -m \"Initial commit\"9、DS：配置本地git（1）安装环境和前面配置源、安装git的操作一致，只需要这两步就可以了。（2）克隆项目：git clone bwb@xxx.xxx.xxx.xxx:/home/testweb会提示输入密码，这是之前设置的id_rsa的密码。（3）[ 可选 ] 创建robot.txt禁止爬取所有文件：vi robot.txt加入：User-agent: *\nDisallow: /（4）[ 可选 ] 创建不想被上传的文件的规则：vi .gitignore加入：#self\n/.gitignore\n\n\n\n#robotrobot.txt（5）测试是否成功echo \"123\" &gt;&gt; README.mdgit add .git statusgit commit -m \"test\"git pushgit status是在提交前查看一下要提交的有哪些东西，可以不用这条命令。10、限制bwb账户的权限如果前面的成功了，基本就搭建完了。这里只是为了更安全限制bwb的权限，只能git，不能登录，且不能用sudo提权了：（1）修改shell权限vi /etc/passwd把：bwb:x:1000:1000:,,,:/home/bwb:/bin/bash改为：bwb:x:1000:1000:,,,:/home/bwb:/usr/bin/git-shell（2）修改sudo权限vi /etc/sudoers把之前添加的：bwb     ALL=(ALL:ALL) ALL用#注释掉：#bwb     ALL=(ALL:ALL) ALL注意使用wq!强制保存，恭喜你，搭建完成了~附录：相关问题解决参考1、为什么WS在config里面加denyCurrentBranch = ignore？因为如果不加的话，DS进行push就会报错，大意是它不是个裸仓库：remote: error: refusing to update checked out branch: refs/heads/masterremote: error: By default, updating the current branch in a non-bare repositoryremote: error: is denied, because it will make the index and work tree inconsistentremote: error: with what you pushed, and will require 'git reset --hard' to matchremote: error: the work tree to HEAD.remote: error:remote: error: You can set 'receive.denyCurrentBranch' configuration variable toremote: error: 'ignore' or 'warn' in the remote repository to allow pushing intoremote: error: its current branch; however, this is not recommended unless youremote: error: arranged to update its work tree to match what you pushed in someremote: error: other way.remote: error:remote: error: To squelch this message and still keep the default behaviour, setremote: error: 'receive.denyCurrentBranch' configuration variable to 'refuse'.2、为什么WS要加那个hook？因为如果不加hook的话，DS进行push，WS是看不到结果的，因为没有更新worktree。你用在WS上使用git status就能看出区别了，它一直停留在master分支上。解决方法是手动更新：git reset --hard但是这样太麻烦了，所以加hook，加了的话，就会自动更新，hook的意思就是“if做了什么操作，then就去做什么操作”，它帮你完成了。3、为什么不使用git init –bare？这是一个我研究了好久并且实践过的问题，答案是，–bare不适合web代码管理。（1）外观首先来看一下 git init --bare（以下简称bare）和git init（以下简称init）的外观区别：init会创建一个.git的隐藏文件夹，内容有branches、config、description、HEAD、hooks、info、objects、refs；bare不会创建.git文件夹，而是直接在当前文件夹下创建同样的这些内容。（2）功能init可以在git服务器上执行git操作；bare不能在git服务器上执行git操作，会报错：This operation must be run in a work tree（3）本质init的本质是会创建工作目录，而bare的本质是只记录历史信息，不维护工作目录。因此，init适合于web项目的维护，可以在WS上实时地看到更新后的完整的web项目文件。而bare适合于多人的项目维护，不需要在远端仓库看到更新后的工作目录，只需要记录每个人操作了些什么东西即可。如果用bare维护web项目，DS进行push后，WS是没有任何反应的（当然会更新objects文件，只是其他文件没有反应），并且不能在WS上执行任何git操作。所以应该使用init。4、我更新了.gitignore，该怎么让它重新生效？git add . //重新提交 .ignore文件git rm -r --cached . //清空缓存git add . //重新提交 所有文件git commit -m \"update .gitignore\"git push注意命令中的点。5、我错误地创建了新用户，该怎么撤销？userdel -r bwbbwb为你不想创建的用户。6、git clone的时候提示失败：Host key verification failed提示：Are you sure you want to continue connecting (yes/no)?Host key verification failed.fatal: Could not read from remote repository.这是因为你输入的是回车而不是“yes”，输入yes即可。7、Please tell me who you are？跟着提示设置一下config即可：git config --global user.email \"&#x79;&#111;&#117;&#64;&#101;&#x78;&#x61;&#109;&#112;&#x6c;&#101;&#x2e;&#x63;&#x6f;&#x6d;\"git config --global user.name \"Your Name\"它的实质是去修改.git/config文件。8、ssh连接提示Permission denied (publickey)？首先检查你是否有那个文件的权限（比如它是root用户才能访问的文件夹），如果没有请赋予权限：chown -R bwb:bwb home/testweb然后检查是否把DS的id_rsa.pub的内容成功添加进WS的authorized_keys了。最后非常可能的就是你配错了用户。比如你把DS的id_rsa.pub配到WS的root用户的authorized_keys里去了，结果后面访问的ssh又是bwb用户，当然被拒绝了。如果还不行，debian操作系统可以查看/var/log/auth.log，其他操作系统可以查看/var/log/secure，然后：tail -n100 /var/log/auth.log|grep sshd来观察到底有没有进行过连接、到底是哪个地方出了问题。9、.gitignore的常见语法#忽略文件test.txt\n#忽略根目录下的文件/test.txt\n#忽略指定目录下的文件/src/test.txt\n#忽略目录/test\n#忽略文件夹，但不忽略其中的某些文件/test!/test/test.txt10、robot.txt常见语法robot.txt在线生成简书的robot.txt爱奇艺的robot.txt最简单的配置：User-agent: * 这里的代表的所有的搜索引擎种类，是一个通配符Disallow: / 这里定义是禁止爬寻站点所有的内容                \n","categories":["转载"],"tags":[]},{"title":"特征归一化特性及其数学原理推导","url":"http://tanqingbo.cn/2019/10/06/特征归一化特性及其数学原理推导/","content":"\nhttp://www.bewindoweb.com/216.html前言买了本《百面机器学习》看着玩，虽然已经毕业了，机器学习还是放不下吧，希望以后新的机会出现能够及时抓住。书中第一章「特征工程」的“01 特征归一化”（第002-003页）提到：对数值类型的特征做归一化可以将所有的特征都统一到一个大致相同的数值区间内。最常用的方法主要有以下两种。（1）线性函数归一化（Min-Max Scaling）。它对原始数据进行线性变换，使结果映射到[0, 1]的范围，实现对原始数据的等比缩放。归一化公式如下其中，X为原始数据，Xmax、Xmin分别为数据最大值和最小值。（2）零均值归一化（Z-Score Normalization）。它会将原始数据映射到均值为0、标准差为1的分布上。具体来说，假设原始特征的均值为μ、标准差为σ，那么归一化公式定义为：我平时使用的全是线性函数归一化……因为比较简单也好理解。零均值归一化看到过，但是不知道该用在哪里，接下来仔细地分析一下相关的内容，以及感兴趣的数学知识。一、为什么需要对数值类型的特征做归一化？这是《百面》提出的问题。官方解答是通过一个形象的随机梯度下降例子：假设有两种数值型特征，x1的取值范围为[0, 10]，x2的取值范围为[0, 3]，于是可以构造一个目标函数符合图1.1(a)中的等值图。在学习速率相同的情况下，x1的更新速度会大于x2，需要较多的迭代才能找到最优解。如果将x1和x2归一化到相同的数值区间后，优化目标的等值图会变成图1.1(b)中的圆形，x1和x2的更新速度变得更为一致，容易更快地通过梯度下降找到最优解。用人话来讲就是，归一化使得特征的变化更容易用统一标准去衡量了。这个例子其实来源于斯坦福机器学习公开课的一节，课题是我们想要去预测房价，假设存在这样一个函数：注意这里的x1是真实的变量，而《百面》中提到的x1��这里的参数θ1（估计是为了避嫌更换了名称），把θ称作参数更符合思维习惯。这个函数里的y是预��房价，x1是房间大小（1~100平方米），x2是房间数量（1~4间）。我们都知道房间越多、房间越大，房子越值钱，但不知道具体“50平方米2间房”和“60平方米1间房”哪个更值钱。所以现在有一批[房间大小, 房间数量, 房价]的训练数据，我们用这批数据去求得使得大部分数据都符合这个公式的参数θ1、θ2，不就得到房价预测模型了吗？以后输入房间大小、房间数量，代入公式，就得到了预测房价。那么“大部分都符合”这个标准用数学量化出来就是“损失函数最小”。命题转变为了求解使得损失函数最小的参数θ1、θ2。损失函数很容易定义为预测房价和真实房价差值的平方（为了取正数）：损失函数值越小，说明预测房价和真实房价的差距越小，预测越精准。可以想象的是，当没有归一化的时候，x1=50，x2=2，y(real)=100，我们可以取1*50+25*2 - 100，也可以取0.2*50+45*2 -100，他们的值都是0，然而θ1的取值范围波动会小一些，θ2的取值范围波动巨大，如果画出等值线，就会是θ1进行缓慢地变化θ2剧烈变化的椭圆；当归一化之后，x1=0.5，x2=0.5，y(real)=1，那么取值1*0.5+1*0.5-1，或者0*0.5+2*0.5-1，会发现参数变化更加均匀一些了，等值线（等高线）也就越趋近于圆。所以，用原始的量纲不同、取值范围差异较大的两个特征，去进行梯度下降寻找最优解，未归一化的话这个圆会变得很尖，归一化了圆就会更圆，但程序不知道啊，它会通过梯度下降去迭代，未归一化的数据更容易产生“之”字型走法来迭代寻找最优解，归一化的数据更容易走直线快速找到最优解。但这只是讲了归一化的好处——提升模型收敛速度，并没有讲不归一化会发生什么。不归一化的最大坏处在于“数值小的特征变化失去意义”，举个例子（我以前就干过这样的事……）：我们已知平面上有很多点(x, y)，现在取一个点(x0, y0)=(0,0)，找出和它最近的2个点。x的取值范围是-1~1，y的取值范围是-1000~1000(0.1,100)\n(0.2,300)\n(0.2,100)\n(0.3,300)我们会发现，当计算距离的时候，y的取值很大程度地影响了距离的值，y稍微一变化，距离就变化很大。x重要吗？根本不重要！完全和已知在纵轴上，y0=0，寻找最近的2个点的命题几乎一样：y1=100\ny2=300\ny3=100\ny4=300最近的仍然是y1、y3，哪怕你有一个(x5,y5)=(1,300)，x变化再剧烈，最近邻也轮不到你。效果就是，x这个特征似乎消失了。所以，归一化在维数非常多的时候，可以防止某一维或某几维对数据影响过大。二、归一化和标准化的取舍虽然可以统称为归一化，但是我更愿意称线性函数归一化（Min-Max Scaling）为极大极小归一化（Min-Max Normalization），称零均值归一化（Z-Score Normalization）为零均值标准化（Z-Score Standardization）。因为极大极小归一化的方法是，根据极值，将所有内部值压缩到[0,1]区间；而零均值标准化做的是，根据所有数值，将分布转为标准正态分布，均值为0，方差为1，取值[-1,1]。在实际使用过程中深有体会，当用极大极小归一化时，如果不是已经知道极值（比如0~255），一旦有新的数据（比如Haar特征）加入，根据固定的极值（当前数据最大最小值）去压缩，就可能产生超过1或者小于0的特征值，但是在处理上会方便许多；采用零均值标准化的话，由于可能取到负值，而且新进来的数据依然可能越界，其实都不好使……那么，应该如何取舍归一化和标准化呢？（1）如果对输出结果有要求，或者数据比较稳定，用归一化。（2）如果存在一些异常值和噪音，数据符合正态分布，用标准化。（3）如果涉及距离度量计算相似性（比如KNN、Kmeans聚类）、或者PCA，用标准化。前面两个都好理解，数据稳定，用极值方便；有异常或噪音，用标准化保证整体数值分布。我们来仔细分析一下第三点，首先推导零均值标准化原理。正态分布的期望从定义开始推导正态分布也叫高斯分布，期望有很多种推导方式，比如极坐标这种很秀的推导方法，我们只记最简单的Γ函数推导就好了。（1）推导E(x)到合适的地方已知一般正态分布：其概率密度函数为：根据期望的定义有：换元积分，令：则E(x)可以改写为：左式为奇函数在对称区间的积分，积分为0，而右边是偶函数在对称区间的积分，积分为2倍半区间积分，于是：（2）推导Γ函数的特性注意到含参变量的以无穷乘积函数定义的反常积分Γ函数定义为：用分部积分法（其公式不再继续往下证明）有：��么，令：得到Γ函数的递推公式及其推论：（3）利用Γ函数的特性所以，对E(X)再次换元：有：正态分布的方差从定义开始推导（1）推导D(x)到合适的地方同样地，进行换元，令：利用分部积分法，有：注意这里分部积分法的使用，是拆开了前面的平方，组合后面的。而且没有用网上所谓的“注意到”：虽然和分部积分法原理一样，但是除非非常熟练，看到这个积分就能想到这个导数，否则以我的视角根本不可能去“注意到”。还是分部积分法靠谱一些。（2）利用Γ函数特性第二种推导方案是利用：来进行推导。第三种推导方案是，不使用奇函数特性，使用洛必达法则推导；不使用Γ函数特性，使用双重积分+极坐标推导。第四种推导方案是，不使用分部积分法，使用一种新奇的换元方法+Γ函数特性：这里不再赘述。为什么零均值标准化能使得均值为0方差为1即需要证明，若X~N(μ,σ)，则Z=(X-μ/σ)~N(0,1)我们知道，分布函数F(x)、概率密度f(x)存在这样的关系：那么：所以，Z=(X-μ/σ)~N(0,1)为什么零均值标准化适合于距离度量、PCAPCA原理不再介绍，我们知道PCA的核心就是方差与协方差。原始特征样本协方差为（N-1是无偏估计，撇表示区分不是指导数）：那么，使用零均值标准化：而使��极大极小归一化：极大极小归一���使得协方差产生了倍数值缩放，无法消除量纲的影响；而零均值标准化对方差进行了归一化，使得量纲不会对协方差的计算产生任何影响。所以，如果需要每个特征值都对整体归一化产生一定影响的话（和分布相关的话），选择零均值归一化。三、特征归一化的使用范围《百面》上说：在实际应用中，通过梯度下降法求解的模型通常是需要归一化的，包括线性回归、逻辑回锅、支持向量机、神经网络等模型。但对于决策树模型则并不适用，以C4.5决策树为例，决策树在进行节点分裂时主要依据数据集D关于特征x的信息增益比，而信息增益比跟特征是否进行归一化是无关的，因为归一化并不会改变样本在特征x上的信息增益。但其实，看一下C4.5的信息增益比公式，样本集合D，类别数N，某类样本子集Ci，Di中属于第n类的子集D(in)，特征取值数K，||表示取元素个数，某特征X，其信息增益比为：信息增益比相当于帮决策树进行了归一化。而且其实，决策树使用了归一化，也不会有太大的问题。总结除了极大极小归一���、零均值归一化，还有一些非线性的归一化，比如log10、log2、tan等。归一化的好处真的非常之大，是机器学习入门必备的概念。这里通过一些数学推导把以前原理模糊的概念都理解透彻了，由于涉及到较多的数学，如有错误还望指正。                \n\n\n","categories":["转载"],"tags":[]},{"title":"用winpcap测试自己的通信协议（一）","url":"http://tanqingbo.cn/2019/10/06/用winpcap测试自己的通信协议（一）/","content":"\nhttp://www.bewindoweb.com/211.html一、通信协议的设计说到通信，我们肯定会想到OSI七层模型，想到TCP/IP，想到Socket。但是如果我们需要直接和物理设备通信，尤其是对实时性、安全性要求较高的时候，采用在数据链路层发送自己设计的裸包的方法是最好不过的了：第一，安全性可控。自己设计的通信协议当然可以控制想要加密什么东西了。第二，实时性。不需要经过高层的封包解包，直接向MAC地址发送裸包。第三，也是最重要的，可裁剪。我们可以裁剪掉不需要的功能，增加需要的功能，这对于有内存闪存大小限制的嵌入式设备是很有意义的。那么，该如何去设计这个通信协议呢？最简单的协议可以考虑这些内容：序号协议字段名详细描述&nbsp;1协议标识&nbsp;标记这个包是用的你的协议&nbsp;2协议版本&nbsp;当协议有多个版本后，可以协调兼容问题&nbsp;3包类型&nbsp;握手包、心跳包、数据包、断开包&nbsp;4包序号&nbsp;发送者设定序号，接受者回复同样的号&nbsp;5数据长度&nbsp;数据字段有多少字节&nbsp;6数据&nbsp;要传输的数据，可以为空&nbsp;&nbsp;7校验和&nbsp;&nbsp;校验包在传输过程中是否发生了错误当然，更深层次的协议可以去设计错误码、重传、分片、加密、压缩、FLAG字段、透传token等等，甚至还需要考虑各种开源代码是否可以使用（如果你不想开源的话，使用MIT License的代码是很好的选择）。简单包中的1~4可以看做传说中的包头（Header），我们定义自己的一个简单通信协议，称为BTP(BWB Transport Protocol)：其中：序号BTP字段名说明&nbsp;1协议标识&nbsp;0x42（大写的'B'）&nbsp;2协议版本&nbsp;0x01（1.0版本）&nbsp;3包类型&nbsp;握手请求包：0x01&nbsp;握手响应包：0x02&nbsp;心跳请求包：0x03&nbsp;心跳响应包：0x04&nbsp;数据包：0x05&nbsp;断开请求包：0x06&nbsp;断开响应包：0x07&nbsp;4包序号&nbsp;0x00~0xFF循环使用&nbsp;5数据长度&nbsp;0x0000~0xFFFF&nbsp;6数据&nbsp;要传输的数据，可以为空&nbsp;&nbsp;7校验和&nbsp;&nbsp;采用经典的CRC32一个简单BTP传输协议就设计好啦。二、使用winpcap进行简单收发包测试实验工具和平台操作系统：windows 8 / VMware14（windows xp sp3）开发软件：Visual Studio 2013 / Wireshark 2.6.2（可以运行在windows 8 上） / Wireshark&nbsp; 1.4.9（可以运行在windows xp上）[百度网盘下载（密码：bclc）]插件：WinPcap 4.1.2 源码包&nbsp; [百度网盘下载（密码：a03g）]&nbsp;实验拓扑PA端是真实的电脑，PB端是vmware开的windows xp虚拟机，虚拟机网络连接方式选择NAT模式。这样，主机上的VMnet8 Adapter就能够和虚拟机的虚拟网卡处于同一个网段中来通信了。收发包基础环境搭建【PA发包】1、搭建Visual Studio可用环境（1）文件→新建→项目→Visual C++空项目→命名为BTPsender（2）右键→添加→新建项：新建一个头文件BTPsender.h和源文件BTPsender.c（3）屏蔽安全报错相信不少VS老玩家都应该知道_s的安全报错，直接在代码里写并不是一个好的方法，修改预处理器更好，当然你也可以直接屏蔽所有的警告，这里不再赘述。调试→属性→配置属性→C/C++→预处理器→预处理器定义，添加：_CRT_SECURE_NO_WARNINGS;（4）写个helloworld测试一下：BTPsender.h#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;BTPsender.c#include \"BTPsender.h\"\nint main()&#123;\n  printf(\"1\");\n  return 0;\n&#125;2、添��winpcap支持（1）前往winpcap官网下载源码包（2）将源码包解压到合适的位置，注意路径不要带中文（3）调试→属性→配置属性→C/C++→预处理器→预处理器定义，添加：HAVE_REMOTE;WPCAP;（4）调试→属性→配置属性→链接器→输入→附加依赖项，添加：ws2_32.lib;wpcap.lib;Packet.lib;（5）调试→属性→VC++目录，包含目录添加E:\\WpdPack\\Include，库目录添加E:\\WpdPack\\Lib，这两个路径就是你刚才解压winpcap源码的路径。（6）测试一下是否引入成功：BTPsender.h添加：#include &lt;pcap.h&gt;运行，发现报错，找不到sys/time.h：我们点击这个报错进去看，发现是这几行代码：很容易能读懂，就是没有定义WIN32这个常量，导致被识别为UNIX系统，引入了UNIX的头文件，当然找不到了。解决办法就是直接注释掉整段，强行写一个#include：保存，再次运行，成功通过编译。3、发包测试（1）打开windows xp虚拟机PB，网络适配器选择NAT模式，用ipconfig /all查看虚拟网卡MAC地址，这里是00-0C-29-86-B8-C8：（2）回到主机PA，同样用ipconfig /all查看本机VMnet8的MAC地址，这里是00-50-56-C0-00-08：（3）构造一个以太网帧，数据字段就随便填写一个字符串，然后使用winpcap发送出去。这里有个知识点就是以太网帧的格式，这里使用最常见的Ethernet II，有关以太网帧的比较可以参看《四种格式的以太网帧结构》，以后也许会有机会自己写一篇。FCS：FCS就是目的MAC到数据之间的内容得到的校验和，一般用CRC32。这一部分是不需要自己添加的，网卡驱动会自行计算。数据：至于为什么数据最少要有46字节，简单的来说就是为了及时检测冲突，如果包小于64字节，那么对于相距很远的主机，很可能这边发送完了认为发送成功，那边冲突的信号还没传过来。我们所设计的协议包就是放在以太网帧的数据字段里面，所以这里先随便填写一个字符串，测试发送的通畅性。类型：类型字段表明这个帧到底是什么，比如常见的IP包，这里会写0x0800；ARP包，这里会写0x0806；PPPoE发现阶段为0x8863等等。这里随便填一个，填类型为IP包即可。不难写出这样的发包程序：BTPsender.h#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;pcap.h&gt;\n#include &lt;winsock.h&gt;\n\n\n\n#define ETHERTYPE_IP                    0x0800 /* IP */#define ERROR_GENERAL                    -1#define ERROR_FINDALLDEVS_FAILURE        -2#define ERROR_INTERFACES_NOT_FOUND        -3#define ERROR_BAD_INPUT                    -4#define ERROR_OPEN_ADAPTER_FAILURE        -5#define ERROR_SENDING_FAILURE            -6#define SEND_BUFSIZE                    1024#define SEND_TIMES                        10000#define SEND_INTVAL                        1000\ntypedef struct ETH_HEADER&#123;    u_char dest_mac[6];    u_char src_mac[6];    u_short etype;&#125;ETH_HEADER;BTPsender.c#include \"BTPsender.h\"\nint main()&#123;    pcap_t adapter;                        / 网卡句柄 /    char errbuf[PCAP_ERRBUF_SIZE];            / 错误信息buffer /    ETH_HEADER eth_header;                    / 以太网包头 */\nchar package[] = &#123; &quot;BTP test.&amp;lt;46&quot; &#125;;        /* 测试用的字符串 */\nint index;                                /* 发送buffer偏移 */\nu_char sendbuf[SEND_BUFSIZE];            /* 发送buffer */\n\npcap_if_t *alldevs;    /* 全部网卡列表 */\npcap_if_t *d;        /* 一个网卡 */\nint did;            /* 选择的网卡ID */\n\nint i;                /* 迭代 */\n\n/* 查找网卡 */\nif (pcap_findalldevs_ex(PCAP_SRC_IF_STRING, NULL, &amp;amp;alldevs, errbuf) == -1) &#123;\n    fprintf(stderr, &quot;[ERROR] pcap_findalldevs error: %s\\n&quot;, errbuf);\n    return ERROR_FINDALLDEVS_FAILURE;\n&#125;\n\n/* 选择网卡d */\nfor (d = alldevs, i = 0; d; d = d-&amp;gt;next) &#123;\n    if (d-&amp;gt;description)\n        printf(&quot;NO.%d: %s\\n&quot;, ++i, d-&amp;gt;description);\n    else\n        printf(&quot;[WARN] No description available\\n&quot;);\n&#125;\n\nif (i == 0) &#123;\n    printf(&quot;[ERROR] No interfaces found! Make sure WinPcap is installed.\\n&quot;);\n    return ERROR_INTERFACES_NOT_FOUND;\n&#125;\n\nprintf(&quot;[INFO] Enter the interface number (1-%d):&quot;, i);\nscanf(&quot;%d&quot;, &amp;amp;did);\n\nif (did &amp;lt; 1 || did &amp;gt; i) &#123;\n    printf(&quot;[ERROR] Interface number out of range.\\n&quot;);\n    pcap_freealldevs(alldevs);\n    return ERROR_BAD_INPUT;\n&#125;\n\nfor (d = alldevs, i = 0; i &amp;lt; did - 1; d = d-&amp;gt;next, i++);\n\n/* 打开网卡 */\nif ((adapter = pcap_open_live(d-&amp;gt;name,    /* 设备名 */\n                        65536,            /* 捕获数据包的长度（65536捕获所有数据包） */\n                        1,                /* 混杂模式（非0表示使用混杂模式） */\n                        1000,            /* 超时时间（0表示没有超时限制） */\n                        errbuf            /* 错误缓存（存储错误信息） */\n    )) == NULL) &#123;\n    fprintf(stderr, &quot;[ERROR] Unable to open the adapter. %s is not supported by WinPcap\\n&quot;);\n    pcap_freealldevs(alldevs);\n    return ERROR_OPEN_ADAPTER_FAILURE;\n&#125;\n\n/*目的PB的mac地址*/\neth_header.dest_mac[0] = 0x00;\neth_header.dest_mac[1] = 0x0C;\neth_header.dest_mac[2] = 0x29;\neth_header.dest_mac[3] = 0x86;\neth_header.dest_mac[4] = 0xB8;\neth_header.dest_mac[5] = 0xC8;\n\n/*源PA的mac地址*/\neth_header.src_mac[0] = 0x00;\neth_header.src_mac[1] = 0x50;\neth_header.src_mac[2] = 0x56;\neth_header.src_mac[3] = 0xC0;\neth_header.src_mac[4] = 0x00;\neth_header.src_mac[5] = 0x08;\n\neth_header.etype = htons(ETHERTYPE_IP);\n\n\n\nmemcpy(sendbuf, &amp;amp;eth_header, sizeof(eth_header));\nindex = sizeof(eth_header);\nmemcpy(&amp;amp;sendbuf[index], package, sizeof(package));\nindex += sizeof(package);\n\n/* 发包 */\nfor (i = 0; i &amp;lt; SEND_TIMES; i++) &#123;\n    if (pcap_sendpacket(adapter,    /* 网卡句柄 */\n                        sendbuf,    /* 要发送的帧 */\n                        index        /* 帧的大小 */\n        ) != 0) &#123;\n        fprintf(stderr, &quot;[ERROR] Error sending the packet: %s\\n&quot;, pcap_geterr(adapter));\n        return ERROR_SENDING_FAILURE;\n    &#125;\n    printf(&quot;packet send successed!\\n&quot;);\n    Sleep(SEND_INTVAL);\n&#125;\n\npcap_close(adapter);\nreturn 0;\n}这里���注意的是，引入了#include &lt;winsock.h&gt;，并且使用了eth_header.etype = htons(ETHERTYPE_IP);的写法，我们来看看不这样做会发生什么，用wireshark抓vmnet8的包：被识别为了802.3的帧，长度为8，巧合的是设置的IP类型也为0x0800。没错，由于网络字节序，0x0800被存储为了0x0008，导致被识别为802.3协议。一种改法是采用类似MAC地址的那种字节数组，然而这不利于使用宏定义；还有一种就是修改宏定义，改为0x0008，但是这又不利于阅读了。所以我们最好写的时候正常写，发包的时候再利用htons（也就是host to network short）函数转换：还有一点值得注意的是，发送的数据包小于46字节，也没有报错。我们先来看看在虚拟机windows xp上低版本的wireshark抓到的包是什么样的：原来后面都填充了0，一共60字节（有4字节校验码没有显示），所以推测wireshark高版本不再显示这些自动填充字节了。PA发包，PB收到相同的包，说明发包成功了~【PB收包】1、搭建Visual Studio可用环境&nbsp;与前面一样，项目名BTPrecver，文件BTPrecver.h / BTPrecver.c2、添加winpcap支持&nbsp;&nbsp;与前面一样。3、支持xp这一步的原因是因为懒得去配置windows xp下的编程环境了，我们直接在windows 8上采用vs2013来编写和编译，然后把生成的exe发到虚拟机运行即可，因此需要让程序支持xp。（1）调试→属性→配置属性→常规→平台工具集，选择Visual Studio 2013 - Windows Xp（v120_xp）（2）调试→属性→配置属性→链接器→系统→子系统，选择窗口(/SUBSYSTEM:WINDOWS)，同时注意一下所需最低版本是不是5.01：（3）调试→属性→配置属性→链接器→命令行，添加：/SUBSYSTEM:CONSOLE,\"5.01\"这一步非常重要，否则你的程序跑在windows xp上就会提示“不是有效的win32应用程序”。4、使用静态编译这样就不需要动态链接库了，把所有依赖都打包进exe：调试→属性→配置属性→C/C++→代码生成→运行库，选择多线程(/MT)：5、收包测试BTPrecver.h#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;pcap.h&gt;#include &lt;winsock.h&gt;\n#define ERROR_GENERAL                    -1#define ERROR_FINDALLDEVS_FAILURE        -2#define ERROR_INTERFACES_NOT_FOUND        -3#define ERROR_BAD_INPUT                    -4#define ERROR_OPEN_ADAPTER_FAILURE        -5#define ERROR_SENDING_FAILURE            -6#define ERROR_INVALID_DATALINK_TYPE        -7#define ERROR_COMPILE_FILTER_FALIURE    -8#define ERROR_SET_FILTER_FALIURE        -9\ntypedef struct ETH_HEADER&#123;    u_char dest_mac[6];    u_char src_mac[6];    u_short etype;&#125;ETH_HEADER;\nvoid packet_handler(u_char param, const struct pcap_pkthdr *header, const u_char *pkt_data);/ 抓包回调函数 */void format_mac(LPSTR lpHWAddrStr, const unsigned char HWAddr);/ mac地址格式化函数 */BTPrecver.c#include \"BTPrecver.h\"\nint main()&#123;    pcap_t adapter;                / 网卡句柄 /    char errbuf[PCAP_ERRBUF_SIZE];    / 错误信息buffer /    u_int netmask;                    / 掩码信息 /    char packet_filter[] = “ether src 00:50:56:C0:00:08 and ether dst 00:0C:29:86:B8:C8”; / 过滤规则 /    struct bpf_program fcode;        / 存储编译好的过滤码 */\npcap_if_t *alldevs;    /* 全部网卡列表 */\npcap_if_t *d;        /* 一个网卡 */\nint did;            /* 选择的网卡ID */\n\nint i = 0;            /* 迭代 */\n\n/*查找网卡*/\nif (pcap_findalldevs_ex(PCAP_SRC_IF_STRING, NULL, &amp;amp;alldevs, errbuf) == -1) &#123;\n    fprintf(stderr, &quot;[ERROR] pcap_findalldevs error: %s\\n&quot;, errbuf);\n    return ERROR_FINDALLDEVS_FAILURE;\n&#125;\n\n/* 选择网卡d */\nfor (d = alldevs, i = 0; d; d = d-&amp;gt;next) &#123;\n    if (d-&amp;gt;description)\n        printf(&quot;NO.%d: %s\\n&quot;, ++i, d-&amp;gt;description);\n    else\n        printf(&quot;[WARN] No description available\\n&quot;);\n&#125;\n\nif (i == 0) &#123;\n    printf(&quot;[ERROR] No interfaces found! Make sure WinPcap is installed.\\n&quot;);\n    return ERROR_INTERFACES_NOT_FOUND;\n&#125;\n\nprintf(&quot;[INFO] Enter the interface number (1-%d):&quot;, i);\nscanf(&quot;%d&quot;, &amp;amp;did);\n\nif (did &amp;lt; 1 || did &amp;gt; i) &#123;\n    printf(&quot;[ERROR] Interface number out of range.\\n&quot;);\n    pcap_freealldevs(alldevs);\n    return ERROR_BAD_INPUT;\n&#125;\n\nfor (d = alldevs, i = 0; i &amp;lt; did - 1; d = d-&amp;gt;next, i++);\n\n/* 打开网卡 */\nif ((adapter = pcap_open_live(d-&amp;gt;name,    /* 设备名 */\n                              65536,    /* 捕获数据包的长度（65536捕获所有数据包） */\n                              1,        /* 混杂模式（非0表示使用混杂模式） */\n                              1000,        /* 超时时间（0表示没有超时限制） */\n                              errbuf    /* 错误缓存（存储错误信息） */\n    )) == NULL) &#123;\n    fprintf(stderr, &quot;[ERROR] Unable to open the adapter. %s is not supported by WinPcap\\n&quot;);\n    pcap_freealldevs(alldevs);\n    return ERROR_OPEN_ADAPTER_FAILURE;\n&#125;\n\n/* 检查链路层类型 */\nif (pcap_datalink(adapter) != DLT_EN10MB) /* DLT_EN10MB指10Mb以太网 */\n&#123;\n    fprintf(stderr, &quot;[ERROR] This program works only on Ethernet networks.\\n&quot;);\n    pcap_freealldevs(alldevs);\n    return ERROR_INVALID_DATALINK_TYPE;\n&#125;\n\n/* 检查地址类型 */\nif (d-&amp;gt;addresses != NULL) /* 如果有IP地址 */\n    netmask = ((struct sockaddr_in *)(d-&amp;gt;addresses-&amp;gt;netmask))-&amp;gt;sin_addr.S_un.S_addr; /* 使用第一个掩码 */\nelse /* 如果没有IP地址，说明是C类网络（局域网） */\n    netmask = 0xffffff;    /* 掩码设置为255.255.255.0 */\n\n\n/* 编译过滤器 */\nif (pcap_compile(adapter, &amp;amp;fcode, packet_filter, 1, netmask) &amp;lt; 0) /* 1表示自动进行优化 */\n&#123;\n    fprintf(stderr, &quot;[ERROR] Unable to compile the packet filter. Check the syntax.\\n&quot;);\n    pcap_freealldevs(alldevs);\n    return ERROR_COMPILE_FILTER_FALIURE;\n&#125;\n\n/* 应用过滤器 */\nif (pcap_setfilter(adapter, &amp;amp;fcode)&amp;lt;0)\n&#123;\n    fprintf(stderr, &quot;[ERROR] Error setting the filter.\\n&quot;);\n    pcap_freealldevs(alldevs);\n    return ERROR_SET_FILTER_FALIURE;\n&#125;\n\n/* 开始抓包 */\nprintf(&quot;listening on %s...\\n&quot;, d-&amp;gt;description);\npcap_freealldevs(alldevs);\npcap_loop(adapter, 0, packet_handler, NULL);\n\nreturn 0;\n}\n/* 抓包回调函数 /void packet_handler(u_char param, const struct pcap_pkthdr *header, const u_char *pkt_data){    time_t local_tv_sec;    / 时间戳 */    struct tm *ltime;        / 本地时间 /    char timestr[16];        / 格式化后的本地时间 /    ETH_HEADER eth_header;    / 以太网帧包头 /    char str_mac[50];        / 源MAC地址 /    char dest_mac[50];        / 目的MAC地址 */    char *data;        / 数据 */\n/* 没有使用param  */\n(VOID)(param);\n\n/* 格式化当前时间 */\nlocal_tv_sec = header-&amp;gt;ts.tv_sec;\nltime = localtime(&amp;amp;local_tv_sec);\nstrftime(timestr, sizeof timestr, &quot;%H:%M:%S&quot;, ltime);\n\n/* 解析以太网帧 */\neth_header = (ETH_HEADER *)pkt_data;\nformat_mac(str_mac, eth_header-&amp;gt;src_mac);\nformat_mac(dest_mac, eth_header-&amp;gt;dest_mac);\n\nprintf(&quot;[ %s.%.6d ] receive package    \\nlength=\\t%d   \\neth type=\\t0x%x    \\nsrc mac=\\t%s    \\ndest mac=\\t%s\\n&quot;, \n                    timestr, header-&amp;gt;ts.tv_usec, header-&amp;gt;len, ntohs(eth_header-&amp;gt;etype), str_mac, dest_mac);\n\n/* 解析数据域 */\ndata = (char *)(pkt_data + 14);\nprintf(&quot;data= \\t%s\\n&quot;, data);\n}\nvoid format_mac(char* lpHWAddrStr, const unsigned char *HWAddr){    int i;    short temp;    char szStr[3];\nstrcpy(lpHWAddrStr, &quot;&quot;);\nfor (i = 0; i&amp;lt;6; ++i)\n&#123;\n    temp = (short)(*(HWAddr + i));\n    _itoa(temp, szStr, 16);\n    if (strlen(szStr) == 1)\n        strcat(lpHWAddrStr, &quot;0&quot;);\n    strcat(lpHWAddrStr, szStr);\n    if (i&amp;lt;5)\n        strcat(lpHWAddrStr, &quot;:&quot;); \n&#125;\n}然后���生成的EXE文件复制到虚拟机运行：这里值得注意的有：（1）解包的时候要使用ntohs(eth_header-&gt;etype)来把字节序展示为正常的字节序（2）过滤器的写法可以参考《WinPcap笔记（6）：过滤数据包》PA端运行发包程序，然后PB端运行收包程序，最后的结果：到这里，已经可以学会如何设计通信协议、以及使用winpcap进行发包收包了，完整的工程文件可以在这里下载（密码：qdnu）。那么接下来应用我们自己的通信协议试一试，如果有兴趣请继续浏览《用winpcap测试自己的通信协议（二）》。参考资料1、《自己设计系统之间的通信协议》2、《如何自定义一个通信协议》3、《四种格式的以太网帧结构》4、《c语言中网络字节序和主机字节序的转换》5、《WinPcap基础知识（第八课：发送数据包）》6、《关于以太网(Ethernet II)这个网络的个人理解以及应用（1）》7、《以太网帧 类型字段及值》8、《WinPcap发送接收裸包（一）》9、《WinPcap发送接收裸包（二）》10、《学习整理——以太帧、ip帧、udp/tcp帧、http报文结构》11、《以太网原理 最大帧长 最小帧长》12、《ARP欺骗源码（基于WinPcap实现）》13、《怎么让VS2015编写的程序在XP中顺利运行》14、《WinPcap笔记（6）：过滤数据包》                \n","categories":["转载"],"tags":[]},{"title":"百度IoT：MQTT Broker架构设计","url":"http://tanqingbo.cn/2019/10/06/百度IoT：MQTT Broker架构设计/","content":"\nhttp://www.bewindoweb.com/261.html��言百度IoT的Broker设计我特别想参考的但是技术能力和时间不够去实现……网上只有一篇百度工程师的总结《共享行业的分布式MQTT设计》，这里将围绕这篇文章去讲解。一、Broker集群架构单机版MQTT Broker有连接数量和并发处理能力的限制，因此分布式必不可少。百度IoT采用的Akka Cluster来做集群管理，每个节点对等，不存在像Mosquitto这种用一台机器“桥接”做分布式产生的单点故障隐患。每个节点监听MemberUp、MemberDown、MemberUnreachable、ClusterMemberState等事件来感知其他节点的上下线，用Akka Actor实现节点间的消息通信。二、Broker服务框架百度Broker抽象了很多服务包括：（1）Authentication Service、Authorization ServiceMQTT的CONNECT阶段提供username和password，Broker可以用这些数据对客户端身份进行校验，我们称为验证（Authentication，AE）；MQTT的PUBLISH、SUBSCRIBE阶段，需要对客户端订阅主题、发布主题进行权限控制，比如只能订阅含有自己DeviceID的主题，避免客户端订阅他人的主题窃听信息，我们称为鉴权（Authorization，AO）。百度Broker提供用户名、密码的认证，以及每个客户端对哪些主题可读、可写。实现上，数据全保存在Mysql，通过内存或Redis做Cache加速，Cache回收策略为LRU。百度这样的做法只适合于固定权限的控制，比如设备拥有的权限几乎相同，而且都是订阅格式相似的主题，只有其中的clientID不同而已，就可以做。如果有权限动态变化、设备粒度划分更细致的情况，采用Mysql+Redis就行不通了。（2）Session ManagerMQTT定义了两种会话：持久会话（Persistent Session）、非持久会话（Transient Session）。持久会话在客户端断开重连后，之前的订阅数据、离线期间接收的消息依然存在；非持久会话断开连接就清空所有数据。对分布式Broker而言，如何实现持久会话就是一个难点。百度Broker的策略是，持久会话每个Broker都会同步一份，即使Broker宕机，其他Broker上也有相应的信息，以解决高可用问题；非持久会话放在内存里，只在连接的Broker上存在，连接断开或Broker崩溃后清空。文中没有提到如何解决跨区问题（跨区时延高容易掉线，最好不做集群而是做数据同步，多个区域的Broker Session应该如何同步），以及Session每个节点都同步一份导致内存随设备数量线性增长的问题。（3）Event Service负责将每个Broker上发生的连接事件、断开连接事件、订阅事件、取消订阅事件通过Event Service发送给每个Broker，以达到同步的目的，类似于消息总线。实现上采用的Kafka，没有采用Akka通信的原因是这些事件需要持久化，比如Broker崩溃、网络波动后之前发送的未被消费的事件还存在。文中没有提到订阅事件、取消订阅事件如何处理顺序消费的问题，因为订阅和取消订阅先后顺序会影响Session的同步，比如同一个主题，客户端取消订阅事件先于订阅事件被消费，会导致一直订阅着某个主题；相反订阅事件先于取消订阅事件，会导致订阅丢失。通过kafka的方式，如果用了重试策略保证可靠性，就可能导致这些问题。虽然客户端订阅后马上取消订阅这种情况几乎不存在，都是上线后订阅、下线前取消订阅。（4）Session State Metadata Service负责持久化Session元数据，它从Event Service接收数据，然后决定哪些数据需要持久化到Hbase存储，比如持久会话���订阅、取消订阅数据。（5）Queue Service管理和分配Queue。根据Session类型不同，分为持久队列（Persistent Queue）、非持久队列（Transient Queue），用于消息下发和离线消息存储。Persistent Queue基于Hbase实现，Transient Queue是内存实现。（6）Quota Service管理并发连接数、上行带宽、下行带宽限制。（7）Metric Service监控并发连接数、并发消息数、当前流量、服务运行指标（CPU、内存、网络吞吐）三、连接层百度的连接层编解码架构如下：百度Broker连接层采用Netty NIO框架，目前大多数MQTT Broker也都是这样做的，没有任何问题。提供四种基本方式：MQTT TCP、MQTT TCP+TLS、MQTT Websocket、MQTT Websocket+TLS。现在SSL大多指代TLS，SSL是早期版本（现在很多组件已经弃用），后来都升级到TLS了，TLSv1/1.1/1.2/1.3是目前最常用的版本，很多组件原生支持TLS全版本，所以开发很简单不必担心，可以参考开源Broker&nbsp;Moquette。而且我们经常会使用负载均衡器LB来终结SSL，终结的意思是LB对外提供SSL的接口，转发进来的数据都是TCP了，EMQ也推荐使用这种方式，经历过云平台搭建的大佬们也都推荐使用这种方式，因为SSL编解码会消耗CPU，由LB来做完SSL处理，前端连接机器负载会小很多，连接就会更稳定不容易崩溃。所以最后只要做TCP、Websocket两种方式就好了。MQTT Websocket指的是，将MQTT协议作为subprotocol，利用Websocket来透传MQTT协议数据。四、持久化Session的处理方式持久化Session，需要同步Session信息到每台机器，每台机器都有全局Session（相当于无状态）。当Broker宕机时，Session中的订阅数据依然存在，所以可以由其他Broker将Publish消息作为离线消息存入客户端在HBase对应的队列中去；当客户端从其他Broker重连时，Session的数据还在、HBase保留了掉线期间的全部消息并会在CONNECT阶段下发给客户端，客户端不会丢失任何信息。4.1 连接阶段和虚拟队列​连接阶段没有相应的描述，这一段只是推测，流程图如下：（1）客户端以持久Session向连接节点Broker1发起MQTT-CONNECT请求，请求连接（2）Broker1接收请求，产生连接事件，发往Event Service（3）Event Service（Broker1上的）将订阅事件发布到Kafka（4）Event Service（多个Broker上的）从Kafka消费订阅事件消息（5）Event Service（多个Broker上的）将消息分发给各自的Broker（6）每个Broker都会创建对应的Session，包含了连接信息（7）其他节点往连接节点Broker1发一个内部通信消息，表明连接结果（8）连接节点Broker1综合连接结果，下发CONNACK给客户端，连接阶段结束4.2 订阅消息流程订阅主题的事件消息会发往Event Service，每个Broker都会订阅Event Service的数据，对于持久化Session，在接收到订阅事件后，会创建对应Session的订阅信息。也就是说，每个客户端产生的订阅、取消订阅操作，会被广播给所有Broker节点，Broker接收到后对内部的订阅树、Session等数据结构进行增删，保持订阅信息的一致性。订阅的流程图如下：（1）客户端以持久Session向连接节点Broker1发起MQTT-SUBSCRIBE请求，请求订阅主题（2）Broker1接收请求，产生订阅事件，发往Event Service（3）Event Service将订阅事件发布到Kafka（4）Event Service（多个Broker上的）从Kafka消费订阅事件消息（5）Event Service（多个Broker上的）将消息分发给Broker（6）每个Broker都会创建对应的Session，记录这个客户端的订阅信息（7）其他节点往连接节点Broker1发一个内部通信消息，表明订阅结果（8）连接节点Broker1综合订阅结果，下发SUBACK给客户端，订阅结束这里提到了一个虚拟队列（Virtual Queue）的概念。我们都知道MQTT要求持久化Session要缓存离线消息和未确认的QoS1消息，常用的做法就是把这些消息放到一个队列里面。对于单点而言，只需要放到内存就可以了，因为客户端只会连接一个节点；对于分布式而言，由于客户端可能会切换节点，放到一台机器的内存里在另一台机器上就无法访问了，百度采用了通用的分布式系统处理数据一致性的方案：计算和存储分离——将存储层单独做成一个集群，计算层做一个“虚拟队列”，只记录队列的状态，当需要获取数据时就利用这些“队列元数据”去存储层获取，保证无论在哪个节点上线，都可以获取到数据。做队列存储的难点在于，目前并没有组件直接提供所需队列功能。第一个肯定会想到使用消息队���（Message Queue， MQ），但是分析下需求，我们需要海量的（和客户端同数量级）、较小的（每个队列可能最多100条消息）队列，目前类似Kafka这样的MQ，都是少量的（Kafka上百个Topic就会速度慢下来）、海量的（囤积大量待消费消息）队列，所以根本不符合需求。第二个想到的就是Redis，像Redisson这样的工具提供了队列的功能，实现上是将Lua脚本发送给Redis执行来实现队列的功能，但Redis用的是内存比较贵，并且Redis更适合做缓存而不是持久化存储。第三个就是自己研发了，有大佬自己基于RocketMQ研发了海量小消息队列，而百度是基于HBase数据库做的海量小消息队列，阿里也有一个基于HBase制作的HQueue，不过是收费的不开源。有关百度HBase队列实现细节将在后面叙述。4.3 接收消息流程接收消息的流程图如下：（1）客户端2发布一条消息给Broker2（不考虑QoS，因为QoS0也是可以这样操作的）（2）Broker2拥有全局Session，发现客户端1订阅了这个主题，因此将消息写入客户端1的虚拟队列（3）Broker2向Broker1发送一个通知（Notification）消息，告诉它有新消息可以消费了（4）Broker2从虚拟队列读出数据，然后发布给客户端1，发布-接收流程结束我们分析一下宕机高可用的原理。当Broker2因为进程挂掉、掉电、网络波动等等宕机了造成客户端1掉线，Broker2会继续往HBase写客户端1待消费消息，HBase是集群因此高可用；等到客户端1从Broker3重新连接，然后在CONNECT阶段触发离线消息推送，一样可以接收到全集信息，本应该收到的数据并不会减少，如下图所示。同时我们可以推测百度QoS1的收发实现，一定是写入HBase成功以后，再回复PUBACK；一定是下发消息成功（收到PUBACK）以后，再删除HBase的数据。五、非持久化Session的处理方式5.1 连接阶段连接阶段没有相应描述，推测会在连接节点Broker上创建连接信息，但并不会同步给其他节点：5.2 订阅消息流程订阅消息没有相应描述，推测：同样会利用Kafka进行订阅事件分发消费（更新订阅树），因为其他节点需要知道这个Broker上有客户端订阅了某个主题但只在连接节点Broker上创建Session记录订阅信息和虚拟队列（更新Session），并且虚拟队列直接用内存来做，因为非持久化Session离线后不需要保存5.3 发送消息流程订阅消息描述不清晰，推测流程图如下：（1）客户端2发送一条消息给Broker2（2）Broker2发现Broker1上有订阅者，因此将消息直接发给Broker1（3）Broker1发现客户端1订阅了这个主题，将数据写入对应内存队列（4）Broker1向Broker2回送一个Event，表明自己成功收到了数据并处理完毕（5）Broker1从内存队列读取数据，然后将数据下发给客户端1六、Event Service的数据压缩Event Service会将持久化Session相关的数据（连接/断开连接事件、订阅/取消订阅事件）放入Kafka，当一个新的Broker加入集群，首先就要将持久化的Session信息全部加载。如果都是从Kafka主题头部开始消费数据的话，可能会花费很久的时间，因此需要对数据进行压缩。压缩做的事情就是保存这些事件消费后产生的最终效果，举个例子，比如订阅我们用订阅树来存储，如果从头消费，需要一根一根分支去插入、删除，模拟客户端做的操作；如果直接保存最后的订阅树在内存中的结果，这些操作就都可以不做了。消费流程解释得不详细，这里按我的理解和推测来描述，流程图如下：（1）Broker新上线，从HBase取出压缩的数据，构建初始数据结构（2）从检查点开始消费Kafka的数据（3）消费到最新一条后，上线完成，新的Broker和其他Broker没有任何区别原文中只描述了SUBSCRIBE/UNSUBSCRIBE事件的压缩，我认为CONNECT/DISCCONECT事件的数据也需要进行压缩，压缩原理一致。七、基于HBase的分布式消息队列HBase本身不提供Queue的功能，但我们可以利用HBase的特性来实现Virtual Queue的概念。整体描述：如图所示，有4个客户端，每个客户端对应一个虚拟队列Virtual Queue。我们为每个客户端分配一个唯一的（unique）QueueID，这样每个队列可以用QueueID+单调递增ID来组合成一个唯一的RowKey。为了保证写入的均匀性，避免热点问题，我们设计合理的唯一ID前缀（Prefix）来将这些RowKey均匀地分布到不同的Region。为了实现Queue的功能，我们在HBase上定义一个协处理器（CoProcessor），用作创建Queue、管理Queue的入队出队等操作、删除Queue、修改Queue的配额等等，HBase的Coprocessor类似于Redis的Lua脚本。7.1 Region Split算法作用我们希望所有的Queue能够均匀地分布到各个Region里面去，需要设计一个特殊的前缀作为分割条件（PatitionKey → Region）名词解释TenantID：百度IoT采用的多租户架构（将在后面叙述），所以有一个TenantID，对于一个企业而言这个ID是常量。clientID：MQTT协议的clientID，百度用的是单调递增的64bit LongQueueID：前文提到的一个客户端对应一个队列，用于唯一标记客户端队列的ID算法流程（1）定义客户端的QueueID为reverse{clientID}_TenantID，其中reverse的含义是字符串反转。（2）PartitionKey设定为log2(REGION_NUM)，其中REGION_NUM是预期的region数量算法解析百度的clientID是系统生成的、单调递增的64位长整型，加入预期region数量为128个的话，可以用前log2(128)=7比特的变化来映射到对应region。但由于数字的前面高位部分变化幅度低（要增长1W个数字万位才会进1），而后面低位数字变化剧烈（每增长1个都会变），我们需要的只是0~127的剧烈变化，所以将clientID进行翻转，取前8bit来做映射。7.2 保证写入消息的有序性我们为每个客户端的每条消息都分配一个唯一ID，记为QueueID_ID，其中QueueID为队列ID（\n\n\n\nreverse{clientID}_TenantID&nbsp;），后面的ID为单调递增64位长整型ID。例如一个客户端的消息ID可能是：3134_BAIDU_234，代表BAIDU这个租户下的第3134个客户端的第234条消息。消息都是批量（batch）写入的，当批量写入Coprocessor后，先获取该Queue的锁，然后分配ID，再将数据写入HBase，最后释放锁。这里的锁粒度是Queue级别（客户端级别），可以保证多个Broker并发写入一个客户端的Queue时不会发生冲突。7.3 读取Queue数据我们会为每个Queue保存该Queue在HBase的最小ID、最大ID，如果该Queue的最小最大ID在内存缓存中过期或丢失（比如很久没有读写队列消息了），就通过HBase的scan操作来重新获取一次最小最大ID，再缓存在Cache里。每一次读��特定长度的数据，保证每次数据的量级不会太大。读取的时候并不需要锁，因为读取只可能是客户端自己在读取，任何时刻读请求只可能来自一台机器的一个客户端。7.4 删除Queue的数据对于已经读取的数据，需要删除掉。由于我们的数据都是有序的，所以删除的时候只需要告诉Coprocessor删除多长的数据，然后根据最小ID、offset可以计算出要删除的RowKey，然后执行batch delete即可。删除同样不需要锁，任何时刻删除请求只可能来自一台机器的一个客户端。7.5 HBase的使用考虑由于HBase不存在官方的异步读写库（async library），目前只有openTSDB提供一个版本，而百度IoT利用coprocessor增加了一个新的endpoint，openTSDB的asnyc library却并不支持coprocessor，所以百度IoT自己扩展了async的库，最终用的自己研发的asnyc library的coprocessor库处理数据。同时，MQTT的消息属于快速消费（short lived）的消息，基本上写入后会被立刻读出，所以百度做了2.0版本，做内存压缩（in memory compaction），不需要将数据写入HFile，只需要写WAL日志，这样可以极大的降低HDFS文件系统的IO，解决了HDFS文件系统瓶颈问题，不过这个版本还没有正式发布。相关参考资料：《Accordion: HBase Breathes with In-Memory Compaction》《Internal design》7.6 提供多种Queue的选择基于HBase的这种Queue更适合小型客户端，比如APP、嵌入式IoT设备等等，对于大规模扇入场景，例如有一个后端服务需要统计数据，要求100W设备都往同一个主题发送消息，基于HBase的Queue只能有一个TCP来处理数据，后端服务肯定处理不过来会有大量消息堆积。所以百度还推荐使用Kafka来应对这种情况，将数据发往Kafka主题，然后利用Kafka的负载均衡客户端来并发消费消息。除了HBase、Kafka、内存，百度IoT还提供Redis做Queue。八、多租户架构百度是一个大平台，肯定不止为一家公司服务，所以用多租户架构来提供IoT Broker功能。一个IoT Hub上会有很多租户的MQTT Broker， 每个Broker对应一个tenant，每个Broker都有自己的Authentication Service, Session manager, Queue Service，以及很多其他的公共服务，比如Unique Id Generator，Backend Sorage Service等等。当客户端通过MQTT/TCP建立连接，云端通过username来区分对应哪个tenant，因此要求username必须为{tenent Name}/{client Name}，取出username、password之后，先算出对应client的tenant name，然后拿到该tanent对应的Broker实例，调用该Broker的Auth Service验证客户端身份。九、Baidu IoT Hub vs EMQ官方测试结果1、测试信息（1）测试机配置：配置参数&nbsp;值&nbsp;Vender IDGenuine Intel&nbsp;&nbsp;CPU Family&nbsp;&nbsp;&nbsp;6&nbsp;Model&nbsp;45&nbsp;Model Name&nbsp;Intel(R) Xeon(R) CPU E5-2620 0 @ 2.00GHz&nbsp;&nbsp;核心数12&nbsp;&nbsp;内存大小132137288KB（约126GB）&nbsp;（2）测试场景：一半PUBLISH和一半SUBSCRIBE，每一个pub对应一个sub，也就是说通过唯一主题关联起来，这种场景是对MQTT协议最严格的考验，其他场景相对来说CPU消耗会少一些&nbsp;&nbsp;（3）消��Payload大小：1024B（1KB）（4）Queue类型：内存Queue（因为EMQ只有内存Queue）文中并没有提到EMQ的版本。2、测试结果MPS：message per seconds，每秒消息量。由于Pub和Sub是一一对应的，所以这里指的消息量是PUBLISH的QPS，总体QPS是这个值的2倍。&nbsp;产品&nbsp;连接数&nbsp;预期MPS&nbsp;实际MPS&nbsp;平均CPU IDEL&nbsp;平均时延（ms）&nbsp;&nbsp;丢失率&nbsp;&nbsp;百度&nbsp;50万&nbsp;&nbsp;20K&nbsp;19.2K&nbsp;34%&nbsp;383&nbsp;0%&nbsp;EMQ&nbsp;50万&nbsp;20K&nbsp;19.2K&nbsp;26%&nbsp;1821&nbsp;0%&nbsp;百度&nbsp;50万&nbsp;10K&nbsp;9.2K&nbsp;58%&nbsp;289&nbsp;0%&nbsp;EMQ&nbsp;50万&nbsp;10K&nbsp;9.2K&nbsp;44%&nbsp;281&nbsp;0%&nbsp;百度&nbsp;20万&nbsp;50K&nbsp;42.5K&nbsp;14%&nbsp;381&nbsp;0.0000314%&nbsp;EMQ&nbsp;20万&nbsp;N/A&nbsp;测试未返回&nbsp;&nbsp;&nbsp;&nbsp;百度&nbsp;20万&nbsp;40K&nbsp;39.7K&nbsp;19%&nbsp;409&nbsp;0%&nbsp;EMQ&nbsp;20万&nbsp;40K&nbsp;38.4K&nbsp;10%&nbsp;17456&nbsp;0.0349%&nbsp;百度&nbsp;20万&nbsp;20K&nbsp;19.7K&nbsp;37%&nbsp;152&nbsp;0%&nbsp;EMQ&nbsp;10万&nbsp;20K&nbsp;19.7K&nbsp;33%&nbsp;449&nbsp;0%&nbsp;百度&nbsp;10万&nbsp;50K&nbsp;48.9K&nbsp;13%&nbsp;315&nbsp;0.000272%&nbsp;EMQ&nbsp;10万&nbsp;50K&nbsp;31.7K&nbsp;11%&nbsp;8014&nbsp;0%&nbsp;百度&nbsp;10万&nbsp;40K&nbsp;39.7K&nbsp;19%&nbsp;209&nbsp;0%&nbsp;EMQ&nbsp;10万&nbsp;40K&nbsp;31.7K&nbsp;11%&nbsp;8014&nbsp;0%&nbsp;百度&nbsp;10万&nbsp;30K&nbsp;29.9K&nbsp;26%&nbsp;152&nbsp;0%&nbsp;EMQ&nbsp;10万&nbsp;30K&nbsp;29.9K&nbsp;19%&nbsp;2727&nbsp;0%&nbsp;百度&nbsp;10万&nbsp;&nbsp;30K&nbsp;19.8K&nbsp;37%&nbsp;113&nbsp;0%可用MPS对比（无丢包、时延小于0.5s）连接数&nbsp;百度可用MPSEMQ可用MPS&nbsp;&nbsp;10万&nbsp;40K（19%IDLE）&nbsp;20K（24%IDLE）&nbsp;20万&nbsp;40K（19%IDLE）&nbsp;20K（33%IDLE）&nbsp;50万&nbsp;20K&nbsp;10K3、官方测试结论同等连接数下，百度Broker的可用最大吞吐量在EMQ的1~2倍之间。十、总结目前很多公司产品经理提的需求动不动就要支持上千万的IoT设备，肯定是要采用类似百度Broker的设计架构。但百度IoT只有这一篇文章，其中的很多细节依然不清楚，并且有自研成分在里面，小公司的普通开发者根本无法参考，所以只是提供了一个思路。MQTT Broker的难点就在于，它有持久Session，前端���连接节点无法做到无状态，会产生两个核心问题：离线消息如何存储和分发、集群如何通信，百度给出的答案是，自研基于HBase的Queue存储离线消息，使用对等节点Akka Cluster做集群通信（然而没有考虑可用区分区的问题，也没有细讲订阅数据同步）。希望以后越来越多的大公司可以开源讲一讲MQTT Broker的思路。                \n","categories":["转载"],"tags":[]},{"title":"知乎高性能长连接网关架构设计","url":"http://tanqingbo.cn/2019/10/06/知乎高性能长连接网关架构设计/","content":"\nhttp://www.bewindoweb.com/263.html��言无意间搜到一篇知乎技术团队一个月前（2019年5月24日）发表的《知乎千万级高性能长连接网关揭秘》，浏览了内容和评论后兴奋了起来，这感觉就像考试之后对答案发现另一个同学的解题思路跟你一模一样而且别人已经考了150分。分布式服务器最头疼的就是长连接了，下面结合知乎的做法，具体说一说长连接网关的设计难点和解决思路。一、长连接网关的需求分析对于安卓APP的应用，长连接能提供推送消息、即时通讯、游戏、共享定位等等功能，也就是适用于需要服务器主动往客户端“推”的业务场景。随着业务规模的扩大，不同的业务可能都会需要长连接，所以现在几乎每个互联网公司都会将长连接系统做成一个基础服务供后面的业务使用。知乎团队称自己的这套长连接网关设计方案“经过一年多开发和演进，面向数个APP，数百万设备同时在线，经历了突发大规模消息推送”，很有借鉴价值。二、知乎网关架构设计概述2.1 整体结构知乎采用了经典的“发布订阅模型”来解耦客户端（APP）、长连接网关、云业务后端三者的关联关系，完全参考了MQTT协议设计。APP通过指定Topic和后端业务通信，消息是二进制数据（MQTT协议的Payload也是二进制数据），因此网关无需关心业务方具体协议规范和序列化方式。2.2 认证和授权网关需要对客户端能够访问的Topic进行权限控制，避免数据污染或越权访问。这里要区分一下认证和授权的概念：认证指的是身份校验，也就是我知道你是我们系统中合法的客户端；授权指的是权限控制，管理员、VIP用户、普通用户、游客，虽然都是合法的客户端，但他们可以访问的Topic应该是不同的。所以对于一般的场景，比如物联网，假设一个品类的权限是固定的，那么可以在客户端内置证书，服务器识别指定的证书来认证，然后根据证书中的信息进行固定授权。知乎遇到的困难在于客户端的权限并不是固定的，知乎Live频道是需要付费的，任何用户都可能付费，付费后才能观看指定的频道内容，对于云网关来说，用户付费后就可以订阅主题，用户没付费就不能订阅，而用户付费状态只有后端服务知道，网关无法独立作出判断。因此知乎在ACL规则设计中提供了基于回调的鉴权机制，也就是网关只提供一个认证、授权接口，后端服务提供认证、授权实现，网关将每个订阅、发布的动作通过HTTP回调给后端服务进行身份权限判断。很容易想到，如果每个客户端的每个订阅、发布请求都要通过HTTP调用一次后端服务接口，这么巨大的访问量会造成性能低下。知乎对内部业务观察后发现，大部分场景下客户端都只订阅自己的主题（物联网的设计上也几乎都是订阅设备自己的主题），所以可以使用Topic模板变量来降低业务方的接入成本，网关可以直接判断是否有模板的权限。举个例子，原本的订阅主题可能是“notification/faceair”、“notification/bwb”等等，这些订阅和业务耦合；现在定义一个Topic模板“notification/{username}”，网关在接收到客户端faceair订阅请求后，将faceair的username��进去变成\"notification/faceair\"，然后对比订阅的是否是这个主题即可，网关完全不知道业务是什么，只做了简单的字符串替换和比对就完成了授权，唯一带来的限制就是，客户端只能订阅公共主题或者包含自己信息的主题，比如客户端faceair无法订阅notification/bwb。对于物联网的场景，APP除了用户账号的Topic，还可能需要订阅其账号下全部设备的Topic，这种动态性简单替换模板是达不到要求的，所以这种场景还是需要和帐号业务耦合，通过帐号拉取其下设备ID，然后替换设备ID的模板。2.3 消息可靠性保证虽然长连接是TCP传输，但一旦遇到TCP状态异常、客户端接收逻辑异常（比如设备更新固件后接收模块有Bug，或者APP升级版本后引入了接收模块的Bug），或者服务器宕机，传输中的消息就会丢失。为了保证传输消息可靠，知乎设计了类似MQTT的QoS1的回执和重传功能，网关下发消息前先缓存一份数据，收到客户端回执则删除消息，超时未收到回执则判断客户端状态并尝试重发，直到客户端收到消息且回执。当服务器业务流量很大时，每条消息都要回执的方式效率较低，所以知乎提供了基于消息队列的接受和发送方式（批量收发），这种方式我没有考虑过，值得参考。知乎明确提到设计通讯协议时参考了MQTT规范，保持了和MQTT协议一定程度的兼容，便于直接使用MQTT的各种语言平台版本开源客户端二次开发，降低业务方接入成本。2.4 具体架构和集群设计知乎的架构由四个主要组件组成：（1）接入层：使用OpenResty实现，负责连接负载均衡和会话保持。OpenResty是目前很火的一个服务端组件，我还不太了解，极客时间上有教程，而且也被人推荐过，很值得学习。如果不用OpenResty，可以采用云负载均衡器（腾讯、百度、阿里、AWS等）+ Netty，或者自己用HaProxy+Keepalive+Netty做，都是可行的方案。（2）长连接Broker：部署在容器中，负责协议解析、认证鉴权、会话管理、发布订阅逻辑（3）Redis存储：持久化会话数据（4）Kafka消息队列：分发消息给Broker或后端业务知乎的设计很清晰，主要考虑的点是：（1）可靠性知乎采用了经典的存储和计算分离的思路，计算由Broker负责，会话数据存储由Redis负责，逻辑简单，职责清晰（2）水平扩展能力知乎通过Kafka广播Publish消息，每个Broker都会收到所有客户端的Publish消息，这样Broker就无状态了（因为Publish不需要指定Broker），这种思路被很多MQTT Broker使用过，比如MqttWk用Redis做广播、Moquette用Hazelcast分布式缓存做广播，保持Broker的简单性，Broker就可以用容器无限水平扩展了。这样做是有一个问题的，不止我们考虑到过，评论里也有人评论。那就是这样的水平扩展只能扩展客户端数量承受能力，不能扩展消息吞吐能力。具体地说，我们确实可以无限扩展机器安装Broker，这样就能够连接更多的客户端；但由于是采用广播的形式，每台机器对Publish消费的能力是有上限的，而消费的又是全量消息（不管该Broker上是否有客户端订阅，都要消费一次Publish消息，然后查询一次订阅树，然后丢弃掉），所以随着客户端数量上升，消息量会不断上升���单台机器的消费能力并不能通过水平扩展增加（只有垂直扩展才可以，比如增加内存、CPU等），所以消息吞吐成为整个系统的瓶颈。如何解决呢，作者也进行了回复：也就是说，Broker保持和设备-Topic的关系，一个后端组件保持Broker-Topic的关系，并去消费全量Publish消息，根据订阅路由到指定的Broker：如果你看过EMQ源码，就知道EMQ就是这样实现的，分发的订阅信息称为路由表，连接的订阅信息称为订阅树。在我看来，如果没有特殊需求，初期直接广播就好，不必这么复杂，因为做定向路由有很多难点，比如路由表应该如何根据订阅树来更新。（3）依赖组件成熟度尽量不要自己写组件，用成熟的库和框架。三、知乎网关架构实现3.1 接入层接入层主要做两件事：（1）负载均衡：每个Broker上的连接数尽可能均衡（2）会话保持：去掉SSL，保持长连接知乎之前用的是四层负载均衡，根据IP进行Hash，这样做后发现有两个坑：（1）分布不够均匀。大部分源IP是大型局域网NAT出口，上面的连接数多，导致Hash集中到少量几个Broker上去（2）不能准确标识客户端，当移动客户端掉线切换网络，就可能无法连接回原来的Broker了最后使用了Nginx的preread机��实现七层负载均衡，用客户端的唯一标识来进行一致性Hash，这样随机性更好，保证网络波动也能正确路由。具体来说，Nginx的preread可以在接受连接时指定预读取连接的数据，通过解析preread buffer中客户端发送的第一个报文中的客户端标识，然后用这个标识进行一致性Hash拿到固定Broker实例。3.2 Kafka的选型理由所有Publish的数据通过Kafka广播给其他Broker或者后端服务，这样做的好处在于：减少长连接Broker内部状态，让Broker能够无压力扩容用消息队列削峰，避免突发性的上行下行消息压垮Broker业务交互大量使用Kafka传输数据，降低业务方对接成本前面已经解释了这样广播可以让Broker无状态；削峰是Kafka这类消息队列的一个重要作用，比如当一个片区断电/断网，然后重新来电/来网，很容易引起一波海量Publish冲垮服务器，用Kafka能让这些Publish消息囤积起来，后端服务慢慢去消费掉；业务上大多用Kafka传递数据，很多MQTT Broker也都在对接MQ方便后端业务处理，几乎所有MQTT Broker都支持Kafka，所以用Kafka没毛病。3.3 发布消息流程Broker根据路由配置（后端服务产生或运维人员配置，声明自己需要哪些Topic，通常是通配符主题）将消息发布到Kafka Topic，也会根据订阅配置（客户端产生或运维人员配置，通常是精确主题）消费Kafka数据，将消息下发给客户端。一共有四种场景：（1）消息路由到Kafka Topic，但不消费，单纯的数据上报场景（肯定是有后端服务消费后处理的，通常是日志信息的上报）（2）消息路由到Kafka Topic，也被消费，普通的即时通信场景（端到端消息，不经过处理）（3）直接从Kafka Topic消费并下发，用于推送场景（4）消息路由到一个Topic，然后从另一个Topic消费，用于消息需要过滤的场景（其实这个场景更像MQTT，所谓的Message Processing Worker类似于Rule Engine的作用）这里很容易有一个疑问，知乎这篇文章的底部也有人提问，那就是Kafka根本不能承受客户端数量级的Topic啊。实际上这是两个概念：Kafka Topic是和业务绑定的，有多少业务就有多少Kafka Topic，例如ruleengine.message；客户端Topic（比如MQTT Topic）则是客户端主动订阅的，通常是和规定的通信流程有关，并且包含客户端标识，例如device/{clientId}/writelog，客户端的Topic和客户端的数据是合起来作为Kafka的数据的。Kafka通常在上百Topic后性能就会大幅度下降，通常业务是不会达到上百Kafka Topic的。3.4 订阅订阅数据都会存储两份，一份是【clientID→Topic】的映射，这属于Session的一部分；另一份是【Topic→clientId（Subscription）】的映射，这是属于订阅树的部分。知乎的客户端都是精确订阅，所以不需要订阅树（订阅树的概念参考Mosquitto），直接用了HashMap来做。知乎实践中发现，订阅和取消订阅都会操作这个HashMap，而HashMap的全局锁冲突很严重，所以他们利用clientID作为Key，Hash到数百个HashMap上去，大大降低了冲突，提升了整体性能。这个���法是我之前从未考虑过的，非常有参考价值。3.5 会话如果是QoS1消息，则先缓存消息到Session（Redis队列），等客户端回送确认ACK后，再将其从Redis队列中删除。有关如何存储Session这块，文中也提到业界的方案：（1）内存维护队列，如EMQ。当扩容和缩容时这块数据没法跟着迁移。EMQ的做法是在连接阶段当发现别的Broker上有未过期Session，则将所有请求代理过去，不用迁移数据，但这块数据会在Broker宕机后丢失。（2）集群中分布式内存存储，如Moquette/HiveMQ，用集群分布式内存存储，当一个Broker宕机后，或者客户端掉线切换Broker后，仍然能够访问到Session数据。缺点是实现复杂度高。（3）统一的存储层存储。采用统一的存储层存储，缺点是需要维护一个存储集群，这对于千万级连接级别的架构来说不是问题。知乎正是采用了第三种方案，他们有专门的团队维护Redis集群。3.6 滑动窗口在MQTT协议中也有滑动窗口（Inflight Window）的概念。当QoS消息量较大，或者客户端处理缓慢，回送ACK可能会很慢，如果发完一条等确认后再发另一条，相当于串行执行，效率低下，因此可以同时下发一批消息，然后分别确认这些消息，并行处理。滑动窗口中的消息就是下发后未确认的消息，通过一个阈值限制下发未确认消息量，像一个窗口一样。并行会有顺序问题，但由于滑动窗口是队列，且通信是TCP连接，只要连接正常、客户端正常，就不会发生业务消息乱序的问题。在这里还有一个经典选择：MQTT协议规定，当客户端超时未ACK，需要服务端重发未确认的QoS1消息，何时重发有两种方案，一种是定时重发，一种是等下次客户端连接再重发。知乎选择的是后者，因为TCP基本保证了消息的可靠性，所以很少会出现由于链路问题导致未ACK的情况；消息的去重由客户端来保证，这也是常见的做法。四、总结知乎提供了一整套长连接方案，基本和MQTT Broker的设计思路一致，在做MQTT Broker时可以参考。长连接网关几乎是一个所有云平台的硬需求，终于有大厂肯开源这些方案了，其中提到的比如HashMap做成多个避免并发锁的冲突等经验非常值得学习。长连接的TCP配置方面还有很多坑，希望以后能通过实践积累更多经验。                \n\n\n","categories":["转载"],"tags":[]},{"title":"简单又复杂的“整数类型”","url":"http://tanqingbo.cn/2019/10/06/简单又复杂的“整数类型”/","content":"\nhttp://www.bewindoweb.com/203.html前言因为一道题目让我不断地深追下去，挖出了我多年的噩梦——数据类型的范围与长度。每次都想得头痛，因为平台不同、编译器不同、编程语言不同等等因素，又没去做实验，网上那么多说法该相信谁都不知道……那不如趁现在就来详细地解决掉它吧。一、原码、反码和补码基础知识相信在大学的《数字逻辑》课上都学过这个内容了，原码、反码和补码都是基于二进制而言的：【原码】第1位表示符号位，其余位是这个数的绝对值。这是最简单能够马上想到的表示方式了。【反码】正数的反码是其本身；负数的反码：在原码的基础上，符号位不变，其余位取反。【补码】正数的补码是其本身；负数的补码：在原码的基础上，符号位不变，其余位取反，最后+1。举个例子，假设整数在机器上是用8位二进制数表示的（8位就和我们经常说的32位、64位是一样的含义）：整数&nbsp;二进制&nbsp;原码&nbsp;反码&nbsp;补码&nbsp;&nbsp;30000 00110000 0011&nbsp;0000 0011&nbsp;0000 0011&nbsp;&nbsp;-3无法表示1000 00111111 11001111 1101&nbsp;-2无法表示1000 00101111 11011111 1110为什么要用原码、反码和补码呢？原码的来源为了让二进制能够表示负数，产生了原码。反码的来源一个正数和一个负数运算需要辨别符号位，然而单独去辨别符号位会给电路设计带来极大的复杂度，因此人们想只设计加法电路，让符号位直接参与加法运算达到减法的目的，产生了反码。例如：3-2 = 3+(-2) = [0000 0011]反+[1111 1101]反 = [0000 0001]反 = [0000 0001]原=1（注意反码的加法当最高位进位的时候，最低位需要+1，不再详细描述，参考百度百科《二进制反码求和》）。这样符号位就能够参与运算了。补码的来源反码看起来很完美，但是仍然存在问题。例如3-3 = 3+(-3) = [0000 0011]反+[1111 1100]反 = [1111 1111]反 = [1000 0000]原=-0，而[0000 0000]反=[0000 0000]原 = +0，也就是说，零可以表示为两种形式，这种歧义同样不利于电路实现。并且由于反码的加减法还需要对溢出位进行处理，于是产生了补码。补码对溢出位直接丢弃，而0的表示只有一种[0000 0000]补，[1000 0000]补则看成是-128，解决了所有问题。原码、反码和补码的范围问题值得注意的是，8位的原码和反码都只能表示[-127, +127]范围内的整数，而补码可以表示[-128, +127]范围，多一个-128。这里的-128是计算得到的，而不是从反码推出的，-128根本无法用反码表示，却能够用补码计算，比如-127+(-1) = [1000 0001]补+[1111 1111]补 = [1000 0000]补。所以我们经常背的整数取值范围[-32768, +32767]之类的东西为什么负数总比整数的真值大1，就是这样来的。计算机中按位取反会发生什么？既然计算机表示的时候用的是补码，那么如果对十进制的整数【按位取反】操作到底操作的是补码还是二进制呢？实验一下吧：printf(\"%d\\n\", ~(3));\nprintf(\"%d\\n\", ~(-3));【平台】windows 8 64位【IDE】vs2013 32位【语言】C语言【取反操作】~【取反结果】~3 = -4，~(-3) = 2数值比较小，最高位没有影响，就按照8位来仔细观察第一组数据：3 = [0000 0011]b = [0000 0011]原 = [0000 0011]反 = [0000 0011]补-4 = [无法表示]b = [1000 0100]原 = [1111 1011]反 = [1111 1100]补对补码取的反，再来看第二组：-3 = [无法表示]b = [1000 0011]原 = [1111 1100]反 = [1111 1101]补2 = [0000 0010]b = [0000 0010]原 = [0000 0010]反 = [0000 0010]补可以确信100%是对补码取的反了，纯的。二、C语言中的整数类型的大小和范围以前我们常常会去记忆[-32767, +32768]，尤其是在学pascal的时候，然而现在仔细想想，pascal都是多少年前的编程语言了，那时的电脑和现在的电脑完全不相同，记这个根本没用。整数类型的大小和范围和操作系统、编译器、编程语言都息息相关，抛开运行环境谈论sizeof出什么结果的题目都是耍流氓，然而笔试题这种流氓经常存在………整数类型的范围与表示位数用不同位数表示整数，取值的范围就不相同，由于采用补码，总可以多表示一个负数：&nbsp;表示位数最小值&nbsp;最大值&nbsp;&nbsp;8-128127&nbsp;16-3276832767&nbsp;&nbsp;32-21 4748 364821 4748 3647&nbsp;64-922 3372 0368 5477 5808922 3372 0368 5477 5807无符号unsigned无符号的时候，就可以不用担心符号位了，也就是可以表示0~2^bit-1个数，比如：表示位数&nbsp;最小值&nbsp;最大值&nbsp;&nbsp;8&nbsp;0&nbsp;255C语言中的整数类型及其长度基本整数类型有：char、short int、int、long、long long（c99新增）。我总是在死记长度，总以为long比int更长，但其实C语言标准是这样规定的：int最少16位（2字节），long不能比int短，short不能比int长，具体位长由编译器开发商根据各种情况自己决定。好一个“自己决定”……好一个“不能比”……还是通常情况吧，列个表：整数类型&nbsp;32位通常大小&nbsp;64位通常大小&nbsp;char1字节1字节short int&nbsp;2字节2字节int4字节4字节long int4字节8字节long long8字节8字节32位表示方式中，long int和int是一样大的！同时还反映了一个问题：64位运行的代码不一定能在32位上运行。C语言数据类型名称、输出和编译器的关系g++和gccg++把.c和.cpp程序都认为是c++程序，gcc则会用C语言的方式编译.c，用C++的方式编译.cpp。也就是说，如果你用C写的程序，用g++编译，很可能会报语法错误，因为g++对语法要求更严格，尽管C++是C语言的超集。其他的区别就是，g++能够自动链接c++的库，而gcc需要手动设置参数。gcc/g++与clvs使用的编译器是cl.exe，这是微软自己开发的编译器。CL.exe是控制 Microsoft C 和 C++ 编译器与链接器的 32 位工具。cl和clang是不同的，在Visual Studio 2015已经整合了clang编译器，但它是被用于Android和 iOS上的应用开发。整数类型不同表示方式以及输出Visual Studio是在windows下运行的，通常支持__intxx这种写法来定义不同位数的整数，这是gcc/g++通常不支持的（没有实验过）。而long long这种写法在Visual C++ 6.0上是不支持的（没有实验过）。不过，在Visual Studio 2013上，全部的写法都支持，很可靠，列个表：整数类型&nbsp;Visual Studio 2013&nbsp;long支持long int支持long long支持long long int&nbsp;支持__int8支持__int16支持__int32支持__int64支持__int128支持并且，所有的printf写法都支持：printf标记&nbsp;数据类型&nbsp;Visual Studio 2013&nbsp;%ldlong/__int32支持%lldlong long/__int64支持&nbsp;%I64dlong long/__int64支持做个实验：【操作系统】windows 8 64位【IDE】Microsoft Visual Studio 2013 32位【编译器】cl.exe win32【代码】long long a = 1231321313131313131;\n__int64 b = 1231321313131313131;\n\n\n\nprintf(“ type=long long\\n d=%d\\n ld=%ld\\n lld=%lld\\n I64d=%I64d\\n —\\n”, a,a,a,a);printf(“ type=__int64\\n d=%d\\n ld=%ld\\n lld=%lld\\n I64d=%I64d\\n”, b,b,b,b);【输出结果】d和ld都溢出了，而lld、I64d可以工作得很好，而且对long long 和__int64没有任何区别整数类型越界会发生什么？这是一直都很好奇的事情，那就来实验一下。【操作系统】windows 8 64位【IDE】Microsoft Visual Studio 2013 32位【编译器】cl.exe win32【实验结果】取值范围unsigned short int 0~65535unsigned int   0～4294967295int -2147483648～2147483647long -2147483648 ~ 2147483647long long -9223372036854775808 ~  9223372036854775807\n超上限（越来越大）会从最小值开始重新增长：unsigned short int 65536=0  |  65537= 1unsigned int   4294967296=0 |  4294967297= 1int 2147483648=-2147483648 | 2147483649 = -2147483647long 2147483648=-2147483648 | 2147483649 = -2147483647long long 9223372036854775808 =  -9223372036854775808 | 9223372036854775809 = -9223372036854775807\n超下限（越来越小）会从最大值开始重新减小：unsigned short int -1=65535  |  -2=65534unsigned int   -1=4294967295 |  -2=4294967294int -2147483649=2147483647 | -2147483650=2147483646long -2147483649=2147483647 | -2147483650=2147483646long long  -9223372036854775809 =  -9223372036854775807 |  9223372036854775810 = -9223372036854775806【探究原因】想一下刚才的补码，假设32位，int取最大值2147483647，打开你的计算器，选择查看→程序员，输入这个数字，看到它的补码：[0111 1111 1111 1111&nbsp; &nbsp;1111 1111 1111 1111]补 + [0000 0000 0000 0000&nbsp; &nbsp; 0000 0000 0000 0001]补的结果是[1000 0000 0000 0000&nbsp; &nbsp; 0000 0000 0000 0000]补 = -2147483648。这就是为什么越界的2147483648，打印输出-2147483648的原因了。【其他】注意如果你直接进行赋值：int a = -2147483648;VS是会报错的：long long 也是如此，因此这时候应该用：int a = INT_MIN;long long b = LLONG_MIN;来表示，可以看到它们的宏定义：说好的可以多表示一个负数呢，怎么不行了呢，具体原因参考wiki《VS编写C程序报错error C4146: 一元负运算符应用于无符号类型，结果仍为无符号类》三、JAVA语言中的整数类型的大小和范围基本信息因为我在尽量主学Java副学Python，所以这里也记录一下java的整数类型。java的整数类型比较神奇，有四种基本整数类型：byte、short、int、long，但由于java的设计初衷是跨平台运行的，Write Once and Run Anywhere，所以这几种类型的字长都是固定的，与任何其他的32位64位都无关，列个表：整数类型&nbsp;字长大小&nbsp;取值范围&nbsp;byte1字节-128127&nbsp;short2字节-3276832767&nbsp;int4字节-21474836482147483647&nbsp;long8字节-9223372036854775808-9223372036854775807你可以自己测试一下：System.out.println(\"Byte: \" + Byte.SIZE/8);System.out.println(\"Short: \" + Short.SIZE/8);System.out.println(\"Integer: \" + Integer.SIZE/8);System.out.println(\"Long: \" + Long.SIZE/8);java中的unsigned类型java是几乎没有unsigned类型的。为什么说几乎呢，因为在多年的呼吁之后，最新的jdk8支持了unsigned的静态方法调用（也就是说不支持直接写unsigned int这种写法，只能通过Integer.xxxx来调用），参看《Unsigned Integer Arithmetic API now in JDK 8》。真应了那句老话：真香！为什么大家那么希望有unsigned类型呢？因为常常需要处理图片，而我们知道通常的图片数据是从0变化到255的，如果有unsigned byte，那不就刚好了嘛由于没有unsigned，目前主流的做法是使用更大的类型比如short或者int。值得注意的是，如果要把表达0255取值的byte转换到short/int，要处理一下符号。因为当从0255的short/int转换为byte时，考虑他们的补码，例如255：255 = short [0000 0000 1111 1111]补 → byte [1111 1111]补 = -1128 = short [0000 0000 1000 0000]补 → byte[1000 0000]补 = -1280 = short [0000 0000 0000 0000]补 → byte[0000 0000]补 = 0127 = short[0000 0000 0111 1111]补 → byte[0111 1111]补 = 127可以看出，0127(short)被映射到0127（byte），而128255则被映射到（-128-1）了，因此在byte转回short/int时，如果不加处理，得到的值会是-128：-128 = byte[1000 0000]补 → short [1111 1111 1000 0000]补 = -128处理的方法很简单，加个掩码0xff屏蔽掉高位的符号扩展即可，也就是将byte的值与0xff进行按位与：-128 &amp; 0xff = byte[1000 0000]补 &amp; [1111 1111] → short[1111 1111 1000 0000]补 &amp; [0000 0000 1111 1111] = [0000 0000 1000 0000]补 = 128得到的值就正常了，用代码实验一下：short s_init = 128,s_force,s_and;        byte b_force;        b_force = (byte)s_init;        s_force = (short)b_force;        s_and = (short)(b_force &amp; 0xFF);        System.out.println(\"初始short值= \"+s_init+\"\\n转为byte= \"+b_force+\"\\nbyte转为short= \"+s_force+\"\\nbyte掩码后转为short= \"+s_and);得到的结果是：初始short值= 128转为byte= -128byte转为short= -128byte掩码后转为short= 128java中的charchar类型长度2个字节，而且取值是无符号的065535，其他编程语言通常都是1个字节。java的char是Unicode编码，可以存放中文字符。那么为什么不用它来作为unsigned int 用呢？【原因1】输出为字符。java的char类型是设计为存储unicode字符的，采用UTF-16固定宽度的编码格式。虽然赋值的是数值88，但当调用System.out.println(a);的时候，出现的是字母X。【原因2】运算困难。char a = 88;a = a + 1;编译器会报错需要char类型，而给的是int，因为当char类型运算后就是int类型了，不能直接存回char类型，需要进行强制转换：a = (char)(a + 1);既然这么麻烦，为何不直接用int呢？java中整数类型越界会发生什么？和C语言是一样的：当越上界，会从最小值继续累加；当越下界，会从最大值继续减小。原因同样是因为补码溢出位被丢弃，在测试的时候，不能直接赋值越界数值，否则会提示类型不匹配或者整数太大了。使用常量+1再强制转换类型，达到越界目的。byte a = (byte)(Byte.MAX_VALUE+1);输出结果：-128                \n","categories":["转载"],"tags":[]},{"title":"类别型特征的处理方法与平均数编码","url":"http://tanqingbo.cn/2019/10/06/类别型特征的处理方法与平均数编码/","content":"\nhttp://www.bewindoweb.com/217.html前言《百面》第二章「类别型特征」，提出一个问题：在对数据进行预处理时，应该怎样处理类别型特征？仔细研究才发现，这里面竟然有很多以前从未听过的知识——毕竟研究生不会有人手把手教你这么系统地去学，只有老板给什么就去实现什么而已……那么开始吧~什么是类别型特征看名字就知道，是机器学习的输入数据中，表示类别的特征。比如：数据ID | 性别 | 学历  | 出生城市 | 10年内深圳买房（y）\n1      | 男   | 博士  | 深圳     | 是\n2      | 女   | 硕士  | 重庆     | 否\n3      | 男   | 大学  | 哈尔滨   | 否\n4      | 女   | 高中  | 成都     | 是\n5      | 男   | 初中  | 湖南     | 是这些数据需要被通过某种方法转换为数字，也就是所谓的编码，才能更好地被那些机器学习算法中建立的各种数学模型来使用。我以前的转换手段就是暴力的：女=0，男=1\n初中=0，高中=1，大学=2，硕士=3，博士=4\n深圳=0，重庆=1，哈尔滨=2，成都=3，湖南=4\n否=0，是=1非常简单，然而这其实并不是最好的处理方式，好在，我一直学习和使用的都是树模型……类别型特征的处理方法序号编码（Label Encoding）上面的暴力方法就是序号编码，通过数字和值的一一映射达到编码的目的。但它适合于处理具有大小关系的特征，比如学历从低到高正好对应了数字从小到大，没有改变特征的特性。如果把它用于处理没有任何大小关系的特征，比如出生城市，所有的城市都是平级的，转变为数值之后却莫名地增加了一层大小关系，这对于数值大小敏感的模型（比如SVM支持向量机）是致命的——因为会影响损失函数之类计算结果。python的机器学习包sklearn的LabelEncoder实现了序号编码。独热编码（One-hot Encoding）独热编码也成为哑变量编码（Dummy Encoding）（不过有的也将哑变量编码区分为“随机去项的降维独热编码”），指的是，将原始特征变量转换为原始特征值分类的多维度变量，在每个维度上使用0/1来进行是/否、有/无的量化。通俗来说就是，把每个取值作为一个新特征，一行数据中，取到了这个值就是1，没取到这个值就是0。用出生城市来举个例子：数据ID | 出生城市=深圳 | 出生城市=重庆 | 出生城市=哈尔滨 | 出生城市=成都 | 出生城市=湖南\n1      | 1             | 0             | 0               | 0             | 0\n2      | 0             | 1             | 0               | 0             | 0\n3      | 0             | 0             | 1               | 0             | 0\n4      | 0             | 0             | 0               | 1             | 0\n5      | 0             | 0             | 0               | 0             | 1这样做的好处在于：（1）没有了数值大小关系，SVM也可以尽情使用哦~（2）扩充了特征，将一个“出生城市”的特征扩充为了5个新特征，有效地减少了过拟合风险。然而也很容易看出缺点：（1）如果取值较多，很可能会分裂出大量的新特征，导致维度过高不容易处理。（2）非常不适合树模型。如果特征很多，取这个值的数量又很少，那么一些特征变量很可能因为树模型的参数配置而无法向下分裂，导致这些信息白白丢失掉了。（3）一个特征变为多个特征，当数据条数越多的时候，整体的数据量会暴增。所以，在使用独热编码的时候可以这样做：（1）使用稀疏向量节省空间。独热编码只有一个取值1，其余为0，符合稀疏向量的特性。也就是说，我们把上述出生城市改写为：数据ID | 出生城市\n1      | 5, (1,1)\n2      | 5, (2,1)\n3      | 5, (3,1)\n4      | 5, (4,1)\n5      | 5, (5,1)只是表述方式上变了，数据量减小了，但仍然是拆分成了5个特征。（2）配合特征选择来降低维度。我们都知道，K近邻算法需要有效地去衡量两点之间的距离，因此通常需要进行降维。独热编码带来的维度灾难副作用可以通过降维来减少其影响。常见的降维方式有PCA主成分分析、随机特征选择等等。我个人是最喜欢用随机了，因为通常采用的是树模型，而且随机能有效减少树的过拟合，实现起来又简单。python的机器学习包sklearn的OneHotEncoder实现了独热编码，pandas的get_dummies同样实现了独热编码，推荐pandas。二进制编码（Binary Encoding）就是用二进制去表示类别，比如出生城市可以表示为：数据ID | 出生城市F1 | 出生城市F2 | 出生城市F3 \n1      | 0          | 0          | 0\n2      | 0          | 0          | 1\n3      | 0          | 1          | 0\n4      | 0          | 1          | 1\n5      | 1          | 0          | 0有的同学会说，哎这不是有大小关系了吗。但仔细看会发现，这种大小关系在单独一列中是不会体现出来的。不过似乎没有看到过这种二进制编码有具体应用，只看见过理解神经网络的中间层原理的时候，发现它利用了这种二进制机制。平均数编码（Mean Encoding）划重点！这个方法是在kaggle圈的各位大佬们针对“高基数类别型特征（High-Cardinality Categorical  Attributes）”使用之后发现非常有效（AUC的提升）的方法，它并没有被大量研究，中文资料甚至更少，但是实践真的有奇效。平均数编码的提出是在2001年的论文《A Preprocessing Scheme for High-Cardinality Categorical Attributes in Classification and Prediction Problems》（百度云盘下载密码：bm8x），其实是相当古老的论文了，只有2017年的一篇《CatBoost: unbiased boosting with categorical features》提到了它。1、clustering和smoothing平均数编码主要用于处理高基数类别型特征，高基数的意思就是类别非常多，比如邮编（000001-999999）、区号、IP、家庭住址，这类特征如果直接用独热编码就不要想了。所以目前常见的做法就是：（1）将1到N（N非常大）的映射问题通过聚类转换为1到K（K&lt;&lt;N）（2）然后再进行独热编码这种方法统称为clustering。举个直观但不真实的例子，虽然颜色可能有[深蓝、浅蓝、湖蓝、碧蓝、靛蓝、钴蓝、蔚蓝、宝蓝、藏蓝、冰蓝、宝石蓝、海蓝、湛蓝、橙红、粉红、紫红]（N=16），那么我们根据分类取值（Y=0/1）把这些颜色都聚合为[蓝色、红色]（K=2）这两个值，一下就减少了大量的特征取值。然后再将[蓝色、红色]通过独热编码变为2列，就完成了类别值到数值的转换。然而这种做法导致了特征信息的丢失（本来有很多种蓝色特征，结果我都看成一种蓝色特征了）。那么我们把这种clustering泛化一下，不要强迫为[蓝色、红色]（=0、=1）了，改成概率估计[是蓝色的概率，是红色的概率]（=0~1之间的小数），也就产生了smoothing。平均数编码就是smoothing的一种实现。2、以二值目标分类理解平均数编码假设我们有一个二值分类问题，给定特征X是高基数类别型特征，Y∈{0,1}，那么对于特定的取值X=Xi，我们希望得到它后验概率（看到这种特征取这个值，这个样本的分类是Y=1的概率），那么可以用标量Si去估计这个后验概率：由于后面需要用这些特征去训练机器学习模型，所以在特征处理这一步，我们只能使用训练数据去估计这个特征值的后验概率。设训练集有n_TR个样本，测试集有n_TS个样本，如果训练集在X的每个取值Xi上都能取到足够多的样本，那么很明显我们可以用最简单的样本数目来做这个后验概率的估计：其中n_iY表示在X取Xi值的时候，Y=1的样本数目；ni表示X取Xi值的样本数目。然而在实际的场景中，ni的数量很小（因为有大量的Xi值可以取，取每个值的样本数目非常有可能不均衡），所以这个估计是不可信的。为了削弱样本数目小带来的负面影响，我们混合先验概率和后验概率：其中，λ是阈值为[0,1]的单调递增函数。很容易理解这个式子：当Xi取值内样本数量非常多的时候，\n\n\n\nn_i→∞，n_iY→∞ ，λ(ni)→1，相当于在使用之前的式子计算；当Xi取值内样本数量非常少的时候，\n&nbsp;n_i→0，n_iY→0 ，&nbsp; λ(ni)→0，那么我们直接采用Y=1的先验概率作为估计，也就是说这时候X=Xi已经不重要了，提供不了任何能判断Y=1的信息，那就直接用整个训练样本中正样本数占总样本数的比例来作为估计就好了。λ采用这样的函数：对比一下神经网络中常常使用的Sigmod函数：从图像上说，相当于把Sigmod函数图像向右平移k个单位+拉伸f倍。从意义上说，k决定了我们完全信任基于这些取值内的样本得到的估计的最小样本数的一半，因为当n=k时λ会等于0.5，这时候我们一半相信先验概率，一半相信后验概率；f控制函数在转折点的斜率，决定了先验概率和后验概率之间的平衡，因为当f→∞的时候，λ→0，不论n为什么值，都几乎是0.5先验+0.5后验。以上Si的计算公式其实来源于经验贝叶斯（Empirical Bayesian），λ就是经验贝叶斯公式中的收缩因子（shrinkage factor）Bi的泛化形式。3、处理缺失值我们只用了训练数据，在测试数据里很可能有根本没有出现过的取值，对于这个公式来讲，处理缺失值非常简单，只需要增加一个空缺值X=X0的估计即可：这样做的好处在于，如果缺失值和分类有很大相关性，那么这个公式就可以很好地表达这种相关信息；反之如果缺失值和分类没有太大关系，那么S0也会很快收敛于先验概率，符合通常情况下对缺失值的中立表示。4、多分类问题只需要将估计的概率转变一下就好啦：注意之前二分类的时候我们是直接替换的那些类别型特征值，而这里多分类的时候，假设有C个类，会产生C列。为什么之前C=2的时候只有1列呢？因为特征线性相关了，比如求P(Y=1|X=Xi)的概率，也就知道了P(Y=0|X=Xi)的概率。所以同样的，这里产生了C列也需要去除最后一列。5、连续型类别问题（回归）对于回归来说，只需要把概率估计改为期望估计就可如果把二分类的类别标记为0/1，那么二分类和回归可以用相同的公式计算。6、具有层次结构的类别型特征有的时候我们的类别型特征可能具有层级结构，比如邮编，北京市前两位全是10开头的，然后再继续往后细分是哪个区。我们可以利用这种层级关系来使得每个取值的样本数目更加合适一点。设5位邮编为ZIP5，4位ZIP4，以此类推。那么最开始的计算公式是这样的：当ZIP5样本很稀疏的时候，它几乎所有的取值都会依赖于先验概率。而我们可以用这种层次结构来尽可能地提取出新的信息。很明显，ZIP5的先验概率可以用ZIP4去估计：当样本充足时，会用ZIP5的后验概率，当样本不充足时，会去考虑ZIP4的后验概率，逐级向上，相当于根据数据密度进行了自动调节。7、平均数编码的过拟合问题有同学在实践中发现，如果使用全部训练数据去处理特征，那么之后的机器学习模型会产生过拟合问题。所以一种解决方法是，分成k份，每份内的特征值处理采用其他k-1份组成的数据集来训练平均数编码模型，再替换自己的值。总结&nbsp;编码方式适用类型&nbsp;实现难度&nbsp;效果&nbsp;序号编码&nbsp;&nbsp;大小不敏感模型（树）&nbsp;容易&nbsp;好独热编码&nbsp;特征取值少、非树模型&nbsp;容易&nbsp;好二进制编码&nbsp;-&nbsp;容易&nbsp;-平均数编码&nbsp;高基数类别型特征&nbsp;困难&nbsp;非常好参考资料1、《百面机器学习》2、《类别特征编码》3、《非数值型特征如何进行编码》4、《处理分类数据 非数值型编码》5、《离散型特征编码方式：one-hot与哑变量》6、《机器学习之特征编码总结》7、《机器学习“特征编码”的经验分享：鱼还是熊掌？》8、《平均数编码：针对高基数定性特征（类别特征）的数据预处理/特征工程》9、《高数量类别特征（high-cardinality categorical attributes）的预处理方法》10、《一种处理高维categorical特征的处理方法-TBS (Target based statistic)》11、《在分类及预测任务中对高维类别（category）变量的预处理方法》&nbsp;                \n","categories":["转载"],"tags":[]},{"title":"MqttWk源码分析（三）：BrokerHandler及协议处理分析","url":"http://tanqingbo.cn/2019/10/06/MqttWk源码分析（三）：BrokerHandler及协议处理分析/","content":"\nhttp://www.bewindoweb.com/250.html\n前言基于MqttWk v1.0.7。&nbsp;&nbsp;一、BrokerHandlerchannelActive()@Override\n  public void channelActive(ChannelHandlerContext ctx) throws Exception &#123;\n      super.channelActive(ctx);\n      this.channelGroup.add(ctx.channel());\n      this.channelIdMap.put(ctx.channel().id().asShortText(), ctx.channel().id());\n  &#125;当channel刚生效（客户端刚连接），将其channel信息存起来。Netty默认提供了channel管理，这里自己做channel管理是为了方便根据channelId快速找到对应channel好下发消息。channelInactive()@Override\n  public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123;\n      super.channelInactive(ctx);\n      this.channelGroup.remove(ctx.channel());\n      this.channelIdMap.remove(ctx.channel().id().asShortText());\n  &#125;当channel失效时，将channel信息移除。exceptionCaught()@Override\n  public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123;\n      if (cause instanceof IOException) &#123;\n          // 远程主机强迫关闭了一个现有的连接的异常\n          ctx.close();\n      &#125; else &#123;\n          super.exceptionCaught(ctx, cause);\n      &#125;\n  &#125;连接发生IO异常时，关闭channel。如果你想要做更多处理，比如发生自定义的异常处理逻辑，也可以在这里做。在这个方法运行完后，会去因为关闭连接触发channelInactive，所以如果在channelInactive那里做了清理工作，这里就不要重复做了。userEventTriggered()@Override\n  public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception &#123;\n      if (evt instanceof IdleStateEvent) &#123;\n          IdleStateEvent idleStateEvent = (IdleStateEvent) evt;\n          if (idleStateEvent.state() == IdleState.ALL_IDLE) &#123;\n              Channel channel = ctx.channel();\n              String clientId = (String) channel.attr(AttributeKey.valueOf(\"clientId\")).get();\n              // 发送遗嘱消息\n              if (this.protocolProcess.getSessionStoreService().containsKey(clientId)) &#123;\n                  SessionStore sessionStore = this.protocolProcess.getSessionStoreService().get(clientId);\n                  if (sessionStore.getWillMessage() != null) &#123;\n                      this.protocolProcess.publish().processPublish(ctx.channel(), sessionStore.getWillMessage());\n                  &#125;\n              &#125;\n              ctx.close();\n          &#125;\n      &#125; else &#123;\n          super.userEventTriggered(ctx, evt);\n      &#125;\n  &#125;userEventTrigger可以编写自定义的事件发生后处理逻辑。这里是判断当客户端一直没有发送消息也没有接收的时候，就触发IdleState，然后发送遗嘱消息并关闭连接。我觉得这里的逻辑有问题，因为遗嘱消息的标准分发条件是：服务端检测到了I/O错误或网络故障客户端在KeepAlive的时间内未能通讯客户端没有发送DISCONNECT报文直接关闭连接由于协议错误关闭了网络连接所以不只是“未能通讯”才分发，抛出异常也会分发的。channelRead0()@Override\n  protected void channelRead0(ChannelHandlerContext ctx, MqttMessage msg) throws Exception &#123;\n      if (msg.decoderResult().isFailure()) &#123;\n          Throwable cause = msg.decoderResult().cause();\n          if (cause instanceof MqttUnacceptableProtocolVersionException) &#123;\n              ctx.writeAndFlush(MqttMessageFactory.newMessage(\n                      new MqttFixedHeader(MqttMessageType.CONNACK, false, MqttQoS.AT_MOST_ONCE, false, 0),\n                      new MqttConnAckVariableHeader(MqttConnectReturnCode.CONNECTION_REFUSED_UNACCEPTABLE_PROTOCOL_VERSION, false),\n                      null));\n          &#125; else if (cause instanceof MqttIdentifierRejectedException) &#123;\n              ctx.writeAndFlush(MqttMessageFactory.newMessage(\n                      new MqttFixedHeader(MqttMessageType.CONNACK, false, MqttQoS.AT_MOST_ONCE, false, 0),\n                      new MqttConnAckVariableHeader(MqttConnectReturnCode.CONNECTION_REFUSED_IDENTIFIER_REJECTED, false),\n                      null));\n          &#125;\n          ctx.close();\n          return;\n      &#125;\n\n  switch (msg.fixedHeader().messageType()) &#123;\n      case CONNECT:\n          protocolProcess.connect().processConnect(ctx.channel(), (MqttConnectMessage) msg);\n          break;\n      case CONNACK:\n          break;\n      case PUBLISH:\n          protocolProcess.publish().processPublish(ctx.channel(), (MqttPublishMessage) msg);\n          break;\n      case PUBACK:\n          protocolProcess.pubAck().processPubAck(ctx.channel(), (MqttMessageIdVariableHeader) msg.variableHeader());\n          break;\n      case PUBREC:\n          protocolProcess.pubRec().processPubRec(ctx.channel(), (MqttMessageIdVariableHeader) msg.variableHeader());\n          break;\n      case PUBREL:\n          protocolProcess.pubRel().processPubRel(ctx.channel(), (MqttMessageIdVariableHeader) msg.variableHeader());\n          break;\n      case PUBCOMP:\n          protocolProcess.pubComp().processPubComp(ctx.channel(), (MqttMessageIdVariableHeader) msg.variableHeader());\n          break;\n      case SUBSCRIBE:\n          protocolProcess.subscribe().processSubscribe(ctx.channel(), (MqttSubscribeMessage) msg);\n          break;\n      case SUBACK:\n          break;\n      case UNSUBSCRIBE:\n          protocolProcess.unSubscribe().processUnSubscribe(ctx.channel(), (MqttUnsubscribeMessage) msg);\n          break;\n      case UNSUBACK:\n          break;\n      case PINGREQ:\n          protocolProcess.pingReq().processPingReq(ctx.channel(), msg);\n          break;\n      case PINGRESP:\n          break;\n      case DISCONNECT:\n          protocolProcess.disConnect().processDisConnect(ctx.channel(), msg);\n          break;\n      default:\n          break;\n  &#125;\n  }这里用channelRead0而不是channelRead是因为作者继承的SimpleChannelInboundHandler&lt;MqttMessage&gt;而不是ChannelInboundHandlerAdapter。ChannelInboundHandlerAdapter是Netty默认的入站消息处理类；SimpleChannelInboundHandler继承了它并实现了一些基础的方法，更方便一些。在里面，首先判断是否是合法的包、合法的协议、合法的ClientID，然后根据不同的报文类型去分发到protocol里不同的处理类处理。二、protocol包1、PingReqpublic void processPingReq(Channel channel, MqttMessage msg) &#123;\n  MqttMessage pingRespMessage = MqttMessageFactory.newMessage(\n      new MqttFixedHeader(MqttMessageType.PINGRESP, false, MqttQoS.AT_MOST_ONCE, false, 0), null, null);\n  LOGGER.debug(&quot;PINGREQ - clientId: &#123;&#125;&quot;, (String) channel.attr(AttributeKey.valueOf(&quot;clientId&quot;)).get());\n  channel.writeAndFlush(pingRespMessage);\n  }简单的心跳回包，心跳包是单向的，总是由客户端发给服务端，服务端回包即可。2、Connectpublic void processConnect(Channel channel, MqttConnectMessage msg) &#123;\n  // 消息解码���出现异常\n  if (msg.decoderResult().isFailure()) &#123;\n      Throwable cause = msg.decoderResult().cause();\n      if (cause instanceof MqttUnacceptableProtocolVersionException) &#123;\n          // 不支持的协议版本\n          MqttConnAckMessage connAckMessage = (MqttConnAckMessage) MqttMessageFactory.newMessage(\n                  new MqttFixedHeader(MqttMessageType.CONNACK, false, MqttQoS.AT_MOST_ONCE, false, 0),\n                  new MqttConnAckVariableHeader(MqttConnectReturnCode.CONNECTION_REFUSED_UNACCEPTABLE_PROTOCOL_VERSION, false), null);\n          channel.writeAndFlush(connAckMessage);\n          channel.close();\n          return;\n      &#125; else if (cause instanceof MqttIdentifierRejectedException) &#123;\n          // 不合格的clientId\n          MqttConnAckMessage connAckMessage = (MqttConnAckMessage) MqttMessageFactory.newMessage(\n                  new MqttFixedHeader(MqttMessageType.CONNACK, false, MqttQoS.AT_MOST_ONCE, false, 0),\n                  new MqttConnAckVariableHeader(MqttConnectReturnCode.CONNECTION_REFUSED_IDENTIFIER_REJECTED, false), null);\n          channel.writeAndFlush(connAckMessage);\n          channel.close();\n          return;\n      &#125;\n      channel.close();\n      return;\n  &#125;\n  // clientId为空或null的情况, 这里要求客户端必须提供clientId, 不管cleanSession是否为1, 此处没有参考标准协议实现\n  if (StrUtil.isBlank(msg.payload().clientIdentifier())) &#123;\n      MqttConnAckMessage connAckMessage = (MqttConnAckMessage) MqttMessageFactory.newMessage(\n              new MqttFixedHeader(MqttMessageType.CONNACK, false, MqttQoS.AT_MOST_ONCE, false, 0),\n              new MqttConnAckVariableHeader(MqttConnectReturnCode.CONNECTION_REFUSED_IDENTIFIER_REJECTED, false), null);\n      channel.writeAndFlush(connAckMessage);\n      channel.close();\n      return;\n  &#125;\n  if (brokerProperties.getMqttPasswordMust()) &#123;\n      // 用户名和密码验证, 这里要求客户端连接时必须提供用户名和密码, 不管是否设置用户名标志和密码标志为1, 此处没有参考标准协议实现\n      String username = msg.payload().userName();\n      String password = msg.payload().passwordInBytes() == null ? null : new String(msg.payload().passwordInBytes(), CharsetUtil.UTF_8);\n      if (!authService.checkValid(username, password)) &#123;\n          MqttConnAckMessage connAckMessage = (MqttConnAckMessage) MqttMessageFactory.newMessage(\n                  new MqttFixedHeader(MqttMessageType.CONNACK, false, MqttQoS.AT_MOST_ONCE, false, 0),\n                  new MqttConnAckVariableHeader(MqttConnectReturnCode.CONNECTION_REFUSED_BAD_USER_NAME_OR_PASSWORD, false), null);\n          channel.writeAndFlush(connAckMessage);\n          channel.close();\n          return;\n      &#125;\n  &#125;\n  // 如果会话中已存储这个新连接的clientId, 就关闭之前该clientId的连接\n  if (sessionStoreService.containsKey(msg.payload().clientIdentifier())) &#123;\n      SessionStore sessionStore = sessionStoreService.get(msg.payload().clientIdentifier());\n      Boolean cleanSession = sessionStore.isCleanSession();\n      if (cleanSession) &#123;\n          sessionStoreService.remove(msg.payload().clientIdentifier());\n          subscribeStoreService.removeForClient(msg.payload().clientIdentifier());\n          dupPublishMessageStoreService.removeByClient(msg.payload().clientIdentifier());\n          dupPubRelMessageStoreService.removeByClient(msg.payload().clientIdentifier());\n      &#125;\n      try &#123;\n          ChannelId channelId = channelIdMap.get(sessionStore.getChannelId());\n          if(channelId!=null) &#123;\n              Channel previous = channelGroup.find(channelId);\n              if (previous != null) previous.close();\n          &#125;\n      &#125;catch (Exception e)&#123;\n          e.printStackTrace();\n      &#125;\n  &#125;\n  // 处理遗嘱信息\n  SessionStore sessionStore = new SessionStore(msg.payload().clientIdentifier(), channel.id().asShortText(), msg.variableHeader().isCleanSession(), null);\n  if (msg.variableHeader().isWillFlag()) &#123;\n      MqttPublishMessage willMessage = (MqttPublishMessage) MqttMessageFactory.newMessage(\n              new MqttFixedHeader(MqttMessageType.PUBLISH, false, MqttQoS.valueOf(msg.variableHeader().willQos()), msg.variableHeader().isWillRetain(), 0),\n              new MqttPublishVariableHeader(msg.payload().willTopic(), 0), Unpooled.buffer().writeBytes(msg.payload().willMessageInBytes()));\n      sessionStore.setWillMessage(willMessage);\n  &#125;\n  // 处理连接心跳包\n  if (msg.variableHeader().keepAliveTimeSeconds() &amp;gt; 0) &#123;\n      if (channel.pipeline().names().contains(&quot;idle&quot;)) &#123;\n          channel.pipeline().remove(&quot;idle&quot;);\n      &#125;\n      channel.pipeline().addFirst(&quot;idle&quot;, new IdleStateHandler(0, 0, Math.round(msg.variableHeader().keepAliveTimeSeconds() * 1.5f)));\n  &#125;\n  // 至此存储会话信息及返回接受客户端连接\n  sessionStoreService.put(msg.payload().clientIdentifier(), sessionStore);\n  // 将clientId存储到channel的map中\n  channel.attr(AttributeKey.valueOf(&quot;clientId&quot;)).set(msg.payload().clientIdentifier());\n  Boolean sessionPresent = sessionStoreService.containsKey(msg.payload().clientIdentifier()) &amp;amp;&amp;amp; !msg.variableHeader().isCleanSession();\n  MqttConnAckMessage okResp = (MqttConnAckMessage) MqttMessageFactory.newMessage(\n          new MqttFixedHeader(MqttMessageType.CONNACK, false, MqttQoS.AT_MOST_ONCE, false, 0),\n          new MqttConnAckVariableHeader(MqttConnectReturnCode.CONNECTION_ACCEPTED, sessionPresent), null);\n  channel.writeAndFlush(okResp);\n  LOGGER.debug(&quot;CONNECT - clientId: &#123;&#125;, cleanSession: &#123;&#125;&quot;, msg.payload().clientIdentifier(), msg.variableHeader().isCleanSession());\n  // 如果cleanSession为0, 需要重发同一clientId存储的未完成的QoS1和QoS2的DUP消息\n  if (!msg.variableHeader().isCleanSession()) &#123;\n      List&amp;lt;DupPublishMessageStore&amp;gt; dupPublishMessageStoreList = dupPublishMessageStoreService.get(msg.payload().clientIdentifier());\n      List&amp;lt;DupPubRelMessageStore&amp;gt; dupPubRelMessageStoreList = dupPubRelMessageStoreService.get(msg.payload().clientIdentifier());\n      dupPublishMessageStoreList.forEach(dupPublishMessageStore -&amp;gt; &#123;\n          MqttPublishMessage publishMessage = (MqttPublishMessage) MqttMessageFactory.newMessage(\n                  new MqttFixedHeader(MqttMessageType.PUBLISH, true, MqttQoS.valueOf(dupPublishMessageStore.getMqttQoS()), false, 0),\n                  new MqttPublishVariableHeader(dupPublishMessageStore.getTopic(), dupPublishMessageStore.getMessageId()), Unpooled.buffer().writeBytes(dupPublishMessageStore.getMessageBytes()));\n          channel.writeAndFlush(publishMessage);\n      &#125;);\n      dupPubRelMessageStoreList.forEach(dupPubRelMessageStore -&amp;gt; &#123;\n          MqttMessage pubRelMessage = MqttMessageFactory.newMessage(\n                  new MqttFixedHeader(MqttMessageType.PUBREL, true, MqttQoS.AT_MOST_ONCE, false, 0),\n                  MqttMessageIdVariableHeader.from(dupPubRelMessageStore.getMessageId()), null);\n          channel.writeAndFlush(pubRelMessage);\n      &#125;);\n  &#125;\n  }1）���里又处理了一次非法值返回码，我想作者可能是忘记了前面处理过。2）clientID要求必须不为空，协议规定为空是可以的，但只能出现在cleansession=1（非持久化）会话上，服务器帮助客户端生成一个随机clientID，一旦断开连接，客户端的ClientID就会发生变化，所以只能非持久化会话。这里没有实现这个逻辑，要求必须不为空。3）用户名和密码认证，协议规定为空是可以的，这里要求必须提供。实际上真实的服务器可能不需要username，因为password很可能是JWT之类的数据，已经足够验证客户端身份了，不需要username。4）获取旧会话，关闭相同clientID的连接。只能同时有一个clientID在线，如果有重复clientID则需要踢掉旧会话。这里的踢操作依赖于本地的channelgroup，所以只会踢掉本地的client，不会踢掉其他Broker上的client，可以说是一个Bug……作者集群做得不好。5）处理遗嘱信息，如果有存起来就好。6）连接心跳包，如果设置了keepAlive的值，则设置Netty的IdleHandler为那个值，如果为0，则保持默认的前面在BrokerServer设置的值。这里其实还应该判断keepAlive是否设置得合法，因为过短的心跳间隔会造成服务器压力很大，应该检查客户端要求的心跳间隔是否服务器能承受，否则就断开连接。作者没有检查。7）如果cleansession为0（持久会话），则重新下发未ACK的QoS1、QoS2消息，第二阶段未完成的QoS2消息。作者保存这些消息都是没有顺序的，是直接Hash到Redis，但理论上应该保证重发顺序。3、Disconnectpublic void processDisConnect(Channel channel, MqttMessage msg) &#123;\n  String clientId = (String) channel.attr(AttributeKey.valueOf(&quot;clientId&quot;)).get();\n  SessionStore sessionStore = sessionStoreService.get(clientId);\n  if (sessionStore != null &amp;amp;&amp;amp; sessionStore.isCleanSession()) &#123;\n      subscribeStoreService.removeForClient(clientId);\n      dupPublishMessageStoreService.removeByClient(clientId);\n      dupPubRelMessageStoreService.removeByClient(clientId);\n  &#125;\n  LOGGER.debug(&quot;DISCONNECT - clientId: &#123;&#125;, cleanSession: &#123;&#125;&quot;, clientId, sessionStore.isCleanSession());\n  sessionStoreService.remove(clientId);\n  channel.close();\n  }根据是否是持久会话清理掉session即可。4、Publishpublic void processPublish(Channel channel, MqttPublishMessage msg) &#123;\n  String clientId = (String) channel.attr(AttributeKey.valueOf(&quot;clientId&quot;)).get();\n  // QoS=0\n  if (msg.fixedHeader().qosLevel() == MqttQoS.AT_MOST_ONCE) &#123;\n      byte[] messageBytes = new byte[msg.payload().readableBytes()];\n      msg.payload().getBytes(msg.payload().readerIndex(), messageBytes);\n      InternalMessage internalMessage = new InternalMessage().setTopic(msg.variableHeader().topicName())\n              .setMqttQoS(msg.fixedHeader().qosLevel().value()).setMessageBytes(messageBytes)\n              .setDup(false).setRetain(false).setClientId(clientId);\n      internalCommunication.internalSend(internalMessage);\n      this.sendPublishMessage(msg.variableHeader().topicName(), msg.fixedHeader().qosLevel(), messageBytes, false, false);\n  &#125;\n  // QoS=1\n  if (msg.fixedHeader().qosLevel() == MqttQoS.AT_LEAST_ONCE) &#123;\n      byte[] messageBytes = new byte[msg.payload().readableBytes()];\n      msg.payload().getBytes(msg.payload().readerIndex(), messageBytes);\n      InternalMessage internalMessage = new InternalMessage().setTopic(msg.variableHeader().topicName())\n              .setMqttQoS(msg.fixedHeader().qosLevel().value()).setMessageBytes(messageBytes)\n              .setDup(false).setRetain(false).setClientId(clientId);\n      internalCommunication.internalSend(internalMessage);\n      this.sendPublishMessage(msg.variableHeader().topicName(), msg.fixedHeader().qosLevel(), messageBytes, false, false);\n      this.sendPubAckMessage(channel, msg.variableHeader().packetId());\n  &#125;\n  // QoS=2\n  if (msg.fixedHeader().qosLevel() == MqttQoS.EXACTLY_ONCE) &#123;\n      byte[] messageBytes = new byte[msg.payload().readableBytes()];\n      msg.payload().getBytes(msg.payload().readerIndex(), messageBytes);\n      InternalMessage internalMessage = new InternalMessage().setTopic(msg.variableHeader().topicName())\n              .setMqttQoS(msg.fixedHeader().qosLevel().value()).setMessageBytes(messageBytes)\n              .setDup(false).setRetain(false).setClientId(clientId);\n      internalCommunication.internalSend(internalMessage);\n      this.sendPublishMessage(msg.variableHeader().topicName(), msg.fixedHeader().qosLevel(), messageBytes, false, false);\n      this.sendPubRecMessage(channel, msg.variableHeader().packetId());\n  &#125;\n  // retain=1, 保留消息\n  if (msg.fixedHeader().isRetain()) &#123;\n      byte[] messageBytes = new byte[msg.payload().readableBytes()];\n      msg.payload().getBytes(msg.payload().readerIndex(), messageBytes);\n      if (messageBytes.length == 0) &#123;\n          retainMessageStoreService.remove(msg.variableHeader().topicName());\n      &#125; else &#123;\n          RetainMessageStore retainMessageStore = new RetainMessageStore().setTopic(msg.variableHeader().topicName()).setMqttQoS(msg.fixedHeader().qosLevel().value())\n                  .setMessageBytes(messageBytes);\n          retainMessageStoreService.put(msg.variableHeader().topicName(), retainMessageStore);\n      &#125;\n  &#125;\n  }回顾一下Publish的流程：如果是QoS0，直接发送；如果是QoS1，除了发送还需要回复PubAck给发送者；如果是QoS2，除了发送还需要回复PubRec给发送者；如果是保留消息，长度为0则清除该主题的保留消息，否则保存该主题的保留消息。如果开启了集群功能，会通过Redis广播；如果开启了Kafka转发，会进行转发。private void sendPublishMessage(String topic, MqttQoS mqttQoS, byte[] messageBytes, boolean retain, boolean dup) &#123;\n  List&amp;lt;SubscribeStore&amp;gt; subscribeStores = subscribeStoreService.search(topic);\n  subscribeStores.forEach(subscribeStore -&amp;gt; &#123;\n      if (sessionStoreService.containsKey(subscribeStore.getClientId())) &#123;\n          // 订阅者收到MQTT消息的QoS级别, 最终取决于发布消息的QoS和主题订阅的QoS\n          MqttQoS respQoS = mqttQoS.value() &amp;gt; subscribeStore.getMqttQoS() ? MqttQoS.valueOf(subscribeStore.getMqttQoS()) : mqttQoS;\n          if (respQoS == MqttQoS.AT_MOST_ONCE) &#123;\n              MqttPublishMessage publishMessage = (MqttPublishMessage) MqttMessageFactory.newMessage(\n                      new MqttFixedHeader(MqttMessageType.PUBLISH, dup, respQoS, retain, 0),\n                      new MqttPublishVariableHeader(topic, 0), Unpooled.buffer().writeBytes(messageBytes));\n              LOGGER.debug(&quot;PUBLISH - clientId: &#123;&#125;, topic: &#123;&#125;, Qos: &#123;&#125;&quot;, subscribeStore.getClientId(), topic, respQoS.value());\n              ChannelId channelId = channelIdMap.get(sessionStoreService.get(subscribeStore.getClientId()).getChannelId());\n              if(channelId!=null) &#123;\n                  Channel channel = channelGroup.find(channelId);\n                  if (channel != null) channel.writeAndFlush(publishMessage);\n              &#125;\n          &#125;\n          if (respQoS == MqttQoS.AT_LEAST_ONCE) &#123;\n              int messageId = messageIdService.getNextMessageId();\n              MqttPublishMessage publishMessage = (MqttPublishMessage) MqttMessageFactory.newMessage(\n                      new MqttFixedHeader(MqttMessageType.PUBLISH, dup, respQoS, retain, 0),\n                      new MqttPublishVariableHeader(topic, messageId), Unpooled.buffer().writeBytes(messageBytes));\n              LOGGER.debug(&quot;PUBLISH - clientId: &#123;&#125;, topic: &#123;&#125;, Qos: &#123;&#125;, messageId: &#123;&#125;&quot;, subscribeStore.getClientId(), topic, respQoS.value(), messageId);\n              DupPublishMessageStore dupPublishMessageStore = new DupPublishMessageStore().setClientId(subscribeStore.getClientId())\n                      .setTopic(topic).setMqttQoS(respQoS.value()).setMessageBytes(messageBytes).setMessageId(messageId);\n              dupPublishMessageStoreService.put(subscribeStore.getClientId(), dupPublishMessageStore);\n              ChannelId channelId = channelIdMap.get(sessionStoreService.get(subscribeStore.getClientId()).getChannelId());\n              if(channelId!=null) &#123;\n                  Channel channel = channelGroup.find(channelId);\n                  if (channel != null) channel.writeAndFlush(publishMessage);\n              &#125;\n          &#125;\n          if (respQoS == MqttQoS.EXACTLY_ONCE) &#123;\n              int messageId = messageIdService.getNextMessageId();\n              MqttPublishMessage publishMessage = (MqttPublishMessage) MqttMessageFactory.newMessage(\n                      new MqttFixedHeader(MqttMessageType.PUBLISH, dup, respQoS, retain, 0),\n                      new MqttPublishVariableHeader(topic, messageId), Unpooled.buffer().writeBytes(messageBytes));\n              LOGGER.debug(&quot;PUBLISH - clientId: &#123;&#125;, topic: &#123;&#125;, Qos: &#123;&#125;, messageId: &#123;&#125;&quot;, subscribeStore.getClientId(), topic, respQoS.value(), messageId);\n              DupPublishMessageStore dupPublishMessageStore = new DupPublishMessageStore().setClientId(subscribeStore.getClientId())\n                      .setTopic(topic).setMqttQoS(respQoS.value()).setMessageBytes(messageBytes).setMessageId(messageId);\n              dupPublishMessageStoreService.put(subscribeStore.getClientId(), dupPublishMessageStore);\n              ChannelId channelId = channelIdMap.get(sessionStoreService.get(subscribeStore.getClientId()).getChannelId());\n              if(channelId!=null) &#123;\n                  Channel channel = channelGroup.find(channelId);\n                  if (channel != null) channel.writeAndFlush(publishMessage);\n              &#125;\n          &#125;\n      &#125;\n  &#125;);\n  }和发送者通信的时候才会收到Publish。发送的具体代码流程是：搜寻订阅这个主题的订阅者；如果是QoS0，直接下发（QoS0的messageId为0）；如果是QoS1，先获取一个未被占用的messageId，缓存一份DupPublish消息，再下发；如果是QoS2，先获取一个未被占用的messageId，缓存一份DupPublish消息，再下发。5、PubRelpublic void processPubRel(Channel channel, MqttMessageIdVariableHeader variableHeader) &#123;\n  MqttMessage pubCompMessage = MqttMessageFactory.newMessage(\n      new MqttFixedHeader(MqttMessageType.PUBCOMP, false, MqttQoS.AT_MOST_ONCE, false, 0),\n      MqttMessageIdVariableHeader.from(variableHeader.messageId()), null);\n  LOGGER.debug(&quot;PUBREL - clientId: &#123;&#125;, messageId: &#123;&#125;&quot;, (String) channel.attr(AttributeKey.valueOf(&quot;clientId&quot;)).get(), variableHeader.messageId());\n  channel.writeAndFlush(pubCompMessage);\n  }和发送者通信的时候才会收到PubRel，处于QoS2第二阶段，服务器需要会送一个PubComp让发送者知道QoS2已经完成了。6、PubAckpublic void processPubAck(Channel channel, MqttMessageIdVariableHeader variableHeader) &#123;\n  int messageId = variableHeader.messageId();\n  LOGGER.debug(&quot;PUBACK - clientId: &#123;&#125;, messageId: &#123;&#125;&quot;, (String) channel.attr(AttributeKey.valueOf(&quot;clientId&quot;)).get(), messageId);\n  dupPublishMessageStoreService.remove((String) channel.attr(AttributeKey.valueOf(&quot;clientId&quot;)).get(), messageId);\n  }和接收者通信的时候才会收到PubAck，表明QoS1已经完成，移除缓存的DupPublish消息。7、PubRecpublic void processPubRec(Channel channel, MqttMessageIdVariableHeader variableHeader) &#123;\n  MqttMessage pubRelMessage = MqttMessageFactory.newMessage(\n      new MqttFixedHeader(MqttMessageType.PUBREL, false, MqttQoS.AT_MOST_ONCE, false, 0),\n      MqttMessageIdVariableHeader.from(variableHeader.messageId()), null);\n  LOGGER.debug(&quot;PUBREC - clientId: &#123;&#125;, messageId: &#123;&#125;&quot;, (String) channel.attr(AttributeKey.valueOf(&quot;clientId&quot;)).get(), variableHeader.messageId());\n  dupPublishMessageStoreService.remove((String) channel.attr(AttributeKey.valueOf(&quot;clientId&quot;)).get(), variableHeader.messageId());\n  DupPubRelMessageStore dupPubRelMessageStore = new DupPubRelMessageStore().setClientId((String) channel.attr(AttributeKey.valueOf(&quot;clientId&quot;)).get())\n      .setMessageId(variableHeader.messageId());\n  dupPubRelMessageStoreService.put((String) channel.attr(AttributeKey.valueOf(&quot;clientId&quot;)).get(), dupPubRelMessageStore);\n  channel.writeAndFlush(pubRelMessage);\n  }和接收者通信的时候才会收到PubRec，表明QoS2的第一阶段完成，移除缓存的Publish消息，重新缓存一份PubRel消息，并下发PubRel消息，开启第二阶段。8、PubComppublic void processPubComp(Channel channel, MqttMessageIdVariableHeader variableHeader) &#123;\n  int messageId = variableHeader.messageId();\n  LOGGER.debug(&quot;PUBCOMP - clientId: &#123;&#125;, messageId: &#123;&#125;&quot;, (String) channel.attr(AttributeKey.valueOf(&quot;clientId&quot;)).get(), messageId);\n  dupPubRelMessageStoreService.remove((String) channel.attr(AttributeKey.valueOf(&quot;clientId&quot;)).get(), variableHeader.messageId());\n  }和接收者通信的时候才会收到PubComp，表明QoS2已经完成，移除缓存的PubRel消息。9、Subscribepublic void processSubscribe(Channel channel, MqttSubscribeMessage msg) &#123;\n  List&amp;lt;MqttTopicSubscription&amp;gt; topicSubscriptions = msg.payload().topicSubscriptions();\n  if (this.validTopicFilter(topicSubscriptions)) &#123;\n      String clientId = (String) channel.attr(AttributeKey.valueOf(&quot;clientId&quot;)).get();\n      List&amp;lt;Integer&amp;gt; mqttQoSList = new ArrayList&amp;lt;Integer&amp;gt;();\n      topicSubscriptions.forEach(topicSubscription -&amp;gt; &#123;\n          String topicFilter = topicSubscription.topicName();\n          MqttQoS mqttQoS = topicSubscription.qualityOfService();\n          SubscribeStore subscribeStore = new SubscribeStore(clientId, topicFilter, mqttQoS.value());\n          subscribeStoreService.put(topicFilter, subscribeStore);\n          mqttQoSList.add(mqttQoS.value());\n          LOGGER.debug(&quot;SUBSCRIBE - clientId: &#123;&#125;, topFilter: &#123;&#125;, QoS: &#123;&#125;&quot;, clientId, topicFilter, mqttQoS.value());\n      &#125;);\n      MqttSubAckMessage subAckMessage = (MqttSubAckMessage) MqttMessageFactory.newMessage(\n          new MqttFixedHeader(MqttMessageType.SUBACK, false, MqttQoS.AT_MOST_ONCE, false, 0),\n          MqttMessageIdVariableHeader.from(msg.variableHeader().messageId()),\n          new MqttSubAckPayload(mqttQoSList));\n      channel.writeAndFlush(subAckMessage);\n      // 发布保留消息\n      topicSubscriptions.forEach(topicSubscription -&amp;gt; &#123;\n          String topicFilter = topicSubscription.topicName();\n          MqttQoS mqttQoS = topicSubscription.qualityOfService();\n          this.sendRetainMessage(channel, topicFilter, mqttQoS);\n      &#125;);\n  &#125; else &#123;\n      channel.close();\n  &#125;\n  }先校验所有的Topic是否正确，如果正确，则回复对应的SubAck报文，并把订阅信息存储起来。对于有保留消息的主题，需要保存该主题的保留消息。private boolean validTopicFilter(List&lt;MqttTopicSubscription&gt; topicSubscriptions) &#123;\n  for (MqttTopicSubscription topicSubscription : topicSubscriptions) &#123;\n      String topicFilter = topicSubscription.topicName();\n      // 以#或+符号开头的、以/符号结尾的订阅按非法订阅处理, 这里没有参考标准协议\n      if (StrUtil.startWith(topicFilter, &#39;+&#39;) || StrUtil.endWith(topicFilter, &#39;/&#39;))\n          return false;\n      if (StrUtil.contains(topicFilter, &#39;#&#39;)) &#123;\n          // 如果出现多个#符号的订阅按非法订阅处理\n          if (StrUtil.count(topicFilter, &#39;#&#39;) &amp;gt; 1) return false;\n      &#125;\n      if (StrUtil.contains(topicFilter, &#39;+&#39;)) &#123;\n          //如果+符号和/+字符串出现的次数不等的情况按非法订阅处理\n          if (StrUtil.count(topicFilter, &#39;+&#39;) != StrUtil.count(topicFilter, &quot;/+&quot;)) return false;\n      &#125;\n  &#125;\n  return true;\n  }验证Topic的正确性只限制了一些格式，没有对“是否有权限订阅”进行权限验证。10、Unsubscribepublic void processUnSubscribe(Channel channel, MqttUnsubscribeMessage msg) &#123;\n  List&amp;lt;String&amp;gt; topicFilters = msg.payload().topics();\n  String clinetId = (String) channel.attr(AttributeKey.valueOf(&quot;clientId&quot;)).get();\n  topicFilters.forEach(topicFilter -&amp;gt; &#123;\n      subscribeStoreService.remove(topicFilter, clinetId);\n      LOGGER.debug(&quot;UNSUBSCRIBE - clientId: &#123;&#125;, topicFilter: &#123;&#125;&quot;, clinetId, topicFilter);\n  &#125;);\n  MqttUnsubAckMessage unsubAckMessage = (MqttUnsubAckMessage) MqttMessageFactory.newMessage(\n      new MqttFixedHeader(MqttMessageType.UNSUBACK, false, MqttQoS.AT_MOST_ONCE, false, 0),\n      MqttMessageIdVariableHeader.from(msg.variableHeader().messageId()), null);\n  channel.writeAndFlush(unsubAckMessage);\n  }移除订阅信息就好了。总结MqttWk的协议处理有一些地方不妥，但是整体结构非常清晰。                \n\n\n","categories":["转载"],"tags":[]},{"title":"用winpcap测试自己的通信协议（二）","url":"http://tanqingbo.cn/2019/10/06/用winpcap测试自己的通信协议（二）/","content":"\nhttp://www.bewindoweb.com/212.html一、通信协议的详细方案前文说到，我们设计了这么一个BTP(BWB Transport Protocol)通信协议：序号BTP字段名占用空间说明&nbsp;1协议标识1字节&nbsp;0x42（大写的'B'）&nbsp;2协议版本1字节&nbsp;0x01（1.0版本）&nbsp;3包类型1字节&nbsp;握手请求包：0x01&nbsp;握手响应包：0x02&nbsp;心跳请求包：0x03&nbsp;心跳响应包：0x04&nbsp;数据包：0x05&nbsp;断开请求包：0x06&nbsp;断开响应包：0x07&nbsp;4包序号1字节&nbsp;0x00~0xFF循环使用&nbsp;5数据长度2字节&nbsp;0x0000~0xFFFF&nbsp;6数据0~65535字节&nbsp;要传输的数据，可以为空&nbsp;&nbsp;7校验和&nbsp;4字节&nbsp;采用经典的CRC32（1）包序号每次开始发送数据时，总是从0x00到0xFF随机挑选一个初始数字，发包和回包必须携带相同的数字，并且下一个包为这一个包序号+1，如果超过0xFF，则从0x00重新开始。（2）握手请求包0x01与握手响应包0x02a. 规定数据长度为0，数据为空。b. 发送者发送握手请求包，接收者接收握手请求包后立即响应握手应答包。c. 只发送一次，1秒超时则认为握手失败。d. 握手必须确认协议标识和版本号，否则认为不是BTP包或者版本不相同进行丢弃（一般的协议都是返回一个带错误码的包，这里直接进行简单丢弃）。（3）心跳请求包0x03与心跳响应包0x04a. 规定数据长度为0，数据为空。b. 在成功握手之后，每隔5秒发送一次心跳请求包，接收者必须立即回应心跳响应包，用来维护链路。c. 1秒超时则认为链路断开。（4）数据包0x05携带着要发送的数据。（5）断开请求包0x06和断开响应包0x07a. 规定数据长度为0，数据为空。&nbsp;&nbsp;b. 当接收者接收到发送者的断开请求包后，立即回应断开响应包，双方各自进行清理工作，结束通信。OK，方案设计完成。二、winpcap的发送者和接收者的实现1、实现思路前面已经实现了基本的发包和收包，要想实现发送者和接收者，核心是要让程序能够同时进行发包和收包。为了方便说明，仍然使用PA进行作为通信发起者，PB作为通信接收者。方案一对于PB来说，用一个全局变量维护当前状态，然后在回调函数里面收到包后进行发包操作即可。对于PA来说，也使用全局变量维护当前状态，在发送第一个握手包之后，就陷入监听，然后在回调函数里实现类似的收包发包操作。但这种方案维护起来很麻烦，比较差。方案二（采用）多线程，用全局变量来进行同步，使用互斥锁进行写操作。【PB】只需要进行反射发包，所以仅仅需要收到特定包后回送特定包，根据状态机前进，两个线程，一个主线程发射发包，一个计时线程计时心跳。如果心跳超时，强行中断所有线程。（这和直接接受心跳包然后计算时间差来判断有什么区别呢？区别在于，如果对方断开了连接，那么永远也接受不到心跳包，也就计算不了时间差了；而线程自己计时则能够自己控制）【PA】线程1为发包线程，在特定条件满足后，开始发送特定包（数据包）或进行特定操作（开启心跳线程）。线程2为接收线程，在接收到特定包后（比如接收到握手包），进行唤醒操作（比如每隔1秒唤醒发包线程，每隔5秒同时唤醒心跳线程）。线程3为心跳线程，在特定条件满足后，开始发送心跳包。线程4为计时线程，如果超时，强行中断所有线程。&nbsp;&nbsp;哎，就很舒服~但是实现起来比较麻烦，一步一步来。2、实现过程（1）配置pthread2.9.1&nbsp;下载地址（密码：vyqi）和前面配置winpcap类似，首先把pthread源代码文件解压到英文目录，比如E:\\pthreads2.9.1。然后添加lib支持，告诉编译器链接的时候先去找这个库。调试→属性→配置属性→链接器→输入，添加：pthreadVC2.lib;pthreadVCE2.lib;pthreadVSE2.lib;最后添加包含目录和库目录，调试→属性→配置属性→VC++目录，添加：包含目录添加     E:\\pthreads2.9.1\\Pre-built.2\\include;\n库目录添加        E:\\pthreads2.9.1\\Pre-built.2\\lib\\x86;这里很可能还是没配置好，运行时还会报错：这是因为之前配置的winpcap在很多软件安装的时候都会自动安装，比如安装wireshark都会提示你安装winpcap否则wireshark不会正常工作，他们把dll文件都拷贝进了C:\\Windows\\System32里面。所以之前能够找到winpcap的动态链接库dll，这里却找不到了。pthread很可能我们只用一次而已，拷贝进系统dll不可取，拷贝进项目dll不方便，因此我们依然采用设置的方法：调试→属性→配置属性→调试→环境，添加：path=E:\\pthreads2.9.1\\Pre-built.2\\dll\\x86编译环境就OK了。但是我们这个exe是要放到windows xp下运行的，由于官方的lib是动态的，依然会提示错误，有兴趣可以看看\n\n\n\n《pthread-win32静态库的编译和使用方法》&nbsp;， 这时候我们采用复制dll的方法，把需要的dll赋值到EXE所���目录，反正都是虚拟机，无所谓，这样就能成功运行啦：（2）编写接收者BTPrecver.h#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;pcap.h&gt;#include &lt;winsock.h&gt;#include &lt;pthread.h&gt;\n#define SEND_BUFSIZE                    1024#define TIMER_SLEEPTIME                 2000#define ERROR_GENERAL                   -1#define ERROR_FINDALLDEVS_FAILURE       -2#define ERROR_INTERFACES_NOT_FOUND      -3#define ERROR_BAD_INPUT                 -4#define ERROR_OPEN_ADAPTER_FAILURE      -5#define ERROR_SENDING_FAILURE           -6#define ERROR_INVALID_DATALINK_TYPE     -7#define ERROR_COMPILE_FILTER_FALIURE    -8#define ERROR_SET_FILTER_FALIURE        -9#define ERROR_CREATE_THREAD             -10#define ERROR_BTP_HELLO_FAILED          -11#define ERROR_BTP_HEARTBEAT_FAILED      -12#define ERROR_BTP_BYE_FAILED            -13#define ERROR_BTP_TIMEOUT               -14#define ERROR_BAD_VERSION               -15\n#define BTP_HELLO_REQUEST       0x01#define BTP_HELLO_RESPONSE      0x02#define BTP_HEARTBEAT_REQUEST   0x03#define BTP_HEARTBEAT_RESPONSE  0x04#define BTP_DATA                0x05#define BTP_BYE_REQUEST         0x06#define BTP_BYE_RESPONSE        0x07#define BTP_PROTOCOL            0x42#define BTP_VERSION             0x01\ntypedef struct ETH_HEADER&#123;    u_char dest_mac[6];    u_char src_mac[6];    u_short etype;&#125;ETH_HEADER;\ntypedef struct BTP_HEADER&#123;    u_char protocol;    u_char version;    u_char type;    u_char pid;    u_short data_length;&#125;BTP_HEADER;\ntypedef struct BTP_STATE&#123;    int state; /* 状态：0=初始（可握手） 1=握手后（可心跳、可数据、可断开）*/    pthread_t pids[1]; /* 只有一个心跳线程 /    int timeout_flag; / 心跳超时标记，每次收包都进行+1，如果计时线程发现两次的flag都相同，说明断开了 */    pcap_t adapter; / 网卡句柄 */&#125;BTP_STATE;\nvoid packet_handler(u_char param, const struct pcap_pkthdr *header, const u_char *pkt_data);/ 抓包回调函数 */void format_mac(LPSTR lpHWAddrStr, const unsigned char HWAddr);/ mac地址格式化函数 */\nint btp_send(ETH_HEADER* eth_header, BTP_HEADER *btp_header, u_char type);void *timer(void *arg);void kill_all(char *msg, int error_code);\nvoid copy_mac(u_char *mac1, u_char mac2);char rec_type(u_char type);BTPrecver.c#include \"BTPrecver.h\"\nBTP_STATE btp_state;\nint main()&#123;    char errbuf[PCAP_ERRBUF_SIZE]; /* 错误信息buffer /    u_int netmask; / 掩码信息 /    char packet_filter[] = “ether src 00:50:56:C0:00:08 and ether dst 00:0C:29:86:B8:C8”; / 过滤规则 /    struct bpf_program fcode; / 存储编译好的过滤码 */\npcap_if_t *alldevs; /* 全部网卡列表 */\npcap_if_t *d; /* 一个网卡 */\nint did; /* 选择的网卡ID */\n\nint i = 0; /* 迭代 */\n\n/*查找网卡*/\nif (pcap_findalldevs_ex(PCAP_SRC_IF_STRING, NULL, &amp;amp;alldevs, errbuf) == -1) &#123;\n    fprintf(stderr, &quot;[ERROR] pcap_findalldevs error: %s\\n&quot;, errbuf);\n    return ERROR_FINDALLDEVS_FAILURE;\n&#125;\n\n/* 选择网卡d */\nfor (d = alldevs, i = 0; d; d = d-&amp;gt;next) &#123;\n    if (d-&amp;gt;description)\n        printf(&quot;NO.%d: %s\\n&quot;, ++i, d-&amp;gt;description);\n    else\n        printf(&quot;[WARN] No description available\\n&quot;);\n&#125;\n\nif (i == 0) &#123;\n    printf(&quot;[ERROR] No interfaces found! Make sure WinPcap is installed.\\n&quot;);\n    return ERROR_INTERFACES_NOT_FOUND;\n&#125;\n\nprintf(&quot;[INFO] Enter the interface number (1-%d):&quot;, i);\nscanf(&quot;%d&quot;, &amp;amp;did);\n\nif (did &amp;lt; 1 || did &amp;gt; i) &#123;\n    printf(&quot;[ERROR] Interface number out of range.\\n&quot;);\n    pcap_freealldevs(alldevs);\n    return ERROR_BAD_INPUT;\n&#125;\n\nfor (d = alldevs, i = 0; i &amp;lt; did - 1; d = d-&amp;gt;next, i++);\n\n/* 打开网卡 */\nif ((btp_state.adapter = pcap_open_live(d-&amp;gt;name, /* 设备名 */\n    65536, /* 捕获数据包的长度（65536捕获所有数据包） */\n    1, /* 混杂模式（非0表示使用混杂模式） */\n    1000, /* 超时时间（0表示没有超时限制） */\n    errbuf /* 错误缓存（存储错误信息） */\n    )) == NULL) &#123;\n    fprintf(stderr, &quot;[ERROR] Unable to open the adapter. %s is not supported by WinPcap\\n&quot;);\n    pcap_freealldevs(alldevs);\n    return ERROR_OPEN_ADAPTER_FAILURE;\n&#125;\n\n/* 检查链路层类型 */\nif (pcap_datalink(btp_state.adapter) != DLT_EN10MB) /* DLT_EN10MB指10Mb以太网 */\n&#123;\n    fprintf(stderr, &quot;[ERROR] This program works only on Ethernet networks.\\n&quot;);\n    pcap_freealldevs(alldevs);\n    return ERROR_INVALID_DATALINK_TYPE;\n&#125;\n\n/* 检查地址类型 */\nif (d-&amp;gt;addresses != NULL) /* 如果有IP地址 */\n    netmask = ((struct sockaddr_in *)(d-&amp;gt;addresses-&amp;gt;netmask))-&amp;gt;sin_addr.S_un.S_addr; /* 使用第一个掩码 */\nelse /* 如果没有IP地址，说明是C类网络（局域网） */\n    netmask = 0xffffff; /* 掩码设置为255.255.255.0 */\n\n\n/* 编译过滤器 */\nif (pcap_compile(btp_state.adapter, &amp;amp;fcode, packet_filter, 1, netmask) &amp;lt; 0) /* 1表示自动进行优化 */\n&#123;\n    fprintf(stderr, &quot;[ERROR] Unable to compile the packet filter. Check the syntax.\\n&quot;);\n    pcap_freealldevs(alldevs);\n    return ERROR_COMPILE_FILTER_FALIURE;\n&#125;\n\n/* 应用过滤器 */\nif (pcap_setfilter(btp_state.adapter, &amp;amp;fcode) &amp;lt; 0)\n&#123;\n    fprintf(stderr, &quot;[ERROR] Error setting the filter.\\n&quot;);\n    pcap_freealldevs(alldevs);\n    return ERROR_SET_FILTER_FALIURE;\n&#125;\n\n/* 开始抓包 */\nbtp_state.state = 0;\nbtp_state.timeout_flag = 0;\nprintf(&quot;listening on %s...\\n&quot;, d-&amp;gt;description);\npcap_freealldevs(alldevs);\npcap_loop(btp_state.adapter, 0, packet_handler, NULL);\n\nsystem(&quot;pause&quot;);\nreturn 0;\n}\n/* 抓包回调函数 /void packet_handler(u_char param, const struct pcap_pkthdr *header, const u_char *pkt_data){    time_t local_tv_sec; / 时间戳 */    struct tm *ltime; / 本地时间 /    char timestr[16]; / 格式化后的本地时间 */    ETH_HEADER eth_header; / 以太网帧包头 /    char str_mac[50]; / 源MAC地址 */    BTP_HEADER *btp_header;    char *data;    int i;\n/* 没有使用param */\n(VOID)(param);\n\n/* 格式化当前时间 */\nlocal_tv_sec = header-&amp;gt;ts.tv_sec;\nltime = localtime(&amp;amp;local_tv_sec);\nstrftime(timestr, sizeof timestr, &quot;%H:%M:%S&quot;, ltime);\n\n/* 解析以太网帧 */\neth_header = (ETH_HEADER *)pkt_data;\nformat_mac(str_mac, eth_header-&amp;gt;src_mac);\nprintf(&quot;[ %s.%.6d ] receive package from %s:\\n&quot;,\n    timestr, header-&amp;gt;ts.tv_usec, str_mac);\n\n/* 解析数据域 */\nbtp_header = (BTP_HEADER *)(pkt_data + sizeof(ETH_HEADER));\nif (btp_header-&amp;gt;protocol == BTP_PROTOCOL)&#123; /* 确认是btp包 */\n    printf(&quot;protocol=\\tBTP \\nversion=\\t%d \\ntype=\\t%s \\npid=\\t%d \\ndata_length=\\t%d \\n&quot;,\n        btp_header-&amp;gt;version, rec_type(btp_header-&amp;gt;type), btp_header-&amp;gt;pid, btp_header-&amp;gt;data_length);\n\n    if (btp_header-&amp;gt;version &amp;gt; BTP_VERSION)&#123;\n        kill_all(&quot;[ERROR] version mismatch.&quot;, ERROR_BAD_VERSION);\n    &#125;\n\n    switch (btp_header-&amp;gt;type)&#123;\n    case BTP_HELLO_REQUEST:\n        if (btp_state.state == 0)&#123;/* 初始，可握手 */\n            if (!btp_send(eth_header, btp_header, BTP_HELLO_RESPONSE))&#123;\n                if (pthread_create(&amp;amp;btp_state.pids[0], NULL, timer, NULL) == -1)&#123;/* 开启心跳线程 */\n                    kill_all(&quot;[ERROR] create thread failed.&quot;, ERROR_CREATE_THREAD);\n                &#125;\n                btp_state.state = 1;/*握手后，可心跳，可数据，可断开*/\n            &#125;\n            else&#123;\n                kill_all(&quot;[ERROR] btp hello failed.&quot;, ERROR_BTP_HELLO_FAILED);\n            &#125;\n        &#125;\n        break;\n    case BTP_HEARTBEAT_REQUEST:\n        if (btp_state.state == 1)&#123;\n            btp_state.timeout_flag = (btp_state.timeout_flag + 1) % 1000;\n            if (btp_send(eth_header, btp_header, BTP_HEARTBEAT_RESPONSE) != 0)\n                kill_all(&quot;[ERROR] btp heartbeat failed.&quot;, ERROR_BTP_HEARTBEAT_FAILED);\n        &#125;\n        break;\n    case BTP_DATA:\n        if (btp_state.state == 1)&#123;\n            data = (char*)(pkt_data + sizeof(ETH_HEADER)+sizeof(BTP_HEADER));\n            printf(&quot;recv data: &quot;);\n            for (i = 0; i &amp;lt; btp_header-&amp;gt;data_length; i++)\n                printf(&quot;%c&quot;, data[i]);\n            printf(&quot;\\n&quot;);\n        &#125;\n        break;\n    case BTP_BYE_REQUEST:\n        if (btp_state.state == 1)&#123;\n            if (btp_send(eth_header, btp_header, BTP_BYE_RESPONSE) != 0)\n                kill_all(&quot;[ERROR] btp bye failed.&quot;, ERROR_BTP_BYE_FAILED);\n            else\n                kill_all(&quot;[INFO] btp finished.&quot;, 0);\n        &#125;\n        break;\n    &#125;\n&#125;\n}\nint btp_send(ETH_HEADER* eth_header, BTP_HEADER btp_header, u_char type){    int index;    u_char sendbuf[SEND_BUFSIZE]; / 发送buffer */    u_char temp_mac[6];\n/* 制作新的eth_header */\ncopy_mac(temp_mac, eth_header-&amp;gt;src_mac);\ncopy_mac(eth_header-&amp;gt;src_mac, eth_header-&amp;gt;dest_mac);\ncopy_mac(eth_header-&amp;gt;dest_mac, temp_mac);\n\n/* 制作新的btp_header */\nbtp_header-&amp;gt;type = type;\nbtp_header-&amp;gt;data_length = 0;\n\n/* 发包 */\nmemcpy(sendbuf, eth_header, sizeof(ETH_HEADER));\nindex = sizeof(ETH_HEADER);\nmemcpy(&amp;amp;sendbuf[index], btp_header, sizeof(BTP_HEADER));\nindex += sizeof(BTP_HEADER);\n\nif (pcap_sendpacket(btp_state.adapter, /* 网卡句柄 */\n    sendbuf, /* 要发送的帧 */\n    index /* 帧的大小 */\n    ) != 0) &#123;\n    fprintf(stderr, &quot;[ERROR] Error sending the packet: %s\\n&quot;, pcap_geterr(btp_state.adapter));\n    return ERROR_SENDING_FAILURE;\n&#125;\nprintf(&quot;response a %s package.\\n&quot;, rec_type(type));\nreturn 0;\n}\nvoid *timer(void arg){    int timeout_flag;    printf(“timer start.\\n”);    while (1){        timeout_flag = btp_state.timeout_flag;        Sleep(3000);        if (timeout_flag == btp_state.timeout_flag){ / 没有改变 */            kill_all(“[ERROR] time out.”, ERROR_BTP_TIMEOUT);            break;        }        printf(“timer ok\\n”);    }    return NULL;}\nvoid kill_all(char *msg, int error_code){    printf(“%s\\n”, msg);    pcap_breakloop(btp_state.adapter);    system(“pause”);    exit(error_code);}\nchar* rec_type(u_char type){    switch (type){    case BTP_HELLO_REQUEST:        return “BTP_HELLO_REQUEST”;    case BTP_HELLO_RESPONSE:        return “BTP_HELLO_RESPONSE”;    case BTP_HEARTBEAT_REQUEST:        return “BTP_HEARTBEAT_REQUEST”;    case BTP_HEARTBEAT_RESPONSE:        return “BTP_HEARTBEAT_RESPONSE”;    case BTP_DATA:        return “BTP_DATA”;    case BTP_BYE_REQUEST:        return “BTP_BYE_REQUEST”;    case BTP_BYE_RESPONSE:        return “BTP_BYE_RESPONSE”;    default:        return “BAD_TYPE”;    }}void copy_mac(u_char *mac1, u_char *mac2){    mac1[0] = mac2[0];    mac1[1] = mac2[1];    mac1[2] = mac2[2];    mac1[3] = mac2[3];    mac1[4] = mac2[4];    mac1[5] = mac2[5];}\nvoid format_mac(char* lpHWAddrStr, const unsigned char *HWAddr){    int i;    short temp;    char szStr[3];\nstrcpy(lpHWAddrStr, &quot;&quot;);\nfor (i = 0; i &amp;lt; 6; ++i)\n&#123;\n    temp = (short)(*(HWAddr + i));\n    _itoa(temp, szStr, 16);\n    if (strlen(szStr) == 1)\n        strcat(lpHWAddrStr, &quot;0&quot;);\n    strcat(lpHWAddrStr, szStr);\n    if (i &amp;lt; 5)\n        strcat(lpHWAddrStr, &quot;:&quot;);\n&#125;\n}注意这里的kill_all函数，你可以自己去编写中止线程的方法，比如cancel或者kill，并且pcap_breakloop(btp_state.adapter);这一句不是必须的，是因为我使用了system(\"pause\");想查看一下输出结果，造成exit(error_code);没有执行，所以使用这一句来结束winpcap抓包。正常的来说，你可以使用打印输出到文件而不是到屏幕，然后注释掉这句，让exit执行，就能够中止所有线程了。整体思路很容易看懂，state就是状态机；pids保存着线程的结构体，用来结束线程；每次收到心跳包后就更新timeout_flag，timer根据这个值是否更新来判断是否心跳超时了，从而判断是否断开连接了，注意接收者是不需要发包计时线程的，因为它只管接受新包和回包，不需要期待对面回包；adapter是网卡句柄。（3）测试接收者把sender稍微改造一下。BTPsender.h#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;pcap.h&gt;#include &lt;winsock.h&gt;#include &lt;pthread.h&gt;\n#define SEND_BUFSIZE                    1024#define TIMER_SLEEPTIME                 2000#define ERROR_GENERAL                   -1#define ERROR_FINDALLDEVS_FAILURE       -2#define ERROR_INTERFACES_NOT_FOUND      -3#define ERROR_BAD_INPUT                 -4#define ERROR_OPEN_ADAPTER_FAILURE      -5#define ERROR_SENDING_FAILURE           -6#define ERROR_INVALID_DATALINK_TYPE     -7#define ERROR_COMPILE_FILTER_FALIURE    -8#define ERROR_SET_FILTER_FALIURE        -9#define ERROR_CREATE_THREAD             -10#define ERROR_BTP_HELLO_FAILED          -11#define ERROR_BTP_HEARTBEAT_FAILED      -12#define ERROR_BTP_BYE_FAILED            -13#define ERROR_BTP_TIMEOUT               -14#define ERROR_BAD_VERSION               -15\n#define BTP_HELLO_REQUEST       0x01#define BTP_HELLO_RESPONSE      0x02#define BTP_HEARTBEAT_REQUEST   0x03#define BTP_HEARTBEAT_RESPONSE  0x04#define BTP_DATA                0x05#define BTP_BYE_REQUEST         0x06#define BTP_BYE_RESPONSE        0x07#define BTP_PROTOCOL            0x42#define BTP_VERSION             0x01\ntypedef struct ETH_HEADER&#123;    u_char dest_mac[6];    u_char src_mac[6];    u_short etype;&#125;ETH_HEADER;\ntypedef struct BTP_HEADER&#123;    u_char protocol;    u_char version;    u_char type;    u_char pid;    u_short data_length;&#125;BTP_HEADER;\ntypedef struct BTP_STATE&#123;    int state; /* 状态：0=初始（可握手） 1=握手后（可心跳、可数据、可断开）*/    pthread_t pids[1]; /* 只有一个心跳线程 /    int timeout_flag; / 心跳超时标记，每次收包都进行+1，如果计时线程发现两次的flag都相同，说明断开了 */    pcap_t adapter; / 网卡句柄 */&#125;BTP_STATE;\nvoid packet_handler(u_char param, const struct pcap_pkthdr *header, const u_char *pkt_data);/ 抓包回调函数 */void format_mac(LPSTR lpHWAddrStr, const unsigned char HWAddr);/ mac地址格式化函数 */\nint btp_send(ETH_HEADER* eth_header, BTP_HEADER *btp_header, u_char type);void *timer(void *arg);void kill_all(char *msg, int error_code);\nvoid copy_mac(u_char *mac1, u_char mac2);char rec_type(u_char type);BTPsender.c#include \"BTPrecver.h\"\nBTP_STATE btp_state;\nint main()&#123;    char errbuf[PCAP_ERRBUF_SIZE]; /* 错误信息buffer /    u_int netmask; / 掩码信息 /    char packet_filter[] = “ether src 00:50:56:C0:00:08 and ether dst 00:0C:29:86:B8:C8”; / 过滤规则 /    struct bpf_program fcode; / 存储编译好的过滤码 */\npcap_if_t *alldevs; /* 全部网卡列表 */\npcap_if_t *d; /* 一个网卡 */\nint did; /* 选择的网卡ID */\n\nint i = 0; /* 迭代 */\n\n/*查找网卡*/\nif (pcap_findalldevs_ex(PCAP_SRC_IF_STRING, NULL, &amp;amp;alldevs, errbuf) == -1) &#123;\n    fprintf(stderr, &quot;[ERROR] pcap_findalldevs error: %s\\n&quot;, errbuf);\n    return ERROR_FINDALLDEVS_FAILURE;\n&#125;\n\n/* 选择网卡d */\nfor (d = alldevs, i = 0; d; d = d-&amp;gt;next) &#123;\n    if (d-&amp;gt;description)\n        printf(&quot;NO.%d: %s\\n&quot;, ++i, d-&amp;gt;description);\n    else\n        printf(&quot;[WARN] No description available\\n&quot;);\n&#125;\n\nif (i == 0) &#123;\n    printf(&quot;[ERROR] No interfaces found! Make sure WinPcap is installed.\\n&quot;);\n    return ERROR_INTERFACES_NOT_FOUND;\n&#125;\n\nprintf(&quot;[INFO] Enter the interface number (1-%d):&quot;, i);\nscanf(&quot;%d&quot;, &amp;amp;did);\n\nif (did &amp;lt; 1 || did &amp;gt; i) &#123;\n    printf(&quot;[ERROR] Interface number out of range.\\n&quot;);\n    pcap_freealldevs(alldevs);\n    return ERROR_BAD_INPUT;\n&#125;\n\nfor (d = alldevs, i = 0; i &amp;lt; did - 1; d = d-&amp;gt;next, i++);\n\n/* 打开网卡 */\nif ((btp_state.adapter = pcap_open_live(d-&amp;gt;name, /* 设备名 */\n    65536, /* 捕获数据包的长度（65536捕获所有数据包） */\n    1, /* 混杂模式（非0表示使用混杂模式） */\n    1000, /* 超时时间（0表示没有超时限制） */\n    errbuf /* 错误缓存（存储错误信息） */\n    )) == NULL) &#123;\n    fprintf(stderr, &quot;[ERROR] Unable to open the adapter. %s is not supported by WinPcap\\n&quot;);\n    pcap_freealldevs(alldevs);\n    return ERROR_OPEN_ADAPTER_FAILURE;\n&#125;\n\n/* 检查链路层类型 */\nif (pcap_datalink(btp_state.adapter) != DLT_EN10MB) /* DLT_EN10MB指10Mb以太网 */\n&#123;\n    fprintf(stderr, &quot;[ERROR] This program works only on Ethernet networks.\\n&quot;);\n    pcap_freealldevs(alldevs);\n    return ERROR_INVALID_DATALINK_TYPE;\n&#125;\n\n/* 检查地址类型 */\nif (d-&amp;gt;addresses != NULL) /* 如果有IP地址 */\n    netmask = ((struct sockaddr_in *)(d-&amp;gt;addresses-&amp;gt;netmask))-&amp;gt;sin_addr.S_un.S_addr; /* 使用第一个掩码 */\nelse /* 如果没有IP地址，说明是C类网络（局域网） */\n    netmask = 0xffffff; /* 掩码设置为255.255.255.0 */\n\n\n/* 编译过滤器 */\nif (pcap_compile(btp_state.adapter, &amp;amp;fcode, packet_filter, 1, netmask) &amp;lt; 0) /* 1表示自动进行优化 */\n&#123;\n    fprintf(stderr, &quot;[ERROR] Unable to compile the packet filter. Check the syntax.\\n&quot;);\n    pcap_freealldevs(alldevs);\n    return ERROR_COMPILE_FILTER_FALIURE;\n&#125;\n\n/* 应用过滤器 */\nif (pcap_setfilter(btp_state.adapter, &amp;amp;fcode) &amp;lt; 0)\n&#123;\n    fprintf(stderr, &quot;[ERROR] Error setting the filter.\\n&quot;);\n    pcap_freealldevs(alldevs);\n    return ERROR_SET_FILTER_FALIURE;\n&#125;\n\n/* 开始抓包 */\nbtp_state.state = 0;\nbtp_state.timeout_flag = 0;\nprintf(&quot;listening on %s...\\n&quot;, d-&amp;gt;description);\npcap_freealldevs(alldevs);\npcap_loop(btp_state.adapter, 0, packet_handler, NULL);\n\nsystem(&quot;pause&quot;);\nreturn 0;\n}\n/* 抓包回调函数 /void packet_handler(u_char param, const struct pcap_pkthdr *header, const u_char *pkt_data){    time_t local_tv_sec; / 时间戳 */    struct tm *ltime; / 本地时间 /    char timestr[16]; / 格式化后的本地时间 */    ETH_HEADER eth_header; / 以太网帧包头 /    char str_mac[50]; / 源MAC地址 */    BTP_HEADER *btp_header;    char *data;    int i;\n/* 没有使用param */\n(VOID)(param);\n\n/* 格式化当前时间 */\nlocal_tv_sec = header-&amp;gt;ts.tv_sec;\nltime = localtime(&amp;amp;local_tv_sec);\nstrftime(timestr, sizeof timestr, &quot;%H:%M:%S&quot;, ltime);\n\n/* 解析以太网帧 */\neth_header = (ETH_HEADER *)pkt_data;\nformat_mac(str_mac, eth_header-&amp;gt;src_mac);\nprintf(&quot;[ %s.%.6d ] receive package from %s:\\n&quot;,\n    timestr, header-&amp;gt;ts.tv_usec, str_mac);\n\n/* 解析数据域 */\nbtp_header = (BTP_HEADER *)(pkt_data + sizeof(ETH_HEADER));\nif (btp_header-&amp;gt;protocol == BTP_PROTOCOL)&#123; /* 确认是btp包 */\n    printf(&quot;protocol=\\tBTP \\nversion=\\t%d \\ntype=\\t%s \\npid=\\t%d \\ndata_length=\\t%d \\n&quot;,\n        btp_header-&amp;gt;version, rec_type(btp_header-&amp;gt;type), btp_header-&amp;gt;pid, btp_header-&amp;gt;data_length);\n\n    if (btp_header-&amp;gt;version &amp;gt; BTP_VERSION)&#123;\n        kill_all(&quot;[ERROR] version mismatch.&quot;, ERROR_BAD_VERSION);\n    &#125;\n\n    switch (btp_header-&amp;gt;type)&#123;\n    case BTP_HELLO_REQUEST:\n        if (btp_state.state == 0)&#123;/* 初始，可握手 */\n            if (!btp_send(eth_header, btp_header, BTP_HELLO_RESPONSE))&#123;\n                if (pthread_create(&amp;amp;btp_state.pids[0], NULL, timer, NULL) == -1)&#123;/* 开启心跳线程 */\n                    kill_all(&quot;[ERROR] create thread failed.&quot;, ERROR_CREATE_THREAD);\n                &#125;\n                btp_state.state = 1;/*握手后，可心跳，可数据，可断开*/\n            &#125;\n            else&#123;\n                kill_all(&quot;[ERROR] btp hello failed.&quot;, ERROR_BTP_HELLO_FAILED);\n            &#125;\n        &#125;\n        break;\n    case BTP_HEARTBEAT_REQUEST:\n        if (btp_state.state == 1)&#123;\n            btp_state.timeout_flag = (btp_state.timeout_flag + 1) % 1000;\n            if (btp_send(eth_header, btp_header, BTP_HEARTBEAT_RESPONSE) != 0)\n                kill_all(&quot;[ERROR] btp heartbeat failed.&quot;, ERROR_BTP_HEARTBEAT_FAILED);\n        &#125;\n        break;\n    case BTP_DATA:\n        if (btp_state.state == 1)&#123;\n            data = (char*)(pkt_data + sizeof(ETH_HEADER)+sizeof(BTP_HEADER));\n            printf(&quot;recv data: &quot;);\n            for (i = 0; i &amp;lt; btp_header-&amp;gt;data_length; i++)\n                printf(&quot;%c&quot;, data[i]);\n            printf(&quot;\\n&quot;);\n        &#125;\n        break;\n    case BTP_BYE_REQUEST:\n        if (btp_state.state == 1)&#123;\n            if (btp_send(eth_header, btp_header, BTP_BYE_RESPONSE) != 0)\n                kill_all(&quot;[ERROR] btp bye failed.&quot;, ERROR_BTP_BYE_FAILED);\n            else\n                kill_all(&quot;[INFO] btp finished.&quot;, 0);\n        &#125;\n        break;\n    &#125;\n&#125;\n}\nint btp_send(ETH_HEADER* eth_header, BTP_HEADER btp_header, u_char type){    int index;    u_char sendbuf[SEND_BUFSIZE]; / 发送buffer */    u_char temp_mac[6];\n/* 制作新的eth_header */\ncopy_mac(temp_mac, eth_header-&amp;gt;src_mac);\ncopy_mac(eth_header-&amp;gt;src_mac, eth_header-&amp;gt;dest_mac);\ncopy_mac(eth_header-&amp;gt;dest_mac, temp_mac);\n\n/* 制作新的btp_header */\nbtp_header-&amp;gt;type = type;\nbtp_header-&amp;gt;data_length = 0;\n\n/* 发包 */\nmemcpy(sendbuf, ð_header, sizeof(eth_header));\nindex = sizeof(eth_header);\nif (pcap_sendpacket(btp_state.adapter, /* 网卡句柄 */\n    sendbuf, /* 要发送的��� */\n    index /* 帧的大小 */\n    ) != 0) &#123;\n    fprintf(stderr, &quot;[ERROR] Error sending the packet: %s\\n&quot;, pcap_geterr(btp_state.adapter));\n    return ERROR_SENDING_FAILURE;\n&#125;\nprintf(&quot;response a %s package.\\n&quot;, rec_type(type));\nreturn 0;\n}\nvoid *timer(void arg){    int timeout_flag;    printf(“timer start.\\n”);    while (1){        timeout_flag = btp_state.timeout_flag;        Sleep(3000);        if (timeout_flag == btp_state.timeout_flag){ / 没有改变 */            kill_all(“[ERROR] time out.”, ERROR_BTP_TIMEOUT);            break;        }        printf(“timer ok\\n”);    }    return NULL;}\nvoid kill_all(char *msg, int error_code){    printf(“%s\\n”, msg);    pcap_breakloop(btp_state.adapter);    system(“pause”);    exit(error_code);}\nchar* rec_type(u_char type){    switch (type){    case BTP_HELLO_REQUEST:        return “BTP_HELLO_REQUEST”;    case BTP_HELLO_RESPONSE:        return “BTP_HELLO_RESPONSE”;    case BTP_HEARTBEAT_REQUEST:        return “BTP_HEARTBEAT_REQUEST”;    case BTP_HEARTBEAT_RESPONSE:        return “BTP_HEARTBEAT_RESPONSE”;    case BTP_DATA:        return “BTP_DATA”;    case BTP_BYE_REQUEST:        return “BTP_BYE_REQUEST”;    case BTP_BYE_RESPONSE:        return “BTP_BYE_RESPONSE”;    default:        return “BAD_TYPE”;    }}void copy_mac(u_char *mac1, u_char *mac2){    mac1[0] = mac2[0];    mac1[1] = mac2[1];    mac1[2] = mac2[2];    mac1[3] = mac2[3];    mac1[4] = mac2[4];    mac1[5] = mac2[5];}\nvoid format_mac(char* lpHWAddrStr, const unsigned char *HWAddr){    int i;    short temp;    char szStr[3];\nstrcpy(lpHWAddrStr, &quot;&quot;);\nfor (i = 0; i &amp;lt; 6; ++i)\n&#123;\n    temp = (short)(*(HWAddr + i));\n    _itoa(temp, szStr, 16);\n    if (strlen(szStr) == 1)\n        strcat(lpHWAddrStr, &quot;0&quot;);\n    strcat(lpHWAddrStr, szStr);\n    if (i &amp;lt; 5)\n        strcat(lpHWAddrStr, &quot;:&quot;);\n&#125;\n}看看实验结果：后面time out是因为那个心跳线程没有直接结束，原因在前面已经说明了。（4）编写发送者sender.h#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;pcap.h&gt;#include &lt;winsock.h&gt;#include &lt;pthread.h&gt;\n#define ETHERTYPE_IP                    0x0800 /* IP */#define ERROR_GENERAL                   -1#define ERROR_FINDALLDEVS_FAILURE       -2#define ERROR_INTERFACES_NOT_FOUND      -3#define ERROR_BAD_INPUT                 -4#define ERROR_OPEN_ADAPTER_FAILURE      -5#define ERROR_SENDING_FAILURE           -6#define ERROR_INVALID_DATALINK_TYPE     -7#define ERROR_COMPILE_FILTER_FALIURE    -8#define ERROR_SET_FILTER_FALIURE        -9#define ERROR_CREATE_THREAD             -10#define ERROR_BTP_HELLO_FAILED          -11#define ERROR_BTP_HEARTBEAT_FAILED      -12#define ERROR_BTP_BYE_FAILED            -13#define ERROR_BTP_TIMEOUT               -14#define ERROR_BAD_VERSION               -15#define ERROR_BTP_DATA_FAILED            -16#define SEND_BUFSIZE                    1024#define SEND_TIMES                      10000#define SEND_INTVAL                     1000#define TIMER_SLEEPTIME                 2000#define TIMER_EXPECT_SLEEPTIME          1000\n#define BTP_HELLO_REQUEST       0x01#define BTP_HELLO_RESPONSE      0x02#define BTP_HEARTBEAT_REQUEST   0x03#define BTP_HEARTBEAT_RESPONSE  0x04#define BTP_DATA                0x05#define BTP_BYE_REQUEST         0x06#define BTP_BYE_RESPONSE        0x07#define BTP_PROTOCOL            0x42#define BTP_VERSION             0x01\ntypedef struct ETH_HEADER&#123;    u_char dest_mac[6];    u_char src_mac[6];    u_short etype;&#125;ETH_HEADER;\ntypedef struct BTP_HEADER&#123;    u_char protocol;    u_char version;    u_char type;    u_char pid;    u_short data_length;&#125;BTP_HEADER;\ntypedef struct BTP_STATE&#123;    int state; /* 状态：0=初始（可发送握手） 1=握手后（可心跳、可数据、可断开）*/    pthread_t pids[3]; /* 0=心跳线程 1=接收线程 2=计时线程 /    int timeout_flag; / 心跳超时标记，每次收包都进行+1，如果计时线程发现两次的flag都相同，说明断开了 /    pcap_t adapter; / 网卡句柄 /    int pid;/ 这个是package id，包序号/    u_char sendbuf[SEND_BUFSIZE]; /* 发送buffer /    int index; / 发送buffer偏移 */&#125;BTP_STATE;\nint send_btp_package(pcap_t adapter, u_char sendbuf, int index, u_char type, char data, int len);char rec_type(u_char type);void timer(void *arg);void *timer_expect(void *arg);void *bye(void *arg);void kill_all(char *msg, int error_code);void btp_listen();void packet_handler(u_char *param, const struct pcap_pkthdr *header, const u_char *pkt_data);int send_btp_package(pcap_t *adapter, u_char *sendbuf, int index, int *pid, u_char type, char data, int len, int te);void format_mac(LPSTR lpHWAddrStr, const unsigned char HWAddr);/ mac地址格式化函数 */sender.c#include \"BTPsender.h\"BTP_STATE btp_state;\nint main()&#123;    pcap_t adapter; / 网卡句柄 /    char errbuf[PCAP_ERRBUF_SIZE]; / 错误信息buffer /    u_int netmask; / 掩码信息 /    char packet_filter[] = “ether src 00:0C:29:86:B8:C8 and ether dst 00:50:56:C0:00:08”; / 过滤规则 /    struct bpf_program fcode; / 存储编译好的过滤码 /    ETH_HEADER eth_header; / 以太网包头 */\npcap_if_t *alldevs; /* 全部网卡列表 */\npcap_if_t *d; /* 一个网卡 */\nint did; /* 选择的网卡ID */\n\nint i; /* 迭代 */\n\n/* 查找网卡 */\nif (pcap_findalldevs_ex(PCAP_SRC_IF_STRING, NULL, &amp;amp;alldevs, errbuf) == -1) &#123;\n    fprintf(stderr, &quot;[ERROR] pcap_findalldevs error: %s\\n&quot;, errbuf);\n    return ERROR_FINDALLDEVS_FAILURE;\n&#125;\n\n/* 选择网卡d */\nfor (d = alldevs, i = 0; d; d = d-&amp;gt;next) &#123;\n    if (d-&amp;gt;description)\n        printf(&quot;NO.%d: %s\\n&quot;, ++i, d-&amp;gt;description);\n    else\n        printf(&quot;[WARN] No description available\\n&quot;);\n&#125;\n\nif (i == 0) &#123;\n    printf(&quot;[ERROR] No interfaces found! Make sure WinPcap is installed.\\n&quot;);\n    return ERROR_INTERFACES_NOT_FOUND;\n&#125;\n\nprintf(&quot;[INFO] Enter the interface number (1-%d):&quot;, i);\nscanf(&quot;%d&quot;, &amp;amp;did);\n\nif (did &amp;lt; 1 || did &amp;gt; i) &#123;\n    printf(&quot;[ERROR] Interface number out of range.\\n&quot;);\n    pcap_freealldevs(alldevs);\n    return ERROR_BAD_INPUT;\n&#125;\n\nfor (d = alldevs, i = 0; i &amp;lt; did - 1; d = d-&amp;gt;next, i++);\n\n/* 打开网卡 */\nif ((btp_state.adapter = pcap_open_live(d-&amp;gt;name, /* 设备名 */\n    65536, /* 捕获数据包的长度（65536捕获所有数据包） */\n    1, /* 混杂模式（非0表示使用混杂模式） */\n    1000, /* 超时时间（0表示没有超时限制） */\n    errbuf /* 错误缓存（存储错误信息） */\n    )) == NULL) &#123;\n    fprintf(stderr, &quot;[ERROR] Unable to open the adapter. %s is not supported by WinPcap\\n&quot;);\n    pcap_freealldevs(alldevs);\n    return ERROR_OPEN_ADAPTER_FAILURE;\n&#125;\n\n/* 检查链路层类型 */\nif (pcap_datalink(btp_state.adapter) != DLT_EN10MB) /* DLT_EN10MB指10Mb以太网 */\n&#123;\n    fprintf(stderr, &quot;[ERROR] This program works only on Ethernet networks.\\n&quot;);\n    pcap_freealldevs(alldevs);\n    return ERROR_INVALID_DATALINK_TYPE;\n&#125;\n\n/* 检查地址类型 */\nif (d-&amp;gt;addresses != NULL) /* 如果有IP地址 */\n    netmask = ((struct sockaddr_in *)(d-&amp;gt;addresses-&amp;gt;netmask))-&amp;gt;sin_addr.S_un.S_addr; /* 使用第一个掩码 */\nelse /* 如果没有IP地址，说明是C类网络（局域网） */\n    netmask = 0xffffff; /* 掩码设置为255.255.255.0 */\n\n\n/* 编译过滤器 */\nif (pcap_compile(btp_state.adapter, &amp;amp;fcode, packet_filter, 1, netmask) &amp;lt; 0) /* 1表示自动进行优化 */\n&#123;\n    fprintf(stderr, &quot;[ERROR] Unable to compile the packet filter. Check the syntax.\\n&quot;);\n    pcap_freealldevs(alldevs);\n    return ERROR_COMPILE_FILTER_FALIURE;\n&#125;\n\n/* 应用过滤器 */\nif (pcap_setfilter(btp_state.adapter, &amp;amp;fcode) &amp;lt; 0)\n&#123;\n    fprintf(stderr, &quot;[ERROR] Error setting the filter.\\n&quot;);\n    pcap_freealldevs(alldevs);\n    return ERROR_SET_FILTER_FALIURE;\n&#125;\n\n/*目的PB的mac地址*/\neth_header.dest_mac[0] = 0x00;\neth_header.dest_mac[1] = 0x0C;\neth_header.dest_mac[2] = 0x29;\neth_header.dest_mac[3] = 0x86;\neth_header.dest_mac[4] = 0xB8;\neth_header.dest_mac[5] = 0xC8;\n\n/*源PA的mac地址*/\neth_header.src_mac[0] = 0x00;\neth_header.src_mac[1] = 0x50;\neth_header.src_mac[2] = 0x56;\neth_header.src_mac[3] = 0xC0;\neth_header.src_mac[4] = 0x00;\neth_header.src_mac[5] = 0x08;\n\neth_header.etype = htons(ETHERTYPE_IP);\n\nmemcpy(btp_state.sendbuf, ð_header, sizeof(eth_header));\nbtp_state.index = sizeof(eth_header);\n\n/* 开启抓包线程 */\nbtp_state.state = 0;\nbtp_state.timeout_flag = 0;\nprintf(&quot;listening on %s...\\n&quot;, d-&amp;gt;description);\npcap_freealldevs(alldevs);\nif (pthread_create(&amp;amp;btp_state.pids[1], NULL, btp_listen, NULL) == -1)&#123;\n    kill_all(&quot;[ERROR] create thread failed.&quot;, ERROR_CREATE_THREAD);\n&#125;\n\n\n/* 发送第一个包 */\nbtp_state.pid = 1;\nif (send_btp_package(btp_state.adapter, btp_state.sendbuf, btp_state.index, &amp;amp;btp_state.pid, BTP_HELLO_REQUEST, NULL, 0, 1) != 0)&#123;\n    kill_all(&quot;[ERROR] send hello failed.&quot;, ERROR_BTP_HELLO_FAILED);\n&#125;\n/* 发包 \n\nSleep(SEND_INTVAL);\nsend_btp_package(adapter, sendbuf, index, &amp;amp;pid, BTP_HEARTBEAT_REQUEST, NULL, 0);\nsend_btp_package(adapter, sendbuf, index, &amp;amp;pid, BTP_DATA, data, strlen(data));\nSleep(SEND_INTVAL);\nsend_btp_package(adapter, sendbuf, index, &amp;amp;pid, BTP_BYE_REQUEST, NULL, 0);\n*/\n\npthread_join(btp_state.pids[1], NULL);\n\npcap_close(btp_state.adapter);\nsystem(&quot;pause&quot;);\nreturn 0;\n}\nvoid *timer(void arg){    int timeout_flag;    printf(“timer start.\\n”);    while (1){        timeout_flag = btp_state.timeout_flag;        Sleep(3000);        if (timeout_flag == btp_state.timeout_flag){ / 没有改变 */            kill_all(“[ERROR] time out.”, ERROR_BTP_TIMEOUT);            break;        }        printf(“timer ok\\n”);    }    return NULL;}\nvoid *timer_expect(void *arg){    Sleep(TIMER_EXPECT_SLEEPTIME);    pthread_testcancel();    kill_all(“[ERROR] timer_expect time out.”, ERROR_BTP_TIMEOUT);}\nvoid *bye(void *arg){    Sleep(10000);    if (send_btp_package(btp_state.adapter, btp_state.sendbuf, btp_state.index, &amp;btp_state.pid,        BTP_BYE_REQUEST, NULL, 0, 1)        != 0){        kill_all(“[ERROR] send bye failed.”, ERROR_BTP_BYE_FAILED);    }}\nvoid kill_all(char *msg, int error_code){    printf(“%s\\n”, msg);    pcap_breakloop(btp_state.adapter);    system(“pause”);    exit(error_code);}\nvoid btp_listen(){    pcap_loop(btp_state.adapter, 0, packet_handler, NULL);}\n/* 抓包回调函数 /void packet_handler(u_char param, const struct pcap_pkthdr *header, const u_char *pkt_data){    time_t local_tv_sec; / 时间戳 */    struct tm *ltime; / 本地时间 /    char timestr[16]; / 格式化后的本地时间 */    ETH_HEADER eth_header; / 以太网帧包头 /    char str_mac[50]; / 源MAC地址 */    BTP_HEADER *btp_header;    char *data;    int i;\n/* 没有使用param */\n(VOID)(param);\n\n/* 格式化当前时间 */\nlocal_tv_sec = header-&amp;gt;ts.tv_sec;\nltime = localtime(&amp;amp;local_tv_sec);\nstrftime(timestr, sizeof timestr, &quot;%H:%M:%S&quot;, ltime);\n\n/* 解析以太网帧 */\neth_header = (ETH_HEADER *)pkt_data;\nformat_mac(str_mac, eth_header-&amp;gt;src_mac);\nprintf(&quot;[ %s.%.6d ] receive package from %s:\\n&quot;,\n    timestr, header-&amp;gt;ts.tv_usec, str_mac);\n\n/* 解析数据域 */\nbtp_header = (BTP_HEADER *)(pkt_data + sizeof(ETH_HEADER));\nif (btp_header-&amp;gt;protocol == BTP_PROTOCOL)&#123; /* 确认是btp包 */\n    printf(&quot;protocol=\\tBTP \\nversion=\\t%d \\ntype=\\t%s \\npid=\\t%d \\ndata_length=\\t%d \\n&quot;,\n        btp_header-&amp;gt;version, rec_type(btp_header-&amp;gt;type), btp_header-&amp;gt;pid, btp_header-&amp;gt;data_length);\n\n    if (btp_header-&amp;gt;version &amp;gt; BTP_VERSION)&#123;\n        kill_all(&quot;[ERROR] version mismatch.&quot;, ERROR_BAD_VERSION);\n    &#125;\n\n    switch (btp_header-&amp;gt;type)&#123;\n    case BTP_HELLO_RESPONSE:\n        if (btp_state.state == 0)&#123;/* 初始，可握手 */\n            if (pthread_create(&amp;amp;btp_state.pids[0], NULL, timer, NULL) == -1)&#123;/* 开启心跳线程 */\n                kill_all(&quot;[ERROR] create thread failed.&quot;, ERROR_CREATE_THREAD);\n            &#125;\n            btp_state.state = 1;/*握手后，可心跳，可数据，可断开*/\n            pthread_cancel(btp_state.pids[2]);/* 中止hello包的计时器 */\n            if (send_btp_package(btp_state.adapter, btp_state.sendbuf, btp_state.index, &amp;amp;btp_state.pid, \n                                 BTP_HEARTBEAT_REQUEST, NULL, 0, 0) \n                                 != 0)&#123;\n                kill_all(&quot;[ERROR] send heartbeat failed.&quot;, ERROR_BTP_HEARTBEAT_FAILED);\n            &#125;\n            if (send_btp_package(btp_state.adapter, btp_state.sendbuf, btp_state.index, &amp;amp;btp_state.pid,\n                                 BTP_DATA, &quot;test btp data.&quot;, strlen(&quot;test btp data.&quot;), 0) \n                                 != 0)&#123;\n                kill_all(&quot;[ERROR] send data failed.&quot;, ERROR_BTP_DATA_FAILED);\n            &#125;\n            if (pthread_create(&amp;amp;btp_state.pids[0], NULL, bye, NULL) == -1)&#123;/* 开启bye线程，等待10秒发包 */\n                kill_all(&quot;[ERROR] create thread failed.&quot;, ERROR_CREATE_THREAD);\n            &#125;\n        &#125;\n        break;\n    case BTP_HEARTBEAT_RESPONSE:\n        if (btp_state.state == 1)&#123;\n            btp_state.timeout_flag = (btp_state.timeout_flag + 1) % 1000;\n            if (send_btp_package(btp_state.adapter, btp_state.sendbuf, btp_state.index, &amp;amp;btp_state.pid,\n                                 BTP_HEARTBEAT_REQUEST, NULL, 0, 0)\n                                 != 0)&#123;\n                kill_all(&quot;[ERROR] btp heartbeat failed.&quot;, ERROR_BTP_HEARTBEAT_FAILED);\n            &#125;\n        &#125;\n        break;\n    case BTP_BYE_RESPONSE:\n        if (btp_state.state == 1)&#123;\n            pthread_cancel(btp_state.pids[2]);/* 中止bye包的计时器 */\n            kill_all(&quot;[INFO] btp finished.&quot;, 0);\n        &#125;\n        break;\n    &#125;\n&#125;\n}\nint send_btp_package(pcap_t adapter, u_char *sendbuf, int index, int *pid, u_char type, char data, int len, int te){    BTP_HEADER package;\npackage.protocol = BTP_PROTOCOL;\npackage.pid = (*pid)++;\npackage.version = BTP_VERSION;\npackage.data_length = type == BTP_DATA ? len : 0;\npackage.type = type;\n\nmemcpy(&amp;amp;sendbuf[index], &amp;amp;package, sizeof(package));\nindex += sizeof(package);\n\nif (type == BTP_DATA)&#123;\n    memcpy(&amp;amp;sendbuf[index], data, len);\n    index += len;\n&#125;\n\nif (pcap_sendpacket(adapter, /* 网卡句柄 */\n    sendbuf, /* 要发送的帧 */\n    index /* 帧的大小 */\n    ) != 0) &#123;\n    fprintf(stderr, &quot;[ERROR] Error sending the packet: %s\\n&quot;, pcap_geterr(adapter));\n    return ERROR_SENDING_FAILURE;\n&#125;\nprintf(&quot;send a %s btp packet success.\\n&quot;, rec_type(type));\n\n/* 启动一个计时器，期待回复 */\nif (te)&#123;\n    if (pthread_create(&amp;amp;btp_state.pids[2], NULL, timer, NULL) == -1)&#123;\n        kill_all(&quot;[ERROR] create thread failed.&quot;, ERROR_CREATE_THREAD);\n    &#125;\n&#125;\nreturn 0;\n}\nchar* rec_type(u_char type){    switch (type){    case BTP_HELLO_REQUEST:        return “BTP_HELLO_REQUEST”;    case BTP_HELLO_RESPONSE:        return “BTP_HELLO_RESPONSE”;    case BTP_HEARTBEAT_REQUEST:        return “BTP_HEARTBEAT_REQUEST”;    case BTP_HEARTBEAT_RESPONSE:        return “BTP_HEARTBEAT_RESPONSE”;    case BTP_DATA:        return “BTP_DATA”;    case BTP_BYE_REQUEST:        return “BTP_BYE_REQUEST”;    case BTP_BYE_RESPONSE:        return “BTP_BYE_RESPONSE”;    default:        return “BAD_TYPE”;    }}\nvoid format_mac(char* lpHWAddrStr, const unsigned char *HWAddr){    int i;    short temp;    char szStr[3];\nstrcpy(lpHWAddrStr, &quot;&quot;);\nfor (i = 0; i &amp;lt; 6; ++i)\n&#123;\n    temp = (short)(*(HWAddr + i));\n    _itoa(temp, szStr, 16);\n    if (strlen(szStr) == 1)\n        strcat(lpHWAddrStr, &quot;0&quot;);\n    strcat(lpHWAddrStr, szStr);\n    if (i &amp;lt; 5)\n        strcat(lpHWAddrStr, &quot;:&quot;);\n&#125;\n}这里���实现上，没有单独地开一个发送线程，只简单地开了一个等待10秒后发送BTP断开包的线程。注意发送者的监听需要调换源MAC和目的MAC，因为是虚拟机PB端发过来的。每次发送期待回复的包后，都会开一个定时器，来判断是否超时。（5）整体测试正常实验结果的sender / PA 端：上来就发了一个hello包，收到回复后开始不断发送和接受心跳包，显示timer start和timer ok，然后10秒后发送了一个bye包：完成了整个过程。我们再试试中途关闭PB端的程序：可以看到心跳包超时了。我们再试试一开始就不开PB端的程序：可以看到PA发送的hello包没有人回复，造成计时器超时了。三、总结整个实验过程非常好玩，只不过时间仓促没有测试完所有的分支，��果你也有兴趣，可以在这里（密码：fqqy）下载代码工程文件，原理上或者程序中有什么错误，欢迎邮件或评论指正。参考资料1、《VS2015中配置Pthread》2、《Linux中pthread线程使用详解》3、《终止正在运行的子线程（一、几种方式的介绍）》4、《linux下pthread_cancel无法取消线程的原因》5、《基于VS2013配置pthread》6、《VS2013中引用dll目录的配置方法》7、《pthread-win32静态库的编译和使用方法》8、《使用pthread-win32工程编译静态库》\n\n                \n","categories":["转载"],"tags":[]},{"title":"论文精度与分析 Inception V1 Going Deeper with Convolutions","url":"http://tanqingbo.cn/2019/10/06/论文精度与分析InceptionV1GoingDeeperwithConvolutions/","content":"\n本文转自：https://blog.csdn.net/dugudaibo/article/details/87924748\n\n                  \n                  \n                      \n                  \n                                          1. 按论文章节回顾具体内容\nAbstract\n  我们提出了一种名为 Inception 的深度卷积网络结构，它在 ILSVRC14 的分类和检测任务上达到了 SOTA 的效果。这个网络的特征是他提升了网络内部计算资源的利用率。通过精细的设计，我们在提升了网络的宽度和深度的同时保持了计算量不变。为了提升网络输出的质量，网络结构的决策是基于 Hebbian 原则和多尺度处理的直观性。在我们提交的 ILSVRC14 中，有一个特殊的体现被称为“谷歌网”，它是一个22层深的网络，其效果是在分类和检测的背景下进行评估的。\n1. Introduction\n  神经网络和深度学习在目标分类和检测上效果的提升，不仅仅是因为更强大的计算硬件，更大的数据机和更大的模型，也是 idaes ，算法和改进的网络结构的结果。一个证明这种结论的实例是，在 ILSVRC14 中，我们所使用的网络的参数量比 ILSVRC12 最好的结果少 12 倍，并且准确率显著的提升，并且这两年的数据是相同的。在目标检测方面，最大的收益不是来源于越来越大的深层网络结构的简单应用，而是来自于深层网络结构和经典计算机视觉的协同作用，比如说 R-CNN。\n  随着手机和嵌入式设备的普及，我们算法的效率，特别是功耗和内存的使用变得越发重要。我们在设计这个网络的时候不仅仅考虑一个好的指标，也考虑了算法的效率。对于大多数的实验，我们将计算量控制在 15 亿次乘加计算，它们就不会纯粹是学术上的好奇心，而是可以以合理的成本投入到现实世界中，即使是在大型数据集上。\n  作者书写这段的逻辑是，理论上一个好的网络在是怎样的，在实际应用上的需求是怎样的。而我们设计的网络怎么怎么好，正好满足了这个需求。\n2. Related Work\n  从 LeNet-5 开始，卷积神经网络开始具有了一种典型的网络结构：叠加的卷积层，之后跟着归一化和最大池化。针对处理如 ImageNet 等更大的数据集，最近（2015年之前）的一个趋势是增加层的个数与层的尺寸，同时使用 dropout 来解决过拟合的问题。\n  受到了灵长类视觉皮层神经元模型的启发， Serre 等人使用了一系列不同尺寸的固定的 Gabor 滤波器来解决多尺度的问题。我们使用了类似的策略，没有使用固定的参数，在 Inception 模块中，所有的参数都是可以学习的。\n  Network-in-Network 是 Lin 等人提出的，用于增强网络表示能力的一种方法。在它们的模型中，网络中增加了额外的 <span class=\"MathJax\" id=\"MathJax-Element-1-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"1&amp;#xD7;1      1 \\times 1\" role=\"presentation\">1×11×1      1 \\times 11×11 \\times 11×1 的卷积，用以增加网络的深度。我们在我们的网络中重度使用这种方法。然而，在我们的设定中，  <span class=\"MathJax\" id=\"MathJax-Element-2-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"1&amp;#xD7;1      1 \\times 1\" role=\"presentation\">1×11×1      1 \\times 11×11 \\times 11×1  的卷积有着双重目标：最重要的，它们主要被用来作为降维的方法，以去除计算瓶颈，否则的话将会限制我们网络的尺寸。这样不仅可以增加网络的深度，还可以增加网络的宽度，而不会造成显著的性能损失。\n  最后，目前（2015年）目标检测的 SOTA 是 Girshick 等人提出的 R-CNN。R-CNN将整个检测问题分解为两个子问题：利用颜色和纹理等低级线索以类别不可知的方式生成对象位置建议，并使用CNN分类器在这些位置识别对象类别。这种两阶段的方法利用了低水平线索边界框分割的准确性，以及先进CNN的强大分类能力。我们在检测提交中采用了类似的方法，但在这两个阶段都进行了改进，例如针对更高对象边界框调用的多框[5]预测，以及用于更好地分类边界框建议的集成方法。\n  作者的相关工作的覆盖面，不仅仅很广， 而且在每一个部分分别指出了与自己的论文中工作的相关性，就是几乎没有废话，真的是大佬的文章，不佩服不行！\n3. Motivation and High Level Considerations\n  提升深度学习网络性能的直接了当的方法是增加它的尺寸。它包括增加他的深度（神经网络的层数）以及他的宽度（每一层神经元的个数）。这是训练一个效果更好的网络的一种简单安全的方法，特别是当大量的已标注的数据是可以获得时候。然而这种简单的解决方法会带来两个缺点：\n  更大的尺寸常常意味着更大的数量的参数量，这会增大神经网络过拟合的可能，尤其当带有标签的训练集是有限的时候。这是一个主要的瓶颈，因为获得标注好的数据是很吃力并且昂贵的，通常需要专业的人工评分员来区分不同的细粒度视觉类别，如图1所示的ImageNet（甚至是1000级ILSVRC子集）中的视觉类别。\n\n  另一个缺点是均匀增加的网络尺寸会急剧的增加计算资源的使用量。例如在一个深度视觉神经网络中，如果两个卷积层是链式的，任何滤波器数量均匀的增长都会导致计算量的翻倍增长。如果加法的能力使用不当（例如大部分的权重都接近于0），会导致大量的计算资源的浪费。因为计算资源总是有限的，所以即使当主要的目标是提升模型的效果，一个有效的计算资源分布也是要好于不加选择的增加网络的尺寸。\n  解决上面两个缺点的一个基本的方法是引入稀疏性，用稀疏的全连接层，替代普通的全连接层，甚至是在卷积的内部使用稀疏。包括模拟生物系统在内，因为 Arora 等人突破性的工作，这将胜过更严格的理论基础。它们的主要结论是如果一个数据集的概率分布是可以通过一个大的，非常稀疏的深度神经网络所表示，那么可以通过分析前一层激活的相关统计数据和具有高度相关输出的神经元聚类数据，构造出一个又一个最优的网络拓扑结构。虽然严格的数学证明需要非常强的假设，但事实上这个与著名的赫布原则（神经元激活在一起，连接在一起）产生了共鸣，意味着在实际中即使在不太严格的条件下其基本思想也是可以接受的。这也意味着确实存在这样的神经网络，并且从神经科学上可以找到一些依据，想表达的就是稀疏确实有用。\n  然而不幸的是，如今（2015年）的运算基础架构在处理非均匀稀疏结构的数值运算时是效率低下的。即使（稀疏的表示使得）算术运算的数目减少了100 倍，查找和缓存未命中的开销将占主导地位：切换到稀疏矩阵可能没有回报。通过使用稳定改进和高度调整的计算库，允许极快的密集矩阵乘法，利用底层CPU或GPU硬件的微小细节，进一步扩大了差距（因为加速，所以密集型矩阵乘法变得更快了）。并且，非均匀的稀疏模型需要更复杂的工程和计算基础架构。最近的面向视觉的机器学习系统大多利用卷积来利用空间的稀疏性。然而，卷积是作为到早期层 patches 的密集连接的集合实现的。自[11]以来，convnets一直使用特征维度中的随机和稀疏连接表来打破对称性并改进学习，但为了进一步优化并行计算，趋势又变回了与[9]的完全连接。现在的 SOTA 的视觉网络结构有着对称的结构。大量的滤波器和更大的  batch size  允许更为高效的使用密集型计算。\n  这引出了一个问题，是否存在这进行下一步的希望，一种折中的方法：如理论所建议的那样，使用这样的一种网络架构，他可以利用滤波器级别的稀疏能力，但利用我们目前的硬件，利用密集矩阵的计算。大量在稀疏矩阵计算上的文章建议，将稀疏矩阵聚类为相对密集的子矩阵，有助于获得稀疏矩阵乘法的竞争性能。认为在不久的将来，类似的方法将被用于非均匀深度学习体系结构的自动构建似乎并不牵强。\n  Inception 网络结构最初是一个案例研究，用于评估复杂网络拓扑结构构建算法的假设输出，该算法试图近似视觉网络的[2]所暗示的稀疏结构，并通过密集的、随时可用的组件覆盖假设结果。尽管这是一个高度投机的项目，但与基于[12]的参考网络相比，早期观察到了适度的收益。经过一点调整，差距变大了，并且事实证明在定位和检测的情况下，以 Inception 作为基础的网络结构尤其有用。有趣的是，虽然大多数最初的体系结构选择已经被分离地进行了彻底的质疑和测试，但结果证明它们接近于局部最优。有一个问题必须仔细的思考：虽然 Inception 在计算机视觉中获得了成功，但是是否可以归因为其构建的指导原则仍是一个疑问。确保这一点需要更彻底的分析和验证。\n  实际上这部分就是在陈述构建 Inception 结构的动机，简单的增加神经网络的尺寸会引起两个缺点：过拟合与计算量过大，解决这个问题一个较好的方式是使用稀疏的网络结构，并且从赫本原理的角度说明了可行性。然而一方面现有的计算基础架构使得稀疏的计算效率低下；另一方面，通过使用随机和稀疏连接的方式又使得网络有变回全连接的趋势。所以作者剔除了这种折衷的方式，使用这样的一种网络架构，他可以利用滤波器级别的稀疏能力，但利用我们目前的硬件，利用密集矩阵的计算，即 Inception。\n4. Architectural Details\n  Inception  结构的主要想法在于考虑一个卷积视觉神经网络的最优局部稀疏结构是如何被现成的密集组件来近似和覆盖。值得注意的是，假设平移不变性意味着我们的网络将由卷积积木构建。 所有的我们所需要做的是找到最优的局部组织并在空间上重复它。 Arora 等人提出了一种逐层的构造方法，在这种方法中，应分析最后一层的相关统计数据，并将其聚类成具有高相关性的单元组。 这些簇构成下一层的单元，并连接到上一层的单元。我们假设来自早期层的每个单元对应于输入图像的某个区域，并且这些单元被分组到过滤器组中。 在较低层（靠近输入层）中，相关单元将集中在局部区域。因此，我们将以集中在单个区域的许多簇结束，并且它们可以被下一层1×1卷积的层覆盖，如[12]所示。然而，我们也可以预期，在更大的 patch 上，可以被卷积覆盖的更多空间分布的集群数量将会减少，在更大的区域，patch 数量也会减少。 为了避免块对齐的问题，现在的 Inception 网络结构的实现使用 <span class=\"MathJax\" id=\"MathJax-Element-3-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"1&amp;#xD7;1      1\\times1\" role=\"presentation\">1×11×1      1\\times11×11\\times11×1，<span class=\"MathJax\" id=\"MathJax-Element-4-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"3&amp;#xD7;3      3\\times3\" role=\"presentation\">3×33×3      3\\times33×33\\times33×3，<span class=\"MathJax\" id=\"MathJax-Element-5-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"5&amp;#xD7;5      5\\times5\" role=\"presentation\">5×55×5      5\\times55×55\\times55×5 尺寸大小的卷积核，这种决定是因为方便操作，而不是必须的。这也意味着，建议的架构是所有这些层与它们的输出滤波器组的组合，这些滤波器组连接成一个单独的输出向量，形成下一阶段的输入。 此外，由于池操作对于当前卷积网络的成功至关重要，因此它建议在每个这样的阶段添加所有外部池路径也应具有额外的效益，如图 2 (a) 所示\n\n  由于这些“初始模块”相互堆叠在一起，它们的输出相关性统计数据必然会有所不同：随着更高层次捕获更高抽象的特征，它们的空间集中度预计会降低。 这表明，3×3和5×5的卷积比应该随着我们向更高层移动而增加。 在Inception中1x1考虑到local region，3x3和5x5则考虑到spatially spread out clusters。所以在lower的层中主要是local信息，所以1x1的output number要多一些，但在higher的层中往往捕捉的是features of higher abstraction，所以在higher layer中3x3和5x5的比例应该增大。\n  上述模块的一个大问题，至少在这种形式下，是即使是少量的5×5卷积，在具有大量过滤器的卷积层的顶部也可能非常昂贵。一旦池化单元被加入到了里面这个问题就变得更加突出：因为输出滤波器的数量等于上一阶段滤波器的数量。池层的输出与卷积层的输出合并将不可避免地导致各个阶段输出数量的增加。虽然这种体系结构可以覆盖最优的稀疏结构，但它的效率非常低，导致在几个阶段内就会出现计算爆炸。\n  这就引出了 Inception 结构的第二个想法：明智地减少维度，否则计算需求会增加很多。这是基于嵌入的成功：即使是低维度的嵌入也可能包含大量关于相对较大的图像 patch 的信息。然而，嵌入式以一种密集的、压缩的形式表示信息，而压缩的信息很难处理。在大多数地方(根据[2]条件的要求)，表示应该保持稀疏，并且只在需要对信号进行大规模聚集时才对其进行压缩。也就是说 <span class=\"MathJax\" id=\"MathJax-Element-6-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"1&amp;#xD7;1      1\\times1\" role=\"presentation\">1×11×1      1\\times11×11\\times11×1 的卷积在  <span class=\"MathJax\" id=\"MathJax-Element-7-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"3&amp;#xD7;3      3\\times3\" role=\"presentation\">3×33×3      3\\times33×33\\times33×3 和 <span class=\"MathJax\" id=\"MathJax-Element-8-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"5&amp;#xD7;5      5\\times5\" role=\"presentation\">5×55×5      5\\times55×55\\times55×5 之前降低了计算量。除了降低计算量，它们还包括使用矫正的线性激活，使它们具有双重用途。最后的结果图 2 的 (b) 所示。\n  整体来说，总体来说一个 Inception 网络有上面所示的模块堆积起来组成，偶尔使用带stride 2的max-pooling层来将网格的分辨率减半。由于技术的原因（训练时的内存利用率），似乎仅仅在高层次开始使用 Inception 而在低层次保持使用传统的卷积风格会比较有益。这并不是完全必要的，只是反映了我们当前实现中的一些基础设施效率低下。\n  该网络结构的一个有用的方面是，它允许在每个阶段显著增加单元的数量，而不会在后期的计算复杂性中出现无法控制的激增。这是通过在昂贵的卷积之前普遍使用降维来实现的。此外，该设计遵循的是一种实践直觉，即视觉信息应该在不同的尺度上进行处理，然后进行聚合，以便下一阶段能够同时从不同尺度上提取特征。\n  改进了对计算资源的使用，可以在不遇到计算困难的情况下增加每个阶段的宽度和阶段的数量。您可以利用Inception架构来创建稍微逊色一些，但是在计算上更便宜的版本。我们发现所有可用的旋钮和杠杆允许控制计算资源的平衡，导致速度是表现相似但没有 Inception 模块的3−10倍，然而在这一点上需要仔细的手工设计。\n关于网络结构的个人理解\n  首先是关于稀疏性的理解，下面的这句话是原文中关于稀疏性的解释\n\nInception  结构的主要想法在于考虑一个卷积视觉神经网络的最优局部稀疏结构是如何被现成的密集组件来近似和覆盖。\n\n具体的是利用滤波器级别的稀疏能力，但利用我们目前的硬件和密集矩阵的计算。那下面的网络结构与稀疏有什么关系呢？\n\n我们可以将 <span class=\"MathJax\" id=\"MathJax-Element-9-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"1&amp;#xD7;1      1\\times1\" role=\"presentation\">1×11×1      1\\times11×11\\times11×1 ，<span class=\"MathJax\" id=\"MathJax-Element-10-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"3&amp;#xD7;3      3\\times3\" role=\"presentation\">3×33×3      3\\times33×33\\times33×3 表示成如下的卷积\n\n实际上可以将 <span class=\"MathJax\" id=\"MathJax-Element-11-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"1&amp;#xD7;1      1\\times1\" role=\"presentation\">1×11×1      1\\times11×11\\times11×1 和 <span class=\"MathJax\" id=\"MathJax-Element-12-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"3&amp;#xD7;3      3\\times3\" role=\"presentation\">3×33×3      3\\times33×33\\times33×3 看成是  <span class=\"MathJax\" id=\"MathJax-Element-13-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"5&amp;#xD7;5      5\\times5\" role=\"presentation\">5×55×5      5\\times55×55\\times55×5 的稀疏表示，只不过是一种特殊的稀疏表示。因为如果是一般形式的稀疏表示的话，那么在 <span class=\"MathJax\" id=\"MathJax-Element-14-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"5&amp;#xD7;5      5\\times5\" role=\"presentation\">5×55×5      5\\times55×55\\times55×5 的矩阵中，哪个位置是 0 都是可以的，但是  <span class=\"MathJax\" id=\"MathJax-Element-15-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"1&amp;#xD7;1      1\\times1\" role=\"presentation\">1×11×1      1\\times11×11\\times11×1 和 <span class=\"MathJax\" id=\"MathJax-Element-16-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"3&amp;#xD7;3      3\\times3\" role=\"presentation\">3×33×3      3\\times33×33\\times33×3 却只有中心位置的数值是非零的，其余部分的数值都是 0。这也说明了为什么作者认为这是一种 “使用密集组建的 近似 和覆盖”。\n  在论文中作者使用了 <span class=\"MathJax\" id=\"MathJax-Element-17-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"1&amp;#xD7;1      1\\times1\" role=\"presentation\">1×11×1      1\\times11×11\\times11×1 的卷积， 它可以降低维度，增加系统的非线性，这是使用了它的好处，但是为什么它是可行的？\n  我们一层可能会有多个卷积核，在同一个位置但在不同通道的卷积核输出结果相关性极高。一个1×1的卷积核可以很自然的把这些相关性很高，在同一个空间位置，但不同通道的特征结合起来。而其它尺寸的卷积核（3×3，5×5）可以保证特征的多样性，因此也可以适量使用[2]。\nNew Version比Old version是如何减少参数量的？\n  1×1 的卷积核和正常的滤波器完全是一样的，只不过它不再感受一个局部区域，不考虑像素与像素之间的关系。1×1的卷积本身就是不同feature channel的线性叠加。1×1的卷积最早出现在Network in Network这篇文章中，在Google的inception结构中也采用了大量1×1的卷积。\n  NIN 论文中解释1×1的卷积实现了多个feature map的结合，从而整合了不同通道间的信息。（个人认为这个作用并不是特点，因为其它大小的卷积核也可以实现）\n   1×1的卷积可以实现通道数量的升维和降维。并且是低成本的特征变换（计算量比3×3小很多）。是一个性价比很高的聚合操作。怎么理解1×1是性价比很高的升降通道数的操作呢？[2]\n\n\n原始结构：\n参数：(1×1×192×64) + (3×3×192×128) + (5×5×192×32) = 153600\n最终输出的feature map：64+128+32+192 = 416\n加入不同channel的1×1卷积后：\n参数：1×1×192×64+（1×1×192×96+3×3×96×128）+（1×1×192×16+5×5×16×32）=15872\n最终输出的feature map： 64+128+32+32=256\n所以加入1×1的卷积后，在降低大量运算的前提下，降低了维度。降低维度也是inception module一个非常明智的举措。\n5.GoogLeNet\n  GoogLeNet 是 Inception 的一个具体实现，我们尝试过更深更宽质量稍好的 Inception，但是提升的效果并不明显。我们忽略具体的网络细节，因为实验表明，精确的网络结构参数的影响相对较小。表格 1 表明了我们在比赛中大部分共用的实例。在我们的集成模型中的 7 个模型，有 6 个网络使用了这样的（表格1）网络，这 6 个网络使用了不同的图像块采样方法进行训练。也就是说作者在使用 GoogLeNet 参加比赛的时候最后使用了模型集成的方法，并且还有一个模型我们不知道时使用了什么样的一种算法。\n\n  在所有的卷积中，包括 Inception 中的卷积，使用的都是修正线性激活函数（ReLu）。神经网络的感受野是大小为 <span class=\"MathJax\" id=\"MathJax-Element-18-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"224&amp;#xD7;224      224\\times224\" role=\"presentation\">224×224224×224      224\\times224224×224224\\times224224×224 均值为 0 彩色空间图像。在面上的表中，patchsize/ stride 表明卷积核的大小和步长，output size 表示输出的数据块的大小（当网络为传统卷积时还可以看出使用了多少个卷积核），depth 是该层重复了几次（具体来说是该行所表示的传统卷层重复了几次，或者是该行所表示的 Inception 重复了几次），#1× 1 表示 Inception 中最坐标的 1×1 大小的卷积核的数量，#3×3 reduce 表示在进行 3×3 的卷积之前，用来降维的 1×1 大小的卷积核的数量，#3×3 表示  3×3 大小卷积核的数量，#5×5 reduce 和 #5×5 同理，pool proj 表示最右侧经过池化之后 1×1 大小的卷积核的数量。\n  在思想上网络设计得具有计算效率和实用性，以至于前向推理的时候可以在单个设备上运行推理，包括计算资源有限的设备，尤其是内存占用较低的设备。当仅仅计算有参数的层数时，网络是22层（如果加上池化是27层）。在网络中使用的独立模块大概有 100 个。具体的数量如何计算依赖于机器学习基础设施是如何计数的。在分类之前使用了均值池化是基于 [12] 的想法，虽然我们添加了一个额外的线性层。线性层可以简单的将我们的网络应用到其他标签上，然而这只是为了方便，它并不起到一个主要的作用。我们发现从全连接层到平均池化的改变提升了 top1 正确率 0.6%，然而即使去掉了全连接层，dropout 仍然是必要的。\n  对于一个相对较深的神经网络，以一种有效的方式将剃度反向传播给所有层。浅层网络在梯度方向上反向传播的强大性能表明，网络中间层所产生的特征应该具有很强的识别性。通过在中间层添加辅助分类器，较低层分类器的识别性是可以期待的。辅助分类器被认为可以在提供正则化的同时，对抗梯度消失问题。这些分类器以小的卷积神经网络的形式放在了  Inception (4a) and (4d)  模块的上方。在训练过程中辅助分类器的损失被加权添加到总体的损失上（辅助分类器的损失权重设置为 0.3）。在进行前向推理的时候，辅助网络是禁用的。实验表明辅助网络的效果比较弱，仅仅使用一个辅助网络也可达到相同的效果。\n  包括辅助分类器在内，在侧面的额外网络的准确结构如下所示\n  (1) 卷积核大小为 <span class=\"MathJax\" id=\"MathJax-Element-19-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"5&amp;#xD7;5      5\\times5\" role=\"presentation\">5×55×5      5\\times55×55\\times55×5 步长为 3 的均值池化层，所以 (4a) 的输出为 <span class=\"MathJax\" id=\"MathJax-Element-20-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"4&amp;#xD7;4&amp;#xD7;512      4\\times4\\times512\" role=\"presentation\">4×4×5124×4×512      4\\times4\\times5124×4×5124\\times4\\times5124×4×512，(4d) 的输出为 <span class=\"MathJax\" id=\"MathJax-Element-21-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"4&amp;#xD7;4&amp;#xD7;528      4\\times4\\times528\" role=\"presentation\">4×4×5284×4×528      4\\times4\\times5284×4×5284\\times4\\times5284×4×528。\n  (2) 大小为  <span class=\"MathJax\" id=\"MathJax-Element-22-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"1&amp;#xD7;1      1\\times1\" role=\"presentation\">1×11×1      1\\times11×11\\times11×1  的128 个用来降维的卷积核和 ReLu 激活函数.\n  (3) 拥有 1024 个神经元的全连接层和 ReLu 激活函数\n  (4) 丢弃输出层 70 % 的 dropout 层\n  (5) 一个有 softmax 损失的线性层（预测与主分类器一样的 1000 个类别，但是在推理的时候会被去掉）。\n  结果网络的示意图如图3所示。\n\n  使用districess[4]分布式机器学习系统，使用适度的模型和数据并行性对googlenet网络进行培训。虽然我们只使用了基于CPU的实现，但粗略估计表明，可以在一周内使用少量高端GPU将谷歌网络训练为收敛，主要限制是内存使用。我们的培训采用了 0.9 动量的异步随机梯度下降[17]，固定的学习速率计划（每8个周期降低4%的学习速率）。Polyak Averaging[13]用于创建推理时使用的最终模型。\n  在比赛的几个月中，图像采样方法已经发生了很大的变化，并且已经将模型与其他选项融合在一起，有时会与改变的超参数（如 dropout 和学习率）结合在一起。因此，很难对最有效的单一网络培训方式给出明确的指导。此外，为了使其更加复杂，一些模型是受[8]启发而设计的，其中一些模型是在较小的图像块中训练的，而另一些模型是在较大的图像块上的。尽管如此，有一个处方在比赛后证明效果很好，它包括对图像中大小均匀分布在图像区域8%到100%之间的各种大小的斑块进行采样，纵横比受间隔限制[3/4，4/3]。此外，我们还发现，安德鲁·霍华德（Andrew Howard）的光度畸变对克服训练数据成像条件的影响非常有用。\n7. ILSVRC 2014 Classiﬁcation Challenge Setup and Results\n   ILSVRC 2014分类挑战涉及到将图像分类为ImageNet层次结构中的1000叶节点类别的任务。训练图像约120万张，验证用图像约5万张，测试用图像约10万张。每幅图像都与一个 gt 类别相关联，并且性能是基于最高评分的更高级预测来衡量的。通常会报告两个数字：第一个准确率（将地面真实性与第一个预测类进行比较）和第五个错误率（将地面真实性与前五个预测类进行比较）：如果地面真实性在前五个预测类中，则不管图像中的等级如何，都认为图像是正确分类的。挑战使用前5个错误率进行排名。\n  我们没有使用额外的数据参加挑战。除了本文前面提到的训练技术之外，我们在测试过程中采用了一套技术来获得更高的性能（可以理解为超级疯狂的模型集成和数据拓展），下面我们将对此进行描述。\n  (1) 我们独立训练了同一个谷歌模型的7个版本（包括一个更广泛的版本），并与他们进行了模型集成。这些模型是用相同的初始化（甚至是相同的初始权重，由于一个监督）和学习率策略进行训练的。它们只在采样方法和随机输入图像顺序上有所不同。\n  (2) 在测试期间我们采取了比 Krizhevsky 等人更为激进的裁剪方法。具体的我们将图像缩放到 4 中尺度，其中他们的短边长度分别是256，288，320，352，取出图像的左中右三个方形（对于肖像图像，我们取顶部、中间和底部的方形）。对于每一个方形，我们取出 4 个角和中心部分，同时也将方形部分缩放回 224*224，并且获得他们的镜像图像。这将导致我们在一张图像中取出 4×3×6×2 = 144 个图像块。安德鲁·霍华德（Andrew Howard）在上一年的比赛中中也采用了类似的方法，我们根据经验证明，该方法的表现略差于我们提出的策略。我们注意到，在实际应用中，这种激进的剪裁可能不是必要的，因为在出现合理数量的剪裁图片之后，更多剪裁的效益变得微乎其微（稍后我们将展示）。\n  (3) softmax 的概率值是对所有的剪切出来的图像和所有的独立的分类器上得到的均值作为预测的结果。在验证集上我们分析了替代的方法，例如对单张图像的所有剪切图像的结果进行最大池化，然后对所有的分类器去均值，但是它们导致的性能比简单的平均差。\n  在本文的其余部分中，我们分析了有助于最终提交的总体性能的多个因素。\n  我们最后提交的挑战获得了6.67%的验证和测试数据的前5个错误，在其他参与者中排名第一。与2012年的训练方法相比，这是一个56.5%的相对减少，与上一年的最佳方法（Clarifai）相比，这是大约40%的相对减少，这两种方法都使用外部数据来训练网络。表2 显示了过去3年中一些表现最好的方法的统计数据。\n\n  当预测一张图像的时候，我们通过改变模型的数量和剪裁的数量来分析和报告不同测试选择的效果，如表 3 所示。当我们使用一个模型时，我们选择了一个在验证数据上具有最低的前1个错误率的模型。所有数字都在验证数据集中报告，以避免超出测试数据统计的范围。\n\n8. ILSVRC 2014 Detection Challenge Setup andResults\n  ILSVRC检测任务是在200个可能的类中，围绕图像中的对象生成边界框。如果检测到的对象与GroundTruth的类相匹配，并且它们的边界框重叠至少50%（使用JacCard索引），则这些对象算是正确的。外来检测被视为假阳性并受到处罚。与分类任务相反，每个图像可以包含多个对象，也可以不包含任何对象，其比例可能有所不同。使用平均精度（MAP）报告结果。googlenet所采用的检测方法与r-cnn的方法相似，但作为区域分类，随着初始模型的增加而增加。此外，通过将选择性搜索[20]方法与多框[5]预测相结合，改进了区域建议步骤，以实现更高的对象边界框调用。\n  为了减少误报的数量，超级像素的大小增加了2倍。这使得来自选择性搜索算法的建议减半。我们增加了来自多框[5]的200个地区提案，总共占[6]所用提案的60%，同时将覆盖率从92%提高到93%。减少覆盖率增加的提案数量的总体效果是提高单个模型案例的平均精度1%。最后，在对每个区域进行分类时，我们使用6个谷歌地图的集合。这导致精确度从40%提高到43.9%。注意，与R-CNN相反，我们没有使用边界框回归，因为缺乏时间。\n  我们首先报告最高检测结果，并显示自检测任务第一版以来的进展。与2013年的结果相比，精度几乎翻了一番。表现最好的团队都使用卷积网络。我们在表4中报告了财务得分以及每个团队的常用策略：使用外部数据、整体模型或上下文模型。外部数据通常是ILSVRC12分类数据，用于对模型进行预培训，该模型稍后将根据检测数据进行重新定义。一些团队还提到了本地化数据的使用。由于本地化任务边界框的很大一部分不包含在检测数据集中，因此可以使用此数据对通用边界框回归器进行预训练，就像在预训练中使用分类一样。googlenet条目没有使用本地化数据进行预培训。\n  在表5中，我们只使用一个模型比较结果。最优秀的表演模型是由深刻的洞察力和令人惊讶的只有0.3分的提高与3个模型的合奏，而谷歌获得了显着更强的效果与合奏。\n9.Conclusions\n  我们的结果提供了一个确凿的证据，证明用现有的密集型卷积计算近似期望的最优稀疏结构是改进计算机视觉神经网络的一种可行方法。这种方法的主要优点是，与较浅和较窄的体系结构相比，在计算需求适度增加的情况下，效果会显著提高。\n  我们的对象检测工作具有竞争力，尽管没有使用上下文，也没有执行边界框回归，这进一步证明了初始体系结构的优势。\n  对于分类和检测任务，可以想象得到获得和我们效果相当的结果需要跟多的昂贵的非 Inception 模块来组成相似的宽度和深度。尽管如此，我们的方法仍然提供了确凿的证据，证明迁移到更稀疏的架构总体上是可行的和有用的。这表明，未来将在[2]的基础上，以自动化方式创建更为稀疏和更复杂的结构，并将 Inception 结构的见解应用到其他领域。\n参考\n[1] Szegedy C , Liu N W , Jia N Y , et al. Going deeper with convolutions[C]// 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE Computer Society, 2015.\n[2] BookThief 简书 《Google Inception Net论文细读》\n\n                              &lt;/div&gt;    \n\n\n","categories":["机器学习"],"tags":[]},{"title":"Java中的单例模式分析和实践","url":"http://tanqingbo.cn/2019/10/06/Java中的单例模式分析和实践/","content":"\nhttp://www.bewindoweb.com/209.html\n前言最近在做一个简单的项目，需要调用大量的无状态函数，首先就想到了之前用过的单例模式设计API类。这是在去年实习的时候发现他们后台用PHP编写的，包括连接数据库之类的操作都用的是同一个类来操作，非常方便，仔细看看源码发现这个类就是一个单例模式设计的。不过最近翻看了一些资料，发现JAVA的单例模式并不简单：PHP并没有线程安全的问题，一个请求在结束后生命周期就结束了，PHP设计单例模式仅仅是为了如果在同一个页面多次处理，可以不用重复创建对象而已；JAVA则不同，需要考虑两个线程同时访问的情况。简单介绍下PHP的单例模式怎么设计，非常简单，保证三点就可以：（1）建立一个私有的静态成员变量，保存实例；（2）构造函数和克隆函数都不允许使用；（3）做一个public的获取实例的函数，自行实例化或者返回实例化后的对象。class bwbAPI&#123;\n  //存储实例的静态成员变量\n  private static $s_instance;\n\n  //构造函数，禁止外部实例化  private function __construct()&#123;  &#125;\n  //重写clone防止用户进行clone  public function __clone()&#123;\n  //当用户clone操作时产生一个错误信息\n  trigger_error(&quot;Can&#39;t clone object&quot;,E_USER_ERROR);\n  }\n  public static function getInstance() {\n  if(self::$s_instance instanceof self) &#123;\n      return self::$s_instance;\n  &#125;\n  self::$s_instance = new self();\n  return self::$s_instance;\n  }}在调用的时候：require (\"xxxxxxx/bwbAPI.php\");$bwb = bwbAPI::getInstance();$bwb-&gt;query(\"xxxxxxxxx\");超级方便，当然设计了这种东西，一定要保护好，比如nginx设置禁止直接访问这个文件所在目录。回到主题，还记得去年被实习老大内推去面大疆创新，因为很多原因啥都没看就上（海文哥对不起浪费了机会QwQ），问了句“你知道哪些JAVA的设计模式”，我的回答是“MVC”………平时多准备一点，当机会到的时候才能抓住，那么，来分析和实践一下JAVA单例模式吧。一、使用单例模式还是使用静态方法类很自然能想到这个问题，既然只需要让它存在一个对象，那使用静态方法类不就好了吗？这里有几个重点问题：1、静态类和静态方法类的区别静态类，指的是用static修饰的类，通常定义的类是不能使用static的，编译都通不过，不信的话实践下：静态类实际上应该称为“静态内部类”，是写在类里面的类，通常只是为了项目打包方便。放在内部才能使用static关键字修饰：而静态方法类是我自己起的名字（请JAVA大佬指教它的本名），指的是一个类，它的所有成员变量都是静态成员变量，所有方法都是静态方法。比如java.lang.Math类：所以我们平时才可以直接调用Math.ceil(3.2)、Math.max(22,33)等等方法。2、单例模式和静态方法类的区别（1）代码结构上单例模式可以有非静态方法和成员的，而且只要获得了实例就可以去调用；静态方法类通常来说全是静态方法，如果有非静态方法，是不能直接调用的。（2）编程思想上单例模式是普通的类，只不过它是有一个实例而已，符合JAVA面向对象的思想；静态方法类通常又称为工具类，它更像是面向过程的一个函数集。（3）JAVA特性上单例模式符合所有面向对象的特性，可以去继承类、可以实现接口、可以被继承、方法可以被重写、可以用于多态（不同实现）；而静态方法类不能。（4）生命周期上单例模式可以延迟初始化，并且一直到运行结束才会被回收；静态方法类在第一次使用��就会被加载，执行完静态方法后就会被回收，如果频繁调用会导致频繁地初始化和释放。（5）实例化上单例模式需要进行实例化（通过静态方法中的new）；静态方法类不需要实例化，可以直接调用。（6）内存占用上单例模式调用哪个方法，就载入哪个方法，但是它需要长时间地维护一个对象；静态方法类需要把所有静态方法都载入内存，不管你用不用。（7）运行速度上《单例模式和静态类的区别》作者称从日志打印看，静态方法比实例方法更快。《java中的单例模式与静态类》作者称静态方法比实例方法更快，因为静态的绑定是在编译期就进行的。（8）线程与共享单例模式的多线程控制很方便，适合维护或者共享一些配置状态信息；静态方法类的多线程控制则非常糟糕。3、单例模式和静态方法类的选择《JAVA Static方法与单例模式的理解》作者称，他最近用sonar测评代码质量的时候，发现工程中一些util类，以前写的static方法都提示最好用单例的方式进行改正。所以，看起来似乎单例模式更加推荐，这里列出几个考虑因素：考虑因素推荐选择&nbsp;&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 30px;=”” orphans:=”” auto;=”” text-align:=”” center;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(242,=”” 241,=”” 241);”=””&gt;涉及文件读写（考虑并发）&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 28px;=”” orphans:=”” auto;=”” text-align:=”” left;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 28px;=”” orphans:=”” auto;=”” text-align:=”” left;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=”” helvetica=””&gt;单例模式&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 28px;=”” orphans:=”” auto;=”” text-align:=”” center;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(242,=”” 241,=”” 241);”=””&gt;涉及数据库（考虑状态）&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 28px;=”” orphans:=”” auto;=”” text-align:=”” left;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;单例模式全是工具函数静态方法类&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 28px;=”” orphans:=”” auto;=”” text-align:=”” left;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;萌新小白&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 28px;=”” orphans:=”” auto;=”” text-align:=”” left;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;静态方法类&nbsp;不知道该如何选择单例模式所以，尽管我的任务里面不需要对状态信息进行维护，也几乎全是工具函数，但是后期很可能会涉及数据库的处理，并且会对方法有频繁的调用，我不希望产生大量的开销，因此使用单例模式来设计。二、JAVA单例模式的实现方法1、饿汉模式1.1 经典饿汉模式public class Singleton&#123;  private static Singleton instance = new Singleton();  private Singleton()&#123;&#125;  public static Singleton getInstance()&#123;\n  return instance;\n  }}【核心实现方式】在类加载时就创建实例，利用classloder机制避免了多线程的同步问题。【优点】简便易懂，实现了单例【缺点】无法做到延迟加载（lazy loading）【推荐】YES √【相关信息】饿汉的含义就是拿起饭碗就开吃，刚加载类就把实例创建了。这种方式非常常用，比如java.lang.Runtime类就是这样实现的单例：有一个重要问题，那就是为什么可以利用classloader机制避免多线程同步问题呢？这句话在好多博客里都提到过，可是没有人解释为什么，这里我来简单地分析一下。我们知道，要想使用一个类，首先得把class文件载入JVM。类的生命周期一共分为加载、验证、准备、解析、初始化、使用、卸载。JDK1.7提出，有且只有5种情况必须对类进行初始化，其中一种的一部分描述为“调用一个类的静态方法的时候需要进行初始化”，也就是说，当我们执行Singleton.getInstance()的时候，这个类就会被初始化。而初始化阶段就是执行类构造器&lt;clinit&gt;()方法的过程，&lt;clinit&gt;()方法会自动收集所有静态变量的赋值动作和静态语句块的操作一起执行，而执行的顺序就是语句在代码中出现的顺序（题外话，如果没有写静态相关的东西，是可以不产生&lt;clinit&gt;方法的）。重点来了，虚拟机会保证类的&lt;clinit&gt;方法在多线程环境中被正确加锁、同步。也就是说，如果我们在代码里产生多个线程调用Singleton.getInstance()，那么一个线程执行clinit，其他线程都会被阻塞。这就是classloader机制避免多线程同步问题的原因。有关详细的机制可以参考《Java虚拟机类加载机制》，有关更多饿汉和类加载的有趣面试题可参考【面试题】java类加载机制探索。1.2 饿汉模式变形1public class Singleton &#123;  private static Singleton instance = null;  static &#123;\n  Singleton.instance = new Singleton();\n  }  private Singleton (){}  public static Singleton getInstance() {\n  return Singleton.instance;\n  }}同样的思路，只不过用静态语句块去实现了而已。很常用，比如Hibernate框架自动生成的session工厂就是典型的静态语句块单例：public class Main &#123;  private static final SessionFactory ourSessionFactory;\n  static &#123;\n  try &#123;\n      ourSessionFactory = new Configuration().\n              configure(&quot;hibernate.cfg.xml&quot;).\n              buildSessionFactory();\n  &#125; catch (Throwable ex) &#123;\n      throw new ExceptionInInitializerError(ex);\n  &#125;\n  }\n  public static Session getSession() throws HibernateException {\n  return ourSessionFactory.openSession();\n  }  …..}&lt;h2helvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” 0px;=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=”” style=”font-weight: bold;”&gt;1.&lt;h2helvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” 0px;=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;3&nbsp;饿汉模式变形2——静态内部类public class Singleton &#123;  private static class SingletonHolder &#123;\n  private static Singleton INSTANCE = new Singleton();\n  }  private Singleton (){}  public static Singleton getInstance() {\n  return SingletonHolder.INSTANCE;\n  }}&lt;h2helvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” 0px;=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;【核心实现方式】创建一个静态内部类（静态类），利用该静态类加载时的classloder机制避免了多线程的同步问题。&lt;h2helvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” 0px;=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;【优点】实现了单例，支持了延迟加载&lt;h2helvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” 0px;=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;【缺点】无法做到延迟加载（lazy loading）&lt;h2helvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” 0px;=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;【推荐】YES √&lt;h2helvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” 0px;=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;【相关信息】&lt;h2helvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” 0px;=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;和经典饿汉模式的区别在于，这里它在初始化的时候并不会创建实例，而在调用&lt;codemicrosoft yahei’,=”” simsun;=”” font-size:=”” 14px;=”” line-height:=”” 18px;=”” text-indent:=”” 0px;=”” background-color:=”” rgb(242,=”” 242,=”” 242);”=””&gt;Singleton.getInstance()的时候触发了&lt;codemicrosoft yahei’,=”” simsun;=”” font-size:=”” 14px;=”” line-height:=”” 18px;=”” text-indent:=”” 0px;=”” background-color:=”” rgb(242,=”” 242,=”” 242);”=””&gt;SingletonHolder.INSTANCE，从而使得SingletonHolder类开始加载，那么利用classloader机制就避免了多线程重复new的行为。&lt;h2helvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” 0px;=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;codemicrosoft yahei’,=”” simsun;=”” font-size:=”” 14px;=”” line-height:=”” 18px;=”” text-indent:=”” 0px;=”” background-color:=”” rgb(242,=”” 242,=”” 242);”=””&gt;&lt;codemicrosoft yahei’,=”” simsun;=”” font-size:=”” 14px;=”” line-height:=”” 18px;=”” text-indent:=”” 0px;=”” background-color:=”” rgb(242,=”” 242,=”” 242);”=””&gt;2、懒汉模式public class Singleton&#123;  private static Singleton instance = null;  private Singleton()&#123;&#125;  public static Singleton getInstance()&#123;\n  if(null == instance)&#123;\n      instance = new Singleton();\n  &#125;\n  return instance;\n  }}&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;【核心实现方式】用静态变量保存实例，如果已经存在实例则直接返回它。&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;【优点】实现了延迟加载&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;【缺点】没有考虑多线程&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;【推荐】NO ×&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;【相关信息】&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;哇，这不就是之前PHP的那种方法吗。然而JAVA中会有多线程的问题，试想当两个线程同时new，那么就会有两个实例，破坏了单例模式的思想。那么可以这样解决，在getInstance方法上加一把同步锁：public static synchronized Singleton getInstance()&#123;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;然而，本来我们的意思是不要同时去创建实例就好了，现在变为了不要同时获得实例。如果本来已经创建好了，两个线程同时想要获取这个实例，也需要阻塞，这浪费时间了吶。3、双重校验锁public class Singleton &#123;  private static Singleton instance = null;  private Singleton()&#123;&#125;  public static Singleton getInstance() &#123;\n  if (instance == null) &#123;\n      synchronized (Singleton.class) &#123;\n          if (instance == null) &#123;\n              instance = new Singleton();\n          &#125;\n      &#125;\n  &#125;\n  return instance;\n  }}&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;【核心实现方式】修改懒汉模式的加锁机制。&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;【优点】实现了单例，支持了延迟加载&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;【缺点】jdk1.5后才能正常实现单例&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;【推荐】NO ×&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;【相关信息】&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软���黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;很好理解，前面提到懒汉模式的加锁的目的变化了，从“不能同时创建”变为了“不能同时获得”，导致很多不必要的加锁阻塞。这里首先判断一下是否是没有创建实例的竞争，如果是，才加锁，这样的话就会放行普通的获取实例的调用。然后再二次判断是否实例为空，为空才new。似乎很完美，然而问题在于JAVA有指令重排优化，为了达到更好的性能，JAVA根据情况可能会对指令调换顺序，new操作和赋值操作是不知道谁先谁后的。也就是说，如果在调用构造函数之前，就已经给instance分配了内存并赋值了默认值，这时候instance就不是null了，如果恰好发生切换，另一个线程就会认为已经创建好了实例，直接return instance，访问到了错误的地址，程序就GG了。jdk1.5以后的版本增加了volatile关键字，可以达到禁止语义重排优化的目的，我们可以这样写：private static volatile Singleton instance = null;这样就不会出现问题了。4、枚举public enum Singleton&#123;  INSTANCE;  public void whateverMethod()&#123;\n  System.out.println(&quot;test enum singleton.&quot;);\n  }}&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;【核心实现方式】利用枚举的特性。&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;【优点】规避了常见的单例缺点，比如线程同步问题、反序列化创建新实例、反射攻击等等&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;【缺点】无法做到延迟加载（lazy loading），jdk1.5以后才支持&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;【推荐】YES √&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;【相关信息】&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;phelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&lt;codemicrosoft yahei’,=”” simsun;=”” font-size:=”” 14px;=”” line-height:=”” 18px;=”” text-indent:=”” 0px;=”” background-color:=”” rgb(242,=”” 242,=”” 242);”=””&gt;&lt;codemicrosoft yahei’,=”” simsun;=”” font-size:=”” 14px;=”” line-height:=”” 18px;=”” text-indent:=”” 0px;=”” background-color:=”” rgb(242,=”” 242,=”” 242);”=””&gt;这是《Effective Java》一书中推荐的方法，它利用了jdk1.5以后出现的新数据结构——枚举的所有特性来几乎完美地实现了单例模式。enum可以有很多成员和方法，这使得我们可以在枚举中定义成员、编写方法。enum有一个默认的private构造器，防止被多次构造，这不就是单例的特性吗。enum就是一个普通的类，它继承自java.lang.Enum，有同学将class反编译后发现是这样的对应关系：原始代码：public enum myEnum &#123;  INSTANCE;&#125;反编译代码：public final class myEnum extends Enum&lt;myEnum&gt; &#123;\npublic static final myEnum INSTANCE;\npublic static myEnum[] values();\npublic static myEnum valueOf(String s);\nstatic &#123;&#125;;\n}在这之后会对这些静态代码进行初始化，也就是说，非常类似于饿汉模式。并且采用了final关键字，无法被继承。至于为什么能防范反序列化，是因为枚举的writeObject、readObject、readObjectNoData、writeReplace和readResolve等方法都是被禁用的，就防止了通过readObject来返回新实例，但是可以通过相同的名字进行valueOf。为什么能防反射，是因为&lt;preconsolas’;font-size:12.0pt;”&gt;java.lang.reflect.Constructor中&lt;/preconsolas’;font-size:12.0pt;”&gt;，屏蔽掉了enum，会直接抛出异常：（jdk1.8 /&nbsp;java.lang.reflect.Constructor /&nbsp;第520行）if ((clazz.getModifiers() &amp; Modifier.ENUM) != 0)\n      throw new IllegalArgumentException(&quot;Cannot reflectively create enum objects&quot;);&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;简直了……完美。&lt;/p&gt;&lt;p&gt;调用方法：&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;prettyprint lang-java linenums&quot;&gt;public class SingletonTest &#123;\n  public static void main(String[] args){\n  Singleton.INSTANCE.whateverMethod();\n  }}结果���三、总结单例实现方法是否推荐&nbsp;饿汉模式（三种方法）&nbsp;√&nbsp;懒汉模式&nbsp;×&nbsp;双重校验锁&nbsp;×&nbsp;枚举&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 28px;=”” orphans:=”” auto;=”” text-align:=”” left;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&nbsp;√ &nbsp;参考资料1、《Java虚拟机类加载机制》2、【面试题】java类加载机制探索3、《Java单例模式——并非看起来那么简单》4、《Java：单例模式的七种写法》5、《Java单例模式(Singleton)以及实现》6、《【单例深思】枚举实现单例原理》7、《为什么不能通过反射来实例化 枚举类》8、《关于枚举式单例的一些详解》9、《Java枚举enum以及应用：枚举实现单例模式》                \n\n\n","categories":["转载"],"tags":[]},{"title":"公众号号文章排版规范","url":"http://tanqingbo.cn/2019/10/06/公众号号文章排版规范/","content":"公众号号文章排版规范\n先登录网页版135编辑器\n排版规范文字教程\n第一步：把文章拷贝到135编辑器，清除格式；\n\n\n\n\n第二步：编辑器左侧：收藏-&gt;模板字体样式，改字号（15号字体）、两端对齐，删除右上角跳动的光标，如下图GIF：\n\n\n\n第三步：标题17号字体，加粗，段落与段落之间空一行，段落与标题之间空两行\n\n\n\n第四步：关键信息加粗\n\n\n\n第五步：插入图片，图片与段落之间空一行，图片来源12号字体，字体变淡\n\n\n\n第六步：文末添加引导，推荐阅读下面的标题，手机上显示时长度只占一行，如果超过一行就缩短标题，右下角引导在看。\n\n\n\n第七步：声明原创，修改摘要，不要用默认的摘要，要自己手动修改，摘要的作用主要是让大家有点进去的欲望。\n\n","categories":["漂来漂去"],"tags":[]},{"title":"也谈2%与98%的问题","url":"http://tanqingbo.cn/2019/10/06/谈谈百分之二与百分之九十八的问题/","content":"《智能时代》里面有一句话说，在未来的智能时代里，受益者只有2%。那么为什么有的人成为了2%的人，而有的人则走到了金字塔的底部。作者在《智能时代》里讲到，一个很重要的原因是很多人没有踏上新的技术革命的大潮，落伍了。另外一个原因就是不同人的思维方式不同，思维方式对个人的最终影响要远远高于智力、学历和家庭因素。\n那么2%的人和98%的人思维方式有什么不同呢？给大家举个例子吧！很多人应该都听过几年前阿里巴巴有5位员工写程序抢月饼被开除的事情，这件事已经过去很久，阿里是否该开除他们已经变得不重要了。但有意思的是大部分IT从业者对这件事的态度分成了界限非常清晰的两个阵营。第一个阵营是明确支持阿里决定的人，占少数，大部分都是行业中的资深人士和管理者；另一个阵营要么认为用程序抢月饼的人做得并没有错，要么认为即便有错，改了就好，阿里不应该用极刑，这个阵营中，大多数是IT行业里底层的工程师和程序员。这一件事情实际上是试金石，轻易地把大众分到了两个阵营中。\n其实这个事情没有绝对的对与错，老板有老板的想法，员工有员工的想法，但他之所以成为老板，在背后必有他的原因，这不仅仅是能力强、运气好、情商高可以解释的。同样，一些长期处在公司底层的人，则需要检讨一下自己的思维方式。\n在任何一个注重干部培养、有一定规模的公司里，都会对干部进行定期培训。在任何这一类的培训中，教授们都要不断告诉学员们两件事，首先，所有的功劳要给下面的员工。其次，每一个人都要帮助你的老板成功。怎么理解第二句话？如果一个人想被提升到他老板的位置，他就必须有他老板的思维方式和眼光，不能只盯着自己那一亩三分田，要从上一级部门乃至整个公司的利益出发考虑问题。\n站在自己的立场，或者自己部门的立场，一个人可能会有一个想法，但是同样这件事，站在老板的立场上、大部门的立场上，会有不同的考虑。帮助自己的老板成功，就意味着能够站在老板的立场上考虑问题，这样，公司才会把更重要的职责交给这个人。可以想象一下，如果在阿里内部，某个员工坚持站在自己的利益上，认为这五个人的行为没有问题，那么公司是否敢把安全性很重要的事情交给那些人呢？如果公司不觉得这些员工可堪大用，这些员工又怎么可能晋级呢？\n再谈一个和阿里巴巴有关的事，在阿里巴巴之前，有一个很火的电商网站叫8848，但是后来关门了，同时关门的还有一大批类似的电商网站。最后，这些搞电子商务的人讲，中国不适合搞电子商务，因为没有支付手段，大家不诚信，没有物流等等。\n他们说的都没有错，但是他们采取的是一种消极态度。比他们稍晚的阿里巴巴也遇到同样的问题，但是马云用的是另一种态度，没有支付手段就搞一个支付宝，没有诚信就搞一个商家评价体系，没有物流就由公司出面和物流公司谈专门的服务协议等等。\n这就是一种积极的思维方式。如果再往高了讲，马云这是站在他的老板——那些商家的角度，来思考这个问题，帮助商家成功，就是帮助阿里巴巴成功。\n98%的人在思维上常常犯的另一个错误就是不能够公正地就事论事。我们经常看到这样一个例子，张三犯了一个错误，别人给他指出来，张三不检讨自己的问题，经常用“李四曾经也这样”来狡辩。\n第一，这种思维是一种失败者的思维，不论李四是否曾经做了类似的事情，张三自己这么说，其实是默认了别人对他的指控。\n第二，张三这种做法非常情绪化，我们做事情应该就事论事，不掺杂太多感情的因素。张三正确的做法是，如果真是他的问题，他不妨虚心接受，然后反思一下自己为什么会犯如此的错误，以后避免就好，这样的人在社会任何地方，都受人欢迎。\n","categories":["漂来漂去"],"tags":[]},{"title":"不懂了吧！这才是名校的正确打开方式","url":"http://tanqingbo.cn/2019/10/05/吴军和三位美国大学教授聊大学教育/","content":"最近在听吴军老师《硅谷来信》专栏，其中有一封信聊到了本科生的教育，我听完之后受益匪浅，把内容整理了一下，分享给大家！\n1、在学校要学习校外很难获得的技能现在网上有很多公开课，大部分主讲人都是领域中的专家，课讲得也很好。如果学生们在大学里只是学习那些可以在课外能够以更低的成本学到的知识，那么上大学就没有什么必要了，或者说时间就利用得不是那么有效了。因此，在大学里就要学习校外学不到的东西，特别是那些很难自学的基础课程和专业知识。\n那么什么课程难以学习呢？像数学、统计、法律、会计、工程理论（比如计算机科学的算法课，电机工程领域的信号处理课）就属于这一类的课程。这些课程需要进行大量的练习，并且接受有丰富经验的教授指导，这些技能将来会在工作中发挥比较长期的作用。\n另外很多技能，即使在工作中没有使用，对生活也很有帮助，比如统计学。当你掌握了基本的统计学原理，在生活中才会对数据的大和小有些概念。\n2、学会写作很重要很多人认为，我不做记者，也不当作家，写作能力派不上用场。其实，不管你从事什么职业，都需要写作。能够将复杂而头绪非常多的想法用简单、平实、生动的语言表达出来，这是非常有用的。\n首先，在生活和工作中，有很多东西要写，包括提建议、写报告、简历和信件。比如写电子邮件可能是你与老板和同事沟通的主要途径。虽然很多人认为微信帮助通信，但是为了讲清楚问题，稍微正规一点的，效果更好一点的信件和短文更容易达到目的。\n其次，无论一个毕业生未来是工程师、律师、医生，还是一个商人，都需要有清晰的逻辑思维，善于写作的人说话会更有条理。\n写作也是一个需要在学校里练习的技巧，因为大家有时间，有指导，有需求，有练习的机会（要完成作业）。\n3、尽可能晚的做硬性抉择从信息论的角度讲，任何硬性的抉择都会失去信息，也就意味着失去机会。大多数大学生都不知道长大后想要什么，成为什么样的人。在这样的情况下，尽量不要断绝选择的可能性。\n像国内很多名校，学生在入学时不给他们分配将来的专业学院，目的就是推迟学生作硬性选择的时间。为了推迟选择，大学生在头两年应该尽可能广泛地选课，这样才能知道自己喜欢什么，集中选择自己喜欢的课程。\n4、注重授课老师而不是课程名称很多学生很在意自己的成绩单上都列举了什么样的课程，其实除了少数前面提到的基础课和专业基础课是为今后进一步学习打基础外，剩下的大部分课程，走出大学后用不了两年，知识就过时了。\n如果遇到一位不好的老师，教得枯燥无味，即便去听课了，可能也会在睡觉，上课变成了自学，最后就算考试通过获得了学分，也对大家将来的学习和工作没有什么帮助。\n但是，从好的老师那里，你可以学到很多东西，它们不仅来自于课程本身，而且是一整套合乎逻辑的解决问题的思路，这些可以让你今后举一反三地学习新东西。\n我现在仍然记得本科教单片机的老师，虽然他上课讲的内容早就忘了，但是他上课常说的两条建议我至今仍然记得，他说作为一个大学生要去多旅游去看看这个世界，也一定要去更高等的学府瞧瞧，体验他们的学习氛围。\n5、至少掌握好一门外语语言是非常重要的，尽管今天翻译软件让不懂外语的人能够与外国人进行简单的交流，但是要和对方进行深交，甚至成为朋友，就不是靠翻译软件能做到的了。因此，熟练掌握一门常用的外语就变得非常重要。今后的世界是全球化的世界，一个没有国际化能力的人就如同缺了一条腿，行事处处遇到困难。\n不过，吴军老师建议不要花太多时间学外语，毕竟在大学里时间有限。像第二外语这种课，即使需要，是可以在走出校园后学习的。在历史上，瑞士虽然有很好的工程师和商人，却很少出杰出的思想家和科学家，因为他们花了太多时间学习语言（瑞士有德语、法语、意大利语、罗曼什语四种官方语言），而没有太多时间思考哲学问题和科学问题。\n6、尽可能多地去旅行旅行的必要性包括三个方面，第一方面就是我们一般理解的旅游，它的目的是了解和自己过去生活环境完全不同的地区，在那里你会了解当地的人和文化，毕竟我们将来可能要和世界各地的人打交道，而他们的习惯和我们可能相去甚远。\n第二方面是利用暑期到各个不同地方的单位做实习，这样可以更早地知道自己将来想做什么，到什么地方去做，同时为了做那些事情需要学习什么。\n第三方面是走出舒适区。我们常说在家百日易，出门一日难。我们只有离开家，走出校园，才能知道世事艰辛，才能更珍惜校园时光，在走出校门后，才能更快地适应社会。\n7、多交流你的思想多和同学或者老师进行思想交流，这有两个目的，首先是通过交流不断更新自己的想法，毕竟学习的场所不仅仅是课堂。其次，也是更重要的一点，在校的年轻人有犯错误的权利，要好好利用这个权利。\n每一个人或多或少地有些错误的、别人不喜欢的想法，这些想法必须改正。而一种想法在说出来以前，你并不知道别人不喜欢，并不能意识到它可能伤害甚至激怒别人，给你带来大麻烦。当你走出校园后，如果犯了这样的错误，可能就不会被别人原谅，甚至惹来大麻烦，因为大家理所应当地把你当成熟的人来看待了。但是在学校里，别人会相对宽容一些。\n","categories":["漂来漂去"],"tags":[]},{"title":"对不起，你不是祖国的花朵，是韭菜","url":"http://tanqingbo.cn/2019/09/20/对不起，你不是祖国的花朵，是韭菜/","content":"不知道大家玩不玩知乎，因为我最近这一个多月比较忙，所以把知乎卸载了，昨天刚安装回来的时候就发现一个特别有趣的事，我把图片拿过来给大家瞅瞅，出处见水印。\n\n嗯，看完之后我只能说这很知乎！你永远不知道那些给你分享经验的人到底是个啥逼样！你不知道他是看上了你的钱，还是只是单纯想装个逼。\n我混知乎也有一段时间了，镰刀也接触不少，所以今天就给大家分享一下如何辨别知乎上的镰刀。或者说怎么快速成为一把锋利的镰刀。\n其实想要快速的涨粉成为一把合格的镰刀很简单，只要三步就够了。\n首先，个人信息里面一定要写上自己是名校毕业，不建议写985学校，可以写国外的名校，或者清北复交浙南科这类名校，毕竟知乎人人都是985毕业，把学校写牛逼一点才有竞争力啊。\n什么？并不是名校毕业！这有关系吗？韭菜们又不会去查你的户口，我就认识好多知乎大V，实则二本或者三本毕业的，但是人家写的在读院校都是国外的名校，瞅瞅人家这觉悟！\n其次，名校毕业的身份有了，你还得有牛逼的经历啊！这也得在个人信息里面体现出来，比如大学里面拿过什么牛逼的奖啊，你现在是某个公司的CEO或者是个合伙人，至于当什么公司的CEO比较好，自己的公司自己编，别问我！或者也可以写某知名企业的高管。如果再把性别设置成女性，头像用不知名的美女照片，那你这把镰刀就更锋利了。\n什么？你其实是抠脚大汉。这个重要吗？韭菜们又看不到电脑面前的你长什么样子。知乎每年被挖出来信息作假，盗用别人照片让粉丝误以为这就是自己的人还少吗？\n最后一步，也是最重要的一步，去答题！肚子里没有货，别慌！有模板的，照着模板写就行，我给大家举个例子哈！\n\n\n问题：大学生有哪些靠谱的兼职？\n\n答：作为一个XX学校（名校）的学生，我靠XX和XX兼职月入5000，所以我建议你一定要看一下这个回答，纯干货分享！\n（收入截图）\n我在做家教的时候，xxxxx（注意描述自己努力和牛逼的经历）\n\n\n\n\n\n问题：有哪些建议给刚入学的大学生？\n\n答：作为一个XX学校（名校）的学生，我在校期间当过学生会长，xxx比赛得过第一名、而且顺利拿到了XXX的offer（可以是名企或者是常青藤高校的offer）。所以我建议你一定要………\n\n\n\n\n问题：财务自由是一种什么样的体验？\n\n答：作为一个XX学校（名校）的学生，现在是XXX公司的CEO，我想要告诉你的是…….\n\n\n\n\n发现了吗？同志们，是不是瞬间感觉自己才思涌泉，也能随便编1-2千字了。\n什么？省略的部分不会写？这个很难吗？起点中文网的小说总看过吧！照着编就行了啊！\n\n只需19.99元，教你如何财务自由，同志们，心动了吗？\n说了这么多不是让大家去模仿这些套路，而是提醒大家在刷知乎的时候，怎么区分它是镰刀还是药。如果有一天，我在知乎上也写满了各种title，各种名校背书，而且变得特别活跃，那说明我可能缺钱了，我要在知乎上变现了。\n其实人人都是韭菜，都逃不掉被收割的命运，但是我希望你就算被人家割了，也要做一棵明明白白的韭菜，别稀里糊涂的被割了。\n我也被别人收割过, 我最近考试就被一些培训机构给割了，下回再来给大家分享培训机构里的一些镰刀都长什么样子的！\n","categories":["漂来漂去"],"tags":[]},{"title":"黄册与大明","url":"http://tanqingbo.cn/2019/06/02/黄册与大明/","content":"洪武四年，朱元璋在全国推行黄册制，类似于现在的身份证，记录了全国上下每一户的人口，田产，丁口。\n这个东西有什么用呢？它国家收税的凭据，税收是一个国家的主要经济来源，能不能正常运转下去就看收上来的税够不够，大明是按人口和田产收税，有了黄册，天下在朱元璋面前，便不存任何秘密了，透明可见。他可以随时看到一个地区的总数据，如果愿意，也可以深入查到任何一户的情况。\n正因为这个制度，明朝在永乐年间，甚至有财力支持郑和远下西洋，扬我天朝国威。\n曾有人这样称赞黄册：“天下黄册，该载户籍、事产，实国家重务，亿万载无疆之根本也。”因为朱元璋是基层出身，在户籍制度的设计上，他深谙基层弊端，手段施展得极有节奏，用了不到几年便完成了前朝所未能完成的版籍大业。\n说到这你可能会说，老朱果然牛逼，但是，明朝的灭亡，多多少少也和这个黄册库有关。\n等等，黄册不是生钱的嘛，国家靠这个谁也没办法逃税，国家应该会越来越有钱才对，它怎么又使国家没钱了呢？\n这事也得怪朱元璋，他是基层出身的，深谙基层的弊病，设计的黄册制度就是专门防止基层耍小聪明的，但是老朱他自己身上也带着一些基层人的毛病，就是舍不得花钱！\n前面已经说了黄册有多重要，但是维护黄册库运行需要成本啊，纸张成本、核查检验成本、管理成本，可是老朱竟然没有专门给黄册库拨款，也就是说虽然维护黄册库要钱，但是户部不会专门给黄册库拨银子。\n因为朱元璋觉得，如果单独为黄册库编一笔预算，会导致开支总数上升，这笔负担最终会落到底层农民身上。他一拍脑袋，想到了个好主意。\n在黄册库投入运营之后，朱元璋是这么安排的：人力成本由国子监负责，如果不够，则由都税司补足；纸墨之类的文具支出，由刑部、都察院负责，不够的话，再由应天府补足；房屋、册架、桌椅板凳之类，由工部负责添造修理；至于其他琐碎支出，则由户部负责。\n朱元璋是这么想的：每个衙门的经费，肯定会有结余。把七八个衙门的结余汇总起来，便可以在不增加支出的情况下养活黄册库。听起来是不是很美好！\n但是稍微有财务经验的人都知道，这个看似完美的结构，运转起来有多么可怕。因为黄册库是依靠好几个部门运转起来的，其实就相当于这几个部门对黄册库的支出与自己的KPI无关，既然不能提高我的KPI，我为什么要给你钱！官老爷别的不擅长，最擅长踢皮球。你想要经费？对不起，本部囊中羞涩，不敷开销。按洪武爷的规矩，您还是去别的部门问问看吧。\n其实一直以来，黄册就是大明政治的一个晴雨表。黄册本身的质量和数量，足以反映政治是否清明、国力是否上升、对基层的控制是否有效。\n洪武和永乐两位皇帝威权深重，又比较有追求，地方上不敢疏忽作弊，进呈的黄册质量都特别好，尺寸整齐，字迹清楚，用料上乘。这一时期的黄册，被称为“铜版册”，可见其过硬的质量。保存百年几无问题。\n可从正统之后，整个黄册制度开始紊乱起来。地方上作弊的手段日益成熟，胡乱填写，故意涂抹，造册尺寸也不怎么讲究；后湖黄册库存管理更是乱七八糟，晾晒不利，搬运不谨，还任由鼠咬虫蚀，黄册损毁严重。因为没钱管理啊！\n后来这种情况越演越烈。弘治三年，朝廷做了一次清查，发现在库黄册七十九万两千九百本，有虫蛀浥烂以及人为损坏痕迹的，竟高达六十四万七千三百本，也就是说，八成黄册都出问题了。更讽刺的是，洪武年间和永乐年间的黄册，反而保存完好的比例最高，接下来的一代不如一代。\n随着黄册的失效，在中枢朝廷眼里，整个天下不再透明，慢慢变得模糊而扭曲。接下来，会变得怎样？\n虽说导致明朝灭亡的原因很多，但是和黄册库没有经费运转，管理絮乱，基层情况不能及时上达天听也是有一定关系的。\n所以你看，朱元璋虽然很厉害，但也有一定的局限性，跟管理员一样，犯过的错误也不少。\n","categories":["漂来漂去"],"tags":[]},{"title":"2018ECCV所有论文下载链接","url":"http://tanqingbo.cn/2019/04/25/2018ECCV所有论文下载链接/","content":"Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper.pdf\nAashish_Sharma_Into_the_Twilight_ECCV_2018_paper.pdf\nAayush_Bansal_Recycle-GAN_Unsupervised_Video_ECCV_2018_paper.pdf\nAbdullah_Abuolaim_Revisiting_Autofocus_for_ECCV_2018_paper.pdf\nAbhimanyu_Dubey_Coreset-Based_Convolutional_Neural_ECCV_2018_paper.pdf\nAbhimanyu_Dubey_Improving_Fine-Grained_Visual_ECCV_2018_paper.pdf\nAdam_Geva_X-ray_Computational_Tomography_ECCV_2018_paper.pdf\nAdria_Recasens_Learning_to_Zoom_ECCV_2018_paper.pdf\nAdrian_Bulat_To_learn_image_ECCV_2018_paper.pdf\nAdrien_Kaiser_Proxy_Clouds_for_ECCV_2018_paper.pdf\nAggeliki_Tsoli_Joint_3D_tracking_ECCV_2018_paper.pdf\nAhmet_Iscen_Local_Orthogonal-Group_Testing_ECCV_2018_paper.pdfAidean_Sharghi_Improving_Sequential_Determinantal_ECCV_2018_paper.pdfAlbert_Pumarola_Anatomically_Coherent_Facial_ECCV_2018_paper.pdfAlex_Locher_Progressive_Structure_from_ECCV_2018_paper.pdfAlex_Zhu_Realtime_Time_Synchronized_ECCV_2018_paper.pdfAlexander_Vakhitov_Stereo_relative_pose_ECCV_2018_paper.pdfAli_Diba_Spatio-Temporal_Channel_Correlation_ECCV_2018_paper.pdfAmeya_Prabhu_Deep_Expander_Networks_ECCV_2018_paper.pdfAmir_Mazaheri_Visual_Text_Correction_ECCV_2018_paper.pdfAmir_Sadeghian_CAR-Net_Clairvoyant_Attentive_ECCV_2018_paper.pdfAmit_Raj_SwapNet_Garment_Transfer_ECCV_2018_paper.pdfAnanya_Harsh_Jha_Disentangling_Factors_of_ECCV_2018_paper.pdfAndreas_Veit_Convolutional_Networks_with_ECCV_2018_paper.pdfAndrew_Gilbert_Volumetric_performance_capture_ECCV_2018_paper.pdfAndrew_Owens_Audio-Visual_Scene_Analysis_ECCV_2018_paper.pdfAngela_Dai_3DMV_Joint_3D-Multi-View_ECCV_2018_paper.pdfAngjoo_Kanazawa_Learning_Category-Specific_Mesh_ECCV_2018_paper.pdfAnil_Baslamisli_Joint_Learning_of_ECCV_2018_paper.pdfAnirudh_Som_Perturbation_Robust_Representations_ECCV_2018_paper.pdfAnkan_Bansal_Zero-Shot_Object_Detection_ECCV_2018_paper.pdfAntonio_Torralba_Interpretable_Basis_Decomposition_ECCV_2018_paper.pdfAnurag_Arnab_Weakly-_and_Semi-Supervised_ECCV_2018_paper.pdfAnurag_Ranjan_Generating_3D_Faces_ECCV_2018_paper.pdfApoorv_Vyas_Out-of-Distribution_Detection_Using_ECCV_2018_paper.pdfArchan_Ray_U-PC_Unsupervised_Planogram_ECCV_2018_paper.pdfArjun_Nitin_Bhagoji_Practical_Black-box_Attacks_ECCV_2018_paper.pdfArmand_Zampieri_Multimodal_image_alignment_ECCV_2018_paper.pdfArslan_Chaudhry__Riemannian_Walk_ECCV_2018_paper.pdfArtsiom_Sanakoyeu_A_Style-aware_Content_ECCV_2018_paper.pdfArun_Mallya_Piggyback_Adapting_a_ECCV_2018_paper.pdfAttila_Szabo_Understanding_Degeneracies_and_ECCV_2018_paper.pdfAuston_Sterling_ISNN_-_Impact_ECCV_2018_paper.pdfBaosheng_Yu_Correcting_the_Triplet_ECCV_2018_paper.pdfBaris_Gecer_Semi-supervised_Adversarial_Learning_ECCV_2018_paper.pdfBeery_Recognition_in_Terra_ECCV_2018_paper.pdfBenjamin_Coors_SphereNet_Learning_Spherical_ECCV_2018_paper.pdfBenjamin_Eckart_Fast_and_Accurate_ECCV_2018_paper.pdfBenjamin_Hepp_Learn-to-Score_Efficient_3D_ECCV_2018_paper.pdfBharath_Bhushan_Damodaran_DeepJDOT_Deep_Joint_ECCV_2018_paper.pdfBin_Xiao_Simple_Baselines_for_ECCV_2018_paper.pdfBingbin_Liu_Temporal_Modular_Networks_ECCV_2018_paper.pdfBo_Dai_Rethinking_the_Form_ECCV_2018_paper.pdfBo_Peng_Extreme_Network_Compression_ECCV_2018_paper.pdfBo_Xiong_Snap_Angle_Prediction_ECCV_2018_paper.pdfBo_Zhao_Modular_Generative_Adversarial_ECCV_2018_paper.pdfBochao_Wang_Toward_Characteristic-Preserving_Image-based_ECCV_2018_paper.pdfBogdan_Bugaev_Combining_3D_Model_ECCV_2018_paper.pdfBolei_Zhou_Temporal_Relational_Reasoning_ECCV_2018_paper.pdfBorui_Jiang_Acquisition_of_Localization_ECCV_2018_paper.pdfBowen_Cheng_Revisiting_RCNN_On_ECCV_2018_paper.pdfBowen_Zhang_Cross-Modal_and_Hierarchical_ECCV_2018_paper.pdfBoyu_Chen_Real-time_Actor-Critic_Tracking_ECCV_2018_paper.pdfBrandon_RichardWebster_Visual_Psychophysics_for_ECCV_2018_paper.pdfBrook_Roberts_A_Dataset_for_ECCV_2018_paper.pdfBruce_Hou_Transferable_Adversarial_Perturbations_ECCV_2018_paper.pdfBryan_Plummer_Conditional_Image-Text_Embedding_ECCV_2018_paper.pdfCHAOWEI_XIAO_Characterize_Adversarial_Examples_ECCV_2018_paper.pdfCHUNLUAN_ZHOU_Bi-box_Regression_for_ECCV_2018_paper.pdfCalvin_Murdock_Deep_Component_Analysis_ECCV_2018_paper.pdfCarl_Toft_Semantic_Match_Consistency_ECCV_2018_paper.pdfCarl_Vondrick_Self-supervised_Tracking_by_ECCV_2018_paper.pdfCarlos_Esteves_Learning_SO3_Equivariant_ECCV_2018_paper.pdfCeyuan_Yang_Pose_Guided_Human_ECCV_2018_paper.pdfChang_Chen_Deep_Boosting_for_ECCV_2018_paper.pdfChang_Liu_Linear_Span_Network_ECCV_2018_paper.pdfChangan_Chen_Constraints_Matter_in_ECCV_2018_paper.pdfChangqian_Yu_BiSeNet_Bilateral_Segmentation_ECCV_2018_paper.pdfChangqing_Zou_SketchyScene_Richly-Annotated_Scene_ECCV_2018_paper.pdfChanho_Kim_Multi-object_Tracking_with_ECCV_2018_paper.pdfChao-Yuan_Wu_Video_Compression_through_ECCV_2018_paper.pdfChao_Li_ArticulatedFusion_Real-time_Reconstruction_ECCV_2018_paper.pdfChao_Wang_Discriminative_Region_Proposal_ECCV_2018_paper.pdfChaojian_Yu_Hierarchical_Bilinear_Pooling_ECCV_2018_paper.pdfCharles_Herrmann_Object-centered_image_stitching_ECCV_2018_paper.pdfCharles_Herrmann_Robust_image_stitching_ECCV_2018_paper.pdfChen_Liu_FloorNet_A_Unified_ECCV_2018_paper.pdfChen_Sun_Actor-centric_Relation_Network_ECCV_2018_paper.pdfChen_Zhu_Fine-grained_Video_Categorization_ECCV_2018_paper.pdfCheng_Wang_Mancs_A_Multi-task_ECCV_2018_paper.pdfChenglong_Li_Cross-Modal_Ranking_with_ECCV_2018_paper.pdfChenxi_Liu_Progressive_Neural_Architecture_ECCV_2018_paper.pdfChenyang_Si_Skeleton-Based_Action_Recognition_ECCV_2018_paper.pdfChi_Li_A_Unified_Framework_ECCV_2018_paper.pdfChieh_Lin_Escaping_from_Collapsing_ECCV_2018_paper.pdfChong_Li_Constrained_Optimization_Based_ECCV_2018_paper.pdfChong_You_A_Scalable_Exemplar-based_ECCV_2018_paper.pdfChristopher_Zach_Descending_lifting_or_ECCV_2018_paper.pdfChristos_Sakaridis_Semantic_Scene_Understanding_ECCV_2018_paper.pdfChu_Wang_Local_Spectral_Graph_ECCV_2018_paper.pdfChuanxia_Zheng_T2Net_Synthetic-to-Realistic_Translation_ECCV_2018_paper.pdfChuhui_Xue_Accurate_Scene_Text_ECCV_2018_paper.pdfChunrui_Han_Face_Recognition_with_ECCV_2018_paper.pdfChunyan_Bai_Deep_Video_Generation_ECCV_2018_paper.pdfChunze_Lin_Graininess-Aware_Deep_Feature_ECCV_2018_paper.pdfCiprian_Corneanu_Deep_Structure_Inference_ECCV_2018_paper.pdfClement_Godard_Deep_Burst_Denoising_ECCV_2018_paper.pdfCsaba_Domokos_MRF_Optimization_with_ECCV_2018_paper.pdfCurtis_Wigington_Start_Follow_Read_ECCV_2018_paper.pdfDamien_Teney_Visual_Question_Answering_ECCV_2018_paper.pdfDanda_Pani_Paudel_Sampling_Algebraic_Varieties_ECCV_2018_paper.pdfDanfeng_Hong_Joint__Progressive_ECCV_2018_paper.pdfDaniel_Barath_Multi-Class_Model_Fitting_ECCV_2018_paper.pdfDaniel_Castro_From_Face_Recognition_ECCV_2018_paper.pdfDaniel_Gehrig_Asynchronous_Photometric_Feature_ECCV_2018_paper.pdfDaniel_Jakubovitz_Improving_DNN_Robustness_ECCV_2018_paper.pdfDaniel_Maurer_Structure-from-Motion-Aware_PatchMatch_for_ECCV_2018_paper.pdfDaniel_Worrall_CubeNet_Equivariance_to_ECCV_2018_paper.pdfDapeng_Chen_Improving_Deep_Visual_ECCV_2018_paper.pdfDario_Rethage_Fully-Convolutional_Point_Networks_ECCV_2018_paper.pdfDavid_Harwath_Jointly_Discovering_Visual_ECCV_2018_paper.pdfDavid_Schubert_Direct_Sparse_Odometry_ECCV_2018_paper.pdfDawei_Du_The_Unmanned_Aerial_ECCV_2018_paper.pdfDeng-Ping_Fan_Salient_Objects_in_ECCV_2018_paper.pdfDhruv_Mahajan_Exploring_the_Limits_ECCV_2018_paper.pdfDi_Chen_Person_Search_via_ECCV_2018_paper.pdfDi_Lin_Multi-Scale_Context_Intertwining_ECCV_2018_paper.pdfDian_SHAO_Find_and_Focus_ECCV_2018_paper.pdfDiana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper.pdfDima_Damen_Scaling_Egocentric_Vision_ECCV_2018_paper.pdfDinesh_Jayaraman_ShapeCodes_Self-Supervised_Feature_ECCV_2018_paper.pdfDiwen_Wan_TBN_Convolutional_Neural_ECCV_2018_paper.pdfDmitry_Baranchuk_Revisiting_the_Inverted_ECCV_2018_paper.pdfDmytro_Mishkin_Repeatability_Is_Not_ECCV_2018_paper.pdfDong_Lao_Extending_Layered_Models_ECCV_2018_paper.pdfDong_Li_Recurrent_Tubelet_Proposal_ECCV_2018_paper.pdfDong_Su_Is_Robustness_the_ECCV_2018_paper.pdfDong_Yang_Proximal_Dehaze-Net_A_ECCV_2018_paper.pdfDongang_Wang_Dividing_and_Aggregating_ECCV_2018_paper.pdfDonghoon_Lee_Unsupervised_holistic_image_ECCV_2018_paper.pdfDongqing_Zhang_Optimized_Quantization_for_ECCV_2018_paper.pdfDongwoo_Lee_Joint_Blind_Motion_ECCV_2018_paper.pdfEddy_Ilg_Occlusions_Motion_and_ECCV_2018_paper.pdfEddy_Ilg_Uncertainty_Estimates_and_ECCV_2018_paper.pdfEdgar_Margffoy-Tuay_Dynamic_Multimodal_Instance_ECCV_2018_paper.pdfEdo_Collins_Deep_Feature_Factorization_ECCV_2018_paper.pdfEdouard_Oyallon_Compressing_the_Input_ECCV_2018_paper.pdfEfstratios_Gavves_Long-term_Tracking_in_ECCV_2018_paper.pdfEric_Muller-Budack_Geolocation_Estimation_of_ECCV_2018_paper.pdfErnesto_Brau_Stereo_gaze_Inferring_ECCV_2018_paper.pdfEunbyung_Park_Meta-Tracker_Fast_and_ECCV_2018_paper.pdfEunhyeok_Park_Value-aware_Quantization_for_ECCV_2018_paper.pdfEunji_Chong_Connecting_Gaze_Scene_ECCV_2018_paper.pdfFabian_Caba_What_do_I_ECCV_2018_paper.pdfFabian_Manhardt_Deep_Model-Based_6D_ECCV_2018_paper.pdfFabien_Baradel_Object_Level_Visual_ECCV_2018_paper.pdfFabio_Tosi_Beyond_local_reasoning_ECCV_2018_paper.pdfFang_Zhao_Dynamic_Conditional_Networks_ECCV_2018_paper.pdfFangneng_Zhan_Verisimilar_Image_Synthesis_ECCV_2018_paper.pdfFanyi_Xiao_Object_Detection_with_ECCV_2018_paper.pdfFatemeh_Sadat_Saleh_Effective_Use_of_ECCV_2018_paper.pdfFatih_Cakir_Hashing_with_Binary_ECCV_2018_paper.pdfFelipe_Codevilla_On_Offline_Evaluation_ECCV_2018_paper.pdfFengting_Yang_Recovering_3D_Planes_ECCV_2018_paper.pdfFilip_Radenovic_Deep_Shape_Matching_ECCV_2018_paper.pdfFilippos_Kokkinos_Deep_Image_Demosaicking_ECCV_2018_paper.pdfFitsum_Reda_SDC-Net_Video_prediction_ECCV_2018_paper.pdfFlorian_Strub_Visual_Reasoning_with_ECCV_2018_paper.pdfFrancisco_M._Castro_End-to-End_Incremental_Learning_ECCV_2018_paper.pdfFudong_Wang_Adaptively_Transforming_Graph_ECCV_2018_paper.pdfGang_Zhang_Generative_Adversarial_Network_ECCV_2018_paper.pdfGaofeng_Meng_Exploiting_Vector_Fields_ECCV_2018_paper.pdfGe_Deep_Metric_Learning_ECCV_2018_paper.pdfGedas_Bertasius_Object_Detection_in_ECCV_2018_paper.pdfGeorge_Papandreou_PersonLab_Person_Pose_ECCV_2018_paper.pdfGilad_Divon_Viewpoint_Estimation_-_ECCV_2018_paper.pdfGilles_Simon_A_Contrario_Horizon-First_ECCV_2018_paper.pdfGoutam_Bhat_Unveiling_the_Power_ECCV_2018_paper.pdfGratianus_Wesley_Putra_Data_Interpolating_Convolutional_Neural_ECCV_2018_paper.pdfGregoire_Payen_de_La_Garanderie_Eliminating_the_Dreaded_ECCV_2018_paper.pdfGuanan_Wang_Semi-Supervised_Generative_Adversarial_ECCV_2018_paper.pdfGuandao_Yang_A_Unified_Framework_ECCV_2018_paper.pdfGuangming_Zang_Super-Resolution_and_Sparse_ECCV_2018_paper.pdfGuangyu_Robert_Yang_A_dataset_and_ECCV_2018_paper.pdfGuanying_Chen_PS-FCN_A_Flexible_ECCV_2018_paper.pdfGuilin_Liu_Image_Inpainting_for_ECCV_2018_paper.pdfGul_Varol_BodyNet_Volumetric_Inference_ECCV_2018_paper.pdfGuo_Lu_Deep_Kalman_Filtering_ECCV_2018_paper.pdfGuojun_Yin_Zoom-Net_Mining_Deep_ECCV_2018_paper.pdfGuoliang_Kang_Deep_Adversarial_Attention_ECCV_2018_paper.pdfGuorun_Yang_SegStereo_Exploiting_Semantic_ECCV_2018_paper.pdfGuosheng_Hu_Deep_Multi-Task_Learning_ECCV_2018_paper.pdfHSUAN-I_HO_Summarizing_First-Person_Videos_ECCV_2018_paper.pdfHUSEYIN_COSKUN_Human_Motion_Analysis_ECCV_2018_paper.pdfHU_Jian-Fang_Deep_Bilinear_Learning_ECCV_2018_paper.pdfHai_Ci_Video_Object_Segmentation_ECCV_2018_paper.pdfHaitian_Zheng_CrossNet_An_End-to-end_ECCV_2018_paper.pdfHang_Yan_RIDI_Robust_IMU_ECCV_2018_paper.pdfHang_Zhao_The_Sound_of_ECCV_2018_paper.pdfHanyu_Wang_Learning_3D_Keypoint_ECCV_2018_paper.pdfHao_Cheng_Evaluating_Capability_of_ECCV_2018_paper.pdfHaoshu_Fang_Pairwise_Body-Part_Attention_ECCV_2018_paper.pdfHaoshuo_Huang_Domain_transfer_through_ECCV_2018_paper.pdfHaroon_Idrees_Composition_Loss_for_ECCV_2018_paper.pdfHeewon_Kim_Task-Aware_Image_Downscaling_ECCV_2018_paper.pdfHei_Law_CornerNet_Detecting_Objects_ECCV_2018_paper.pdfHelge_Rhodin_Unsupervised_Geometry-Aware_Representation_ECCV_2018_paper.pdfHeng_Wang_Scenes-Objects-Actions_A_Multi-Task_ECCV_2018_paper.pdfHengcan_Shi_Key-Word-Aware_Network_for_ECCV_2018_paper.pdfHengshuang_Zhao_Compositing-aware_Image_Search_ECCV_2018_paper.pdfHengshuang_Zhao_ICNet_for_Real-Time_ECCV_2018_paper.pdfHengshuang_Zhao_PSANet_Point-wise_Spatial_ECCV_2018_paper.pdfHenry_W._F._Yeung_Fast_Light_Field_ECCV_2018_paper.pdfHieu_Le_AD_Net_Training_ECCV_2018_paper.pdfHiroaki_Santo_Light_Structure_from_ECCV_2018_paper.pdfHoang_Le_Interactive_Boundary_Prediction_ECCV_2018_paper.pdfHong-Min_Chu_Deep_Generative_Models_ECCV_2018_paper.pdfHong_Xuan_Randomized_Ensemble_Embeddings_ECCV_2018_paper.pdfHongmei_Song_Pseudo_Pyramid_Deeper_ECCV_2018_paper.pdfHongyang_Li_Neural_Network_Encapsulation_ECCV_2018_paper.pdfHongyu_Xu_Deep_Regionlets_for_ECCV_2018_paper.pdfHossam_Isack_K-convexity_shape_priors_ECCV_2018_paper.pdfHsin-Ying_Lee_Diverse_Image-to-Image_Translation_ECCV_2018_paper.pdfHsueh-Fu_Lu_Toward_Scale-Invariance_and_ECCV_2018_paper.pdfHuaizu_Jiang_Self-Supervised_Relative_Depth_ECCV_2018_paper.pdfHuajie_Jiang_Learning_Class_Prototypes_ECCV_2018_paper.pdfHuang_Predicting_Gaze_in_ECCV_2018_paper.pdfHuayi_Zeng_Neural_Procedural_Reconstruction_ECCV_2018_paper.pdfHuizhong_Zhou_DeepTAM_Deep_Tracking_ECCV_2018_paper.pdfHumam_Alwassel_Action_Search_Spotting_ECCV_2018_paper.pdfHumam_Alwassel_Diagnosing_Error_in_ECCV_2018_paper.pdfHyo_Jin_Kim_Hierarchy_of_Alternating_ECCV_2018_paper.pdfHyojin_Bahng_Coloring_with_Words_ECCV_2018_paper.pdfIan_Cherabier_Learning_Priors_for_ECCV_2018_paper.pdfIkehata_CNN-PS_CNN-based_Photometric_ECCV_2018_paper.pdfIlchae_Jung_Real-Time_MDNet_ECCV_2018_paper.pdfIsma_Hadji_A_New_Large_ECCV_2018_paper.pdfIssam_Hadj_Laradji_Where_are_the_ECCV_2018_paper.pdfIvan_Eichhardt_Affine_Correspondences_between_ECCV_2018_paper.pdfJacob_Huh_Fighting_Fake_News_ECCV_2018_paper.pdfJi_Zhu_Online_Multi-Object_Tracking_ECCV_2018_paper.pdfJiabei_Zeng_Facial_Expression_Recognition_ECCV_2018_paper.pdfJiafan_Zhuang_Towards_Human-Level_License_ECCV_2018_paper.pdfJiahui_Zhang_Efficient_Semantic_Scene_ECCV_2018_paper.pdfJiajun_Wu_Learning_3D_Shape_ECCV_2018_paper.pdfJialin_Wu_Dynamic_Sampling_Convolutional_ECCV_2018_paper.pdfJian_Wang_Programmable_Light_Curtains_ECCV_2018_paper.pdfJianbo_Jiao_Look_Deeper_into_ECCV_2018_paper.pdfJiangxin_Dong_Learning_Data_Terms_ECCV_2018_paper.pdfJianwei_Yang_Graph_R-CNN_for_ECCV_2018_paper.pdfJiawei_He_Probabilistic_Video_Generation_ECCV_2018_paper.pdfJiaxin_Chen_Deep_Cross-modality_Adaptation_ECCV_2018_paper.pdfJiayuan_Gu_Learning_Region_Features_ECCV_2018_paper.pdfJie_Guo_Single_Image_Highlight_ECCV_2018_paper.pdfJie_Liang_Sub-GAN_An_Unsupervised_ECCV_2018_paper.pdfJie_Song_Selective_Zero-Shot_Classification_ECCV_2018_paper.pdfJie_Yang_Seeing_Deeply_and_ECCV_2018_paper.pdfJie_Zhang_Geometric_Constrained_Joint_ECCV_2018_paper.pdfJieru_Mei_Online_Dictionary_Learning_ECCV_2018_paper.pdfJin-Dong_Dong_DPP-Net_Device-aware_Progressive_ECCV_2018_paper.pdfJin-Seok_Park_Double_JPEG_Detection_ECCV_2018_paper.pdfJingwei_Ji_End-to-End_Joint_Semantic_ECCV_2018_paper.pdfJingyi_Zhang_Generative_Domain-Migration_Hashing_ECCV_2018_paper.pdfJinkyu_Kim_Textual_Explanations_for_ECCV_2018_paper.pdfJinlong_YANG_Analyzing_Clothing_Layer_ECCV_2018_paper.pdfJiqing_Wu_Wasserstein_Divergence_For_ECCV_2018_paper.pdfJiren_Zhu_HiDDeN_Hiding_Data_ECCV_2018_paper.pdfJiuxiang_Gu_Unpaired_Image_Captioning_ECCV_2018_paper.pdfJiyang_Gao_CTAP_Complementary_Temporal_ECCV_2018_paper.pdfJiyang_Yu_Selfie_Video_Stabilization_ECCV_2018_paper.pdfJoel_Janai_Unsupervised_Learning_of_ECCV_2018_paper.pdfJohannes_Schoenberger_Learning_to_Fuse_ECCV_2018_paper.pdfJongbin_Ryu_DFT-based_Transformation_Invariant_ECCV_2018_paper.pdfJoseph_DeGol_Improved_Structure_from_ECCV_2018_paper.pdfJue_Wang_Learning_Discriminative_Video_ECCV_2018_paper.pdfJulieta_Martinez_LSQ_lower_runtime_ECCV_2018_paper.pdfJuncheng_Li_Multi-scale_Residual_Network_ECCV_2018_paper.pdfJunho_Jeon_Reconstruction-based_Pairwise_Depth_ECCV_2018_paper.pdfJunjie_Zhang_Goal-Oriented_Visual_Question_ECCV_2018_paper.pdfJunwu_Weng_Deformable_Pose_Traversal_ECCV_2018_paper.pdfJustin_Liang_End-to-End_Deep_Structured_ECCV_2018_paper.pdfJyh-Jing_Hwang_Adaptive_Affinity_Field_ECCV_2018_paper.pdfKai_Xu_LAPCSRA_Deep_Laplacian_ECCV_2018_paper.pdfKaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper.pdfKaipeng_Zhang_Super-Identity_Convolutional_Neural_ECCV_2018_paper.pdfKaiyue_Lu_Deep_Texture_and_ECCV_2018_paper.pdfKaiyue_Pang_Deep_Factorised_Inverse-Sketching_ECCV_2018_paper.pdfKang_Pairwise_Relational_Networks_ECCV_2018_paper.pdfKarim_Ahmed_MaskConnect_Connectivity_Learning_ECCV_2018_paper.pdfKe_Gong_Instance-level_Human_Parsing_ECCV_2018_paper.pdfKe_LI_Universal_Sketch_Perceptual_ECCV_2018_paper.pdfKe_Zhang_Retrospective_Encoders_for_ECCV_2018_paper.pdfKeisuke_Tateno_Distortion-Aware_Convolutional_Filters_ECCV_2018_paper.pdfKeizo_Kato_Compositional_Learning_of_ECCV_2018_paper.pdfKejie_Li_Efficient_Dense_Point_ECCV_2018_paper.pdfKemal_Oksuz_Localization_Recall_Precision_ECCV_2018_paper.pdfKeren_Ye_ADVISE_Symbolism_and_ECCV_2018_paper.pdfKim_SAN_Learning_Relationship_ECCV_2018_paper.pdfKo_Nishino_Variable_Ring_Light_ECCV_2018_paper.pdfKohei_Uehara_Visual_Question_Generation_ECCV_2018_paper.pdfKonda_Reddy_Mopuri_Ask_Acquire_and_ECCV_2018_paper.pdfKonstantin_Shmelkov_How_good_is_ECCV_2018_paper.pdfKonstantinos-Nektarios_Lianos_VSO_Visual_Semantic_ECCV_2018_paper.pdfKripasindhu_Sarkar_Learning_3D_shapes_ECCV_2018_paper.pdfKrishna_Kumar_Singh_Transferring_Common-Sense_Knowledge_ECCV_2018_paper.pdfKuan-Chuan_Peng_Zero-Shot_Deep_Domain_ECCV_2018_paper.pdfKuang-Huei_Lee_Stacked_Cross_Attention_ECCV_2018_paper.pdfKuang-Jui_Hsu_Unsupervised_CNN-based_co-saliency_ECCV_2018_paper.pdfKuniaki_Saito_Adversarial_Open_Set_ECCV_2018_paper.pdfKyoungoh_Lee_Propagating_LSTM_3D_ECCV_2018_paper.pdfKyungmin_Kim_Multimodal_Dual_Attention_ECCV_2018_paper.pdfLai_Jiang_DeepVS_A_Deep_ECCV_2018_paper.pdfLan_Wang_PM-GANs_Discriminative_Representation_ECCV_2018_paper.pdfLawrence_Neal_Open_Set_Learning_ECCV_2018_paper.pdfLei_Chen_Part-Activated_Deep_Reinforcement_ECCV_2018_paper.pdfLei_Zhou_Learning_and_Matching_ECCV_2018_paper.pdfLei_Zhu_Bi-directional_Feature_Pyramid_ECCV_2018_paper.pdfLele_Chen_Lip_Movements_Generation_ECCV_2018_paper.pdfLequan_Yu_EC-Net_an_Edge-aware_ECCV_2018_paper.pdfLi_Jiang_GAL_Geometric_Adversarial_ECCV_2018_paper.pdfLiang-Chieh_Chen_Encoder-Decoder_with_Atrous_ECCV_2018_paper.pdfLiang_Generative_Semantic_Manipulation_ECCV_2018_paper.pdfLiang_Mi_Variational_Wasserstein_Clustering_ECCV_2018_paper.pdfLiangliang_Ren_Collaborative_Deep_Reinforcement_ECCV_2018_paper.pdfLiangliang_Ren_Deep_Reinforcement_Learning_ECCV_2018_paper.pdfLiangyan_Gui_Adversarial_Geometry-Aware_Human_ECCV_2018_paper.pdfLiangyan_Gui_Few-Shot_Human_Motion_ECCV_2018_paper.pdfLigeng_Zhu_Sparsely_Aggregated_Convolutional_ECCV_2018_paper.pdfLinchao_Zhu_Compound_Memory_Networks_ECCV_2018_paper.pdfLingjie_Zhu_Large_Scale_Urban_ECCV_2018_paper.pdfLingyu_Wei_Real-Time_Hair_Rendering_ECCV_2018_paper.pdfLior_Talker_Efficient_Sliding_Window_ECCV_2018_paper.pdfLior_Wolf_Estimating_the_Success_ECCV_2018_paper.pdfLipeng_Ke_Multi-Scale_Structure-Aware_Network_ECCV_2018_paper.pdfLiren_Chen_The_Devil_of_ECCV_2018_paper.pdfLisa_Anne_Hendricks_Grounding_Visual_Explanations_ECCV_2018_paper.pdfLisa_Anne_Hendricks_Women_also_Snowboard_ECCV_2018_paper.pdfLiuhao_Ge_Point-to-Point_Regression_PointNet_ECCV_2018_paper.pdfLixiong_Chen_Polarimetric_Three-View_Geometry_ECCV_2018_paper.pdfLluis_Gomez_Single_Shot_Scene_ECCV_2018_paper.pdfLong_Zhao_Learning_to_Forecast_ECCV_2018_paper.pdfLuona_Yang_Real-to-Virtual_Domain_Uni_ECCV_2018_paper.pdfMang_YE_Robust_Anchor_Embedding_ECCV_2018_paper.pdfMarc_Oliu_Folded_Recurrent_Neural_ECCV_2018_paper.pdfMaria_Klodt_Supervising_the_new_ECCV_2018_paper.pdfMarie-Morgane_Paumard_Image_Reassembly_Combining_ECCV_2018_paper.pdfMariya_Vasileva_Learning_Type-Aware_Embeddings_ECCV_2018_paper.pdfMarkus_Oberweger_Making_Deep_Heatmaps_ECCV_2018_paper.pdfMartin_Sundermeyer_Implicit_3D_Orientation_ECCV_2018_paper.pdfMartyushev_Self-Calibration_of_Cameras_ECCV_2018_paper.pdfMarzieh_Edraki_Generalized_Loss-Sensitive_Adversarial_ECCV_2018_paper.pdfMateusz_Malinowski_Learning_Visual_Question_ECCV_2018_paper.pdfMatheus_Gadelha_Multiresolution_Tree_Networks_ECCV_2018_paper.pdfMathieu_Garon_A_Framework_for_ECCV_2018_paper.pdfMathilde_Caron_Deep_Clustering_for_ECCV_2018_paper.pdfMatteo_Fabbri_Learning_to_Detect_ECCV_2018_paper.pdfMatthew_Trager_On_the_Solvability_ECCV_2018_paper.pdfMatthew_Trumble_Deep_Autoencoder_for_ECCV_2018_paper.pdfMatthias_Kummerer_Saliency_Benchmarking_Made_ECCV_2018_paper.pdfMatthias_Muller_TrackingNet_A_Large-Scale_ECCV_2018_paper.pdfMedhini_Gulganjalli_Narasimhan_Straight_to_the_ECCV_2018_paper.pdfMeiguang_Jin_Normalized_Blind_Deconvolution_ECCV_2018_paper.pdfMelih_Engin_DeepKSPD_Learning_Kernel-matrix-based_ECCV_2018_paper.pdfMeng_Tang_On_Regularized_Losses_ECCV_2018_paper.pdfMengshi_Qi_stagNet_An_Attentive_ECCV_2018_paper.pdfMeredith_Hu_Understanding_Perceptual_and_ECCV_2018_paper.pdfMian_Wei_Coded_Two-Bucket_Cameras_ECCV_2018_paper.pdfMichael_Moeller_Lifting_Layers_Analysis_ECCV_2018_paper.pdfMichal_Polic_Fast_and_Precise_ECCV_2018_paper.pdfMichelle_Guo_Focus_on_the_ECCV_2018_paper.pdfMichelle_Guo_Neural_Graph_Matching_ECCV_2018_paper.pdfMichitaka_Yoshida_Joint_optimization_for_ECCV_2018_paper.pdfMiika_Aittala_Burst_Image_Deblurring_ECCV_2018_paper.pdfMikael_Persson_Lambda_Twist_An_ECCV_2018_paper.pdfMing_Liang_Deep_Continuous_Fusion_ECCV_2018_paper.pdfMing_Sun_Multi-Attention_Multi-Class_Constraint_ECCV_2018_paper.pdfMingfei_Gao_C-WSL_Count-guided_Weakly_ECCV_2018_paper.pdfMinghao_Guo_Dual-Agent_Deep_Reinforcement_ECCV_2018_paper.pdfMingtao_Feng_3D_Face_Reconstruction_ECCV_2018_paper.pdfMingze_Xu_Joint_Person_Segmentation_ECCV_2018_paper.pdfMinho_Shim_Teaching_Machines_to_ECCV_2018_paper.pdfMinhyeok_Heo_Monocular_Depth_Estimation_ECCV_2018_paper.pdfMinjun_Li_Unsupervised_Image-to-Image_Translation_ECCV_2018_paper.pdfMinxian_Li_Unsupervised_Person_Re-identification_ECCV_2018_paper.pdfMir_Rayat_Imtiaz_Hossain_Exploiting_temporal_information_ECCV_2018_paper.pdfMohammad_Tavakolian_Deep_Discriminative_Model_ECCV_2018_paper.pdfMohammadreza_Zolfaghari_ECO_Efficient_Convolutional_ECCV_2018_paper.pdfMohammed_Fathy_Hierarchical_Metric_Learning_ECCV_2018_paper.pdfMohit_Gupta_A_Geometric_Perspective_ECCV_2018_paper.pdfMoitreya_Chatterjee_Diverse_and_Coherent_ECCV_2018_paper.pdfMostafa_Ibrahim_Hierarchical_Relational_Networks_ECCV_2018_paper.pdfMrigank_Rochan_Video_Summarization_Using_ECCV_2018_paper.pdfMuhammed_Kocabas_MultiPoseNet_Fast_Multi-Person_ECCV_2018_paper.pdfMyunggi_Lee_Motion_Feature_Network_ECCV_2018_paper.pdfNIKITA_DVORNIK_Modeling_Visual_Context_ECCV_2018_paper.pdfNIKOLAOS_ZIOULIS_OmniDepth_Dense_Depth_ECCV_2018_paper.pdfNaeha_Sharif_NNEval_Neural_Network_ECCV_2018_paper.pdfNamhyuk_Ahn_Fast_Accurate_and_ECCV_2018_paper.pdfNan_Yang_Deep_Virtual_Stereo_ECCV_2018_paper.pdfNanyang_Wang_Pixel2Mesh_Generating_3D_ECCV_2018_paper.pdfNatalia_Neverova_Two_Stream__ECCV_2018_paper.pdfNathan_Silberman_ExplainGAN_Model_Explanation_ECCV_2018_paper.pdfNavaneeth_Bodla_Semi-supervised_FusedGAN_for_ECCV_2018_paper.pdfNgoc-Trung_Tran_Generative_Adversarial_Autoencoder_ECCV_2018_paper.pdfNicholas_Rhinehart_R2P2_A_ReparameteRized_ECCV_2018_paper.pdfNiclas_Zeller_Scale-Awareness_of_Light_ECCV_2018_paper.pdfNikolaos_Karianakis_Reinforced_Temporal_Attention_ECCV_2018_paper.pdfNikolaos_Passalis_Learning_Deep_Representations_ECCV_2018_paper.pdfNikolaos_Sarafianos_Deep_Imbalanced_Attribute_ECCV_2018_paper.pdfNimisha_T_M_Unsupervised_Class-Specific_Deblurring_ECCV_2018_paper.pdfNing_Xu_YouTube-VOS_Sequence-to-Sequence_Video_ECCV_2018_paper.pdfNingning_Light-weight_CNN_Architecture_ECCV_2018_paper.pdfNuno_Garcia_Modality_Distillation_with_ECCV_2018_paper.pdfOliver_Groth_ShapeStacks_Learning_Vision-Based_ECCV_2018_paper.pdfOliver_Zendel_WildDash_-_Creating_ECCV_2018_paper.pdfOlivia_Wiles_X2Face_A_network_ECCV_2018_paper.pdfPanna_Felsen_Where_Will_They_ECCV_2018_paper.pdfParikshit_Sakurikar_Single_Image_Scene_ECCV_2018_paper.pdfPatrick_Follmann_D2S_Densely_Segmented_ECCV_2018_paper.pdfPatrick_Wieschollek_Separating_Reflection_and_ECCV_2018_paper.pdfPau_Rodriguez_Lopez_Attend_and_Rectify_ECCV_2018_paper.pdfPaul_Hongsuck_Seo_Attentive_Semantic_Alignment_ECCV_2018_paper.pdfPaul_Hongsuck_Seo_Enhancing_Image_Geolocalization_ECCV_2018_paper.pdfPauline_Luc_Predicting_Future_Instance_ECCV_2018_paper.pdfPedro_Miraldo_A_Minimal_Closed-Form_ECCV_2018_paper.pdfPei_Wang_Towards_Realistic_Predictors_ECCV_2018_paper.pdfPeiliang_LI_Stereo_Vision-based_Semantic_ECCV_2018_paper.pdfPeng_Tang_Weakly_Supervised_Region_ECCV_2018_paper.pdfPengfei_Zhang_Adding_Attentiveness_to_ECCV_2018_paper.pdfPengyuan_Lyu_Mask_TextSpotter_An_ECCV_2018_paper.pdfPierre_Stock_ConvNets_and_ImageNet_ECCV_2018_paper.pdfPiotr_Koniusz_Museum_Exhibit_Identification_ECCV_2018_paper.pdfPo-Yu_Huang_Efficient_Uncertainty_Estimation_ECCV_2018_paper.pdfPradeep_Kumar_Jayaraman_Quadtree_Convolutional_Neural_ECCV_2018_paper.pdfPyojin_Kim_Linear_RGB-D_SLAM_ECCV_2018_paper.pdfQi_Guo_Tackling_3D_ToF_ECCV_2018_paper.pdfQi_Ye_Occlusion-aware_Hand_Pose_ECCV_2018_paper.pdfQiang_Qiu_ForestHash_Semantic_Hashing_ECCV_2018_paper.pdfQianru_Sun_A_Hybrid_Model_ECCV_2018_paper.pdfQing_Li_VQA-E_Explaining_Elaborating_ECCV_2018_paper.pdfQinghao_Hu_Training_Binary_Weight_ECCV_2018_paper.pdfQingnan_Fan_Learning_to_Learn_ECCV_2018_paper.pdfQingqiu_Huang_Person_Search_in_ECCV_2018_paper.pdfQingyi_Tao_Zero-Annotation_Object_Detection_ECCV_2018_paper.pdfQixing_Huang_Joint_Map_and_ECCV_2018_paper.pdfQuanlong_Zheng_Task-driven_Webpage_Saliency_ECCV_2018_paper.pdfRAFAEL_FELIX_Multi-modal_Cycle-consistent_Generalized_ECCV_2018_paper.pdfRahaf_Aljundi_Memory_Aware_Synapses_ECCV_2018_paper.pdfRajendra_Nagar_Fast_and_Accurate_ECCV_2018_paper.pdfRajvi_Shah_View-graph_Selection_Framework_ECCV_2018_paper.pdfRameswar_Panda_Contemplating_Visual_Emotions_ECCV_2018_paper.pdfRamprasaath_Ramasamy_Selvaraju_Choose_Your_Neuron_ECCV_2018_paper.pdfRelja_Arandjelovic_Objects_that_Sound_ECCV_2018_paper.pdfRene_Ranftl_Deep_Fundamental_Matrix_ECCV_2018_paper.pdfRenjiao_Yi_Faces_as_Lighting_ECCV_2018_paper.pdfRex_Yue_Wu_BusterNet_Detecting_Copy-Move_ECCV_2018_paper.pdfRishabh_Dabral_Learning_3D_Human_ECCV_2018_paper.pdfRoberto_Valle_A_Deeply-initialized_Coarse-to-fine_ECCV_2018_paper.pdfRoey_Mechrez_The_Contextual_Loss_ECCV_2018_paper.pdfRohit_Pandey_Efficient_6-DoF_Tracking_ECCV_2018_paper.pdfRonald_Clark_Neural_Nonlinear_least_ECCV_2018_paper.pdfRonghang_Hu_Explainable_Neural_Computation_ECCV_2018_paper.pdfRui_Yu_Hard-Aware_Point-to-Set_Deep_ECCV_2018_paper.pdfRuochen_Fan_Associating_Inter-Image_Salient_ECCV_2018_paper.pdfRuohan_Gao_Learning_to_Separate_ECCV_2018_paper.pdfRuohan_Zhang_AGIL_Learning_Attention_ECCV_2018_paper.pdfRuoteng_Li_Robust_Optical_Flow_ECCV_2018_paper.pdfRuoxi_Deng_Learning_to_Predict_ECCV_2018_paper.pdfSEUNG_HYUN_LEE_Self-supervised_Knowledge_Distillation_ECCV_2018_paper.pdfSachin_Mehta_ESPNet_Efficient_Spatial_ECCV_2018_paper.pdfSafa_Cicek_SaaS_Speed_as_ECCV_2018_paper.pdfSafa_Messaoud_Structural_Consistency_and_ECCV_2018_paper.pdfSaihui_Hou_Progressive_Lifelong_Learning_ECCV_2018_paper.pdfSaining_Xie_Rethinking_Spatiotemporal_Feature_ECCV_2018_paper.pdfSameh_Khamis_StereoNet_Guided_Hierarchical_ECCV_2018_paper.pdfSamuel_Albanie_Learnable_PINs_Cross-Modal_ECCV_2018_paper.pdfSamuel_Albanie_Semi-convolutional_Operators_for_ECCV_2018_paper.pdfSamuel_Schulter_Learning_to_Look_ECCV_2018_paper.pdfSanghyun_Son_Clustering_Kernels_for_ECCV_2018_paper.pdfSanghyun_Woo_Convolutional_Block_Attention_ECCV_2018_paper.pdfSangryul_Jeon_PARN_Pyramidal_Affine_ECCV_2018_paper.pdfSanthosh_Kumar_Ramakrishnan_Sidekick_Policy_Learning_ECCV_2018_paper.pdfSantiago_Cadena_Diverse_feature_visualizations_ECCV_2018_paper.pdfSantiago_Cortes_ADVIO_An_Authentic_ECCV_2018_paper.pdfSasikiran_Yelamarthi_A_Zero-Shot_Framework_ECCV_2018_paper.pdfSatwik_Kottur_Visual_Coreference_Resolution_ECCV_2018_paper.pdfSebastian_Bullinger_3D_Vehicle_Trajectory_ECCV_2018_paper.pdfSekii_Pose_Proposal_Networks_ECCV_2018_paper.pdfSeong-Jin_Park_SRFeat_Single_Image_ECCV_2018_paper.pdfSeong_Tae_Kim_Facial_Dynamics_Interpreter_ECCV_2018_paper.pdfSeonwook_Park_Deep_Pictorial_Gaze_ECCV_2018_paper.pdfSergey_Prokudin_Deep_Directional_Statistics_ECCV_2018_paper.pdfSergio_Silva_License_Plate_Detection_ECCV_2018_paper.pdfSeung-Wook_Kim_Parallel_Feature_Pyramid_ECCV_2018_paper.pdfShangbang_Long_TextSnake_A_Flexible_ECCV_2018_paper.pdfShangzhe_Wu_Deep_High_Dynamic_ECCV_2018_paper.pdfShao-Hua_Sun_Multi-view_to_Novel_ECCV_2018_paper.pdfShaofei_Wang_Accelerating_Dynamic_Programs_ECCV_2018_paper.pdfSheng-Wei_Huang_AugGAN_Cross_Domain_ECCV_2018_paper.pdfSheng_Guo_CurriculumNet_Learning_from_ECCV_2018_paper.pdfShervin_Ardeshir_Integrating_Egocentric_Videos_ECCV_2018_paper.pdfShi_Chen_Boosted_Attention_Leveraging_ECCV_2018_paper.pdfShi_Yan_DDRNet_Depth_Map_ECCV_2018_paper.pdfShifeng_Zhang_Occlusion-aware_R-CNN_Detecting_ECCV_2018_paper.pdfShihao_Wu_Specular-to-Diffuse_Translation_for_ECCV_2018_paper.pdfShitala_Prasad_Using_Object_Information_ECCV_2018_paper.pdfShivanthan_Yohanandan_Saliency_Preservation_in_ECCV_2018_paper.pdfShiyao_Wang_Fully_Motion-Aware_Network_ECCV_2018_paper.pdfShuangjun_Liu_Inner_Space_Preserving_ECCV_2018_paper.pdfShubham_Tulsiani_Layer-structured_3D_Scene_ECCV_2018_paper.pdfShuhan_Chen_Reverse_Attention_for_ECCV_2018_paper.pdfSiddharth_Tourani_MPLP_Fast_Parallel_ECCV_2018_paper.pdfSifei_Liu_Switchable_Temporal_Propagation_ECCV_2018_paper.pdfSijia_Cai_Weakly-supervised_Video_Summarization_ECCV_2018_paper.pdfSimon_Hecker_Learning_to_Drive_ECCV_2018_paper.pdfSimon_Jenni_Deep_Bilevel_Learning_ECCV_2018_paper.pdfSimyung_Chang_Broadcasting_Convolutional_Network_ECCV_2018_paper.pdfSiqi_Liu_Remote_Photoplethysmography_Correspondence_ECCV_2018_paper.pdfSiqi_Yang_Using_LIP_to_ECCV_2018_paper.pdfSiyang_Li_Unsupervised_Video_Object_ECCV_2018_paper.pdfSiyeong_Lee_Deep_Recursive_HDRI_ECCV_2018_paper.pdfSiyuan_Huang_Monocular_Scene_Parsing_ECCV_2018_paper.pdfSiyuan_Qi_Learning_Human-Object_Interactions_ECCV_2018_paper.pdfSiyuan_Qiao_Deep_Co-Training_for_ECCV_2018_paper.pdfSizhuo_3D_Motion_Sensing_ECCV_2018_paper.pdfSlawomir_Bak_Domain_Adaptation_through_ECCV_2018_paper.pdfSongtao_Liu_Receptive_Field_Block_ECCV_2018_paper.pdfSouYoung_Jin_Unsupervised_Hard-Negative_Mining_ECCV_2018_paper.pdfSteffen_Wolf_The_Mutex_Watershed_ECCV_2018_paper.pdfStephane_Lathuiliere_DeepGUM_Learning_Deep_ECCV_2018_paper.pdfSujoy_Paul_W-TALC_Weakly-supervised_Temporal_ECCV_2018_paper.pdfSunghun_Kang_Pivot_Correlational_Neural_ECCV_2018_paper.pdfT_M_Feroz_Ali_Maximum_Margin_Metric_ECCV_2018_paper.pdfTae-Hyun_Oh_Learning-based_Video_Motion_ECCV_2018_paper.pdfTae_Hyun_Kim_Spatio-temporal_Transformer_Network_ECCV_2018_paper.pdfTaihong_Xiao_ELEGANT_Exchanging_Latent_ECCV_2018_paper.pdfTal_Remez_Learning_to_Segment_ECCV_2018_paper.pdfTan_Yu_Product_Quantization_Network_ECCV_2018_paper.pdfTanmay_Gupta_Imagine_This_Scripts_ECCV_2018_paper.pdfTao_Kong_Deep_Feature_Pyramid_ECCV_2018_paper.pdfTao_Song_Small-scale_Pedestrian_Detection_ECCV_2018_paper.pdfTat-Jun_Chin_Robust_fitting_in_ECCV_2018_paper.pdfTete_Xiao_Unified_Perceptual_Parsing_ECCV_2018_paper.pdfThemos_Stafylakis_Zero-shot_keyword_search_ECCV_2018_paper.pdfThibault_Groueix_Shape_correspondences_from_ECCV_2018_paper.pdfThomas_Holzmann_Semantically_Aware_Urban_ECCV_2018_paper.pdfThomas_Probst_Incremental_Non-Rigid_Structure-from-Motion_ECCV_2018_paper.pdfThomas_Probst_Model-free_Consensus_Maximization_ECCV_2018_paper.pdfThomas_Robert_HybridNet_Classification_and_ECCV_2018_paper.pdfTian_Feng_Urban_Zoning_Using_ECCV_2018_paper.pdfTian_Ye_Interpretable_Intuitive_Physics_ECCV_2018_paper.pdfTianfan_Xue_Seeing_Tree_Structure_ECCV_2018_paper.pdfTianlang_Chen_Factual_or_Emotional_ECCV_2018_paper.pdfTianshu_Yu_Incremental_Multi-graph_Matching_ECCV_2018_paper.pdfTianwei_Lin_BSN_Boundary_Sensitive_ECCV_2018_paper.pdfTianyu_Yang_Learning_Dynamic_Memory_ECCV_2018_paper.pdfTianyun_Zhang_A_Systematic_DNN_ECCV_2018_paper.pdfTien-Ju_Yang_NetAdapt_Platform-Aware_Neural_ECCV_2018_paper.pdfTimo_von_Marcard_Recovering_Accurate_3D_ECCV_2018_paper.pdfTing_Yao_Exploring_Visual_Relationship_ECCV_2018_paper.pdfTobias_Fischer_RT-GENE_Real-Time_Eye_ECCV_2018_paper.pdfTolga_Birdal_PPF-FoldNet_Unsupervised_Learning_ECCV_2018_paper.pdfTomas_Hodan_PESTO_6D_Object_ECCV_2018_paper.pdfTrung_Pham_Bayesian_Instance_Segmentation_ECCV_2018_paper.pdfTsung-Yu_Lin_Second-order_Democratic_Aggregation_ECCV_2018_paper.pdfTushar_Nagarajan_Attributes_as_Operators_ECCV_2018_paper.pdfTz-Ying_Wu_Liquid_Pouring_Monitoring_ECCV_2018_paper.pdfUmar_Iqbal_Hand_Pose_Estimation_ECCV_2018_paper.pdfUta_Buchler_Improving_Spatiotemporal_Self-Supervision_ECCV_2018_paper.pdfVarun_Jampani_Superpixel_Sampling_Networks_ECCV_2018_paper.pdf\nVassileios_Balntas_RelocNet_Continous_Metric_ECCV_2018_paper.pdfVincent_Leroy_Shape_Reconstruction_Using_ECCV_2018_paper.pdfViorica_Patraucean_Massively_Parallel_Video_ECCV_2018_paper.pdfViresh_Ranjan_Iterative_Crowd_Counting_ECCV_2018_paper.pdfVivek_B_S_Gray_box_adversarial_ECCV_2018_paper.pdfWayne_Wu_Learning_to_Reenact_ECCV_2018_paper.pdfWei-Chih_Hung_Learning_to_Blend_ECCV_2018_paper.pdfWei-Chiu_Single_Image_Intrinsic_ECCV_2018_paper.pdfWei-Sheng_Lai_Real-Time_Blind_Video_ECCV_2018_paper.pdfWei_Dong_Probabilistic_Signed_Distance_ECCV_2018_paper.pdfWei_Liu_Learning_Efficient_Single-stage_ECCV_2018_paper.pdfWei_Tang_Deeply_Learned_Compositional_ECCV_2018_paper.pdfWeidi_Xie_Comparator_Networks_ECCV_2018_paper.pdfWeiwei_Shi_Transductive_Semi-Supervised_Deep_ECCV_2018_paper.pdfWeixuan_Chen_DeepPhys_Video-Based_Physiological_ECCV_2018_paper.pdfWeiyue_Wang_Depth-aware_CNN_for_ECCV_2018_paper.pdfWenhao_Jiang_Recurrent_Fusion_Network_ECCV_2018_paper.pdfWenqian_Liu_DYAN_A_Dynamical_ECCV_2018_paper.pdfWenqiang_Xu_SRDA_Generating_Instance_ECCV_2018_paper.pdfWonmin_Byeon_ContextVP_Fully_Context-Aware_ECCV_2018_paper.pdfWonsik_Kim_Attention-based_Ensemble_for_ECCV_2018_paper.pdfWoojae_Kim_Deep_Video_Quality_ECCV_2018_paper.pdfXU_JUN_A_Trilateral_Weighted_ECCV_2018_paper.pdfXU_YANG_Shuffle-Then-Assemble_Learning_Object-Agnostic_ECCV_2018_paper.pdfXi_Zhang_Attention-aware_Deep_Adversarial_ECCV_2018_paper.pdfXia_Li_Recurrent_Squeeze-and-Excitation_Context_ECCV_2018_paper.pdfXiang_Li_Adversarial_Open-World_Person_ECCV_2018_paper.pdfXiangyu_He_Learning_Compression_from_ECCV_2018_paper.pdfXiangyu_Xu_Rendering_Portraitures_from_ECCV_2018_paper.pdfXiangyun_Zhao_A_Modulation_Module_ECCV_2018_paper.pdfXiankai_Lu_Deep_Regression_Tracking_ECCV_2018_paper.pdfXiao_Sun_Integral_Human_Pose_ECCV_2018_paper.pdfXiaodan_Liang_CIRL_Controllable_Imitative_ECCV_2018_paper.pdfXiaofeng_Han_Single_Image_Water_ECCV_2018_paper.pdfXiaofeng_Liu_Dependency-aware_Attention_Control_ECCV_2018_paper.pdfXiaohan_Fei_Visual-Inertial_Object_Detection_ECCV_2018_paper.pdfXiaohang_Zhan_Consensus-Driven_Propagation_in_ECCV_2018_paper.pdfXiaojun_Chang_RCAA_Relational_Context-Aware_ECCV_2018_paper.pdfXiaokun_Wu_HandMap_Robust_Hand_ECCV_2018_paper.pdfXiaolin_Zhang_Self-produced_Guidance_for_ECCV_2018_paper.pdfXiaolong_Wang_Videos_as_Space-Time_ECCV_2018_paper.pdfXiaoming_Li_Learning_Warped_Guidance_ECCV_2018_paper.pdfXiaopeng_Zhang_ML-LocNet_Improving_Object_ECCV_2018_paper.pdfXiaoqing_Ye_3D_Recurrent_Neural_ECCV_2018_paper.pdfXiaoqing_Yin_FishEyeRecNet_A_Multi-Context_ECCV_2018_paper.pdfXiaoxiao_Li_Video_Object_Segmentation_ECCV_2018_paper.pdfXiaoyang_Guo_Learning_Monocular_Depth_ECCV_2018_paper.pdf\nXihui_Liu_Show_Tell_and_ECCV_2018_paper.pdfXin_Li_Contour_Knowledge_Transfer_ECCV_2018_paper.pdfXin_Wang_Look_Before_You_ECCV_2018_paper.pdfXin_Wang_SkipNet_Learning_Dynamic_ECCV_2018_paper.pdfXin_Yu_Face_Super-resolution_Guided_ECCV_2018_paper.pdfXin_Yuan_Towards_Optimal_Deep_ECCV_2018_paper.pdfXinchen_Yan_Generating_Multimodal_Human_ECCV_2018_paper.pdfXing_Wei_Grassmann_Pooling_for_ECCV_2018_paper.pdfXingang_Pan_Two_at_Once_ECCV_2018_paper.pdfXinge_Zhu_Penalizing_Top_Performers_ECCV_2018_paper.pdfXingping_Dong_Triplet_Loss_with_ECCV_2018_paper.pdfXingyi_Zhou_Category-Agnostic_Semantic_Keypoint_ECCV_2018_paper.pdfXingyi_Zhou_Unsupervised_Domain_Adaptation_ECCV_2018_paper.pdfXinjing_Cheng_Depth_Estimation_via_ECCV_2018_paper.pdfXinkun_Cao_Scale_Aggregation_Network_ECCV_2018_paper.pdfXinyu_Gong_Neural_Stereoscopic_Image_ECCV_2018_paper.pdfXinyuan_Chen_Attention-GAN_for_Object_ECCV_2018_paper.pdfXiyu_Yu_Learning_with_Biased_ECCV_2018_paper.pdfXu_Lan_Person_Search_by_ECCV_2018_paper.pdfXu_Tang_PyramidBox_A_Context-assisted_ECCV_2018_paper.pdfXuan_Chen_Focus_Segment_and_ECCV_2018_paper.pdfXuanqing_Liu_Towards_Robust_Neural_ECCV_2018_paper.pdfXuanyu_Zhu_Quaternion_Convolutional_Neural_ECCV_2018_paper.pdfXudong_Lin_Deep_Variational_Metric_ECCV_2018_paper.pdfXuecheng_Nie_Mutual_Learning_to_ECCV_2018_paper.pdfXuecheng_Nie_Pose_Partition_Networks_ECCV_2018_paper.pdfXuelin_Qian_Pose-Normalized_Image_Generation_ECCV_2018_paper.pdfXun_Huang_Multimodal_Unsupervised_Image-to-image_ECCV_2018_paper.pdfYa_Li_Deep_Domain_Generalization_ECCV_2018_paper.pdfYabin_Zhang_Fine-Grained_Visual_Categorization_ECCV_2018_paper.pdfYagiz_Aksoy_A_Dataset_of_ECCV_2018_paper.pdfYalong_Bai_Deep_Attention_Neural_ECCV_2018_paper.pdfYan-Pei_Cao_Learning_to_Reconstruct_ECCV_2018_paper.pdfYan_Wang_Spatial_Pyramid_Calibration_ECCV_2018_paper.pdfYanbei_Chen_Semi-Supervised_Deep_Learning_ECCV_2018_paper.pdfYanchao_Yang_Conditional_Prior_Networks_ECCV_2018_paper.pdfYandong_Li_How_Local_is_ECCV_2018_paper.pdfYang_Du_Interaction-aware_Spatio-temporal_Pyramid_ECCV_2018_paper.pdfYang_Feng_Video_Re-localization_via_ECCV_2018_paper.pdfYang_He_Diverse_Conditional_Image_ECCV_2018_paper.pdfYang_Liu_Synthetically_Supervised_Feature_ECCV_2018_paper.pdfYang_Shen_Egocentric_Activity_Prediction_ECCV_2018_paper.pdf\nYang_Shi_Question_Type_Guided_ECCV_2018_paper.pdfYang_Zou_Unsupervised_Domain_Adaptation_ECCV_2018_paper.pdfYangyu_Chen_Less_is_More_ECCV_2018_paper.pdfYantao_Shen_Person_Re-identification_with_ECCV_2018_paper.pdfYanting_Pei_Does_Haze_Removal_ECCV_2018_paper.pdfYao_Feng_Joint_3D_Face_ECCV_2018_paper.pdfYao_Yao_MVSNet_Depth_Inference_ECCV_2018_paper.pdfYaojie_Liu_Face_De-spoofing_ECCV_2018_paper.pdfYapeng_Tian_Audio-Visual_Event_Localization_ECCV_2018_paper.pdfYasutaka_Inagaki_Learning_to_Capture_ECCV_2018_paper.pdfYawei_Luo_Macro-Micro_Adversarial_Network_ECCV_2018_paper.pdfYe_Yuan_3D_Ego-Pose_Estimation_ECCV_2018_paper.pdfYedid_Hoshen_Separable_Cross-Domain_Translation_ECCV_2018_paper.pdfYeong_Jun_Koh_Sequential_Clique_Optimization_ECCV_2018_paper.pdfYi_Li_DeepIM_Deep_Iterative_ECCV_2018_paper.pdfYi_Wei_Quantization_Mimic_Towards_ECCV_2018_paper.pdfYi_Zhou_Semi-Dense_3D_Reconstruction_ECCV_2018_paper.pdfYi_Zhou_Single-view_Hair_Reconstruction_ECCV_2018_paper.pdf\nYidan_Zhou_HBE_Hand_Branch_ECCV_2018_paper.pdfYiding_Liu_Affinity_Derivation_and_ECCV_2018_paper.pdfYifan_Sun_Beyond_Part_Models_ECCV_2018_paper.pdfYifan_Xu_SpiderCNN_Deep_Learning_ECCV_2018_paper.pdfYifei_Shi_PlaneMatch_Patch_Coplanarity_ECCV_2018_paper.pdfYihua_Cheng_Appearance-Based_Gaze_Estimation_ECCV_2018_paper.pdfYihui_He_AMC_Automated_Model_ECCV_2018_paper.pdfYijun_Li_A_Closed-form_Solution_ECCV_2018_paper.pdfYijun_Li_Flow-Grounded_Spatial-Temporal_Video_ECCV_2018_paper.pdfYikang_LI_Factorizable_Net_An_ECCV_2018_paper.pdfYilei_Xiong_Move_Forward_and_ECCV_2018_paper.pdfYiming_Qian_Simultaneous_3D_Reconstruction_ECCV_2018_paper.pdfYin_Li_In_the_Eye_ECCV_2018_paper.pdfYin_Xia_Fictitious_GAN_Training_ECCV_2018_paper.pdfYinda_Zhang_Active_Stereo_Net_ECCV_2018_paper.pdfYing_Fu_Joint_Camera_Spectral_ECCV_2018_paper.pdfYing_Zhang_Deep_Cross-Modal_Projection_ECCV_2018_paper.pdfYingjie_Yao_Joint_Representation_and_ECCV_2018_paper.pdf\nYingwei_Li_RESOUND_Towards_Action_ECCV_2018_paper.pdfYinlong_Liu_Efficient_Global_Point_ECCV_2018_paper.pdfYipu_Zhao_Good_Line_Cutting_ECCV_2018_paper.pdfYiran_Zhong_Open-World_Stereo_Video_ECCV_2018_paper.pdfYiran_Zhong_Stereo_Computation_for_ECCV_2018_paper.pdfYiru_Zhao_A_Principled_Approach_ECCV_2018_paper.pdfYizhen_Lao_Rolling_Shutter_Pose_ECCV_2018_paper.pdfYongcheng_Jing_Stroke_Controllable_Fast_ECCV_2018_paper.pdfYonggen_Ling_Modeling_Varying_Camera-IMU_ECCV_2018_paper.pdf\nYongqiang_Zhang_SOD-MTGAN_Small_Object_ECCV_2018_paper.pdfYongyi_Lu_Attribute-Guided_Face_Generation_ECCV_2018_paper.pdfYongyi_Lu_Image_Generation_from_ECCV_2018_paper.pdfYoungjae_Yu_A_Joint_Sequence_ECCV_2018_paper.pdfYu-Ting_Chen_Leveraging_Motion_Priors_ECCV_2018_paper.pdfYuKang_Gan_Monocular_Depth_Estimation_ECCV_2018_paper.pdfYu_Liu_Transductive_Centroid_Projection_ECCV_2018_paper.pdfYuan-Ting_Hu_Unsupervised_Video_Object_ECCV_2018_paper.pdfYuan-Ting_Hu_VideoMatch_Matching_based_ECCV_2018_paper.pdfYue_Cao_Cross-Modal_Hamming_Hashing_ECCV_2018_paper.pdfYufei_Wang_ConceptMask_Large-Scale_Segmentation_ECCV_2018_paper.pdf\nYuge_Shi_Action_Anticipation_with_ECCV_2018_paper.pdfYuhang_Liu_Deblurring_Natural_Image_ECCV_2018_paper.pdfYuhang_Song_Contextual_Based_Image_ECCV_2018_paper.pdfYujun_Cai_Weakly-supervised_3D_Hand_ECCV_2018_paper.pdfYuliang_Zou_DF-Net_Unsupervised_Joint_ECCV_2018_paper.pdfYulun_Zhang_Image_Super-Resolution_Using_ECCV_2018_paper.pdfYumin_Suh_Part-Aligned_Bilinear_Representations_ECCV_2018_paper.pdfYunchao_Wei_TS2C_Tight_Box_ECCV_2018_paper.pdf\nYunhua_Zhang_Structured_Siamese_Network_ECCV_2018_paper.pdfYunlong_Wang_End-to-end_View_Synthesis_ECCV_2018_paper.pdfYunpeng_Chen_Fast_Multi-fiber_Network_ECCV_2018_paper.pdfYuta_Asano_Coded_Illumination_and_ECCV_2018_paper.pdf\nYuxin_Wu_Group_Normalization_ECCV_2018_paper.pdfZe_Yang_Learning_to_Navigate_ECCV_2018_paper.pdfZehao_Huang_Data-Driven_Sparse_Structure_ECCV_2018_paper.pdfZelun_Luo_Graph_Distillation_for_ECCV_2018_paper.pdfZeming_Li_DetNet_Design_Backbone_ECCV_2018_paper.pdfZeng_Huang_Deep_Volumetric_Video_ECCV_2018_paper.pdfZerong_Zheng_HybridFusion_Real-Time_Performance_ECCV_2018_paper.pdfZhangjie_Cao_Partial_Adversarial_Domain_ECCV_2018_paper.pdfZhao_Chen_Estimating_Depth_from_ECCV_2018_paper.pdf\nZhaoyang_Lv_Learning_Rigidity_in_ECCV_2018_paper.pdfZhaoyi_Yan_Shift-Net_Image_Inpainting_ECCV_2018_paper.pdfZhe_Chen_Context_Refinement_for_ECCV_2018_paper.pdfZhenbo_Xu_Towards_End-to-End_License_ECCV_2018_paper.pdfZhenfeng_Fan_Dense_Semantic_and_ECCV_2018_paper.pdfZheng_Dang_Eigendecomposition-free_Training_of_ECCV_2018_paper.pdfZheng_Shou_AutoLoc_Weakly-supervised_Temporal_ECCV_2018_paper.pdf\nZheng_Shou_Online_Detection_of_ECCV_2018_paper.pdfZheng_Zhang_Highly-Economized_Multi-View_Binary_ECCV_2018_paper.pdfZheng_Zhu_Distractor-aware_Siamese_Networks_ECCV_2018_paper.pdfZhengming_Ding_Graph_Adaptive_Knowledge_ECCV_2018_paper.pdfZhengqi_Li_CGIntrinsics_Better_Intrinsic_ECCV_2018_paper.pdfZhengqin_Li_Materials_for_Masses_ECCV_2018_paper.pdfZhenli_Zhang_ExFuse_Enhancing_Feature_ECCV_2018_paper.pdfZhenyu_Wu_Towards_Privacy-Preserving_Visual_ECCV_2018_paper.pdfZhenyu_Zhang_Joint_Task-Recursive_Learning_ECCV_2018_paper.pdf\nZhiding_Yu_SEAL_A_Framework_ECCV_2018_paper.pdfZhijian_Liu_Physical_Primitive_Decomposition_ECCV_2018_paper.pdfZhipeng_Cai_Deterministic_Consensus_Maximization_ECCV_2018_paper.pdfZhiqiang_Tang_Quantized_Densely_Connected_ECCV_2018_paper.pdfZhirong_Wu_Improving_Embedding_Generalization_ECCV_2018_paper.pdfZhiwen_Fan_A_Segmentation-aware_Deep_ECCV_2018_paper.pdf\nZhiwen_Shao_Deep_Adaptive_Attention_ECCV_2018_paper.pdf\nZhixin_Shu_Deforming_Autoencoders_Unsupervised_ECCV_2018_paper.pdfZhongzheng_Ren_Learning_to_Anonymize_ECCV_2018_paper.pdfZhou_GridFace_Face_Rectification_ECCV_2018_paper.pdfZhun_Zhong_Generalizing_A_Person_ECCV_2018_paper.pdfZi_Jian_Yew_3DFeat-Net_Weakly_Supervised_ECCV_2018_paper.pdfZihang_Meng_Efficient_Relative_Attribute_ECCV_2018_paper.pdfZiheng_Zhang_Saliency_Detection_in_ECCV_2018_paper.pdfZixin_Luo_Learning_Local_Descriptors_ECCV_2018_paper.pdfZorah_Laehner_DeepWrinkles_Accurate_and_ECCV_2018_paper.pdfZuxuan_Wu_DCAN_Dual_Channel-wise_ECCV_2018_paper.pdfgao_peng_Question-Guided_Hybrid_Convolution_ECCV_2018_paper.pdfmengdan_zhang_Visual_Tracking_via_ECCV_2018_paper.pdfshaifali_parashar_Self-Calibrating_Isometric__ECCV_2018_paper.pdfshi_jin_Learning_to_Dodge_ECCV_2018_paper.pdfyaxing_wang_Transferring_GANs_generating_ECCV_2018_paper.pdfyitong_wang_Orthogonal_Deep_Features_ECCV_2018_paper.pdfzechun_liu_Bi-Real_Net_Enhancing_ECCV_2018_paper.pdf\n","categories":["技术博客"],"tags":[]},{"title":"推荐一款程序员神器","url":"http://tanqingbo.cn/2019/04/24/推荐一款程序员神器/","content":"\n不知道大家有没有用过latex和markdown，两个都是用来编辑文档的语言，不过LaTeX偏学术风格，用来写paper写书是用的比较多，而markdown偏程序员风格，适合程序员写博客、贴代码，很多博客网站的默认编辑器都是markdown格式的。所以今天给大家介绍一款支持markdown语法的编辑器。如果想先了解一下markdown语法的同学可以先看一下这一片文章。\n事情是这样的，我之前写博客的时候用的是markdown iPad 这个编辑器，左边语法右边预览如下图：\n\n\n\n很多人都和我说markdown iPad左边语法右边预览这个太占屏幕空间了，体验不好，但是这个软件自带图床，可以直接把图片上传到他们的云上去，不用另外找图床了，我想偷一下懒，所以就一直用，可是前段时间我突然发现我个人博客网站上的图片全都失效了，3年多时间写的博客，图片全部失效，气的我差点爆炸。果然把图片上传到别人的图床上不靠谱，于是终于下定决心要搭建自己的图床，并换一个markdown编辑。\n所以今天给大家介绍一款新的markdown编辑器typora和图床的搭建过程。\n\nTypora\n优点\n\n简洁美观\n实时预览所，见即所得\n扩展语法\n跨平台\n免费 \n\n\n如下图：\n\n\n\n\n如上图，写完语法之后立刻就能看到排版的效果，美观整洁。\nTypora下载地址：https://www.typora.io/\n\nPicGo和github设置免费图床\n我之前用过微博图床，后来不知道是什么原因挂掉了，后来用了markdown ipad自带的图床，结果又挂掉了，我真的是有点坎坷。最终决定还是自己在github上建一个库专门存放博客图片。\n用到的工具：PicGo\nPicGo是一款简易的图床上传工具，可以通过拖拽或者复制粘贴的方式将图片上传到图床。\n下载地址：https://github.com/Molunerfinn/PicGo/releases\n\n新建github库\n很多人只知道github可以用来备份代码，但其实github仓库有很多用处，这里我们建一个专门用来存放图片的库，如下图：\n\n\n\n然后安装前面已经下载好的PicGo，打开后的界面如下所示：\n\n\n\n点击左边的图床设置-》github图床，将我们之前建的github图片库与PicGo绑定，如下图：\n\n\n\n只需要填写标“*”的三个部分，Token可以理解为可以标志你github账号地址的一个字符串，因为要把图片上传到你的账号对应的仓库中，所以要先定位你的账号，获取Token的方法如下,依次点击如下按钮：\n\ngithub头像-&gt;Settings-&gt;Developer settings-&gt;Personnal access tokens-&gt;Generate new token\n\n\n\n\n下图中红框中的字符串就是你的token。\n\n\n\n把这个字符串复制到PicGo的设置中，然后就可以直接将图片复制粘贴，或者拖拽上传到自己的github图床了，上传完之后PicGo会自动将链接保存到粘贴板，然后只需要一个粘贴操作就可以把图片插入到你的文档博客中了。如下图：\n\n\n","categories":["技术博客"],"tags":[]},{"title":"整理了一些刷题的网站和值得关注的企业算法大赛","url":"http://tanqingbo.cn/2019/04/17/和竞赛有关的资源或链接/","content":"刷题的网站LeetCode\n算法刷题网站首推LeetCode，业界一直有句话说把LeetCode上的题都刷烂熟了就可以进谷歌了。不过上面的题都是英语描述，需要一定的英语基础，还需要一定的算法基础，地址如下：\nhttps://leetcode.com/\n\n\n\n此外我这里还有一本LeetCode题解的书，也一起分享给大家。\n\nleetcode题解大全\n\n链接：http://pan.baidu.com/s/1c1Jaht2    \n提取码：fa1w\n\n\n\n牛客网\n“牛客网”是一个专注于程序员的学习和成长的专业平台，集笔面试系统、课程教育、社群交流、招聘内推于一体。计算专业的同学找工作的时候几乎都会用到牛客网。很多同学会在上面分享找工作的面经，不少公司的笔试题也是在牛客网上答的，当然它本身上面也有很多题库，适合初学者在上面练手。不仅如此，保研的同学还能在上面找到一些名校往年的复试的算法机试题。也是很强大了。地址如下：\n\nhttps://www.nowcoder.com/\n\n\n\n\n我之前在牛客网上刷完了PAT乙级(Basic Level)真题，PAT又叫计算机程序设计能力考试（Programming Ability Test，简称PAT）是由浙江大学计算机科学与技术学院组织的统一考试，旨在培养和展现学生分析问题、解决问题和计算机程序设计的能力，科学评价计算机程序设计人才，并为企业选拔人才提供参考标准。我可以把我刷完的源码给大家参考一下：\nhttps://github.com/tqb4342/PAT_Basic_Level\n\n赛码网\n性质和牛客网差不多，但个人感觉做的没有牛客网好。\n地址： http://www.acmcoder.com/index\n\n\n北京大学的OJ\n地址：http://poj.org/problemlist?volume=1\n\n\n杭电OJ\n地址：http://acm.hdu.edu.cn/\n\n\n值得关注企业比赛\n只是整理出来了一部分，欢迎大家补充~腾讯广告算法大赛\n报名日期2019年5月9号截止，想报名的同学现在可以报名，冠军20000美元奖金哦~\n地址：https://algo.qq.com/\n\n\n华为软件精英挑战赛\n这个比赛今年已经开始了，目前已经进行到决赛阶段，感兴趣的同学明年可以关注一下。\n地址：https://codecraft.huawei.com/\n\n\n搜狐图文匹配大赛\n官网介绍说提供业务场景、真实数据、专家指导，选拔和培养有志于自然语言处理领域的算法研究、应用探索的青年才俊，共同探索更多可能、开启无限未来。目前比赛刚刚开始，想要参赛的同学还来得及。\n地址：https://biendata.com/competition/sohu2019/\n\n\n阿里云安全算法挑战赛\n由天池平台与阿里云安全联合举办的最具“正义感”和“实战感”的大赛-『阿里云安全算法挑战赛』，作为国内首个以“安全”为主题的算法赛事，旨在挖掘安全算法的未来之星，并通过数据实战的形式，展现大数据对于安全监测和防御的重要性。\n比赛时间是2019年8月份才开始，大家可以关注一下。\n地址：https://m.aliyun.com/markets/aliyun/security\n\n\n人工智能竞赛平台Biendata.com\nBiendata.com是一个人工智能竞赛学习平台。用户可通过该平台报名并参加人工智能领域各类赛事，用户还可在线注册进行课程学习，并针对课程中遇到的问题进行反馈于总结。你感兴趣的的比赛在这上面都能找到。\n地址：https://www.biendata.com/\n\n\nKaggle\nKaggle主要是为开发商和数据科学家提供举办机器学习竞赛、托管数据库、编写和分享代码的平台。\n地址：https://www.kaggle.com/\n\n\n","categories":["技术博客"],"tags":[]},{"title":"深度学习在医学图像分析领域的研究","url":"http://tanqingbo.cn/2019/04/11/深度学习在医学图像分析领域的研究/","content":"深度学习在医学图像分析领域的研究摘要\n随着医学成像技术和计算机技术的不断发展和进步，医学图像分析已成为医学研究、临床疾病诊断和治疗中一个不可或缺的工具和技术手段。近几年来，深度学习（Deep learning,DL），特别是深度卷积神经网络（Convolutional neural networks,CNNs）已经迅速发展成为医学图像分析的研究热点，它能够从医学图像大数据中自动特区隐含的疾病诊断特征。本文首先简述医学图像分析的特点；其次，论述深度学习的基本原理，介绍主要用于医学图像分析的主要深度学习技术；然后分别论述深度学习在医学图像分类、检测、分割、配准、检索、图像生成和增强等各领域的国内外研究现状；最后，讨论归纳医学图像分析深度学习方法未来要面临的挑战和应对的策略。\n关键词：医学图像分析；深度学习；卷积神经网络\n\n1、介绍\n在医学图像领域，医生或者研究人员在对某种特定的内部组织器官进行定量分析、实时监控和治疗规划时，为了做出正确的治疗决策，通常需要了解这种组织器官的一些详细信息。所以生物医学影像已成为疾病诊断和治疗中不可或缺的组成部分，且日益重要。\n核磁共振成像 (Magnetic resonance image, MRI)、正电子发射断层扫 描 (Positron emission tomography, PET)、计算机 断层扫描 (Computer tomography, CT)、锥形束 CT、3D 超声成像等医学影像技术目前已广泛应用于临床检查、诊断、治疗与决策。如何充分利用人工智能深度学习方法分析处理这些超大规模的医学图像大数据，为临床医学中各种重大疾病的筛查、诊断、疗效评估提供科学方法，是当前医学图像分析领域急需解决的重大科学问题和前沿医学影像关键技术。\n医学图像分析最初主要采用边缘检测、纹理特征、形态学滤波以及构建形状模型和模板匹配等方法。这类分析方法通常针对特定任务而设计，被称为手工定制式设计方法。而深度学习是以数据驱动方式分析任务，能自动地从特定问题的大规模数据集中学习相关模型特征和数据特性。与针对特定问题而显式地手工设计模型不同，深度学习方法可直接从数据样本中隐式地自动学习医学图像特征，其学习过程本质上是一个优化问题的求解过程。通过学习，模型从训练数据中选择正确的特征，使其在测试新数据时做出正确决策。因此，深度学习在医学图像 分析中起着至关重要的作用。 \n近年来, 深度学习不断取得重大进展, 主要得益于不断提高的计算能力和持续增长的可用数据量，以及深度学习模型及其算法的不断改进。其实质是通过构建多隐层的机器学习模型，利用海量的样本数据训练，学习更精准的特征，最终提高分类或预测的准确性[1]。 深度学习这种从数据中学习层次特征的特点，使得它非常适合发现高维数据中的复杂结构，目前深度学习已经应用到图像识别、语音识别、自然语言处理、天气预测、基因表达、内容推荐等领域和各种挑战赛中。\n深度学习在计算机视觉领域的巨大成功, 激发了国内外许多学者将其应用于医疗图像分析。近年来，已有多位专家对深度学习在医学图像分析中的研究现状及问题进行了总结、评述和讨论。最近,Medical Image Analysis上发表的综述对深度学习在医学图像分类、检测和分割、配准 和检索等方面的研究进行了较全面的归纳总结[2] 。\n\n2、医学图像分析的特点\n医学图像分析已广泛应用于良恶性肿瘤、脑功能与精神障碍、心脑血管疾病等重大疾病的临床辅助筛查、诊断、分级、治疗决策与引导、疗效评估等方面。医学图像分类与识别、定位与检测、组织器官与病灶分割是当前医学图像分析深度学习方法研究主要应用领域。不同成像原理的医学图像分析和计算机视觉领域中的自然图像分析存在较大的差别。至今为止，国内外学者主要针对MRI、CT、X射线、超声、PET、病理光学显微镜等不同成像原理的医学图像分析任务开展了一系列的深度学习研究工作。因此，本节主要简述这几种医学图像的分析。\n\n2.1 常见的医学图像\nMRI图像：核磁共振图像（MRI），该图像是人体组织器官和病灶中的氢原子核在外部强磁场作用下产生的磁共振信号大小的度量，并通过计算机对体外核磁共振信号探测器接收到的信息数据进行3D图像重建。它能够提供非常清晰的人体软组织解剖结构和病灶影像。\nCT图像：计算机断层扫描(CT)利用精确准直的X射线束对人体某部位一定厚度的断面进行照射扫描，并由与射线线束一起旋转的探测器接收透射穿过该断面的X射线，最后，计算机根据探测器接收到的X射线信号数据重建相应人体断面的3D图像。它具有亚毫米级的空间分辨率，能够提供清晰的人体骨性组织解剖结构和病灶影像，已广泛应用于多种临床疾病检查和辅助诊断。\nX射线图像：医学X射线图像是人体不同组织器官和病灶的电子密度度量影像。基于X射线的成像包括2D的计算机放射成像、数字化 X 射线摄影术、数字减影血管造影术和乳房X线摄影术，以及3D的螺旋计算机断层扫描术等，已广泛地应用于骨科、肺部、乳腺和心血管等临床疾病检测和辅助诊断，但2DX射线图像不能提供人体组织器官和病灶的三维立体信息。\n超声成像：利用超声束扫描人体，通过对反射信号的接收、处理，以获得体内器官的图像。近年来，超声成像技术不断发展，出现了 3D 彩超、超声全息摄影、体腔内超声成像、彩色多普勒成像及超声生物显微镜等新的超声成像技术。\nPET图像：正电子发射断层扫描(PET)利用F18等放射性元素标记的示踪剂 衰变时发射的正电子信息成像，因此，PET图像是相应示踪剂放射性活度的度量， 能提供肿瘤生物学特性(如葡萄糖代谢、乏氧、增殖等)信息，其标准摄入值大小可用于临床辅助判别肿瘤良/恶性。PET能提供比CT、MRI更直观、更精确的可视化生物学与放射生物学特性信息。\n病理图像：是指切取一定大小的病变组织，采用苏木精和曙红 (H ＆ E) 等染色方法将切片组织做成病理玻片，然后用显微镜成像技术对微观的细胞和腺体成像。通过对病理图像进行分析，可探讨病变产生的原因、发病机理、病变的发生发展过程，从而做出病理诊断。\n\n目前，临床医学图像分析深度学习研究对象主要可分为上述6类医学图像。\n2.2 主要的医学图像分析任务\n医学图像分类与识别\n临床医生需要借助医学图像来辅助诊断人体是否有病灶，并对病灶的轻重程度进行量化分级，因此自动识别图像中的病灶区域和正常组织器官是医学图像分析的基本任务。\n\n\n医学图像定位与检测\n人体组织器官解剖结构和病灶区域的定位是临床治疗计划和干预流程中非常重要的预处理步骤,定位的精度直接影响治疗的效果。图像目标定位任务不仅需要识别图像中的特定目标,而且需要确定其具体的物理位置。图像目标检测任务则需要把图像中所有目标识别出来，且确定它们的物理位置和类别。\n\n\n医学图像分割任务\n图像分割是识别图像中感兴趣的目标区域内部体素以及外部轮廓，它是临床手术图像导航和图像引导肿瘤放疗的关键任务。\n\n\n\n3、深度学习方法概述\n机器学习算法通常分为有监督学习算法和无监督学习算法。在有监督学习算法中不仅把训练的数据输入给计算机，同时还把数据的标签也一并作为输入传给计算机，计算机进行学习之后，再给它传进新的未知的数据，它也能计算出该数据属于某种结果的概率，最后给你一个最接近正确的结果。由于计算机在学习的过程中不仅有训练数据，而且还有结果（标签），因此训练的效果往往都不错。与有监督学习不同的是，无监督学习的输入数据只有原始数据，没有标签，因此计算机无法准确地知道哪些数据属于哪些类，只能凭借强大的计算能力分析数据的特征，从而得到一定的成果，通常得到的是一些集合，集合内的数据在某些特征上相同，或相似。\n\n3.1 神经网络\n神经网络是一门重要的机器学习技术，在机器学习和认知领域。是一种模仿生物神经网络的结构和功能的数学模型或计算模型，用于对函数进行估计或近似。神经网络由大量的人工神经元联结进行计算。大多数情况下人工神经网络能在外界信息的基础上改变内部结构，是一种自适应系统，通俗的讲就是具备学习功能。现代神经网络是一种非线性统计性数据建模工具。典型的神经网络具有以下三个部分：\n结构（Architecture）：结构指定了网络中的变量和它们的拓扑关系。例如，神经网络中的变量可以是神经元连接的权重（weights）和神经元的激励值（activities of the neurons）。\n激励函数（Activity Rule）：大部分神经网络模型具有一个短时间尺度的动力学规则，来定义神经元如何根据其他神经元的活动来改变自己的激励值。一般激励函数依赖于网络中的权重（即该网络的参数）。\n学习规则（Learning Rule）：学习规则指定了网络中的权重如何随着时间推进而调整。这一般被看做是一种长时间尺度的动力学规则。一般情况下，学习规则依赖于神经元的激励值。它也可能依赖于监督者提供的目标值和当前权重的值。\n通常一个简单的神经网络包含3部分：输入层、隐含层和输出层。一般输入层和输出层的节点是固定的，隐含层可以自由指定，图1是一个简单的神经网络结构示意图，图中的圆圈代表神经元，箭头代表数据的流向，每根连线上面都对应一个不同的权重，权重是网络通过学习自己得到的。\n\n\n![图1 神经网络结构图](https://pic3.zhimg.com/80/v2-8efd606ab74d660844736e0f57979496_hd.png)\n\n\n\n每一个神经元都包含了输入、输出以及计算模型3个部分，可以把神经元看成一个计算与存储单元，计算是神经元对其的输入进行计算功能。存储是神经元会暂存计算结果，并传递到下一层。如图2所示是一个典型的神经元模型，包含3个输入，1个输出以及1个计算功能。\n\n\n![图2 神经元结构图](https://pic2.zhimg.com/80/v2-874256715b8e6dc07e87f0adf815e081_hd.png)\n\n\n\n其中a表示输入，w表示权值，一个表示连接的有向箭头可以这样理解：在初端，传递的信号大小仍然是a，端中间有加权参数w，经过这个加权后的信号会变成aw，因此在连接的末端，信号的大小就变成了aw。在神经元处加权信号求和通过函数f就得到了输出Z,公式如下：\n\n![](https://pic2.zhimg.com/80/v2-3b9e86f223d5e2aa5c68243468383d17_hd.png)\n\n\n事实上，为了使神经元取得更好的效果，通常对每一个输入进行加权之后都会加上一个偏置b，此时Z的计算公式如下：\n\n\n![](https://pic3.zhimg.com/80/v2-f2464fdefe8124a5e6d37206c8812bdf_hd.png)\n\n\n其中函数f又称为激活函数，常见的激活函数有sigmoid函数、tanh函数和ReLU函数等。\n\n\n3.2 神经网络框架1.深度神经网络（DNN）####\nDNN是层数很深的全连接网络，层数决定了神经网络对数据的刻画能力：利用每层更少的神经元拟合更加复杂的函数。2006年Hinton利用预训练方法缓解了局部最优解问题，将隐含层推动到了7层，揭开了深度学习的浪潮。注意这里的“深度”并没有固定的定义，在语音识别领域，4层就认为是比较深的了；而在图像识别领域20层的模型屡见不鲜。2016年提出的highway network以及深度残差学习（deep residual learning）进一步杜绝了梯度消失达到了一百多层。2.卷积神经网络（CNN）\n卷积神经网络更改了神经网络的结构，不再是全连接的结构了，大量的减少了网络的参数；同时，通过参数共享进一步减少了网络参数。它考虑到了空间结构和局部特征，非常适用于图像处理领域，目前卷积神经网络在医学图像分析领域应用的最为广泛。例如对医学图像进行分割时，CNN可以简单的对图像中的每个像素进行分类，方法是在特定像素周围提取补丁。\n\n3.循环神经网络（RNN）\n鉴于深度学习在现实任务中的广泛适用性，它已经吸引了众多技术专家、投资者和非专业人员的关注。尽管深度学习最著名的成果是使用前馈卷积神经网络来解决计算机视觉问题，少数公众的注意力已经投入到使用递归神经网络来对时间关系进行建模。在普通的全连接网络或者CNN中，每层神经元的信号只能向上传播，样本的处理在各个时刻独立，因此又称为前馈神经网络。而在RNN中，神经元的输出可以在下一个时间戳直接作用到自身；即第i层的神经元在m时刻的输入包含i-1层在该时刻的输出以及其自身在m-1时刻的输出。在此基础上发展出了长短期记忆LSTM网络。4.深度置信网络DBN\n深度置信网络（deep belief networks，DBN）是一种包含多层隐单元的概率生成模型，可被视为多层简单学习模型组合而成的复合模型。可以作为深度神经网络的预训练部分，并为网络提供初始权重，再使用反向传播或者其他判定算法作为调优的手段。\n虽然我们可以对深度学习的各种方法进行分类，但是广义上来说NN或者DNN是包含了其它各种变种方法的。在实际使用中往往也是多种结构的融合。\n\n4、深度学习在医学图像中应的用4.1 医学图像分类\n医学图像分类可以分为图像筛查和目标或病灶分类。图像筛查是深度学习在医学图像分析领域中的最早应用之一, 是指将一个或多个检查图像作为输入, 通过训练好的模型对其预测, 输出一个表示是否患某种疾病或严重程度分级的诊断变量。图像筛查属于图像级分类，用来解决此任务的深度学习模型最初关注于 SAE、 DBN 及 DBM 网络和非监督预训练方法。研究主要集中在神经影像的分析上，如通过神经影像诊断是否患有老年痴呆症 (Alzheimer0s disease, AD) 或轻度认识功能障碍(Mild cognitive impairment, MCI)[90−92]。这些算法通常利用多模态图像作为输入，提取MRI、PET等模态中的互补特征信息。目前, CNN 正逐渐成为图像筛查分类中的标准技术,其应用非常广泛。如 Arevalo 等提出了乳腺癌诊断的特征学习框架, 采用CNN自动学习区分性特征，对乳房X线照片病变分类[3]。Kooi等比较了传统CAD中手动设计和自动CNN特征提取方法,两者都在约4.5万乳房X线图像的大数据集上训练,结果显示 CNN 在低灵敏度下优于传统CAD系统方法,且在高灵敏度下两者相当[4]。Spampinato等应用深度 CNN 自动评估骨骼骨龄[5]。另外,还有一些工作将CNN与RNN结合起来，如Gao等利用CNN 提取裂隙灯图像中的低层局部特征信息,结合RNN进一步提取高层特征，对核性白内障进行分级[6]。\n目标或病灶的分类可以辅助医生对疾病进行诊断，如对乳腺病灶进行良恶性分类。其处理过程通常首先通过预处理方法识别或标记出的特定区域,然后再对特定区域进行目标或病灶分类。精确的分类不仅需要病灶外表的局部信息,而且还需结合其位置的全局上下文信息。CNN在目标或病灶的分类中也应用的非常广泛。Kawahara等采用多处理流CNN对皮肤病灶分类,其中每个流程处理不同分辨率的图像[7]。Jiao等利用CNN提取不同层次的深度特征,提高了乳腺癌的分类准确率[8]。Tajbakhsh 等就 CT 图像中检测肺结节且区分良性和恶性肺结节的任务,比较了大规模训练人工神经网络(Massive-training artificial neuralnetworks, MTANNs) 与 CNN 这两种端到端训练的人工神经网络的性能,其实验结果表明,只有使用较少训练数据时,MTANN的性能明显高于 CNN[9]。\n\n4.2 医学图像定位与检测\n准确地在医学图像中定位特定生物标记或解剖结构在临床治疗中具有非常重要的意义，直接关系到治疗效果的好坏。医学图像定位常需要分析3D体素信息。为了使用经典深度学习算法进行3D数据处理,一些方法将3D空间看成2D正交面的组合,这样可将定位任务转换成为分类任务,利用通用深度学习框架进行处理。如Yang等结合三个正交方向CNN的信息识别股骨末端的标记,标记3D位置定义为三个2D图块的交点[10]。Vos等通过将3D CT体积解析成2D形式,识别目标3D矩形包围盒,进而定位到感兴趣的心脏、主动脉弧和下降主动脉等解剖区域[11]。\n而医学图像的感兴趣目标或病灶检测的关键是对每个像素进行分类。目前大多数基于深度学习目标检测系统采用CNN执行像素分类任务,之后采用某种形式的后处理方式得到目标。香港中文大学Chen等利用多个2D深层特征近似表达3D医学图像的特征,结合SVM分类器,实现敏感性加权图像(Susceptibility weighted imaging,SWI)自动检测脑微出血(Cerebral microbleeds, CMBs)[12]。还有少量工作采用其他深度学习方法来实现感兴趣目标或病灶检测, 如 Shin 等将SAE深度学习方法应用于MRI图像上检测腹部器官,先以非监督方式学习空间特征,然后基于兴趣点进行多器官检测[13]。\n\n4.3 医学图像分割\n医学图像分割的任务通常被定义为识别组成感兴趣对象的轮廓或内部的体素集，它是深度学习应用于医学图像分析领域的论文中最常见的主题。医学图像中器官及其子结构的分割可用于定量分析体积和形状有关的临床参数，如心脏的心室体积和收缩射出率。另一方面，在采用智能调强放疗技术对肿瘤进行治疗时, 危及器官勾画是制定放疗计划中非常重要的步骤之一，深度学习在此任务中应用非常广泛，主要应用于：组织病理学图像和显微镜图像分割；脑组织结构分割以及心脏心室分割等领域。\n通过计算机分割来自手术和活检组织标本的图像特征可以帮助预测疾病侵袭性的程度，从而进行疾病诊断和分级。这些预测器的关键组成部分就是从组织病理图像挖掘的图像特征。目前绝大对数组织病理学图像和显微镜图像分割的方法都是基于CNN的。许多学者利用图块训练网络取得了非常优秀的分割结果。Ciresan等率先将深度CNN应用于医学图像分割，他们以滑窗方式在电子显微镜图像中分割出生物神经膜[14]。Kumar等利用基于块的CNN对H&amp;E染色的病理学图像进行细胞核分割[15]。\n脑组织结构的体积形态与很多的脑部神经疾病都息息相关。如抑郁症、阿耳茨海默氏病、精神分裂症和躁郁症等。因此通过计算机技术对脑组织结构的解剖结构进行研究在医学研究、临床诊断和治疗方面都起着十分重要的意义。例如Zhang 等将 T1、T2和FA (Fractional anisotropy) 三种模态图像作为输入,采用深度CNN网络解决婴儿GM、WM和CSF分割这一挑战性任务，从而对婴儿脑发育优劣程度作评估[16]。\n从心脏MRI数据中分割出左心室是计算心室体积和收缩射出率等临床指标的重要步骤之一。Carneiro等采用基于DBN学习特征对左心室外观建模,利用监督学习模型在心脏超声波图像中自动分割出左心室[17]，而Avendi等采用SAE 学习深度特征初步推断左心室的形状，再结合形变模型提高左心室分割的准确性和鲁棒性[18]。\n从深度学习应用框架来看，目前大多数图像分割方法都是基于CNN的。许多学者利用基于图像块方式训练网络取得了很好的分割结果。\n\n5、总结\n综上所述,深度学习具有自动地从数据中学习深层次、更具鉴别性特征的能力，已应用于医学图像分析的多个研究领域，并取得了突破性进展。我们注意到,在大多数文献中，使用深度学习相关方法展示了其领先水平的性能，这已由医学图像分析的若干计算挑战赛结果证明；其次，云计算和多 GPU高性能并行计算技术的发展，使得深度学习从海量的医学图像大数据中学习深层特征成为可能； 最后，可公开访问的相关医学图像数据库的出现及多个医学图像分割挑战赛数据集，使得基于深度学习的分割算法能够得到有效验证。\n我们相信，通过深度学习算法的不断改进，借助高性能并行计算技术的发展和日益改善的医学图像质量与不断增长的医学图像标记样本集，基于深度学习的医学图像分析将大有所为。\n\n参考文献[1]Zhang Lei, Zhang Yi. Big data analysis by infinite deep neural networks. Journal of Computer Research and Development, 2016, 53(1): 68−79.\n[2]Litjens G, Kooi T, Bejnordi B E, Setio A A A, Ciompi F,Ghafoorian M, van der Laak J A W M, van Ginneken B,S´anchez C. A survey on deep learning in medical image analysis. Medical Image Analysis, 2017, 42(9): 60−88.\n[3]Arevalo J, Gonz´alez F A, Ramos-Poll´an R, Oliveira J L,Lopez M A G. Representation learning for mammographymass lesion classification with convolutional neural networks. Computer Methods and Programs in Biomedicine,2016, 127: 248−257.\n[4]Kooi T, Litjens G, van Ginneken B, Gubern-M´erida A,S´anchez C I, Mann R, den Heeten A, Karssemeijer N.Large scale deep learning for computeraided detection of mammographic lesions. Medical Image Analysis, 2017, 35:303−312.\n[5]Spampinato C, Palazzo S, Giordano D, Aldinucci M,Leonardi R. Deep learning for automated skeletal bone age assessment in X-ray images. Medical Image Analysis, 2016,36: 41−51.\n[6]Gao X T, Lin S, Wong T Y. Automatic feature learning to grade nuclear cataracts based on deep learning. IEEE Transactions on Biomedical Engineering, 2015, 62(11):2693-2701.\n[7]Kawahara J, Hamarneh G. Multi-resolution-tract CNN with hybrid pretrained and skin-lesion trained layers. International Workshop on Machine Learning in Medical Imaging. Athens, Greece: Springer, 2016. 164−171.\n[8]Jiao Z C, Gao X B, Wang Y, Li J. A deep feature based framework for breast masses classification. Neurocomputing, 2016, 197: 221−231.\n[9]Tajbakhsh N, Suzuki K. Comparing two classes of end-toend machine-learning models in lung nodule detection and classification: MTANNs vs. CNNs. Pattern Recognition,2016, 63: 476−486.\n[10]Yang D, Zhang S T, Yan Z N, Tan C W, Li K, Metaxas D.Automated anatomical landmark detection ondistal femur surface using convolutional neural network. In: Proceedings of the 12th International Symposium on Biomedical Imaging. New York, NY, USA: IEEE, 2015. 17−21.\n[11]de Vos B D, Wolterink J M, de Jong P A, Viergever MA, Iˇsgum I. 2D image classification for 3D anatomy localization: employing deep convolutional neural networks.In: Proceedings of the 9784, Medical Imaging 2016: ImageProcessing. San Diego, California, US: SPIE, 2016, 9784:Article No. 97841Y.\n[12]Chen H, Yu L Q, Dou Q, Shi L, Mok V C T, Heng PA. Automatic detection of cerebral microbleeds via deep learning based 3D feature representation. In: Proceedings of the 12th International Symposium on Biomedical Imaging (ISBI). New York, NY, USA: IEEE, 2015. 764−767.\n[13]Shin H C, Orton M R, Collins D J, Doran S J, Leach M O. Stacked autoencoders for unsupervised feature learning and multiple organ detection in a pilot study using 4D patient data. IEEE Transactions on Pattern Analysisand Machine Intelligence, 2013, 35(8): 1930−1943.\n[14]Cire¸san D C, Giusti A, Gambardella L M, Schmidhuber J. Deep neural networks segment neuronal membranes in electron microscopy images. In: Proceedings of the 25th International Conference on Neural Information Processing Systems. Lake Tahoe, Nevada: Curran Associates Inc., 2012. 2843−2851.\n[15]Kumar N, Verma R, Sharma S, Bhargava S, Vahadane A,Sethi A. A dataset and a technique for generalized nuclear segmentation for computational pathology. IEEE Transactions on Medical Imaging, 2017, 36(7): 1550−1560.\n[16]Zhang W L, Li R J, Deng H T, Wang L, Lin W L, Ji S W, Shen D G. Deep convolutional neural networks for multi-modality isointense infant brain image segmentation. NeuroImage, 2015, 108: 214−224.\n[17]Carneiro G, Nascimento J C, Freitas A. The segmentation of the left ventricle of the heart from ultrasound data using deep learning architectures andderivative-based search methods. IEEE Transactions on Image Processing, 2012,21(3): 968−982.\n[18]Avendi M R, Kheradvar A, Jafarkhani H. A combined deep-learning and deformable-model approach to fully automatic segmentation of the left ventricle in cardiac MRI.Medical Image Analysis, 2016, 30: 108−119.\n","categories":["机器学习"],"tags":[]},{"title":"卷积与反卷积（转置卷积）关系超详细说明及推导","url":"http://tanqingbo.cn/2019/04/10/卷积与反卷积（转置卷积）关系超详细说明及推导/","content":"\n                            \n                            \n                            \n本文是论文《A guide to convolution arithmetic for deep learning》的阅读笔记及思考，对于文章中浅尝则止的部分进行了深入的分析，如步长大于 1 的卷积与池化之间是否存在一种等价的关系，用矩阵的形式表示CNN的前向传播和反向传播。\n\n  以 CNN 为代表的卷积神经网络在图像的相关领域得到了较为长足的发展。在 CNN 中卷积实际分类两大类，一种是卷积，另一种是转置卷积（transposed convolutional ），或者称为分数步长卷积（ fractionally strided convolutional layers），亦或者是反卷积（deconvolution）。\n  虽然在一些文章中将反卷积与转置卷积认为是等价的，但是 [1] 中的作者表示他们反对使用反卷积来表示转置卷积，他们的依据是在数学中反卷积被定义为卷积的逆，这实际上与转置卷积是不相同的。所以在下面的内容，我都是用转置卷积这个名词。\n1.CNN中的卷积\n  因为本文主要介绍卷积与转置卷积之间的关系，所以对于卷积相关的知识并没有过多的介绍，如果想详细了解卷积的相关基础知识课参考我的博文《卷积神经网络入门详解》。在这里只是概括性的讲述一些知识点，方便叙述卷积与转置卷积之间的关系。\n1.1 卷积与相关滤波间的差别\n   卷积运算与相关滤波之间的差别主要在于，相关滤波直接在核所对应的区域进行相乘再相加，而卷积需要先将卷积核旋转 180 度在进行相乘和相加。所以我们平时所接触的卷积实际上不是卷积，而是一种相关滤波。但是当核是可学习的时候，卷积和相关滤波是可以互换的，所以在 CNN 中我们认为两者是等价的，具体原理及计算过程可以参考《图像的复原与重建（4）：图像处理中滤波（filtering）与卷积（convolution）的区别》\n1.2 卷积输出尺寸计算\n  卷积输出尺寸计算公式如下，假设输出数据体在空间上的尺寸 <span class=\"MathJax\" id=\"MathJax-Element-1-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W2&amp;#xD7;H2&amp;#xD7;D2      W_2 \\times H_2 \\times D_2\" role=\"presentation\">W2×H2×D2W2×H2×D2      W_2 \\times H_2 \\times D_2W2×H2×D2W_2 \\times H_2 \\times D_2W2​×H2​×D2​ 可以通过输入数据体尺寸<span class=\"MathJax\" id=\"MathJax-Element-2-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W1&amp;#xD7;H1&amp;#xD7;D1      W_1 \\times H_1 \\times D_1\" role=\"presentation\">W1×H1×D1W1×H1×D1      W_1 \\times H_1 \\times D_1W1×H1×D1W_1 \\times H_1 \\times D_1W1​×H1​×D1​，卷积层中神经元的感受野尺寸（F），步长（S），滤波器数量（K）和零填充的数量（P）计算输出出来。\n<span class=\"MathJax\" id=\"MathJax-Element-3-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W2=(W1&amp;#x2212;F+2P)/S+1H2=(H1&amp;#x2212;F+2P)/S+1D2=K      \\begin{matrix}W_2=(W_1-F+2P)/S+1 \\\\H_2=(H_1-F+2P)/S+1 \\\\D_2=K \\\\\\end{matrix}\" role=\"presentation\">W2=(W1−F+2P)/S+1H2=(H1−F+2P)/S+1D2=KW2=(W1−F+2P)/S+1H2=(H1−F+2P)/S+1D2=K      \\begin{matrix}W_2=(W_1-F+2P)/S+1 \\\\H_2=(H_1-F+2P)/S+1 \\\\D_2=K \\\\\\end{matrix}W2=(W1−F+2P)/S+1H2=(H1−F+2P)/S+1D2=K\n        \\begin{matrix}\n        W_2=(W_1-F+2P)/S+1 \\\\\n        H_2=(H_1-F+2P)/S+1 \\\\\n        D_2=K \\\\\n        \\end{matrix}\nW2​=(W1​−F+2P)/S+1H2​=(H1​−F+2P)/S+1D2​=K​\n  一般说来，当步长S=1时，零填充的值是P=(F-1)/2，这样就能保证输入和输出数据体有相同的空间尺寸。\n  但是这里有一点需要注意，对于某一个 <span class=\"MathJax\" id=\"MathJax-Element-4-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W1      W_1\" role=\"presentation\">W1W1      W_1W1W_1W1​，如果 <span class=\"MathJax\" id=\"MathJax-Element-5-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W1&amp;#x2212;F+2P      W_1-F+2P\" role=\"presentation\">W1−F+2PW1−F+2P      W_1-F+2PW1−F+2PW_1-F+2PW1​−F+2P 满足是 s 的整数倍，那么这时将输入增大到 <span class=\"MathJax\" id=\"MathJax-Element-6-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W3=W1+a,a&amp;#x2208;(0,1,&amp;#x2026;,s&amp;#x2212;1)      W_3=W_1+a,a\\in (0,1,&amp;#x2026;,s-1)\" role=\"presentation\">W3=W1+a,a∈(0,1,…,s−1)W3=W1+a,a∈(0,1,…,s−1)      W_3=W_1+a,a\\in (0,1,…,s-1)W3=W1+a,a∈(0,1,…,s−1)W_3=W_1+a,a\\in (0,1,…,s-1)W3​=W1​+a,a∈(0,1,…,s−1)，那么都会输出与原来一样大小的 feature map。这个虽然对卷积的影响并不是很大，但是会使得转置卷积的计算变得复杂。\n1.3 s&gt;1 的卷积\n  假设现在输入的特征图 (input feature map) 的大小是 <span class=\"MathJax\" id=\"MathJax-Element-7-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"5&amp;#xD7;5&amp;#xD7;1      5\\times5\\times1\" role=\"presentation\">5×5×15×5×1      5\\times5\\times15×5×15\\times5\\times15×5×1，使用一个大小为 <span class=\"MathJax\" id=\"MathJax-Element-8-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"3&amp;#xD7;3      3\\times3\" role=\"presentation\">3×33×3      3\\times33×33\\times33×3 的卷积核进行步长为 <span class=\"MathJax\" id=\"MathJax-Element-9-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"s=2      s=2\" role=\"presentation\">s=2s=2      s=2s=2s=2s=2 的卷积，将会得到如下图中左侧的结果\n\n其中蓝色的部分是输入，绿色的部分是输出，所以经过卷积后会产生一个 <span class=\"MathJax\" id=\"MathJax-Element-10-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"2&amp;#xD7;2&amp;#xD7;1      2\\times2\\times1\" role=\"presentation\">2×2×12×2×1      2\\times2\\times12×2×12\\times2\\times12×2×1 的 output feature map。步长为 1 的卷积很好理解，对于步长为2的卷积我们可以以内核的增量为 1 ，只有 <span class=\"MathJax\" id=\"MathJax-Element-11-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"s=2      s=2\" role=\"presentation\">s=2s=2      s=2s=2s=2s=2 的对应部分才会被保留。如上图的右侧所示，用一种比较好理解的方式就是，步长为 2 的卷积，可以理解为在步长为 1 的卷积输出的 feature 上（上图右半部分绿色整体）进行 <span class=\"MathJax\" id=\"MathJax-Element-12-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"s=2      s=2\" role=\"presentation\">s=2s=2      s=2s=2s=2s=2 的采样（未画叉的部分为采样部分），因此可以将它也认为是下采样的一种。\n1.4 s&gt;1 的卷积与 pooling 之间的关系\n  在上面那节我们了解到，步长大于1的卷积可以理解为在步长为1的卷积的 feature 上进行下采样的过程；然而我们又知道 pooling 也是一种下采样的方法，所以两者之间到底有什么关系呢？如下图所示\n\n假设现在输入的特征图 (input feature map) 的大小是 <span class=\"MathJax\" id=\"MathJax-Element-13-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"7&amp;#xD7;7&amp;#xD7;1      7\\times7\\times1\" role=\"presentation\">7×7×17×7×1      7\\times7\\times17×7×17\\times7\\times17×7×1，使用一个大小为 <span class=\"MathJax\" id=\"MathJax-Element-14-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"3&amp;#xD7;3      3\\times3\" role=\"presentation\">3×33×3      3\\times33×33\\times33×3 的卷积核进行步长为 <span class=\"MathJax\" id=\"MathJax-Element-15-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"s=2      s=2\" role=\"presentation\">s=2s=2      s=2s=2s=2s=2 的卷积。如上图所示，中间绿色的部分是对原始图像进行步长为 1 的卷积得到的结果。对于 s=2 的卷积，相当于在步长为1的卷积的输出结果上（绿色的部分）每隔一个点采样一次，我们可以想想绿色的那部分，被若干个红色的框不重复的覆盖，然后每次采样都是在左上角的位置进行采样。所以 s&gt;1 的卷积可以认为是一种在步长为 1 的卷积的 output feature map 上进行等间距采样的过程。\n  在上图中下半部分，我们也可以想想绿色的那部分，被若干个红色的框不重复的覆盖，但这次不是采样左上角的位置，而是这个红色矩形框中最大值的位置。所以都是下采样，但是 maxpooling 不会是那种等间距的采样。\n  另一个值得思考的问题是，两者虽然都是下采样，但是输出的 feature 的大小却不相同。这是因为对于奇数大小边长的 feature 没有办法进行步长为 2 下采样，所以在这里我们假设它输出的是一个 <span class=\"MathJax\" id=\"MathJax-Element-16-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"2&amp;#xD7;2      2\\times2\" role=\"presentation\">2×22×2      2\\times22×22\\times22×2 大小的 feature。一个很自然的想法，有没有可能让步长为 2 的卷积的输出结果和步长为1的卷积再经过 maxpooling 的输出结果，尺寸相等？很遗憾，在卷积核大小不变的情况下是不可能的。 具体原因如下\n  我们假设 input feature map 的大小为 <span class=\"MathJax\" id=\"MathJax-Element-17-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W&amp;#xD7;W      W\\times W\" role=\"presentation\">W×WW×W      W\\times WW×WW\\times WW×W，卷积核的大小为 <span class=\"MathJax\" id=\"MathJax-Element-18-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"K1&amp;#xD7;K1      K_1\\times K_1\" role=\"presentation\">K1×K1K1×K1      K_1\\times K_1K1×K1K_1\\times K_1K1​×K1​，padding 的大小为 <span class=\"MathJax\" id=\"MathJax-Element-19-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"P1      P_1\" role=\"presentation\">P1P1      P_1P1P_1P1​，则 <span class=\"MathJax\" id=\"MathJax-Element-20-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"S1=2      S_1=2\" role=\"presentation\">S1=2S1=2      S_1=2S1=2S_1=2S1​=2 的卷积输出尺寸如下所示\n<span class=\"MathJax\" id=\"MathJax-Element-21-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W1=(W&amp;#x2212;K1+2P1)/2+1      W_1=(W -K_1+2P_1)/2+1\" role=\"presentation\">W1=(W−K1+2P1)/2+1W1=(W−K1+2P1)/2+1      W_1=(W -K_1+2P_1)/2+1W1=(W−K1+2P1)/2+1W_1=(W -K_1+2P_1)/2+1W1​=(W−K1​+2P1​)/2+1\n对于卷积核大小为 <span class=\"MathJax\" id=\"MathJax-Element-22-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"K2&amp;#xD7;K2      K_2\\times K_2\" role=\"presentation\">K2×K2K2×K2      K_2\\times K_2K2×K2K_2\\times K_2K2​×K2​，padding 的大小为 <span class=\"MathJax\" id=\"MathJax-Element-23-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"P2      P_2\" role=\"presentation\">P2P2      P_2P2P_2P2​，则 <span class=\"MathJax\" id=\"MathJax-Element-24-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"S2=1      S_2=1\" role=\"presentation\">S2=1S2=1      S_2=1S2=1S_2=1S2​=1 的卷积，再经过 maxpooling 的结果为\n<span class=\"MathJax\" id=\"MathJax-Element-25-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W2=(W&amp;#x2212;K2+2P2+1)/2      W_2=(W -K_2+2P_2+1)/2\" role=\"presentation\">W2=(W−K2+2P2+1)/2W2=(W−K2+2P2+1)/2      W_2=(W -K_2+2P_2+1)/2W2=(W−K2+2P2+1)/2W_2=(W -K_2+2P_2+1)/2W2​=(W−K2​+2P2​+1)/2\n如果另 <span class=\"MathJax\" id=\"MathJax-Element-26-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W1=W2      W_1=W_2\" role=\"presentation\">W1=W2W1=W2      W_1=W_2W1=W2W_1=W_2W1​=W2​，则会得到如下的关系式\n<span class=\"MathJax\" id=\"MathJax-Element-27-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"K2&amp;#x2212;K1+1=2(P2&amp;#x2212;P1)      K_2-K_1+1=2(P_2-P_1)\" role=\"presentation\">K2−K1+1=2(P2−P1)K2−K1+1=2(P2−P1)      K_2-K_1+1=2(P_2-P_1)K2−K1+1=2(P2−P1)K_2-K_1+1=2(P_2-P_1)K2​−K1​+1=2(P2​−P1​)\n如果令 <span class=\"MathJax\" id=\"MathJax-Element-28-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"K2=K1      K_2=K_1\" role=\"presentation\">K2=K1K2=K1      K_2=K_1K2=K1K_2=K_1K2​=K1​，则<span class=\"MathJax\" id=\"MathJax-Element-29-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"2(P2&amp;#x2212;P1)=1      2(P_2-P_1)=1\" role=\"presentation\">2(P2−P1)=12(P2−P1)=1      2(P_2-P_1)=12(P2−P1)=12(P_2-P_1)=12(P2​−P1​)=1，这明显是不可能的；如果令 <span class=\"MathJax\" id=\"MathJax-Element-30-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"P2=P1      P_2=P_1\" role=\"presentation\">P2=P1P2=P1      P_2=P_1P2=P1P_2=P_1P2​=P1​，则<span class=\"MathJax\" id=\"MathJax-Element-31-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"K2=K1&amp;#x2212;1      K_2=K_1-1\" role=\"presentation\">K2=K1−1K2=K1−1      K_2=K_1-1K2=K1−1K_2=K_1-1K2​=K1​−1，这就意味着在两个卷积核中有一个卷积核是偶数，但是偶数的卷积核在实际应用中很少见到。只有当卷积核的大小和 pading 的大小均不相等时，才会得到的相等大小的输出。\n2. 转置卷积\n  转置卷积常常用于自编码器中的解码器部分，或者将 feature 映射到高维。\n2.1 将卷积转化为矩阵相乘\n  我们可以将图像的卷积过程转变成矩阵相乘的过程，比如说下面的这个卷积的过程\n\n上图中最左边的是一个卷积核，中间的是一个原始的卷积过程，蓝色部分 (44) 是输入 input feature map ，而绿色部分 (22) 是输出 output feature map 部分，其中深蓝色对应一个卷积核的大小 (3*3) ，上面的卷积的过程共经历 4 次卷积。\n  假如我们将原始图像按照上图中最右边所标注的顺序展开为列向量，并记为向量 <span class=\"MathJax\" id=\"MathJax-Element-32-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"X      X\" role=\"presentation\">XX      XXXX ，将得到的向量式的 feature map 作为输出并记为 <span class=\"MathJax\" id=\"MathJax-Element-33-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"Y      Y\" role=\"presentation\">YY      YYYY，则卷积的过程可以表示如下的这种形式\n<span class=\"MathJax\" id=\"MathJax-Element-34-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"Y=CX      Y=CX\" role=\"presentation\">Y=CXY=CX      Y=CXY=CXY=CXY=CX\n其中的 <span class=\"MathJax\" id=\"MathJax-Element-35-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"C      C\" role=\"presentation\">CC      CCCC 如下所示\n\n  以矩阵 <span class=\"MathJax\" id=\"MathJax-Element-36-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"C      C\" role=\"presentation\">CC      CCCC 的第一行为例，其实非零权重的位置与上图左右边标注的位置是一样的；同理第二行与第二次卷积运算是一样的……。经过上面的运算我们会得到一个 <span class=\"MathJax\" id=\"MathJax-Element-37-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"4&amp;#xD7;1      4\\times1\" role=\"presentation\">4×14×1      4\\times14×14\\times14×1 大小的向量，将这个向量按照展开图像的反向顺序，重构成为一个矩阵，即可得到卷积所对应的输出。\n  这样，卷积的过程就转变为了一个稀疏的权重矩阵与一个图像向量相乘的过程。\n2.2 卷积的前向传播和反向传播\n  因为通过上面 2.1 的知识卷积可以表示为如上的矩阵相乘的形式，关于卷积的求导很容易通过下面这种方式进行，这里主要引用了[2] 的求导过程，十分感谢\n\n  所以我们可以知道，通过卷积核可以定义两个矩阵，一个是对应前向传播的矩阵 <span class=\"MathJax\" id=\"MathJax-Element-38-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"C      C\" role=\"presentation\">CC      CCCC ，另一个是对应反向传播的矩阵  <span class=\"MathJax\" id=\"MathJax-Element-39-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"CT      C^T\" role=\"presentation\">CTCT      C^TCTC^TCT 。\n2.3 转置卷积\n  转置卷积是通过交换前向传播与反向传播得到的。还有一种说法是核定义了卷积，但是它定的是直接卷积还是转置卷积是由前向和反向的计算方式得到的。所以定义分别乘以 <span class=\"MathJax\" id=\"MathJax-Element-40-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"C      C\" role=\"presentation\">CC      CCCC 和 <span class=\"MathJax\" id=\"MathJax-Element-41-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"CT      C^T\" role=\"presentation\">CTCT      C^TCTC^TCT 来计算前向传播和反向传播的是直接卷积（也就是常说的卷积），使用 <span class=\"MathJax\" id=\"MathJax-Element-42-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"CT      C^T\" role=\"presentation\">CTCT      C^TCTC^TCT 和 <span class=\"MathJax\" id=\"MathJax-Element-43-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"C      C\" role=\"presentation\">CC      CCCC 来计算反向传播和前向传播的是转置卷积。\n  总可以使用直接卷积来模拟转置卷积，但是由于要在行列之间补零，所以执行的效率会低。通过后面的分析，我们也可以认为，转置卷积实际上就是卷积。\n2.4 转置卷积的计算\n  由 1.2 部分已经知道，卷积神经网络的 out feature map 可以通过下面的等式进行计算\n<span class=\"MathJax\" id=\"MathJax-Element-44-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W2=(W1&amp;#x2212;F+2P)/S+1      W_2=(W_1-F+2P)/S+1\" role=\"presentation\">W2=(W1−F+2P)/S+1W2=(W1−F+2P)/S+1      W_2=(W_1-F+2P)/S+1W2=(W1−F+2P)/S+1W_2=(W_1-F+2P)/S+1W2​=(W1​−F+2P)/S+1\n这里我们只考虑一条边，因为另外一条边是一样的道理。转置卷积的计算其实很简单，实际上就是求上面那个等式中的 <span class=\"MathJax\" id=\"MathJax-Element-45-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W1      W_1\" role=\"presentation\">W1W1      W_1W1W_1W1​，很容易得到如下的结果\n<span class=\"MathJax\" id=\"MathJax-Element-46-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W1=S(W2&amp;#x2212;1)&amp;#x2212;2P+F      W_1=S(W_2-1)-2P+F\" role=\"presentation\">W1=S(W2−1)−2P+FW1=S(W2−1)−2P+F      W_1=S(W_2-1)-2P+FW1=S(W2−1)−2P+FW_1=S(W_2-1)-2P+FW1​=S(W2​−1)−2P+F\n分析上面的表达式我们可以看到，<span class=\"MathJax\" id=\"MathJax-Element-47-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W2      W_2\" role=\"presentation\">W2W2      W_2W2W_2W2​ 的形式与 <span class=\"MathJax\" id=\"MathJax-Element-48-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W1      W_1\" role=\"presentation\">W1W1      W_1W1W_1W1​ 的形式是相同的，当 <span class=\"MathJax\" id=\"MathJax-Element-49-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"S      S\" role=\"presentation\">SS      SSSS 为原来的倒数且 <span class=\"MathJax\" id=\"MathJax-Element-50-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"F&amp;#x2212;2P=1      F-2P=1\" role=\"presentation\">F−2P=1F−2P=1      F-2P=1F−2P=1F-2P=1F−2P=1。这也对应上了上面的结论，总可以使用直接卷积来模拟转置卷积。\n  下面我们具体举几个例子来说明转置卷积的计算过程。\n\n如上图所示，第一行是卷积的过程，第二行是一个反卷积的过程。卷积和转置卷积是一对相关的概念，转置卷积嘛，你总得告诉我你针对谁是转置卷积啊。在上图中，卷积过程是在一个 <span class=\"MathJax\" id=\"MathJax-Element-51-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"4&amp;#xD7;4      4\\times4\" role=\"presentation\">4×44×4      4\\times44×44\\times44×4 大小，padding =0 的 feature map 上使用一个 <span class=\"MathJax\" id=\"MathJax-Element-52-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"3&amp;#xD7;3      3\\times3\" role=\"presentation\">3×33×3      3\\times33×33\\times33×3 大小的卷积核进行 <span class=\"MathJax\" id=\"MathJax-Element-53-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"s=1      s=1\" role=\"presentation\">s=1s=1      s=1s=1s=1s=1 的卷积计算，输出的 output feature map 大小为 <span class=\"MathJax\" id=\"MathJax-Element-54-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"2&amp;#xD7;2      2\\times2\" role=\"presentation\">2×22×2      2\\times22×22\\times22×2 。\n  这个时候，根据 <span class=\"MathJax\" id=\"MathJax-Element-55-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W1=S(W2&amp;#x2212;1)&amp;#x2212;2P+F=1&amp;#xD7;(2&amp;#x2212;1)&amp;#x2212;2&amp;#xD7;0+3=4      W_1=S(W_2-1)-2P+F=1\\times(2-1)-2\\times0+3=4\" role=\"presentation\">W1=S(W2−1)−2P+F=1×(2−1)−2×0+3=4W1=S(W2−1)−2P+F=1×(2−1)−2×0+3=4      W_1=S(W_2-1)-2P+F=1\\times(2-1)-2\\times0+3=4W1=S(W2−1)−2P+F=1×(2−1)−2×0+3=4W_1=S(W_2-1)-2P+F=1\\times(2-1)-2\\times0+3=4W1​=S(W2​−1)−2P+F=1×(2−1)−2×0+3=4 可知输出的 output feature map 的大小为 <span class=\"MathJax\" id=\"MathJax-Element-56-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"4&amp;#xD7;4      4\\times4\" role=\"presentation\">4×44×4      4\\times44×44\\times44×4。但是需要注意的是这里根据 <span class=\"MathJax\" id=\"MathJax-Element-57-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W1=S(W2&amp;#x2212;1)&amp;#x2212;2P+F      W_1=S(W_2-1)-2P+F\" role=\"presentation\">W1=S(W2−1)−2P+FW1=S(W2−1)−2P+F      W_1=S(W_2-1)-2P+FW1=S(W2−1)−2P+FW_1=S(W_2-1)-2P+FW1​=S(W2​−1)−2P+F 计算只是输出 feature map 的大小。如果将转置卷积以卷积的形式实现出来，那么它与上图中第二行是相对应的，卷积核与步长与原来相等，步长为原来的倒数，但是的 padding 值需要通过下面这种方式计算\n<span class=\"MathJax\" id=\"MathJax-Element-58-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"PT=F&amp;#x2212;P&amp;#x2212;1      P^T=F-P-1\" role=\"presentation\">PT=F−P−1PT=F−P−1      P^T=F-P-1PT=F−P−1P^T=F-P-1PT=F−P−1\n其中 <span class=\"MathJax\" id=\"MathJax-Element-59-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"PT      P^T\" role=\"presentation\">PTPT      P^TPTP^TPT 是转置卷积中 padding 的大小，<span class=\"MathJax\" id=\"MathJax-Element-60-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"F      F\" role=\"presentation\">FF      FFFF 是直接卷积中卷积核的大小，<span class=\"MathJax\" id=\"MathJax-Element-61-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"P      P\" role=\"presentation\">PP      PPPP 是直接卷积中 padding 的大小。\n  另外我们可以以一种较为直觉的角度去理解卷积和反卷积。在上图中的第一行，我们看到代表输入的蓝色矩阵中的 1 实际上只对计算代表输出的绿色矩阵中的 1 有贡献，对绿色矩阵中的其他值并没有贡献。因为直接卷积的输入是转置卷积的输出，转置卷积的输出是直接卷积的输入，所以第二行绿色矩阵中的 1 实际是与第一行蓝色矩阵中的 1 相对应的，而第一行蓝色矩阵中的 1 有只影响第一行绿色矩阵中的 1，所以在计算转置卷积的过程中，绿色矩阵中 1 的值只与蓝色矩阵中 1 的值有关，其他的位置都补零了；我们可以相同的思想思考剩下的结果。\n  我们看到一个有趣的现象，valid卷积 (0 padding ,s=1) 的转置卷积实际上是一个 fully 卷积 (F-1 padding , =1s)的过程。而且我们可以看到 same 卷积的转置卷积实际上还是一个 same 卷积，如下图所示\n\n而且 fully 卷积 (F-1 padding , s=1) 的转置卷积实际上是一个 valid 卷积 (0 padding ,s=1)  的过程，如下图所示\n\n2.5 步长小于 1 的转置卷积\n  由于转置卷积的步长是直接卷积的倒数，因此当直接卷积的步长 s&gt;1 的时候，那么转置卷积的步长就会是分数，这也是转置卷积又称为分数步长卷积的原因。在 2.4 的例子中，我们所处理的都是直接卷积步长为1 的例子，所以可以认为直接卷积与转置卷积的步长相等。当转置卷积的步长小于1的时候，我们可以通过下面的例子有一个直接的了解\n\n如上图是一个输入 feature map 为 <span class=\"MathJax\" id=\"MathJax-Element-62-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"5&amp;#xD7;5      5\\times5\" role=\"presentation\">5×55×5      5\\times55×55\\times55×5，卷积核大小为 <span class=\"MathJax\" id=\"MathJax-Element-63-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"3&amp;#xD7;3      3\\times3\" role=\"presentation\">3×33×3      3\\times33×33\\times33×3，步长 <span class=\"MathJax\" id=\"MathJax-Element-64-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"s=2      s=2\" role=\"presentation\">s=2s=2      s=2s=2s=2s=2 的直接卷积的转置卷积，此时的转置卷积的输入是在 <span class=\"MathJax\" id=\"MathJax-Element-65-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"2&amp;#xD7;2      2\\times2\" role=\"presentation\">2×22×2      2\\times22×22\\times22×2 的矩阵间进行插孔得到的。首先计算此时转置卷积输出的大小，我们发现与之前的计算方法是一样的\n<span class=\"MathJax\" id=\"MathJax-Element-66-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W1=S(W2&amp;#x2212;1)&amp;#x2212;2P+F=2&amp;#xD7;(2&amp;#x2212;1)&amp;#x2212;2&amp;#xD7;0+3=5      W_1=S(W_2-1)-2P+F=2\\times(2-1)-2\\times0+3=5\" role=\"presentation\">W1=S(W2−1)−2P+F=2×(2−1)−2×0+3=5W1=S(W2−1)−2P+F=2×(2−1)−2×0+3=5      W_1=S(W_2-1)-2P+F=2\\times(2-1)-2\\times0+3=5W1=S(W2−1)−2P+F=2×(2−1)−2×0+3=5W_1=S(W_2-1)-2P+F=2\\times(2-1)-2\\times0+3=5W1​=S(W2​−1)−2P+F=2×(2−1)−2×0+3=5\n果然通过之前推导出的公式计算出了与上图相同的结果，这时我们计算下转置卷积中 padding 的大小\n<span class=\"MathJax\" id=\"MathJax-Element-67-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"PT=F&amp;#x2212;P&amp;#x2212;1=3&amp;#x2212;0&amp;#x2212;1=2      P^T=F-P-1=3-0-1=2\" role=\"presentation\">PT=F−P−1=3−0−1=2PT=F−P−1=3−0−1=2      P^T=F-P-1=3-0-1=2PT=F−P−1=3−0−1=2P^T=F-P-1=3-0-1=2PT=F−P−1=3−0−1=2\n很明显 padding  的计算结果也是符合上面的公式要求的。之后就是最关键的部分了，如何体现出步长是分数步长。在原始的卷积中插入数字 0，这使得内核以比单位步幅的速度移动慢，具体的在输入的每两个元素之间插入 <span class=\"MathJax\" id=\"MathJax-Element-68-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"s&amp;#x2212;1      s-1\" role=\"presentation\">s−1s−1      s-1s−1s-1s−1 个 0。所以此时转置卷积的输入尺寸大小由原来的 <span class=\"MathJax\" id=\"MathJax-Element-69-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W2      W_2\" role=\"presentation\">W2W2      W_2W2W_2W2​ 变为 <span class=\"MathJax\" id=\"MathJax-Element-70-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W2+(W2&amp;#x2212;1)(s&amp;#x2212;1)      W_2 + (W_2-1)(s-1)\" role=\"presentation\">W2+(W2−1)(s−1)W2+(W2−1)(s−1)      W_2 + (W_2-1)(s-1)W2+(W2−1)(s−1)W_2 + (W_2-1)(s-1)W2​+(W2​−1)(s−1)。\n  记得在 1.2 节曾经提到过\"对于某一个 <span class=\"MathJax\" id=\"MathJax-Element-71-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W1      W_1\" role=\"presentation\">W1W1      W_1W1W_1W1​，如果 <span class=\"MathJax\" id=\"MathJax-Element-72-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W1&amp;#x2212;F+2P      W_1-F+2P\" role=\"presentation\">W1−F+2PW1−F+2P      W_1-F+2PW1−F+2PW_1-F+2PW1​−F+2P 满足是 s 的整数倍，那么这时将输入增大到 <span class=\"MathJax\" id=\"MathJax-Element-73-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W3=W1+a,a&amp;#x2208;(0,1,&amp;#x2026;,s&amp;#x2212;1)      W_3=W_1+a,a\\in (0,1,&amp;#x2026;,s-1)\" role=\"presentation\">W3=W1+a,a∈(0,1,…,s−1)W3=W1+a,a∈(0,1,…,s−1)      W_3=W_1+a,a\\in (0,1,…,s-1)W3=W1+a,a∈(0,1,…,s−1)W_3=W_1+a,a\\in (0,1,…,s-1)W3​=W1​+a,a∈(0,1,…,s−1)，那么都会输出与原来一样大小的 feature map。这个虽然对卷积的影响并不是很大，但是会使得转置卷积的计算变得复杂。\"现在我们就来考虑一下这样的问题会复杂在哪里？\n  虽然在直接卷积的过程中，将输入增大到 <span class=\"MathJax\" id=\"MathJax-Element-74-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W3=W1+a,a&amp;#x2208;(0,1,&amp;#x2026;,s&amp;#x2212;1)      W_3=W_1+a,a\\in (0,1,&amp;#x2026;,s-1)\" role=\"presentation\">W3=W1+a,a∈(0,1,…,s−1)W3=W1+a,a∈(0,1,…,s−1)      W_3=W_1+a,a\\in (0,1,…,s-1)W3=W1+a,a∈(0,1,…,s−1)W_3=W_1+a,a\\in (0,1,…,s-1)W3​=W1​+a,a∈(0,1,…,s−1)，那么都会输出与原来一样大小的 feature map。但是转置卷积的过程肯定是希望获得与直接卷积输入一样大的 feature map，那么应该如何做呢？\n  输出相同的大小，是因为在原图中有一部分的输入没有经过卷积计算，直接忽略掉了，所以我们就求出这部分的大小是多少，然后直接加到转置卷积的 output feature map 上就好了，具体计算如下\n<span class=\"MathJax\" id=\"MathJax-Element-75-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"a=(W1&amp;#x2212;K+2P)mod(s)      a = (W_1-K+2P)mod(s)%s\" role=\"presentation\">a=(W1−K+2P)mod(s)a=(W1−K+2P)mod(s)      a = (W_1-K+2P)mod(s)%sa=(W1−K+2P)mod(s)a = (W_1-K+2P)mod(s)%sa=(W1​−K+2P)mod(s)\n这个很好理解，就是在直接卷积中有多少是没有被卷积而遗留下来的。所以这个时候转置卷积的输出也变为了\n<span class=\"MathJax\" id=\"MathJax-Element-76-Frame\" tabindex=\"0\" style=\"position: relative;\" data-mathml=\"W1=S(W2&amp;#x2212;1)&amp;#x2212;2P+F+a      W_1=S(W_2-1)-2P+F+a\" role=\"presentation\">W1=S(W2−1)−2P+F+aW1=S(W2−1)−2P+F+a      W_1=S(W_2-1)-2P+F+aW1=S(W2−1)−2P+F+aW_1=S(W_2-1)-2P+F+aW1​=S(W2​−1)−2P+F+a\n下面的图像将直观地解释这一过程\n\n可以看到在最右侧和最下面补了一圈 0，就是上面计算转置卷积输出中的 a。\n参考\n[1] Dumoulin V, Visin F. A guide to convolution arithmetic for deep learning[J]. 2016.\n[2] ustc_lijia CSDN 博客 《反卷积，转置卷积》\n\n        &lt;/div&gt;\n","categories":["机器学习"],"tags":[]},{"title":"3D Unet 实验笔记","url":"http://tanqingbo.cn/2019/03/06/3D Unet实验笔记/","content":"\n\n  Evernote Export\n  \n  \n  \n  \n    body, td {\n      font-family: 微软雅黑;\n      font-size: 10pt;\n    }\n  \n\n\n\n\n\n3D Unet3D卷积代码解释def conv3d(name, in_layer, ksize, out_channels, padding='SAME', in_channel=0):name：每一层的名字in_layer：上一层的输出，本层的输入ksize：卷积核大小padding：卷积方式W = tf.get_variable(name + 'W', shape=[ksize[0], ksize[1], ksize[2], in_channel, out_channels],dtype=tf.float32,initializer=tf.truncated_normal_initializer(0.0, 0.01))shape：新变量或现有变量的形状或者维度。大小为3*3*3*in_channel*out_channelstf.truncated_normal_initializer：截取的正态分布，均值为0，方差为0.01out_channels：输出的维度，in_channel：输入的维度。上面代码是初始化权值wb = tf.get_variable(name + 'b', shape=[out_channels], dtype=tf.float32, initializer=tf.constant_initializer(0.1))初始化偏差btf.constant_initializer：常量初始化函数，0.1初始化3D卷积层主要经历了如下几个步骤：初始化过滤器W和偏差b过滤器w对输入数据卷积，之后再dropout（其实dropout就是随机将一些节点置0）dropout的输出加上偏差b之后再通过batch_normalization层，最后通过relu函数。l2_loss = tf.contrib.layers.l2_regularizer(0.003)(W) 返回一个执行L2正则化的函数，正则项系数为0.003.关于正则化的解释可以参考《统计学习》13页。tf.add_to_collection('l2_loss', l2_loss) 将正则化项放到'l2_loss'  列表里面。 tf.add_to_collection是把多个变量放入一个自己y用引号命名的集合里，也就是把多个变量统一放在一个列表中。tf.get_collection与之相反，是从列表中取出所有元素，构成一个新的列表。   3D反卷积代码解释with tf.name_scope(name + 'op'):output_shape = tf.stack([in_shape[0], in_shape[1] * 2, in_shape[2] * 2, in_shape[3] * 2, out_channels])deconv = tf.nn.conv3d_transpose(in_layer, W, output_shape, strides=[1, 2, 2, 2, 1], padding=padding)bias = tf.nn.relu(tf.nn.bias_add(deconv, b))in_shape[1] * 2, in_shape[2] * 2, in_shape[3] * 2 反卷积一次，size要变大两倍。out_channels：输出的通道数。每做一次反卷积，通道数减半。网络结构placeholder，占位符，在tensorflow中类似于函数参数，运行时必须传入值。conv1_1 = conv3d('conv1_1', X, [3, 3, 3],root_layers, padding=&quot;SAME&quot;) # batch_size*512*512*64conv1_2 = conv3d('conv1_2', conv1_1, [3, 3, 3], root_layers, padding='SAME') # 融合层1 512*512*64512*512是数据块的大小，有一维数据块大小没写出来。64是通道数。root_layers=64flat_labels = tf.reshape(tf.one_hot(Y, CLASSES), [-1, CLASSES])简单解释一下什么是one_hot，one-hot code也称独热码，通常用于分类任务中作为最后的FC层的输出。在机器学习中对于离散型的分类型的数据，需要对其进行数字化，比如说对性别这一属性，只有男女两种值，用数字化表达，指定男性为0，女性为1，那么一个特征向量(1,0,1),转换成独热码（one_hot）就变成([1,0],[0,1],[1,0])。loss_map = tf.nn.softmax_cross_entropy_with_logits(logits=flat_logits, labels=flat_labels)解释在下面的图片：损失函数w = tf.reduce_mean(Y)W[0] = wW[1] = 1-wclass_weights = Wweight_map = tf.multiply(flat_labels, class_weights)weight_maps = tf.reduce_sum(weight_map, axis=1)weighted_loss = tf.multiply(loss_map + loss1 + loss2, weight_maps)做图像分割的时候，loss是所有点交叉熵求和，这样所有的点权重都是一样的，这样很不合理，因为不可能图像的前景和背景一样大，如果一张图像就10个像素是前景，如果1：1权重训练的时候很容易被忽略所以增加点交叉熵的权重项可以让训练的时候都关注一下这些前景很小的点。classweight就是统计金标准中正负样本比例算的，比如 10个正样本 100个负样本，那就给正样本10倍权重flat_labels 是金标准转换成one_hot码之后的结果，如果是前景点值为[1,0],背景点值为[0,1].  而class_weights[0]是正样本比值，class_weights[1]是负样本比值，所以weight_map = tf.multiply(flat_labels, class_weights) 是由金标准计算出来的权重map。   tf.multiply(loss_map + loss1 + loss2, weight_maps) ，计算loss的时候加入了DSN机制，可以加速收敛。#计算模型准确度pre_img = tf.argmax(pre, -1) #返回最大的那个数值所在的下标。ans = tf.equal(pre_img, Y) #tf.equal(A, B)是对比这两个矩阵或者向量的相等的元素，如果是相等的那就返回True，反正返回False，返回的值的矩阵维度和A是一样的acc = tf.reduce_mean(tf.cast(ans, tf.float32)) #tf.cast(ans, tf.float32) 原来x的数据格式是bool， 那么将其转化成float以后，就能够将其转化成0和1的序列。   这个函数的计算公式为：rates = tf.train.exponential_decay(learning_rate, global_, decay_steps, decay_rate, staircase=True)decayed_learning_rate=learining_rate*decay_rate^(global_step/decay_steps)  其中，rates为每一轮优化时使用的学习率；           learning_rate为事先设定的初始学习率；           decay_rate为衰减系数；           decay_steps为衰减速度。而tf.train.exponential_decay函数则可以通过staircase(默认值为False,当为True时，（global_step/decay_steps）则被转化为整数) ,选择不同的衰减方式。数据读取改成了DSN的那个数据读取方式，Data_Generator.py\n \n\n","categories":["机器学习"],"tags":[]},{"title":"论文笔记：条件对抗网络用于图像到图像的转换（Image-to-Image）","url":"http://tanqingbo.cn/2018/12/12/条件对抗网络用于图像到图像的转换/","content":"1、摘要\n研究条件对抗网络作为图像到图像转换问题的通用解决方案。网络不仅学习从输入图像到输出图像的映射，还学习了用于训练该映射的损失函数。这使得可以用相同的方法解决传统上需要不同损失函数的问题。这项工作表明我们可以在不用手动设计损失函数的情况下获得合理的结果。\n\n2、介绍\n我们将图像到图像的转换定义为一个场景到另一个场景的转换，如图一的input与output所示，在传统上，每一个转换任务都需要单独训练一个机器模型，尽管这些模型的最终目的都是一样的：从像素预测像素。而本文的目标是为所有这些像素转换问题开发一个通用框架。\n\n\n\n卷积神经网络（CNNs）成为各种图像预测问题背后的共同主力。 但仍需要进行大量的手工操作来设计有效的损失函数。 使用CNN针对不同的问题，需要手动设计不同的损失函数，例如，输出清晰，逼真的图像…..这是一个开放的问题，通常需要各种不同的专业知识。\n如果我们只能指定一个高级目标，然后自动学习适合于这一目标的损失函数，那将是非常可取的。这也就是生成性对抗网络（GAN）所做的事情。GAN可以自动学习损失函数去区分输出图像时真实的还是伪造的，所以它可以应用于传统上需要非常多不同类型的损失函数的大量任务。\n本文的主要贡献是证明在有各种各样的问题上，conditional GANs produce reasonable results. 我们的第二个贡献是提供一个足以取得良好结果的简单框架，并分析几个重要架构选择的影响。\n图像条件模型已经从法线贴图[54]，未来帧预测[39]，产品照片生成[58]以及稀疏注释[30,47]的图像生成中解决了图像预测问题。\n我们的框架不同之处在于没有任何特定应用程序。这使我们的设置比大多数其他设置简单得多。在生成器(generator)和判别器(discriminator)几个架构的选择中，生成器基于U-net网络，判别器选择卷积PatchGAN分类器，仅在图像块的比例下惩罚结构。\n\n3、方法\nGANs是生成模型，可以学习从随机噪声向量z到输出图像y，G : z -&gt; y。相反，条件GANs学习从观察图像x和随机噪声向量z到y的映射，G : &#123;x; z&#125; -&gt; y.对生成器G进行训练以产生输出，使这个输出与对抗训练过的判别器产生的“真实”图像无法区分，D，经过训练，尽可能地检测生成器的“fakes”。 训练过程如图二所示：\n\n\n3.1 目标\nconditional GAN的目标方程可以表示为：\n\n![](https://i.imgur.com/zBmFCBh.png)\n\n\n其中G试图最小化这个目标，而D试图最大化目标形成对抗。\n\n![](https://i.imgur.com/mPz7TNd.png)\n\n为了测试discriminator的重要性，我们还比较了一个无条件变量，其中discriminator没有观察量x，公式如下：\n\n![](https://i.imgur.com/jxYsQee.png)\n\n\n以前的方法发现将GAN objective与更多传统的loss混合是有益的，例如L2距离。discriminator的工作保持不变，但是generator的任务不仅是fool the discriminator，而且还要接近L2意义上的ground truth output。 我们还探索了这个选项，使用L1距离而不是L2，因为L1鼓励减少模糊：\n\n\n\n![](https://i.imgur.com/3CX8c3Y.png)\n\n\n\n最终我们的目标函数变成：\n\n\n![](https://i.imgur.com/zDoQcN2.png)\n\n\n\n如果没有随机噪声向量z，网络仍然可以学习从x到y的映射，但会产生确定性输出，因此无法匹配delta函数以外的任何分布。 过去的条件GAN已经意识到了这一点并且除了x之外还提供了高斯噪声z作为generator的输入。\n对于我们的最终模型，我们仅以dropout的形式提供噪声，在训练和测试的时候应用我们generator的多个层，尽管存在dropout噪音，但我们观察到网络输出中只有轻微的随机性。 设计产生高随机输出的条件GAN，从而捕获它们建模的条件分布的完整熵，是当前工作留下的一个重要问题。\n\n3.2 网络结构\n网络结构在论文Unsupervised representationlearning with deep convolutional generative adversarialnetworks的网络结构的基础上微调。generator和discriminator采用的都是convolution-BatchNorm-ReLu的形式。包含了下面主要讨论的功能。3.2.1 Generator with skips\n要求输入与输出大致对齐，shape大小一样，基于这个考虑设计generator的架构，为了给generator提供一种信息瓶颈的方法，按照U-net的方式进行跳转连接。U-net原理可参考论文笔记：Unet用于医学图像分割的卷积网络\n\n3.2.2 马尔可夫鉴别器（PatchGAN）\n众所周知，L2损失在图像生成问题上产生模糊结果，见图4。 虽然这些损失不能鼓励高频脆度，但在许多情况下它们仍能准确地捕获低频。 对于这种情况的问题，我们不需要一个全新的框架来强制低频率的正确性。 L1已经做好了。\n这促使限制GAN鉴别器仅模拟高频结构，依赖于L1项来强制低频正确性（方程4）。为了模拟高频，将我们的注意力限制在局部图像块中的结构就足够了。因此，我们设计了一个鉴别器结构，我们将其称为PatchGAN，它只对补丁规模的结构进行惩罚。该鉴别器试图鉴别图像中的每个N*N贴片是真实的还是假的。我们在图像中对这个鉴别器进行了卷积处理，平均所有响应以提供D的最终输出。\nN可以比图像的完整尺寸小得多，并且仍然可以产生高质量的结果。这是有利的，因为较小的PatchGAN具有较少的参数，运行得更快，并且可以应用于任意大的图像。这种鉴别器有效地将图像建模为马尔可夫随机场.3.3 Optimization and inference\n为了优化网络，遵循论文Generative Adversarial Nets\n中的标准方法：我们固定D的参数然后在G上交替执行梯度下降。如原始GAN论文中提到的一样，我们不是最小化log(1-D(x;G(x; z))而是最大化logD(x;G(x; z))。我们使用minibatch SGD并应用Adam优化器，学习率设为0:0002,动量参数β1 = 0.5, β2 = 0.999.\n在预测时，我们以与训练阶段完全相同的方式运行generator。 这与通常的协议不同之处在于我们在测试时应用了dropout，并且我们在test batch上应用了batch normalization，而不是训练批次的汇总统计数据。 当批量大小设置为1时，这种batch normalization的方法被称为instance normalization。 并且已被证明在图像生成任务中有效[53]。 在我们的实验中，我们根据实验使用1到10之间的批量大小。\n\n4、Experiments\n实验部分主要讲用了哪些数据集，做了哪些对比试验，结果分析以及一些评估标准。就不一一详细写出来了。\n\n5、总结\n总的来说，我个人觉得这篇文章的只是给Generative Adversarial Nets多找了几个应用场景，为图像到图像的转换的转换提供了一个通用的框架，局部像素处理，平均所有块响应以提供D的最终输出以及平均所有响应以提供D的最终输出。是个很好的创新点。\n此外看这篇文章之前需要GAN网络的基础。可以先看一下论文Generative Adversarial Nets\n，或者先看一下李宏毅教授讲解GAN网络的视频。我记得是在他的机器学习课程的第18节，在微信公众号：轮子工厂  后台回复：机器学习，可获取李宏毅教授整套机器学习视频。\n\n","categories":["机器学习"],"tags":[]},{"title":"Hexo相关资源","url":"http://tanqingbo.cn/2018/12/10/Hexo相关资源/","content":"\n转自：http://madaimeng.com/article/hexo-resources/                                \n \n  Hexo相关资源\n        \n\n\n\n\n\nWordPress运维那点事http://www.ywnds.com/\nhttp://www.imekaku.com/\n欲思博客WordPress主题发布：Yusi1.0(扁平化+响应式)免费下载http://yusi123.com/\nHexo插件与技巧\n在 Hexo 中创建匹配主题的404页面http://www.tuicool.com/articles/MjiM7ba\n\n相册,fancybox,gallery\nhexo主题中添加相册功能http://www.cnblogs.com/xljzlw/p/5137622.html\n\nHexo+Github实现相册功能http://lawlite.me/2017/04/13/Hexo-Github实现相册功能/\n\nHexo+yilia主题实现文章目录和添加视频http://lawlite.me/2017/04/17/Hexo-yilia主题实现文章目录和添加视频/\n\n\n\n站内搜索\n利用swiftype为hexo添加站内搜索v2.0http://www.jerryfu.net/post/search-engine-for-hexo-with-swiftype-v2.html\n\njQuery-based Local Search Engine for Hexo介绍如何为 hexo 写一个本地的搜索引擎。http://hahack.com/codes/local-search-engine-for-hexo/\n\n让 Hexo 博客支持本地站内搜索给 Yelee 主题加上hexo-generator-searchhttp://moxfive.xyz/2016/05/31/hexo-local-search/\n\nHexo添加站内搜索功能初步完成介绍了Swiftype, hexo-generator-json-content和hexo-generator-searchhttp://imys.net/20160511/hexo-search.html\n\n\n\n插件\n详谈如何定制自己的博客园皮肤http://www.cnblogs.com/jingmoxukong/p/7826982.html小老鼠游戏控件，人体时钟控件，GitHub Corner fork GitHub角，动态多边形连线背景动画，标签云\n\nhexo标签云插件https://github.com/MikeCoder/hexo-tag-cloud\n\n豆瓣读书插件https://github.com/Yikun/hexo-generator-douban\n\n在hexo中添加Flag Counter边栏，显示国旗及其他国家访问者数量http://www.lichanglin.cn/在hexo中添加%60Flag%20Counter%60边栏%20-/\n\nHexo添加日历云http://lupeng.me/2016/05/11/Hexo添加日历云.html\n\nHexo添加hexo-wordcount字数统计http://blog.csdn.net/sunshine940326/article/details/69933696\n\n添加多级分类http://lupeng.me/2015/06/23/添加多级分类.html\n\nHexo主题中新添加resume布局http://lupeng.me/2015/06/10/添加resume布局.html\n\n如何为博客增加打赏功能(微信支付二维码打赏)http://qifuguang.me/2016/08/14/如何为博客增加打赏功能/\n\n页面上的GitHub展示插件不错【Spring】Bean的生命周期https://yemengying.com/2016/07/14/spring-bean-life-cycle/\n\n\n\n第三方评论系统\nValine - 一款快速、简洁且高效的无后端评论系统https://valine.js.org/\n\nGitment：使用 GitHub Issues 搭建评论系统https://imsun.net/posts/gitment-introduction/https://github.com/imsun/gitment\n\nComment.js：一个纯JS实现的静态站点评论系统http://www.hahack.com/codes/comment-js/\n\nHEXO评论从“多说”搬迁到Hashoverhttp://www.candura.us/posts/post-348/\n\n网易云跟帖关闭服务后转移到来必力http://www.cduyzh.com/livere/\n\n美化多说评论，添加浏览器、操作系统信息http://lovenight.github.io/2015/11/10/Hexo-3-1-1-静态博客搭建指南/\n\nHexo博客（Next主题）放弃多说，接入网易云跟贴http://blog.csdn.net/yingpaixiaochuan/article/details/68954103\n\n在Hexo中使用畅言评论系统http://www.lichanglin.cn/在Hexo中使用畅言评论系统/\n\n\n\n访问量统计\n不蒜子：两行代码 搞定访问量统计http://service.ibruce.info/\n\nleancloud阅读次数统计http://blog.csdn.net/sunshine940326/article/details/69933696\n\nhexo干货系列：（七）hexo安装统计插件文中介绍的cnzz统计能显示当前在线人数等http://tengj.top/2016/03/17/hexo7count/\n\n访问量统计工具 Hit Kounter v0.2http://jerryzou.com/posts/introduction-to-hit-kounter-lc/\n\n访问量统计 amazingcountershttp://blog.liuxianan.com/nginx-config.htmlhttps://www.cnblogs.com/alex-13/p/5174764.htmlhttp://www.cnblogs.com/facingwaller/\n\n\n\nGoStats 网站流量统计分析http://gostats.cn/https://www.cnblogs.com/yanghuahui/p/3365922.html\n\nClusterMaps 地图访问量统计http://www.cnblogs.com/flying_bat/\n\n\n\n部署,搜索引擎收录,SEO\n如何解决百度爬虫无法爬取搭建在Github上的个人博客的问题？https://www.zhihu.com/question/30898326\n\n提交搜索引擎收录\n\nhexo干货系列：（六）hexo提交搜索引擎（百度+谷歌）http://tengj.top/2016/03/14/hexo6seo/\n\nHexo折腾记——性能优化篇搜索引擎优化(SEO)，添加百度主动推送代码，让搜索引擎最快发现文章https://joway.wang/posts/Hexo/2016-03-19-Hexo-optimize.html\n\n\nCDN镜像缓存方法\n\n解决 Github Pages 禁止百度爬虫的方法与可行性分析(介绍了CDN)http://jerryzou.com/posts/feasibility-of-allowing-baiduSpider-for-Github-Pages/\n\n利用 CDN 解决百度爬虫被 Github Pages 拒绝的问题(利用又拍云CDN解决)http://www.dozer.cc/2015/06/github-pages-and-cdn.html\n\n让百度索引你的github的博客(利用又拍云CDN解决，又拍云cdn配置步骤，Nginx服务器方法Github webhook同步)http://michael-j.net/2016/06/23/让百度索引你的github的博客/\n\n解决GitHub Pages屏蔽百度爬虫的方法http://blog.beanmr.com/2016/02/24/solve-github-baidu-spider-blocking/\n\n\nVPS独立部署方法\n\n【牛刀杀鸡】Ubuntu搭建cloud9环境在线管理HEXO博客http://www.candura.us/posts/post-343/\n\n在vps上安装hexo(直接hexo server命令启动，不用部署在容器中)http://www.lichanglin.cn/在vps上安装hexo/\n\n让GitHub Pages博客支持百度搜索引擎收录(VPS部署，DNSPOD针对百度解析)http://tabalt.net/blog/make-blog-support-baidu-search-engine/\n\n部署 hexo 静态博客到自有服务器（部署到Nginx）http://www.dullong.com/deploy-hexo-blog-to-my-own-server.html\n\n\n国内国外双部署方法\n\n解决 Github Pages 禁止百度爬虫的方法2–从gitcafe迁移到coding.nethttp://bblove.me/2016/03/06/migrate-pages-from-gitcafe-to-coding/\n\nhexo干货系列：（四）将hexo博客同时托管到github和codinghttp://tengj.top/2016/03/06/hexo干货系列：（四）将hexo博客同时托管到github和coding/\n\n\nSEO\n\n针对hexo静态博客的简单SEO技巧(1)http://www.rudy-yuan.net/archives/hexo-seo-meta-nofollow/\n\n\nHexo基础\nhexo：快速、简洁且高效的博客框架https://hexo.io/zh-cn/\n\nHexo-GitHubhttps://github.com/hexojs\n\n如何利用GitHub Pages和Hexo快速搭建个人博客http://sunwhut.com/2015/10/30/buildBlog/\n\n如何搭建一个独立博客——简明Github Pages与Hexo教程(文后的参考链接不错)http://www.jianshu.com/p/05289a4bc8b2\n\nhexo系列教程：（四）hexo博客的优化技巧http://zipperary.com/2013/05/30/hexo-guide-4/\n\n\n\nHexo主题\nHexo主题wikihttps://github.com/hexojs/hexo/wiki/themes\n\nYelee，markdown表格样式不错，版权信息https://github.com/MOxFIVE/hexo-theme-yelee\n\nhexo-theme-freemindhttps://github.com/wzpan/hexo-theme-freemindhttp://hahack.com/codes/hexo-theme-freemind/\n\nfree2mindhttps://github.com/rudy-yuan/free2mindhttp://www.rudy-yuan.net/\n\nnext，博文有目录，多说，标签无文章数量，https://github.com/iissnan/hexo-theme-next\n\nlightumhttps://github.com/zippera/lightum\n\npacman，博文有目录，有分类、标签，且分类标签有文章数量，多说，搜索不好用，暂不支持hexo3https://github.com/A-limon/pacman\n\nlandscape-plus，hexo3官方网站主题的改版https://github.com/xiangming/landscape-plus使用landscape-plus的网站列表https://github.com/xiangming/landscape-plus/wiki\n\njacmanhttps://github.com/wuchong/jacman\n\nmaupassant-hexohttps://github.com/tufu9441/maupassant-hexo\n\nhexo-theme-tranquilpeak，左侧边栏列出整个网站标题https://github.com/LouisBarranqueiro/hexo-theme-tranquilpeak\n\n\n\n\n                ","categories":["技术博客"],"tags":[]},{"title":"DSN分割肝脏实验总结","url":"http://tanqingbo.cn/2018/11/29/DSN分割肝脏实验总结/","content":"前言\n本实验采用3D深度监督网络（DSN）对肝脏进行分割，因为使用3D的肝脏数据进行分割可以很好的体积上下文信息。\nDSN的大致学习过程是：基于CNN，为了应对梯度消失和模型辨别能力问题，在隐藏层加入一些额外的监督来抵消梯度消失的不利影响。具体而言，使用一些额外的反卷积层来扩展一些低级和中级特征向量。然后使用softmax层来获得用于计算分类误差的dense预测(监督层的预测)。**利用从这些分支预测和最后输出层得到的梯度，可以有效地减轻梯度消失的影响。\ndeeply- supervision 的优点包括：\n能够减轻梯度爆炸或梯度消失，收敛速度更快（辅助 loss 将误差直接注入中间层，有点类似于 resnet 的机制，不同的是 loss 来源不同 ）;\n辅助 loss 起到 regularization 的作用.\n\n\n\n\n详情可参见这篇文章《论文解读：Deeply-Supervised Nets》和《论文笔记：3D Deeply Supervised Network for Automatic Liver Segmentation from CT Volumes》\n\n数据问题one_hot处理\n在开始训练DSN网络之前要对数据进行一些预处理，首先将标签数据转成0 1值，即前景的像素值为1，背景的像素值为0。因为再算loss的时候，要将金标准标签转成one_hot值，想把标签处理成0 1方便做**one_hot处理。**\n简单解释一下什么是one_hot，one-hot code也称独热码，通常用于分类任务中作为最后的FC层的输出。在机器学习中对于离散型的分类型的数据，需要对其进行数字化，比如说对性别这一属性，只有男女两种值，用数字化表达，指定男性为0，女性为1，那么一个特征向量(1,0,1),转换成独热码（one_hot）就变成([1,0],[0,1],[1,0])。\n\n内存不足问题\n因为3D肝脏数据，数据量庞大，如果一次性把整组的数据都加载进去可能导致计算内存不足的问题，所以在训练之前需要减少训练数据的size，本实验中将所有的数据都转换成了[16,512,512]大小。\n还有也是因为内存不足的问题，再加载数据的时候用到了yield迭代器，需要注意的是，它yield是一个类似 return 的关键字，迭代一次遇到yield时就返回yield后面的值。重点是：下一次迭代时，从上一次迭代遇到的yield后面的代码开始执行。详细理解yield可以参考文章《彻底理解python中的yeild》\n\n代码解读\n网络的架构大致如下：\n      layers = [[&#39;block0&#39;, [[&#39;conv&#39;, [9, 9, 7, 1, 8], [1, 1, 1, 1, 1], &#39;SAME&#39;, 0.7]]],\n                [&#39;block1&#39;, [[&#39;conv&#39;, [9, 9, 7, 8, 16], [1, 1, 1, 1, 1], &#39;SAME&#39;, 0.7],\n                            [&#39;maxpool&#39;, [1, 2, 2, 2, 1], [1, 2, 2, 2, 1], &#39;SAME&#39;]]],\n                [&#39;block2&#39;, [[&#39;conv&#39;, [7, 7, 5, 16, 32], [1, 1, 1, 1, 1], &#39;SAME&#39;, 0.7]]],\n                [&#39;block3&#39;, [[&#39;conv&#39;, [7, 7, 5, 32, 32], [1, 1, 1, 1, 1], &#39;SAME&#39;, 0.7],\n                            [&#39;maxpool&#39;, [1, 2, 2, 2, 1], [1, 2, 2, 2, 1], &#39;SAME&#39;]], ],\n                [&#39;block4&#39;, [[&#39;conv&#39;, [5, 5, 3, 32, 32], [1, 1, 1, 1, 1], &#39;SAME&#39;, 0.7]]],\n                [&#39;block5&#39;, [[&#39;conv&#39;, [1, 1, 1, 32, 32], [1, 1, 1, 1, 1], &#39;SAME&#39;, 0.7]]],\n                [&#39;block6&#39;, [[&#39;deconv&#39;, [3, 3, 3, 32, 32], [1, 2, 2, 2, 1], &#39;SAME&#39;]]],\n                [&#39;block7&#39;, [[&#39;deconv&#39;, [3, 3, 3, 2, 32], [1, 2, 2, 2, 1], &#39;SAME&#39;]]],\n                ]\n\n在[&#39;block0&#39;, [[&#39;conv&#39;, [9, 9, 7, 1, 8], [1, 1, 1, 1, 1], &#39;SAME&#39;, 0.7]]]中，[9, 9, 7, 1, 8]表示卷积核的大小为[9,9,7],当前深度为1，卷积核的深度为7.SAME表示在卷积之前加了padding是特征图在卷积前后特征不变。0.7是dropout系数。\n\n\n整理并给出代码\n代码地址：https://github.com/tqb4342/DSN\n\n","categories":["机器学习"],"tags":[]},{"title":"彻底理解python中的yeild","url":"http://tanqingbo.cn/2018/11/27/彻底理解python中的yeild/","content":"\n在用DSN分割3D肝脏的时候，如果把数据全部加载到内存的话，内存一下就爆了， 因此用到了yield关键字，它的功能类似于return，但是不同之处在于它返回的是生成器。\n生成器是通过一个或多个yield表达式构成的函数，每一个生成器都是一个迭代器（但是迭代器不一定是生成器）。\n如果一个函数包含yield关键字，这个函数就会变为一个生成器。\n生成器并不会一次返回所有结果，而是每次遇到yield关键字后返回相应结果，并保留函数当前的运行状态，等待下一次的调用。\n由于生成器也是一个迭代器，那么它就应该支持next方法来获取下一个值。\n\n\n通常的for…in…循环中，in后面是一个数组，这个数组就是一个可迭代对象，类似的还有链表，字符串，文件。它可以是mylist=[1, 2, 3]，也可以是mylist = [x*x for x in range(3)]。 它的缺陷是所有数据都在内存中，如果有海量数据的话将会非常耗内存。\n生成器是可以迭代的，但只可以读取它一次。因为用的时候才生成。比如mygenerator = (x*x for x in range(3))，注意这里用到了()，它就不是数组，而上面的例子是[]。\n我理解的生成器(generator)能够迭代的关键是它有一个next()方法，工作原理就是通过重复调用next()方法，直到捕获一个异常。可以用上面的mygenerator测试。\n带有 yield 的函数不再是一个普通函数，而是一个生成器generator，可用于迭代，工作原理同上。\nyield 是一个类似 return 的关键字，迭代一次遇到yield时就返回yield后面的值。重点是：下一次迭代时，从上一次迭代遇到的yield后面的代码开始执行。\n简要理解：yield就是 return 返回一个值，并且记住这个返回的位置，下次迭代就从这个位置后开始。\n带有yield的函数不仅仅只用于for循环中，而且可用于某个函数的参数，只要这个函数的参数允许迭代参数。比如array.extend函数，它的原型是array.extend(iterable)。\nsend(msg)与next()的区别在于send可以传递参数给yield表达式，这时传递的参数会作为yield表达式的值，而yield的参数是返回给调用者的值。——换句话说，就是send可以强行修改上一个yield表达式值。比如函数中有一个yield赋值，a = yield 5，第一次迭代到这里会返回5，a还没有赋值。第二次迭代时，使用.send(10)，那么，就是强行修改yield 5表达式的值为10，本来是5的，那么a=10\nsend(msg)与next()都有返回值，它们的返回值是当前迭代遇到yield时，yield后面表达式的值，其实就是当前迭代中yield后面的参数。\n第一次调用时必须先next()或send(None)，否则会报错，send后之所以为None是因为这时候没有上一个yield(根据第8条)。可以认为，next()等同于send(None)。\n\n代码示例        #encoding:UTF-8  \n        def yield_test(n):  \n            for i in range(n):  \n                yield call(i)  \n                print(&quot;i=&quot;,i)  \n            #做一些其它的事情      \n            print(&quot;do something.&quot;)      \n            print(&quot;end.&quot;)  \n\n        def call(i):  \n            return i*2  \n\n        #使用for循环  \n        for i in yield_test(5):  \n            print(i,&quot;,&quot;)\n\n结果是：\n      &gt;&gt;&gt;   \n      0 ,  \n      i= 0  \n      2 ,  \n      i= 1  \n      4 ,  \n      i= 2  \n      6 ,  \n      i= 3  \n      8 ,  \n      i= 4  \n      do something.  \n      end.  \n      &gt;&gt;&gt;\n\n\n\n理解的关键在于：下次迭代时，代码从yield的下一跳语句开始执行。 for循环就用到了next(),所以到yield能再执行。\n\n代码示例\n![](https://i.imgur.com/yH4zqH5.png)\n\n\n\n\n需要注意的是，在python3.X里面类的迭代器方法next()改名为__next__()，所以在使用yeild的时候，如果是python2.x，用next(),如果是python3.x，用__next__()函数。\n\n","categories":["机器学习"],"tags":[]},{"title":"分享8个找电子书的神器","url":"http://tanqingbo.cn/2018/11/22/分享6个找电子书的神器/","content":"今天给大家分享8个不错的电子书资源、论文资源免费下载网站，每一个都不错，值得推荐收藏。\n1、epubw传送门：https://epubw.com/\n这是一个免费电子书资源分享网站，提供优质的 kindle, epub, mobi, azw3, pdf等格式的电子书资源，几乎你想要找的电子书这里都可以免费找到，第一次见到这个网站就把它加到我的浏览器书签里去了。\n\n2、读书皮传送门：http://slfswh.xiangzhan.com/\n这也是一个电子书资源免费下载的网站，只提供pdf 格式电子书载。涵盖社会科学，经济管理学，计算机科学，工作效率工具类，脸型男女、成功励志等等！\n\n3、万千合集站传送门： http://www.hejizhan.com/bbs/ \n最专业的外链学术资源搜集整理网站。 包含各个学科的专业教材，文献笔记都可以下载，再也不用花钱买厚厚的专业书了。\n\n4、书格传送门： https://new.shuge.org/ \n书格是一个自由开放的在线古籍图书馆资源网站。\n致力于开放式分享、介绍、推荐有价值的古籍善本，并鼓励将文化艺术作品数字化归档，分享的内容限定为公共版权领域的书籍。\n\n5、田间小站传送门：https://www.tianfateng.cn/\n这是一个高质量英语免费学习和资源分享的宝库网站！里面有各种英语文摘，英语演讲，英语杂谈等等学习资料，可以帮助你提高英语口语、词汇、写作、阅读。\n\n6、ePUBee电子书库传送门： http://cn.epubee.com/books/ \n号称全网最大的电子书库，可以在线管理电子书，资源特别全，但是好像不能下载，只能在线阅读，不过都是免费的。\n同时还可以在线转换电子书格式。\n\n7、喵咪论文传送门：https://lunwen.im/\n这是一个免费的，又好用的论文搜索资源分享网站。\n作者利用海外服务器中转／数据爬虫／智能化线路选择等技术，聚合了现有95%以上的开放论文数据源。才有这个相对搜索快速，又稳定的搜索论文资源网站。\n\n8、 爱如生论坛传送门： http://forum.er07.com/ \n 国学、古籍、数典电子资料免费分享。 \n\n","categories":["技术博客"],"tags":[]},{"title":"keras+TensorBoard实现训练可视化","url":"http://tanqingbo.cn/2018/11/20/keras+TensorBoard实现训练可视化/","content":"keras+TensorBoard实现训练可视化        # 引入Tensorboard\n        from keras.callbacks import TensorBoard\n\n        tbCallBack = TensorBoard(log_dir=&#39;./logs&#39;,  # log 目录\n                         histogram_freq=0,  # 按照何等频率（epoch）来计算直方图，0为不计算\n        #                  batch_size=32,     # 用多大量的数据计算直方图\n                         write_graph=True,  # 是否存储网络结构图\n                         write_grads=True, # 是否可视化梯度直方图\n                         write_images=True,# 是否可视化参数\n                         embeddings_freq=0, \n                         embeddings_layer_names=None, \n                         embeddings_metadata=None)\n\n        model.fit(...inputs and parameters..., callbacks=[tbCallBack])\n\n通过引入tensorboard加入了回调函数的功能。 它将在训练期间运行并输出可用于张量板的文件。如果您想要在训练的过程中可视化，请在terminal终端输入\n  tensorboard --logdir=./logs \n\n然后在浏览器中访问http://localhost:6006\n\n\n\n![](https://upload-images.jianshu.io/upload_images/1083106-2d58623df8b995fa.png)\n\n\n\n完整代码如下：\n由keras/examples/mnist_mlp.py示例代码修改:\n\n        from __future__ import print_function\n\n        import keras\n        from keras.datasets import mnist\n        from keras.models import Sequential\n        from keras.layers import Dense, Dropout\n        from keras.optimizers import RMSprop\n\n        # 引入Tensorboard\n        from keras.callbacks import TensorBoard\n\n        batch_size = 128\n        num_classes = 10\n        epochs = 20\n\n        # the data, split between train and test sets\n        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n        x_train = x_train.reshape(60000, 784)\n        x_test = x_test.reshape(10000, 784)\n        x_train = x_train.astype(&#39;float32&#39;)\n        x_test = x_test.astype(&#39;float32&#39;)\n        x_train /= 255\n        x_test /= 255\n        print(x_train.shape[0], &#39;train samples&#39;)\n        print(x_test.shape[0], &#39;test samples&#39;)\n\n        # convert class vectors to binary class matrices\n        y_train = keras.utils.to_categorical(y_train, num_classes)\n        y_test = keras.utils.to_categorical(y_test, num_classes)\n\n        model = Sequential()\n        model.add(Dense(512, activation=&#39;relu&#39;, input_shape=(784,)))\n        model.add(Dropout(0.2))\n        model.add(Dense(512, activation=&#39;relu&#39;))\n        model.add(Dropout(0.2))\n        model.add(Dense(num_classes, activation=&#39;softmax&#39;))\n\n        model.summary()\n\n        model.compile(loss=&#39;categorical_crossentropy&#39;,\n                      optimizer=RMSprop(),\n                      metrics=[&#39;accuracy&#39;])\n\n        tbCallBack = TensorBoard(log_dir=&#39;./logs&#39;,  # log 目录\n                         histogram_freq=0,  # 按照何等频率（epoch）来计算直方图，0为不计算\n        #                  batch_size=32,     # 用多大量的数据计算直方图\n                         write_graph=True,  # 是否存储网络结构图\n                         write_grads=True, # 是否可视化梯度直方图\n                         write_images=True,# 是否可视化参数\n                         embeddings_freq=0, \n                         embeddings_layer_names=None, \n                         embeddings_metadata=None)\n\n        history = model.fit(x_train, y_train,\n                            batch_size=batch_size,\n                            epochs=epochs,\n                            verbose=1,\n                            validation_data=(x_test, y_test),\n                            callbacks=[tbCallBack])\n        score = model.evaluate(x_test, y_test, verbose=0)\n        print(&#39;Test loss:&#39;, score[0])\n        print(&#39;Test accuracy:&#39;, score[1])\n","categories":["机器学习"],"tags":[]},{"title":"你确定真的要转学计算机吗？","url":"http://tanqingbo.cn/2018/11/16/你确定真的要转学计算机吗？/","content":"\n最近有一种感觉，好像全世界所有的人在转学计算机，大家熟悉的呆博，本科学电子的，来哈工大之后转了计算机的研究生，他的那些没读计算机研究生的同学，现在也在刷Java后端的书，准备找一个后端工程师的岗位。更夸张的是前两天在朋友圈看一个信息：哈工程船舶专业的博士报培训班，要转行从事软件开发工作，要知道哈工程船舶专业在上轮评估中全国排第一。\n确实，现在的计算机专业真的很吃香，尤其是人工智能浪潮刚来，做算法的工资更是高到可怕，很多本科生都拿着20w+的年薪，研究生30~40w+的年薪也很正常，呆博还拿到过45w+的offer呢！这些数据确实是事实，但是还有另外一个事实：80%的高新岗位被20%的人拿走了！什么意思呢？就是计算机的应届生拿40W+的年薪确实是事实，但是这些高薪岗位都被那几所计算机名校的学生拿走了，跟你半毛钱关系都没有。华为应该是大部分同学可望而不可及的目标，非985的同学连简历筛选都过不了，可是我身边找工作的同学和我说，只要是你是工科名校出身的男生，管你学成啥样都能去。可能你觉得不合理，但是从企业的角度来说却很合理：与其花大量的成本在一堆不优秀的人里面挑优秀的人，不如用很少的成本把大部分都比较优秀的这一堆人招走。错过你，人家一点都不遗憾！\n抛去这些最高与最低薪资不谈，我也去了解了一下大部分应届程序员的工资，大概在4-8k/月左右，所以对于非计算机专业毕业想转计算机的同学来说，做为没有接受过系统训练的非科班生，可以自己估算一下自己值这个区间的哪个数字，是否符合你的预期，为了这个数字放弃自己的头发是否真的值得。\n对于想要跨考计算机研究生的同学，我也有几点建议给你：\n如果你的实力不是超级强，那么学历真的特别特别重要。最好能考到985，如果时间成本允许，可以接受复读。我有一朋友在一本读自然语言处理的研究生，最后自学转成了java后台，因为身边没有人会自然语言处理，老师也不会。如果你不想有这种经历的话，那就考到一所好的学校去吧！\n努力真的很重要，不断学习新技术的能力更重要。IT行业是技术更新最快的行业，我本科时候用的spring现在已经被人说成老古董了，现在最流行的深度学习网络，其实也就是这几年提出来的，你看技术更新如此之快，如果你不能保持持续学习的能力，第一个淘汰的肯定是你。\n有自己的主见很重要。别随大流，不要看着别人都转计算机了，那我也转吧！还是前面说的那句话：80%的高新岗位被20%的人拿走了，要是成为不了这20%，对编程也不感兴趣的话，那就别难为自己了，头发很重要，放过自己吧！IT不值得。\n\n\n\n","categories":["漂来漂去"],"tags":[]},{"title":"论文笔记：3D Deeply Supervised Network for Automatic Liver Segmentation from CT Volumes","url":"http://tanqingbo.cn/2018/11/13/3D Deeply Supervised Network for Automatic Liver Segmentation from CT Volumes/","content":"前言\n本文提出3D DSN对3d的肝脏数据进行分割，采用完全卷积架构，有效的执行端到端学习和推理，此外条件随机场（CRF）来获得更加精细的分割。\n通常统计变形模型最流行和成功的分割方法，该方法利用形状先验信息、强度分布以及边界区域信息来描述肝脏的特征和划定界限。但是这些方法过度的依赖人工，或者没有利用3D空间信息，因此如何利用体积上下文信息，提取强大的高级特征来自动分割肝脏一直都为解决。\n为了充分利用空间信息，提出了3D CNN，尽管3D CNN没有端到端训练，而且数据有限且存在风险，但依然大量的激励研究者去深入研究3D CNN在医学图像领域的应用。\n本文采用3D DSN分割，并用条件随机场（CRF）执行轮廓修正，得到最终的结构。\n\n方法\n3D DSN的架构如图1所示。 主流网络由11层组成，即6个卷积层，2个max pooling层，2个反卷积层和1个softmax层。 通过第三层和第六层涉及深层监督机制，如灰色虚线框所示。\n\n\n\n为了对体积数据中的空间信息进行充分编码，我们DSN中的所有层都以3D格式构建，如图1所示。3D卷积层和3Dmax pooling层交替堆叠来连续提取中间特征。\n每个卷积层中使用的内核的数量和大小如图1所示。我们设计相对较大的内核大小，以形成适合肝脏识别的接收领域。所有max pooling层都使用2 * 2 * 2的内核。经过几个阶段的下采样后，特征体积的尺寸逐渐减小，并且比gt_mask的尺寸小得多。在这方面，我们开发3D反卷积层以将这些粗糙feature map桥接到密集概率预测（即变为原来的尺寸大小）。反卷积的时候卷积核大小是333（正向卷积核大小见上图），方向的是尺寸双倍放大。此外反向卷积核在训练的过程中学习得来。\n\n深层监督的学习过程\n3D网络的学习过程可以认为是提速二分类误差最小化问题，在优化的过程中一个挑战就是：梯度消失，这使得早期层中的损失反向传播无效。这种问题在3D情况下可能更严重，并且不可避免地会降低收敛速度并降低模型的辨别能力。为了应对这一挑战，我们利用注入一些隐藏层的额外监督来抵消梯度消失的不利影响。\n具体而言，我们使用一些额外的反卷积层来扩展一些低级和中级特征向量。然后使用softmax层来获得用于计算分类误差的dense预测(监督层的预测)。利用从这些分支预测和最后输出层得到的梯度，可以有效地减轻梯度消失的影响。\n令wl为l层的权重，W = (w1;w2; …;wL)为主流网络的权重，p (ti | xi;W)表示体素xi属于ti类的概率(softmax function输出)，则最后一个输出层的负对数似然损失如下：\n![](https://i.imgur.com/ab2Au8T.png)\n\n其中X表示训练集，从第d层引入深度监督，用Wd =(w1;w2; …;wd)表示主流网络第d层的权重。使用w^d表示将第d层特征桥接到dense预测(监督层的预测)的权重，深度监督的辅助损失如下：\n![](https://i.imgur.com/HmX0giV.png)\n\n最后，我们采用标准反向传播，通过最小化以下总体目标函数来学习权重W和所有w^d：\n![](https://i.imgur.com/2ltLfLZ.png)\n\n其中ηd是ζd的平衡权重，在学习的过程中衰减。D是具有深层监督的所有隐藏层的索引集。 上面公式中第一项对应于最后一层的输出预测， 第二项来自深层监督，提高了网络的识别能力，加快了收敛速度，第三项是权重衰减正则化，λ是权衡超参数。在每次训练迭代中，网络的输入是一个大的体积数据（见图1），并且同时进行来自不同损耗分量的误差反向传播。\n\n使用条件随机场(CRF)进行轮廓修正\n尽管3D DSN可以生成高质量的概率图，但是如果仅使用阈值概率，则模糊区域的轮廓有时可能是不精确的。 因此，我们进一步采用图形模型来细化分割结果。 考虑到网络已经充分考虑了3D空间信息，我们在横向平面上利用了完全连接的CRF模型，该模型具有高分辨率。 该模型解决了如下能量函数：\n![](https://i.imgur.com/t5ldYpZ.png)\n\n第一项是指体素xi被分配标签yi的概率对数， 具体而言，p^（yi|xi）被初始化为来自3D DSN的最后层和分支概率预测的加权平均值，计算公式如下：\n![](https://i.imgur.com/EW5gKKI.png)\n\nE(y)中的第二项是pairwise potential,其中f(yi; yj)=1 if yi != yj and 0 otherwise;∮(xi; xj)通过采用灰度值I和双边位置s来结合局部外观和平滑度，如下：\n![](https://i.imgur.com/TAAF5N2.png)\n\n使用训练集上的网格搜索来优化一元势中的恒定权重τd和成对势中的参数μ1; μ2; θα; θβ; θγ。。\n\n实验\n使用MICCAI-SLiver07 [6]数据集（20组训练和10组测试）。\n实施细节。我们的3D DSN是通过Theano库实现的。我们从头开始训练网络，权重是从高斯分布（μ= 0;σ= 0:01）初始化的。学习率初始化为0.1，每50个epochs除以10。深度监督平衡权重初始化为0.3和0.4，每十个epochs衰减5％。\n\n参考\n论文：3D Deeply Supervised Network for Automatic Liver Segmentation from CT Volumes\n\n","categories":["机器学习"],"tags":[]},{"title":"论文解读：Deeply-Supervised Nets","url":"http://tanqingbo.cn/2018/11/12/Deeply-Supervised Nets/","content":"前言\n深度监督网络（DSN）可以提高隐藏层学习过程的直接性和透明度。本文注意力集中在卷积神经网络（CNN型）架构的三个方面：\n\n（1）影响中间层的透明度具有整体分类; \n（2）学习特征的辨别力和稳健性，特别是在早期阶段; \n（3）面对消失的“梯度”训练有效性。\n\n\n为了解决这些问题，我们在每个隐藏层引入伴随目标函数，以及输出层的整体目标函数（与分层预训练不同的集成策略）。我们还使用随机梯度方法扩展的技术分析我们的算法。\n\nDSN的核心思想是为隐藏层提供集成的直接监督层，而不是仅在输出层提供监督，并将此监督传播回早期层的标准方法。我们通过为每个隐藏层引入伴随目标函数来提供这种集成的直接隐藏层监督;这些伴随目标函数可以被视为学习过程中的附加（软）约束。\n\n使用来自随机梯度方法的分析技术来研究限制性设置，其中并入伴随目标函数直接导致提高的收敛率。这种综合深度监督的优势是显而易见的：\n\n（1）对于小型训练数据和相对较浅的网络，对于分类准确性和学习特征问题，深度监督可以提供强大的“正规化”；\n（2）用于大型训练数据和更深层次的网络深度监控使得利用极深度网络可以通过改善其他有问题的收敛行为来使的性能增益提升。\n\n\nDSN的主要特征是通过伴随目标对深度监督进行综合编制，在最简单的情况下，其形式几乎与输出层的目标函数相同，如下公式所示：\n\n\n\n![](https://i.imgur.com/AjsBEz9.png)\n\n\n\n但是在初始化和重新调整的时候过度的使用这种分层预训练容易导致过拟合。\n我们注意到我们DSN的方法独立于averaging [22]，drop-connect [17]和Maxout [10]等技术; 因此，我们如果将DSN与这些技术相结合可能会使分类误差大大减少。\n\nDeeply-Supervised Nets\nDSD是在现有的CNN基础上提出来的，在隐藏层引入了分类器（SVM或Softmax）。DSN提出的动机\n一般来说，在较多的特征上训练判别分类器比在较少的特征上训练判别分类器的性能要更好，如果讨论的特征是深层网络中的隐藏层特征，意味着使用这些隐藏层特征图训练的判别分类器的性能可以作为这些隐藏层特征图的质量好坏的评判标准（我猜论文应该是表达这个意思）。\n我们还期望这种深度监督可以缓解消除“渐变”的常见问题。我们通过将“伴随”分类输出与每个隐藏层相关联来引入我们的额外深度反馈。实证结果表明了伴随目标的以下主要特性：\n（1）它是一个特征正则化的类型，它导致测试误差的减少，而不一定减少训练误差;\n（2）它导致改进的对流性能行为，需要更少的手动调整（特别是对于非常深的网络）。\n\n\n\n公式\n将一个分类与每个隐藏层相关联。 对应的权重表示为：\n\n\n![](https://i.imgur.com/y2EptGX.png)\n\n\n\n为了便于参考，我们将总体提目标函数定义为：\n\n\n![](https://i.imgur.com/00cmlK9.png)\n\n\n\n其中P(W)为输出层的目标函数，定义如下：\n\n\n![](https://i.imgur.com/CAz1x4Z.png)\n\n\n\n隐藏层伴随目标函数如下：\n\n![](https://i.imgur.com/TUcn9xi.png)\n\n\n在上述公式中，w(out)表示输出层权重，那么我们的总体目标函数F(W)就可以表示为：\n\n![](https://i.imgur.com/v8nKNiw.png)\n\n\n我们使用SGD训练DSN模型，梯度W遵循传统的CNN模型，加上来自隐藏层直接监督的梯度;我们还使用伴随目标归零，如下所述，我们将（与输出层相关）称为总损失，将称为伴随损失。在L2SVM中这些都是预测误差的损失。\n\n出来学习卷积核和权重W之外，我们在每个隐藏层包含了一个额外的目标，与该层的良好标签预测相关联，这个额外的目标强烈支持在每个隐藏层上具有辨别力和敏感性的特征。\n\n注意：对于每一个，w(m)取决于Z(m)(Z(m)表示中间层的输出),而Z(m)又取决于第一到m层。\n\n在训练过程中经常被送到零;这意味着产生良好的输出层分类的总体目标不会从根本上改变，而且这个目标可以作为一种正则化或作为判别特征的代理。在公式（4）中我们追求这种伴随目标归零的一种方法是设置一个阈值γ（超参数）。一旦每个隐藏层的伴随损失低于阈值，它就会消失（我理解的是伴随目标函数不再工作），不再有助于学习过程中的梯度更新（见上述的公式4便可知）。第m个平衡参数αm表示输出目标与相应的伴随目标之间的权衡。\n\n伴随目标归零的另一种方法是使用简单的衰减函数，例如αm × 0.1 × (1 − t/N) → αm强制F(W)的第二个项在一定次数的迭代后消失，其中t是当前迭代步数，N是总迭代步数。我们从这两种方法中获得了可观的初步结果;\n\n最先进的基准测试结果表明，深度监督方法不会显示有害的过拟合：如图（2.c）所示，而CNN和DSN的训练误差最终接近于零，DSN 显示出较低的测试误差，因此证明了其优于标准CNN的优势。\n\n\n随机梯度下降视图（Stochastic Gradient Descent View）\n深度神经网络中的目标函数是高度非凸函数，这一特征导致当前缺乏对DL框架的清晰数学/统计分析。 一种常见的方法是通过将注意力仅限于局部凸性所处的环境来提高可追溯性。 在这里，我们遵循这个例子，假设我们的目标函数是λ-strongly局部凸的，并遵循随机梯度下降的分析技术[3]。\nλ-strongly 凸函数F(W)定义如下(对W if ∀ W,W′ ∈ W and any subgradient g at W)：\n\n\n![](https://i.imgur.com/dN7kgp9.png)\n\n\n\n令W⋆为最优解，假设凸函数设置中存在E[∥WT −W⋆∥2]和E[F(WT ) − F(W⋆)]的上界。或者说在凸函数设置中存在E[F(WT ) − F(W⋆)]的上界。在这个基础上我们试着去理解目标函数的收敛性，图一(b)大致可以说明E[∥WT −W⋆∥2]假设特征。 在[19]中，给出了具有局部凸函数的M-估计量的收敛速度，其具有成分损失和规则化项。\n\n\n\n定义：用Sγ(F) = &#123;W | F(W) ≤ γ&#125;表示γ-sublevel集合，在这里等价于F(W) ≡ P(W) + Q(W).\n接下来论文中是证明Sγ(F) = &#123;W | F(W) ≤ γ&#125;于F(W) ≡ P(W) + Q(W)等价的过程，我把这部分过程省略了。\n\n实验\n文章中在四个数据集上评估我们提出的DSN：MNIST，CIFAR-10，CIFAR-100和SVHN。还使用ImageNet来评估DSN在大型数据集上的行为。\n使用小批量大小为128且固定动量为0.9的SGD求解器。学习率和体重衰减因子的初始值由评估集确定。\n我们还包含两个丢失率为0.5的丢失层。 卷积层上的伴随目标被强制反向传播去指导误分类的相关层。我们提出的DSN框架并不难以训练，也没有采用特定的工程技巧。\nDSN可以配备不同类型的分类目标功能;我们考虑L2SVM和softmax，并显示DSN-L2SVM和DSN-Softmax性能超过相应的CNN-L2SVM和CNN-Softmax方法，如图2.a所示，在小型训练数据体系中，性能提升更为明显（见图（2.b））;这可能部分减轻了DL需要大量训练数据的负担。\n\n\n\n总的来说，我们在所有四个数据集上都观察到了最新的分类错误。所有结果都是在没有aver- aging（我的理解是没有均值化）的情况下实现的[22]，这可以进一步提高分类精度。\n\n我们的DSN方法可以与许多现有的CNN类型方法结合使用。总体而言，如前所述：对于小型训练数据和相对较浅的网络，DSN起到强大的“正规化”的作用;对于大型训练数据和非常深的网络，DSN使训练过程变得方便，\n\n\n总结\n这篇论文首次提出 deeply -supervision 的做法，文章的 motivation 基于这样的观察： 如果 features 越 discrminative , 那么 classifier 的性能就越好 。\n\n文章还提到 deeply- supervision 的优点包括：\n\n能够减轻梯度爆炸或梯度消失，收敛速度更快（辅助 loss 将误差直接注入中间层，有点类似于 resnet 的机制，不同的是 loss 来源不同 ）\n\n辅助 loss 起到 regularization 的作用 （我猜应该是超参 λ起得作用）\n\n作者可视化了第一卷积层学到的feature map, 发现比普通 CNN 学到的特征更加 intuitive（论文提到了这一现象，但没有给出解释，后面几层特征图的特点也没有提及）.\n\n\n\n文章里的辅助分类器为 SVM。\n\n\n\n后记\n论文后面的内容都是对数据集合实验精度的介绍，我没有详细写了。\npaper下载：http://arxiv.org/abs/1409.5185\ncode 和prototxt文件下载：https://github.com/s9xie/DSN\n\n参考\nDeeply-Supervised Nets\n简书：月牙眼的楼下小黑 论文阅读：《Deeply-Supervised Nets》\n\n","categories":["机器学习"],"tags":[]},{"title":"常见医疗扫描图像处理步骤","url":"http://tanqingbo.cn/2018/10/30/常见医疗扫描图像处理步骤/","content":"\n本文转自：http://shartoo.github.io/medical_image_process/一、数据格式1.1 dicom\nDICOM是医学图像中的标准文件，这些文件包含了诸多元数据信息（比如像素尺寸），此处以kaggle Data Science Bowl数据集为例：data-science-bowl-2017,数据列表如下：\n\n\n![](https://i.imgur.com/MnKy7Xw.png)\n\n\n\n后缀为 .dcm。\n\n每个病人的一次扫描CT(scan)可能有几十到一百多个dcm数据文件(slices)。可以使用 python的dicom包读取，读取示例代码如下:\n      dicom.read_file(&#39;/data/lung_competition/stage1/7050f8141e92fa42fd9c471a8b2f50ce/498d16aa2222d76cae1da144ddc59a13.dcm&#39;)\n\n其pixl_array包含了真实数据。\n      slices = [dicom.read_file(os.path.join(folder_name,filename)) for filename in os.listdir(folder_name)]\n      slices = np.stack([s.pixel_array for s in slices])\n\n\n1.2 mhd格式\nmhd格式是另外一种数据格式，来源于(LUNA2016)[https://luna16.grand-challenge.org/data/]。每个病人一个mhd文件和一个同名的raw文件。如下:\n\n\n![](https://i.imgur.com/BEHFky3.png)\n\n\n\n一个raw通常有几百兆，对应的mhd文件只有1kb。mhd文件需要借助python的SimpleITK包来处理。SimpleITK 示例代码如下:\n      import SimpleITK as sitk\n      itk_img = sitk.ReadImage(img_file)\n      img_array = sitk.GetArrayFromImage(itk_img) # indexes are z,y,x (notice the ordering)\n      num_z, height, width = img_array.shape        #heightXwidth constitute the transverse plane\n      origin = np.array(itk_img.GetOrigin())      # x,y,z  Origin in world coordinates (mm)\n      spacing = np.array(itk_img.GetSpacing())    # spacing of voxels in world coor. (mm)\n\n需要注意的是，SimpleITK的img_array的数组不是直接的像素值，而是相对于CT扫描中原点位置的差值，需要做进一步转换。\n\n\n1.3 查看CT扫描文件软件\n一个开源免费的查看软件 mango\n\n\n![](https://i.imgur.com/65V28LN.png)\n\n\n二 dicom格式数据处理过程2.1 处理思路\n首先，需要明白的是医学扫描图像其实是三维图像，使用代码读取之后查看不同的切面的切片(slices),可以从不同轴切割。\n\n\n![](https://i.imgur.com/XiG8Gaw.png)\n\n\n\n如下图展示了一个病人CT扫描中，其中部分切片slices：\n\n\n![](https://i.imgur.com/X8hBT12.png)\n\n\n\n其次，CT扫描图是包含了所有组织的，如果直接去看，看不到任何有用的信息，需要做一些预处理，预处理中一个重要概念是仿射剂量，衡量单位为HU(Hounsfield Unit),下表是不同放射剂量对应的组织器官：\n\n![](https://i.imgur.com/XFwZbzH.png)\n\n\n      Hounsfield Unit = pixel_value * rescale_slope + rescale_intercept\n\n一般情况rescale slope = 1, intercept = -1024。\n\n上表中肺部组织的HU数值为-500,但通常是大于这个值，比如-320、-400。挑选出这些区域，然后做其他变换抽取出肺部像素点。\n\n\n2.2 先载入必要的包    # -*- coding:utf-8 -*-\n    &#39;&#39;&#39;\n    this script is used for basic process of lung 2017 in Data Science Bowl\n    &#39;&#39;&#39;\n    import glob\n    import os\n    import pandas as pd\n    import SimpleITK as sitk\n    import numpy as np # linear algebra\n    import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n    import skimage, os\n    from skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\n    from skimage.measure import label,regionprops, perimeter\n    from skimage.morphology import binary_dilation, binary_opening\n    from skimage.filters import roberts, sobel\n    from skimage import measure, feature\n    from skimage.segmentation import clear_border\n    from skimage import data\n    from scipy import ndimage as ndi\n    import matplotlib\n    #matplotlib.use(&#39;Agg&#39;)\n    import matplotlib.pyplot as plt\n    from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n    import dicom\n    import scipy.misc\n    import numpy as np\n2.3 将厚度加入到元数据\n如下代码是载入一个扫描面，包含了多个(slices)，我们仅简化的将其存储为python列表，数据集中每个目录都是一个扫描集(一个病人)。有个元数据域丢失，即Z轴方向上的像素尺寸，也即切片的厚度，所幸，我们可以用其他值推测出来，并加入到元数据中。\n\n            # Load the scans in given folder path\n            def load_scan(path):\n                slices = [dicom.read_file(path + &#39;/&#39; + s) for s in os.listdir(path)]\n                #对一个病人的所有slices进行排序，x指的是一个slice。slice里面有好多属性，\n                #有一个是ImagePositionPatient.按照他的这个属性进行对这些slices排序，方便我们组三维rendering。\n                #imageOrientationPatient表示的是当前图像的第一行在空间中的三维方向向量与第一列的三维方向向量。\n                slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n                try:\n                    slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n                except:\n                    slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)  #SliceLocation：表示的图像平面的相对位置。\n                for s in slices:\n                    s.SliceThickness = slice_thickness   #切片厚度\n                return slices\n2.4 灰度值转换为HU单元\n首先去除灰度值为-2000的pixl_array(pixl_array包含了真实数据),CT扫描边界之外的灰度值固定为-2000(dicom和mhd都是这个值)。第一步设定这些值为0，当前对应为空气(值为0).\n\n回到HU单元，乘以rescale比率并加上intercept(存储在扫描面的元数据中)。(Hounsfield Unit = pixel_value * rescale_slope + rescale_intercept).\n      def get_pixels_hu(slices):\n          image = np.stack([s.pixel_array for s in slices])\n          # Convert to int16 (from sometimes int16),\n          # should be possible as values should always be low enough (&lt;32k)\n          image = image.astype(np.int16)\n          # Set outside-of-scan pixels to 0\n          # The intercept is usually -1024, so air is approximately 0\n          image[image == -2000] = 0\n          # Convert to Hounsfield units (HU)\n          for slice_number in range(len(slices)):\n              intercept = slices[slice_number].RescaleIntercept  #Intercept\n              slope = slices[slice_number].RescaleSlope  #Rescale\n              if slope != 1:\n                  image[slice_number] = slope * image[slice_number].astype(np.float64)\n                  image[slice_number] = image[slice_number].astype(np.int16)\n              image[slice_number] += np.int16(intercept)\n          return np.array(image, dtype=np.int16)\n\n可以查看病人的扫描HU分布值情况：\n      first_patient = load_scan(INPUT_FOLDER + patients[0])\n      first_patient_pixels = get_pixels_hu(first_patient)\n      plt.hist(first_patient_pixels.flatten(), bins=80, color=&#39;c&#39;)\n      plt.xlabel(&quot;Hounsfield Units (HU)&quot;)\n      plt.ylabel(&quot;Frequency&quot;)\n      plt.show()\n\n\n2.5 重采样\n不同扫描面的像素尺寸，粗细粒度是不同的，这不利于我们进行CNN任务，我们可以使用同构采样。\n\n一个扫描面的像素区间可能是[2.5,0.5,0.5],即切片之间的距离为2.5mm。可能另外一个扫描面的范围是[1.5,0.725,0.725]。这可能不利于自动分析。常见的处理方法是从全数据集中以固定的同构分辨率重新采样，将所有的东西采样为(1,1,1).\n      def resample(image, scan, new_spacing=[1,1,1]): # scan是load_scan函数返回的结果\n          # Determine current pixel spacing\n          spacing = map(float, ([scan[0].SliceThickness] + scan[0].PixelSpacing))\n          spacing = np.array(list(spacing))\n          resize_factor = spacing / new_spacing\n          new_real_shape = image.shape * resize_factor\n          new_shape = np.round(new_real_shape)   #返回浮点数x的四舍五入值。\n          real_resize_factor = new_shape / image.shape\n          new_spacing = spacing / real_resize_factor\n          image = scipy.ndimage.interpolation.zoom(image, real_resize_factor, mode=&#39;nearest&#39;) #使用所请求顺序的样条插值来缩放数组。\n          return image, new_spacing\n      # 现在重新取样病人的像素，将其映射到一个同构分辨率 1mm x1mm x1mm。\n      pix_resampled, spacing = resample(first_patient_pixels, first_patient, [1,1,1])\n\n使用matplotlib输出肺部扫描的3D图像方法。可能需要一两分钟。\n      def plot_3d(image, threshold=-300):\n          # Position the scan upright,\n          # so the head of the patient would be at the top facing the camera\n          p = image.transpose(2,1,0)  #将扫描件竖直放置\n          verts, faces = measure.marching_cubes(p, threshold) #Liner推进立方体算法来查找3D体积数据中的曲面。\n          fig = plt.figure(figsize=(10, 10))\n          ax = fig.add_subplot(111, projection=&#39;3d&#39;)\n          # Fancy indexing: `verts[faces]` to generate a collection of triangles\n          mesh = Poly3DCollection(verts[faces], alpha=0.1)  #创建3Dpoly\n          face_color = [0.5, 0.5, 1]\n          mesh.set_facecolor(face_color)  #设置颜色\n          ax.add_collection3d(mesh)\n          ax.set_xlim(0, p.shape[0])\n          ax.set_ylim(0, p.shape[1])\n          ax.set_zlim(0, p.shape[2])\n          plt.show()\n      # 调用函数\n      plot_3d(pix_resampled, 400)\n\n打印函数有个阈值（threshold）参数，来打印特定的结构，比如tissue或者骨头。400是一个仅仅打印骨头的阈值(HU对照表)，如下图：\n\n\n\n![](https://i.imgur.com/Gj1XR45.png)\n\n\n\n2.6 输出一个病人scans中所有的slices    def plot_ct_scan(scan):\n        &#39;&#39;&#39;\n                plot a few more images of the slices\n        :param scan:\n        :return:\n        &#39;&#39;&#39;\n        f, plots = plt.subplots(int(scan.shape[0] / 20) + 1, 4, figsize=(50, 50))\n        for i in range(0, scan.shape[0], 5):\n            plots[int(i / 20), int((i % 20) / 5)].axis(&#39;off&#39;)\n            plots[int(i / 20), int((i % 20) / 5)].imshow(scan[i], cmap=plt.cm.bone)\n\n此方法的效果示例如下:\n\n\n![](https://i.imgur.com/hUEPwDA.png)\n\n\n2.7 数据标准化处理\n归一化处理：\n当前的值范围是[-1024,2000]。而任意大于400的值并不是处理肺结节需要考虑，因为它们都是不同反射密度下的骨头。LUNA16竞赛中常用来做归一化处理的阈值集是-1000和400.以下代码：\n\n\n\n            MIN_BOUND = -1000.0\n            MAX_BOUND = 400.0\n            def normalize(image):\n                image = (image - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)\n                image[image&gt;1] = 1.\n                image[image&lt;0] = 0.\n                return image\n\n0值中心化：\n\n简单来说就是所有像素值减去均值。LUNA16竞赛中的均值大约是0.25.\n\n不要对每一张图像做零值中心化（此处像是在kernel中完成的）CT扫描器返回的是校准后的精确HU计量。不会出现普通图像中会出现某些图像低对比度和明亮度的情况\n      PIXEL_MEAN = 0.25\n      def zero_center(image):\n          image = image - PIXEL_MEAN\n          return image\n\n\n\n\n三 mhd格式数据处理过程\nmhd的数据只是格式与dicom不一样，其实质包含的都是病人的扫描，处理MHD需要借助SimpleITK这个包，处理思路详情可以参考Data Science Bowl2017的toturail Data Science Bowl 2017.需要注意的是MHD格式的数据没有HU值，它的值域范围与dicom很不同。\n\n我们以LUNA2016年的数据处理流程为例。参考代码为: LUNA2016数据切割.\n3.1 载入必要的包  import SimpleITK as sitk\n  import numpy as np\n  import csv\n  from glob import glob  #用它可以查找符合自己目的的文件\n  import pandas as pd\n  # glob方法返回所有匹配的文件路径列表（list）；该方法需要一个参数用来指定匹配的路径字符串，\n  # 其返回的文件名只包括当前目录里的文件名，不包括子文件夹里的文件。\n  file_list=glob(luna_subset_path+&quot;*.mhd&quot;)  \n  #####################\n  #\n  # Helper function to get rows in data frame associated\n  # with each file\n  def get_filename(case):\n      # 如果你想要为一个定义在函数外的变量，那么你就得告诉Python这个变量名不是局部的，而是 全局 的。\n      global file_list\n      for f in file_list:\n          if case in f:\n              return(f)\n  #\n  # The locations of the nodes\n  df_node = pd.read_csv(luna_path+&quot;annotations.csv&quot;)\n  df_node[&quot;file&quot;] = df_node[&quot;seriesuid&quot;].apply(get_filename)  #调用get_filename函数，并函数参数为df_node[&quot;seriesuid&quot;]\n  df_node = df_node.dropna() #将所有含有nan项的row删除\n  #####\n  #\n  # Looping over the image files\n  #\n  fcount = 0\n  for img_file in file_list:\n      print &quot;Getting mask for image file %s&quot; % img_file.replace(luna_subset_path,&quot;&quot;)\n      mini_df = df_node[df_node[&quot;file&quot;]==img_file] #get all nodules associate with file\n      if len(mini_df)&gt;0:       # some files may not have a nodule--skipping those\n          biggest_node = np.argsort(mini_df[&quot;diameter_mm&quot;].values)[-1]   # just using the biggest node\n          node_x = mini_df[&quot;coordX&quot;].values[biggest_node]\n          node_y = mini_df[&quot;coordY&quot;].values[biggest_node]\n          node_z = mini_df[&quot;coordZ&quot;].values[biggest_node]\n          diam = mini_df[&quot;diameter_mm&quot;].values[biggest_node]\n3.2 LUNA16的MHD格式数据的值\n一直在寻找MHD格式数据的处理方法，对于dicom格式的CT有很多论文根据其HU值域可以轻易地分割肺、骨头、血液等，但是对于MHD没有这样的参考。从LUNA16论坛得到的解释是，LUNA16的MHD数据已经转换为HU值了，不需要再使用slope和intercept来做rescale变换了。此论坛主题下，有人提出MHD格式没有提供pixel spacing(mm) 和 slice thickness(mm) ，而标准文件annotation.csv文件中结节的半径和坐标都是mm单位，最后确认的是MHD格式文件中只保留了体素尺寸以及坐标原点位置，没有保存slice thickness。即，dicom才是原始数据格式。\n\n\n3.4 坐标体系变换\nMHD值的坐标体系是体素，以mm为单位（dicom的值是GV灰度值）。结节的位置是CT scanner坐标轴里面相对原点的mm值，需要将其转换到真实坐标轴位置，可以使用SimpleITK包中的 GetOrigin() GetSpacing()。图像数据是以512x512数组的形式给出的。\n坐标体系变换如下：\n\n\n![](https://i.imgur.com/fly8c4C.png)\n\n\n\n相应的代码处理如下：\n\n  itk_img = sitk.ReadImage(img_file)\n  img_array = sitk.GetArrayFromImage(itk_img) # indexes are z,y,x (notice the ordering)\n  center = np.array([node_x,node_y,node_z])   # nodule center\n  origin = np.array(itk_img.GetOrigin())      # x,y,z  Origin in world coordinates (mm)\n  spacing = np.array(itk_img.GetSpacing())    # spacing of voxels in world coor. (mm)\n  # np.rint(a) 各元素四舍五入\n  v_center = np.rint((center-origin)/spacing)  # nodule center in voxel space (still x,y,z ordering) \n\n\n\n在LUNA16的标注CSV文件中标注了结节中心的X,Y,Z轴坐标，但是实际取值的时候取的是Z轴最后三层的数组(img_array)。\n下述代码只提取了包含结节的最后三个slice的数据，代码参考自 LUNA_mask_extraction.py\n\n            i = 0\n            for i_z in range(int(v_center[2])-1,int(v_center[2])+2):\n                mask = make_mask(center,diam,i_z*spacing[2]+origin[2],width,height,spacing,origin)\n                masks[i] = mask\n                imgs[i] = matrix2int16(img_array[i_z])\n                i+=1\n            np.save(output_path+&quot;images_%d.npy&quot; % (fcount) ,imgs)\n            np.save(output_path+&quot;masks_%d.npy&quot; % (fcount) ,masks)\n3.5 查看节点\n以下代码用于查看原始CT和结节mask。其实就是用matplotlib打印上一步存储的npy文件。\n          import matplotlib.pyplot as plt\n          imgs = np.load(output_path+&#39;images_0.npy&#39;)\n          masks = np.load(output_path+&#39;masks_0.npy&#39;)\n          for i in range(len(imgs)):\n              print &quot;image %d&quot; % i\n              fig,ax = plt.subplots(2,2,figsize=[8,8])\n              ax[0,0].imshow(imgs[i],cmap=&#39;gray&#39;)\n              ax[0,1].imshow(masks[i],cmap=&#39;gray&#39;)\n              ax[1,0].imshow(imgs[i]*masks[i],cmap=&#39;gray&#39;)\n              plt.show()\n              raw_input(&quot;hit enter to cont : &quot;)\n\n接下来的处理和DICOM格式数据差不多，腐蚀膨胀、连通区域标记等。\n\n\n参考信息\n灰度值是pixel value经过重重LUT转换得到的用来进行显示的值，而这个转换过程是不可逆的，也就是说，灰度值无法转换为ct值。只能根据窗宽窗位得到一个大概的范围。 pixel value经过modality lut得到Hu，但是怀疑pixelvalue的读取出了问题。dicom文件中存在（0028，0106）（0028，0107）两个tag，分别是最大最小pixel value，可以用来检验你读取的pixel value 矩阵是否正确。\n\nLUT全称look up table，实际上就是一张像素灰度值的映射表，它将实际采样到的像素灰度值经过一定的变换如阈值、反转、二值化、对比度调整、线性变换等，变成了另外一 个与之对应的灰度值，这样可以起到突出图像的有用信息，增强图像的光对比度的作用。\n\n\n","categories":["机器学习"],"tags":[]},{"title":"论文笔记：基于3D卷积神经网络的人体行为识别(3D Convolutional Neural Networks for Human Action Recognition)","url":"http://tanqingbo.cn/2018/10/23/基于3D卷积神经网络的行为识别（3D Convolutional Neural Networks for Human Action Recognition）/","content":"摘要\n当前很多人体行为识别分类器都是基于从原始图像上手工提取的特征，本文提出的3D CNN能够直接从原始输入中提取特征，通过执行3D卷积在监控视频中从时间和空间维度提取特征，将高级功能模型规范化，并结合各种不同模型的输出，进一步提高3D CNN的性能。在机场的监控视频中，该方法相比于传统的方法，取的了卓越的性能。\n\n介绍\n现实的环境的监控视频背景杂乱、遮挡等原因，在识别之前会对视频中的某些情况作出某些假设（假设在现实环境中很少存在），然后遵循两步原则：\n\n计算原始视频帧的特征；\n基于获得的特征学习分类器；\n\n\n而然在实际场景中，很少知道哪些特征对手头任务很重要，因为特征选择高度依赖问题。特别是对于人类动作识别，不同的动作类别在其外观和运动模式方面可能显得截然不同。\n\n深度学习模型是一类可以通过从低级特征构建高级特征来学习特征层次结构的机器。这种学习机可以使用有监督或无监督的方法进行训练。\n\nCNN主要用于2D图像，本文探讨将CNN用于视频中人体动作的识别，一种容易想到的方法是将视频的每一帧视为静止图像，并用CNN来识别单个帧的级别动作，但这种方法没有考虑多个连续帧的编码运动信息。为了有效的结合视频中的运动信息，文章提出可以在CNN卷积层中执行3D卷积，以便捕获沿空间和时间维度的辨别特征。3D CNN架构可以从相邻的视频帧生成多个信息通道，并在每个通道中分别执行卷积和下采样，通过组合来自视频通道的信息获得最终特征表示。为了进一步提升3D CNN模型的性能，我们建议增加模型，辅助输出计算为高级运动特征，并集成各种不同架构的输出进行预测。\n\n本文贡献：\n\n本文应用3D卷积运算从视频数据中提取空间和时间特征以进行动作识别。这些3D特征提取器在空间和时间维度上操作，从而捕获视频流中的运动信息；\n开发了基于3D卷积特征提取的3D卷积神经网络架构（CNN），该CNN架构从相邻视频帧生成多个信息通道，并在每个通道中分别执行卷积和下采样。通过组合来自所有通道的信息获得最终的特征表示；\n建议通过增加具有高级运动特征的输出来规范3D CNN模型；\n建议通过组合各种不同3D CNN架构的输出来提高模型的性能。\n\n\n\n3D卷积神经网络\n在二维CNN中，卷积应用于2D特征图，仅从空间维度计算特征。当利用视频数据分析问题的时候，我们期望捕获在多个连续帧编码的运动信息。为此，提出在CNN的卷积进行3D卷积，以计算空间和时间维度特征， 3D卷积是通过堆叠多个连续的帧组成一个立方体，然后在立方体中运用3D卷积核。通过这种结构，卷积层中的特征图都会与上一层中的多个相邻帧相连，从而捕获运动信息。如下图所示，一个feature map的某一位置的值是通过卷积上一层的三个连续的帧的同一位置的局部感受野得到的。\n\n\n![](https://i.imgur.com/IDZyLpe.png)\n\n\n\n要注意的是，3D卷积核只能从cube中提取一种类型特征，因为在整个卷积的过程中卷积核的权值都是一样的的（共享权值），都是同一种卷积核，上图中同一颜色的连线表示相同的权值。因此我们可以采用多种卷积核来提取多种特征。\n对于CNNs，有一个通用的设计规则就是：在后面的层（离输出层近的）特征map的个数应该增加，这样就可以从低级的feature map组合产生更多类型的特征。\n\n3D CNN架构\n基于上述的3D卷积，可以设计出各种CNN架构。在上下文中，我们描述了为了描述了为TRECVID数据集中的人为动作识别开发的3D CNN架构，如图所示：\n\n\n\n文中的3D CNN架构包含一个硬连线hardwired层、3个卷积层、2个下采样层和一个全连接层。每个3D卷积核卷积的立方体是连续7帧，没帧patch大小是60x40；\n在第一层，我们应用了一个固定的hardwired的核去对原始的帧进行处理，产生多个通道的信息，然后对多个通道分别处理。最后再将所有通道的信息组合起来得到最终的特征描述。这个hardwired层实际上是编码了我们对特征的先验知识，这比随机初始化性能要好。\n每帧提取五个通道的信息，分别是：灰度、x和y方向的梯度，x和y方向的光流。其中，前面三个都可以每帧都计算。然后水平和垂直方向的光流场需要两个连续帧才确定。所以是7x3 + (7-1)x2=33个特征maps。\n\n\n![](https://i.imgur.com/JGLAHLM.png)\n\n\n\n然后我们用一个7x7x3的3D卷积核（7x7在空间，3是时间维）在五个通道的每一个通道分别进行卷积。为了增加feature map个数（实际上就是提取不同的特征），我们在每一个位置都采用两个不同的卷积核，这样在C2层的两个特征maps组中，每组都包含23个特征maps。23=(7-3+1)x3+(6-3+1)x2，前面那个是：七个连续帧，其灰度、x和y方向的梯度这三个通道都分别有7帧，然后水平和垂直方向的光流场都只有6帧。54x34是(60-7+1)x(40-7+1)。\n\n在紧接着的下采样层S3层max pooling，我们在C2层的特征maps中用2x2窗口进行下采样，这样就会得到相同数目但是空间分辨率降低的特征maps。下采样后，就是27x17=(54/2)*(34/2)。\n\nC4是在5个通道中分别采用7x6x3的3D卷积核。为了增加特征maps个数，我们在每个位置都采用3个不同的卷积核，这样就可以得到6组不同的特征maps，每组有13个特征maps。13=((7-3+1)-3+1)x3+((6-3+1)-3+1)x2，前面那个是：七个连续帧，其灰度、x和y方向的梯度这三个通道都分别有7帧，然后水平和垂直方向的光流场都只有6帧。21x12是(27-7+1)x(17-6+1)。\n\nS5层用的是3x3的下采样窗口，所以得到7x4。所以本文中，空间维度上卷积后的尺寸变化可以通过下图很直观的表现出来：\n\n\n\n![](https://i.imgur.com/BzT9Q6K.png)\n\n\n\n到这个阶段，时间维上帧的个数已经很小了，在这一层，我们只在空间维度上面卷积，这时候我们使用的核是7x4，然后输出的特征maps就被减小到1x1的大小。而C6层就包含有128个feature map，每个特征map与S5层中所有78（13x6）个特征maps全连接，这样每个特征map就是1x1，也就是一个值了，而这个就是最终的特征向量了，共128维。\n经过多层的卷积和下采样后，每连续7帧的输入图像都被转化为一个128维的特征向量，这个特征向量捕捉了输入帧的运动信息。输出层的节点数与行为的类型数目一致，而且每个节点与C6中这128个节点是全连接的。如下图：\n\n\n![](https://i.imgur.com/7kuJ39y.png)\n\n\n\n在这里，我们采用一个线性分类器来对这128维的特征向量进行分类，实现行为识别。\n\n模型中所有可训练的参数都是随机初始化的，然后通过在线BP算法进行训练。\n\n\nModel Regularization（模型规范化）\n3D CNN模型的输入被限制为一个少的连续视频帧（论文中取的是7帧），因为随着输入窗口大小的增加，模型需要训练的参数也会增加。但是呢，很多人的行为是跨越很多帧的。\n因此，在3D CNN模型中，有必要捕捉这种高层的运动信息。为了达到这个目的，我们用大量的帧来计算运动特征，然后把这些运动特征作为辅助输出去规则化3D CNN模型。\n对于每一个需要训练的行为，我们提取其长时间的行为信息，作为其高级行为特征。这个运动信息因为时间够长，所以要比CNN的输入帧的立方体包含的信息要丰富很多。然后我们就迫使CNN学习一个非常接近这个特征的特征向量。这可以通过在CNN的最后一个隐层再连接一系列的辅助输出节点，然后训练过程中，使提取的特征更好的逼近这个计算好的高层的行为运动特征向量。如下图所示：\n\n\n![](https://i.imgur.com/Yir3o7k.png)\n\n\n\n高级行为辅助特征的提取过程是先在原始的灰度图像上计算稠密sift描述子，然后通过这些sift描述子和运动边缘历史图像（MEHI）组合构造bag-of-words特征作为高级行为辅助特征（我也还不太懂bag-of-words特征，可以自己查一下）。如下图：\n\n\n![](https://i.imgur.com/iGENkQB.png)\n\n\n\n因为灰度图保留了外观信息，运动边缘历史图像（MEHI）只关心形状和运动模式，所以可以提取这两个互补的信息作为两个连续帧的局部特征bag。MEHI 的计算见上图右，先简单的计算两帧间的差分，这样就可以保留运动信息，然后对其执行一次Canny边缘检测，这样可以使得观测图像更加清楚简洁。最终的运动边缘图像就是将历史的这些图像乘以一个遗忘因子再累加起来得到。具体的构造需要参考更多的论文了。\n\nModel Combination(模型组合)\n不同的3D CNN模型在不同的应用环境下性能不一样，一种自适应的方法就是构造多个不同模型，然后对一个特定的输入，每个模型都做出预测，然后组合这些模型的预测得到最后的决策。\n本文中，我们构造多个不同的3D CNN模型，因此它可以从输入捕捉潜在的互补信息，然后在预测阶段，每个模型都针对一个输入得到对应的输出，然后再组合这些输出得到最终的结果。\n\nModel Implementation(模型实现)\n在本实验中，所有的子采样层都是最大子采样，用于训练规范化模型的整体代价函数是有真实的行为类的误差和高层特征的辅助输入代价项的线性加权得到，，权值分别是1和0.005，模型的所有参数都是随机初始化，然后通过diagonal Levenberg-Marquardt方法来优化训练。\n\n疑问\n在3D CNN网络架构中，S5层13*2@7x4经过7x4的卷积核卷积之后为什么会出处128个feature map，有了解的同行可以给我解答一下，谢谢啦！\n\n参考\n论文原文：3D Convolutional Neural Networks for Human Action Recognition\nCSDN-zouxy09：基于3D卷积神经网络的人体行为理解\nCSDN-karen17：深度学习文章阅读2–3D Convolutional Neural Networks for Human Action Recognition\n\n","categories":["机器学习"],"tags":[]},{"title":"论文笔记：图像数据增强之弹性形变（Elastic Distortions）","url":"http://tanqingbo.cn/2018/10/15/数据增强-弹性形变/","content":"前言\n我们都知道，深度学习的成功的原因主要有两点：\n\n当前计算机的计算能力有很大提升；\n随着大数据时代的到来，当前的训练样本数目有很大的提升。\n\n\n然而深度学习的一大问题是，有的问题并没有大量的训练数据，而由于深度神经网络具有非常强的学习能力，如果没有大量的训练数据，会造成过拟合，训练出的模型难以应用。因此对于一些没有足够样本数量的问题，可以通过已有的样本，对其进行变化，人工增加训练样本。\n\n对于图像而言，常用的增加训练样本的方法主要有对图像进行旋转、移位等仿射变换，也可以使用镜像变换等等，这里介绍一种常用于字符样本上的变换方法，**弹性变换算法(Elastic Distortion)**。\n\n该算法最先是由Patrice等人在2003年的ICDAR上发表的《Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis》。本文主要是对论文中提出的弹性形变数据增强方法进行解读。\n\n\n插播一下双线性插值的定义\n双线性插值，顾名思义就是两个方向的线性插值加起来（这解释过于简单粗暴，哈哈）。所以只要了解什么是线性插值，分别在x轴和y轴都做一遍，就是双线性插值了。\n线性插值：两个点A，B，要在AB中间插入一个点C（点C坐标在AB连线上），就直接让C的值落在AB的值的连线上就可以了。如A点坐标(0,0),值为3，B点坐标(0,2)，值为5，那要对坐标为(0,1)的点C进行插值，就让C落在AB线上，值为4就可以了。\n但是如果C不在AB的线上肿么办捏，所以就有了双线性插值。如下图，已知Q12，Q22，Q11，Q21，但是要插值的点为P点，这就要用双线性插值了，首先在x轴方向上，对R1和R2两个点进行插值，这个很简单，然后根据R1和R2对P点进行插值，这就是所谓的双线性插值。\n![](https://upload.wikimedia.org/wikipedia/commons/e/e7/Bilinear_interpolation.png)\n\n\n\n\n1、仿射变换\n仿射变换是最常用的空间坐标变换的方法之一，具体定义可参考冈萨雷斯的《数字图像处理第三版》50页。论文中是如下解释仿射变换的：\n\n将仿射变换应用于图像，新像素的位置是由原始位置确定的，Δx(x,y)=1，Δy(x,y)=0代表向右移一个单位，Δx(x,y)= αx, Δy(x,y)= αy代表像素点由原点位置进行缩放。\n\n上面说明了如何计算变换之后每个像素点的坐标，下图说明了如何应用位移字段来计算每个像素的新值（其实就是双线性插值的方法）：\n\n![](https://i.imgur.com/YLULBaL.png)\n\n\n假设A是原点(0,0),而数字3,7,5,9是图像要转换的灰度等级，坐标分别为(1,0),(2,0),(1,-1),(1,-2),A的位移由Δx(0,0) = 1.75 and Δy(0,0) = -0.5给出，如箭头所示。通过评估原始图像的位置（1.75，-0.5）处的灰度级来计算新（扭曲）图像中的A的新灰度值。用于评估灰度级的简单算法是原始图像的像素值进行“线性插值”。尽管可以使用其他插值方案（例如，双三次和B样条插值），但双线性插值是最简单的插值方法之一，并且适用于以所选分辨率（29×29）生成附加的扭曲字符图像。\n\n先水平插值，然后垂直插值，完成评估。箭头结束的位置在3,5,7,9的方格内，这样我们先计算箭头相对于它结束的方格的坐标。在这种情况下，它相对于正方形方格中的坐标是（0.75,0.5），假设该正方形的原点是左下角（也就是灰度值为5的点）。在此示例中，水平插值为：3 +0.75×(7-3)= 6;垂直插值为：8 +0.5×(6-8)= 7，因此A的新像素值为7.\n\n对所有像素都进行了类似的计算。在给定图像之外的所有像素位置都假定有一个灰度值。\n\n\n2、弹性形变\n仿射变换改善了在MNIST数据集上的实验结果，但是实验在弹性形变后的数据集上取得了最好的结果。那么什么是弹性形变呢？\n首先创建随机位移场来使图像变形，即Δx(x,y) = rand(-1,+1)、Δy(x,y)=rand(-1,+1),其中rand(-1,+1)是生成一个在(-1,1)之间均匀分布的随机数，然后用标准差为σ的高斯函数对Δx和Δy进行卷积，如果σ值很大，则结果值很小，因为随机值平均为0.如果我们将位移场标准化（达到1的范数），则该字段接近常数，具有随机方向。\n如果σ很小，则归一化后该字段看起来像一个完全随机的字段（如图2右上角所示）。\n对于中间σ值，位移场看起来像弹性变形，其中σ是弹性系数。然后将位移场乘以控制变形强度的比例因子α。 在我们的MNIST实验（29x29输入图像）中，产生最佳结果的值是σ = 4和α= 34。\n将经过高斯卷积的位移场乘以控制变形强度的比例因子α，得到一个弹性形变的位移场，最后将这个位移场作用在仿射变换之后的图像上，得到最终弹性形变增强的数据。作用的过程相当于在仿射图像上插值的过程，最后返回插值之后的结果。\n关于高斯卷积的原理可以参考这篇文章：高斯卷积滤波\n如果文章看完文章，还是不太懂弹性形变数据增强的原理的话，可以结合代码一起看，下面是参考代码，我都有注释。\n\n3、参考代码            # -*- coding:utf-8 -*-\n            &quot;&quot;&quot;\n            @author:TanQingBo\n            @file:elastic_transform.py\n            @time:2018/10/1221:56\n            &quot;&quot;&quot;\n            # Import stuff\n            import os\n            import numpy as np\n            import pandas as pd\n            import cv2\n            from scipy.ndimage.interpolation import map_coordinates\n            from scipy.ndimage.filters import gaussian_filter\n            import matplotlib.pyplot as plt        \n\n            # Function to distort image  alpha = im_merge.shape[1]*2、sigma=im_merge.shape[1]*0.08、alpha_affine=sigma\n            def elastic_transform(image, alpha, sigma, alpha_affine, random_state=None):\n                &quot;&quot;&quot;Elastic deformation of images as described in [Simard2003]_ (with modifications).\n                .. [Simard2003] Simard, Steinkraus and Platt, &quot;Best Practices for\n                     Convolutional Neural Networks applied to Visual Document Analysis&quot;, in\n                     Proc. of the International Conference on Document Analysis and\n                     Recognition, 2003.                \n                 Based on https://gist.github.com/erniejunior/601cdf56d2b424757de5\n                &quot;&quot;&quot;\n                if random_state is None:\n                    random_state = np.random.RandomState(None)\n\n                shape = image.shape\n                shape_size = shape[:2]   #(512,512)表示图像的尺寸                \n                # Random affine\n                center_square = np.float32(shape_size) // 2\n                square_size = min(shape_size) // 3\n                # pts1为变换前的坐标，pts2为变换后的坐标，范围为什么是center_square+-square_size？\n                # 其中center_square是图像的中心，square_size=512//3=170\n                pts1 = np.float32([center_square + square_size, [center_square[0] + square_size, center_square[1] - square_size],\n                                   center_square - square_size])\n                pts2 = pts1 + random_state.uniform(-alpha_affine, alpha_affine, size=pts1.shape).astype(np.float32)\n                # Mat getAffineTransform(InputArray src, InputArray dst)  src表示输入的三个点，dst表示输出的三个点，获取变换矩阵M\n                M = cv2.getAffineTransform(pts1, pts2)  #获取变换矩阵\n                #默认使用 双线性插值，\n                image = cv2.warpAffine(image, M, shape_size[::-1], borderMode=cv2.BORDER_REFLECT_101)\n\n                # # random_state.rand(*shape) 会产生一个和 shape 一样打的服从[0,1]均匀分布的矩阵\n                # * 2 - 1 是为了将分布平移到 [-1, 1] 的区间\n                # 对random_state.rand(*shape)做高斯卷积，没有对图像做高斯卷积，为什么？因为论文上这样操作的\n                # 高斯卷积原理可参考：https://blog.csdn.net/sunmc1204953974/article/details/50634652\n                # 实际上 dx 和 dy 就是在计算论文中弹性变换的那三步：产生一个随机的位移，将卷积核作用在上面，用 alpha 决定尺度的大小\n                dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n                dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n                dz = np.zeros_like(dx)  #构造一个尺寸与dx相同的O矩阵                \n                # np.meshgrid 生成网格点坐标矩阵，并在生成的网格点坐标矩阵上加上刚刚的到的dx dy\n                x, y, z = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]), np.arange(shape[2]))  #网格采样点函数\n                indices = np.reshape(y + dy, (-1, 1)), np.reshape(x + dx, (-1, 1)), np.reshape(z, (-1, 1))\n                # indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1)), np.reshape(z, (-1, 1))                \n                return map_coordinates(image, indices, order=1, mode=&#39;reflect&#39;).reshape(shape)                \n\n            # Define function to draw a grid\n            def draw_grid(im, grid_size):\n                # Draw grid lines\n                for i in range(0, im.shape[1], grid_size):\n                    cv2.line(im, (i, 0), (i, im.shape[0]), color=(255,))\n                for j in range(0, im.shape[0], grid_size):\n                    cv2.line(im, (0, j), (im.shape[1], j), color=(255,))                \n\n            if __name__ == &#39;__main__&#39;:\n                img_path = &#39;E:/liverdata/nii/png/img&#39;\n                mask_path = &#39;E:/liverdata/nii/png/label&#39;\n                # img_path =  &#39;/home/changzhang/ liubo_workspace/tmp_for_test/img&#39;\n                # mask_path = &#39;/home/changzhang/liubo_workspace/tmp_for_test/mask&#39;                \n                img_list = sorted(os.listdir(img_path))\n                mask_list = sorted(os.listdir(mask_path))\n                print(img_list)                \n                img_num = len(img_list)\n                mask_num = len(mask_list)                \n                assert img_num == mask_num, &#39;img nuimber is not equal to mask num.&#39;                \n                count_total = 0\n                for i in range(img_num):\n                    print(os.path.join(img_path, img_list[i]))   #将路径和文件名合成一个整体\n                    im = cv2.imread(os.path.join(img_path, img_list[i]), -1)\n                    im_mask = cv2.imread(os.path.join(mask_path, mask_list[i]), -1)                \n                    # # Draw grid lines\n                    # draw_grid(im, 50)\n                    # draw_grid(im_mask, 50)                \n                    # Merge images into separete channels (shape will be (cols, rols, 2))\n                    im_merge = np.concatenate((im[..., None], im_mask[..., None]), axis=2)                \n                    # get img and mask shortname\n                    (img_shotname, img_extension) = os.path.splitext(img_list[i])  #将文件名和扩展名分开\n                    (mask_shotname, mask_extension) = os.path.splitext(mask_list[i])                \n                    # Elastic deformation 10 times\n                    count = 0                \n                    while count &lt; 10:\n                        # Apply transformation on image  im_merge.shape[1]表示图像中像素点的个数\n                        im_merge_t = elastic_transform(im_merge, im_merge.shape[1] * 2, im_merge.shape[1] * 0.08,\n                                                       im_merge.shape[1] * 0.08)\n\n                        # Split image and mask\n                        im_t = im_merge_t[..., 0]\n                        im_mask_t = im_merge_t[..., 1]                \n                        # save the new imgs and masks\n                        cv2.imwrite(os.path.join(img_path, img_shotname + &#39;-&#39; + str(count) + img_extension), im_t)\n                        cv2.imwrite(os.path.join(mask_path, mask_shotname + &#39;-&#39; + str(count) + mask_extension), im_mask_t)                \n                        count += 1\n                        count_total += 1\n                    if count_total % 100 == 0:\n                        print(&#39;Elastic deformation generated &#123;&#125; imgs&#39;, format(count_total))\n                        # # Display result\n                        # print &#39;Display result&#39;\n                        # plt.figure(figsize = (16,14))\n                        # plt.imshow(np.c_[np.r_[im, im_mask], np.r_[im_t, im_mask_t]], cmap=&#39;gray&#39;)\n                        # plt.show()\n\n关于map_coordinates函数原理的参考文章：Python/Scipy插值（map_coordinates）\n\n参考\n论文原文：Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis\nMingChaoSun-CSDN：高斯卷积滤波\nPython/Scipy插值（map_coordinates）\n\n","categories":["机器学习"],"tags":[]},{"title":"TensorFlow的一些函数应用","url":"http://tanqingbo.cn/2018/10/08/TensorFlow的一些函数应用/","content":"TensorFlow的一些函数应用    saver = tf.train.Saver(max_to_keep=3)\n\n保存训练模型，如果你需要在当前训练好的模型的基础上进行 fine-tune，那么尽可能多的保存模型，后继 fine-tune 不一定从最好的 ckpt 进行，因为有可能一下子就过拟合了。但是如果保存太多，硬盘也有压力呀。如果只想保留最好的模型，方法就是每次迭代到一定步数就在验证集上计算一次 accuracy 或者 f1 值，如果本次结果比上次好才保存新的模型，否则没必要保存。\n\ntf.global_variables_initializer().run()   #变量初始化\n\n输出网络结构：\n      with tf.Session() as sess:\n        writer = tf.summary.FileWriter(your_dir, sess.graph)\n\n\n\n","categories":["机器学习"],"tags":[]},{"title":"论文笔记：Unet用于医学图像分割的卷积网络(UNet Convolutional Networks for Biomedical Image Segmentation)","url":"http://tanqingbo.cn/2018/10/08/论文笔记：用于医学图像分割的卷积网络/","content":"摘要\n本文中提出了一种网络结构的训练策略，它依赖于充分利用数据增强技术来更高效的使用带有标签的数据。在U-Net结构中，包括一个捕获上下文信息的收缩路径和一个允许精确定位的对称拓展路径。这种方法可以使用非常少的数据完成端到端的训练，并获得最好的效果。\n\n介绍\n卷积网络的典型用途是分类任务，其中图像的输出是单个类别标签。 然而，在许多视觉任务中，尤其是在生物医学图像处理中，期望的输出应该包括定位，即，应该将类标签分配给每个像素。（也就是分割）\n\nCiresan等人用滑动窗口取像素像素周围的局部区域俩训练网络，训练数据远远大于训练图像的数量。 \n\n本文提出一种新的完全卷积网络，即U-Net网，主要思想是在收缩网络的后面补充一个与前面类似的网络，其中池化运算符由上采样运算符替换。因此，这些层增加了输出的分辨率。为了定位，从收缩路径的高分辨率特征与上采样输出相结合。然后，连续卷积层可以学习基于该信息组装更精确的输出。\n\n作者提出U-Net的本意是将其用于医学图像分割，在以往的CNN中，想将其用于医学图像存在两个困难：\n\n通常CNN都是应用于分类，生物医学图像更关注的是分割以及定位的任务；\nCNN需要获取大量的训练数据，而医学图像很难获得那么大规模的数据。\n\n\n以往解决上面两点困难的方法是使用滑窗的方法，为每一个待分类的像素点取周围的一部分邻域输入。这样的方法有两点好处，首先它完成了定位的工作，其次因为每次取一个像素点周围的邻域，所以大大增加了训练数据的数量。但是这样的方法也有两个缺点，首先通过滑窗所取的块之间具有较大的重叠，所以会导致速度变慢；其次是网络需要在局部准确性和获取上下文之间进行取舍。因为更大的块需要更多的池化层进而降低了定位的准确率，而小的块使网络只看到很小的一部分上下文。\n\n\nU-Net\n在本文中，作者修改并扩展了FCN网络结构，使它在使用少量的数据进行训练的情况下获得精确的分割结果，具体结构示意图如下所示：\n\n\n\n在上图中，每一个蓝色块表示一个多通道特征图，特征图的通道数标记在顶部，X-Y尺寸设置在块的左下边缘。不同颜色的箭头代表不同的操作。图的左半部分是收缩路径，右半部分是扩展路径。\n其中需要注意的是，每经过一次上采样都会将通道数减半，再与收缩路径对应的特征图进行拼接。在拼接之前进行 crop 是必要的(例如在上图中，6464大与5656，为了使这两个特征图能够顺利拼接，取6464中间部分5454的大小，然后拼接)，因为两者的尺寸并不相同（主要是因为 valid conv 造成的）。最后一层使用1 X 1大小的卷积核，将通道数降低至特定的数量（如像素点的类别数量）。\n网络对于输入的大小也是有要求的。为了使得输出的分割图无缝拼接，重要的是选择输入块的大小，以便所有的2 X 2的池化层都可以应用于偶数的 x 层和 y 层。一个比较好的方法是从最下的分辨率从反向推到，比如说在网络结构中，最小的是32 X 32，沿着收缩路径的反向进行推导可知，输入图像的尺寸应该为572×572。 \n\nFCN与U-net的区别\nFCN的主要思想是使用连续的层补充通常的收缩网络，在判别输出的位置添加上采样层，这些层增加了输出层的分别率，为了定位。来自于收缩路径的高分别率与上采样输出相结合，基于这个信息，一个连续的卷积层可以学习组装更精确的输出。（关于FCN详细内容可以参考我的上一篇文章：论文笔记：用于语义分割的全卷积网络 （fully convolutional networks for semantic segmentation））\n而U-net与FCN的不同在于，U-net的上采样依然有大量的通道，这使得网络将上下文信息向更高层分辨率传播，作为结果，扩展路径与收缩路径对称，形成一个U型的形状（如上图所示）。 网络没有全连接层并且只是用每一个卷积层的有效部分。\n\nOverlap-tile\n作者在文中介绍了一种Overlap-tile策略，使得任意大小的输入图像都可以获得一个无缝分割，因为输出的分割图它包含的像素点，它们的周围像素点（上下文）都出现在了输入图像中，因此使用Overlap-tile策略对数据进行预处理是有必要的。\nOverlap-tile策略的过程具体如下所示：\n\n\n\n上图是针对任意大小的输入图像的无缝分割的 Overlap-tile 策略。如果我们要预测黄色框内区域（即对黄色的内的细胞进行分割，获取它们的边缘），需要将蓝色框内部分作为输入，如果换色区域在输入图像的边缘的话，那么缺失的数据使用镜像进行补充。如上图左边图像所示，输入图像周围一圈都进行了镜像补充。\n\n因为进行的是valid卷积，即上下文只取有效部分，可以理解为padding为0，卷积之后的图像尺寸会改变，所以需要取比黄色框大的图像来保证上下文的信息是有意义的，缺失的部分用镜像的方法补充是填充上下文信息最好的方法了。这种方法通常需要将图像进行分块的时候才使用。\n\n那么为什么要对图像分块，不输入整张图像呢？因为内存限制，有的机器内存比较小，需要分块输入。但比之前的滑窗取块要好很多，一方面不用取那么多块，另一方面块之间也没有那么大的区域重叠。通过Overlap-tile 策略可以将图像分块输入，否则的话就只能对图像进行 resize 了，但是这样会降低输入图像的分辨率。\n\n此外，如果数据不够的话可以应用弹性形变，对数据进行增强，增加数据量，这允许网络可以学习到这种形变的不变形，并且并不要求带有原始预料库进行到这样的变化（指弹性形变）。\n\n\n细胞分割\n进行细胞的分割，另一种挑战是同一类物体的分类，如下图所示：\n\n\n\n上图是用DIC（二次干涉对比）显微技术记录的玻璃上的 HeLa 细胞。其中图 (a) 是原始图像；图 (b) 是基于 gt 的分割覆盖。其中不同的颜色表示不同的 HeLa 细胞示例。图 (c) 是生成的分割掩膜，其中白色部分是前景，黑色部分是后景；图 (d) 是像素级损失权重图，使得网络强制学习边缘像素。\n 为了解决这个问题，作者使用加权损失，对于位与细胞接触部分的像素加大权重，如图 (d) 中的红色的部分。\n\nTraining（训练）\n作者使用caffe框架，并采用带动量的SGD方法，其中动量的值设为 momentum=0.99。动量设这么大的原因是这样可以使用大量先前看到的训练样本确定当前最优步骤的更新(因为动量的原理就是用先前很多步的状态确定下一步的方向)。相比于大的batchsize，作者喜欢大的input tiles（指的是over-tile）中的那种图像块，因此我们可以将一个batch缩小为一个单张图片的输入。\n能量函数通过结合交叉熵损失函数的最后特征图上的像素级 soft-max 值来计算，通常多分类问题用soft-max函数作为输出，二分类问题用sigmoid函数作为输出，其中 soft-max 的计算方法如下：\n\n\n![](https://i.imgur.com/tqAPxnz.png)\n \n\n\n其中 αk(x)代表在位置 x 处的像素在特征图中的第 k 层的激活值，其中 x∈Ω，，Ω⊂Z^2 ，即 x 属于空间 Ω，而空间 Ω是整数集合Z^2的子集。K 是像素点的类别总数，p_k(x)是近似最大函数。这里面的定义和我们平时使用的 sift-max 是一样的。损失函数是交叉熵损失函数，或者也可以成为 log-likelihood，具体如下所示\n\n\n![](https://i.imgur.com/xNb9fTZ.png)\n \n\n\n其中需要注意的是这里使用的是加权的损失函数，对于每一个像素点有着自己的权重，这点可以在上面的细胞图中看到。\n\n我们通过预先计算权重图来获得每一个像素在损失函数中的权值，这种方法补偿了训练数据每类像素的不同频率，并且使网络更注重学习相互接触的细胞的边缘。\n\n分割边界使用形态学运算，特征图的计算方法如下：\n\n\n\n![](https://i.imgur.com/9IVztjc.png)\n\n\n\n其中的 w_c是用于平衡类别频率的权重图，d_1是该像素点到最近的细胞边界的距离；d_2是该像素点到第二近的细胞边界的距离。在我们的实验中，将 w0设置为10，将σs设置为大约 5 个像素。\n权值的初始化对于模型的正确训练起着很大的作用，一个好的初始化应该保证网络中的每一个特征图有近似的单位方差。在这里使用服从标准差为√2/N      的高斯分布来进行初始化（实际上就是 He normal），其中的 N 代表着一个神经元的传入节点的数目，比如说某一个卷积层，他的卷积核的大小为 3×3，通道数是 64，那么 N=9×64=576。Data Augmentation（数据增强/扩充）\n当只有少量训练样本的时候，对于让网络学习到所需的不变形和鲁棒性来说，数据增强是必要的。\n显微镜图像一般需要旋转平移不变性，弹性形变和灰度值变化鲁棒性。训练样本的随机性变形似乎是训练之后少量标注图像的分割网络的关键。\n此外在本文中，早收缩路径的最后加入了Drop-out，隐式的加强了数据增强。\n\n总结\n本文提出了很多数据预处理的技巧，有较强的实用性。\n\n本文的创新点\n提出了U-net这种网络结构。它同时具备捕捉上下文信息的收缩路径和允许精确定位的对称扩展路径，并且与FCN相比，U-net的上采样过程依然有大量的通道，这使得网络将上下文信息向更高层分辨率传播。\nOverlap-tile 策略，这种方法用于补全输入图像的上下信息，可以解决由于现存不足造成的图像输入的问题。\n使用随机弹性变形进行数据增强。\n使用加权损失。预先计算权重图，一方面补偿了训练数据每类像素的不同频率，另一方面是网络更注重学习相互接触的细胞间边缘。\n\n但是上面的这些创新点并不适合所有任务，比如说对刚体进行分割，那么久很难通过弹性变形对数据进行增强。\n本文学到的一些实用的技巧\n因为使用了 valid conv ，所以采用 Overlap - tile 策略补充图像，其中空白的部分用镜像的方法进行补充；\n因为有池化层，因此要保证输入的图像在经过每一次池化的时候都要是边长偶数。这点与一般的卷积神经网络不同，因为一般的网络会使用 padding ，这样会保证卷积前后的大小不变，但是 valid conv 会使卷积后的尺寸变小，所以要特别注意输入图像的尺寸。一个比较好的方法是从最小分辨率出发沿收缩路径的反方向进行计算，得到输入图像的尺寸。\n预先计算权重图，以此计算后面的加权损失函数；\n加权损失的权重中有一部分是经验值，因此对于不同的任务可以进行调整（只是理论上可以进行调整，并没有试验过）；\n使用标准差为√2/N的高斯分布来进行权值初始化，其中需要注意的是，对于不同的卷积层，N 的大小也是不同的。\n在收缩路径的最后部加入了 dropout ，隐式地加强了数据增强。\n\n一些疑惑\n为什么加入 dropout 后可以对数据进行增强？\n反卷积（上采样）的具体过程是怎么样的？\n弹性形变数据增强具体是如何对数据增强的？\n\n参考\n论文原文：U-Net: Convolutional Networks for Biomedical Image Segmentation\nCSDN-独孤呆博：论文精读及分析：U-Net: Convolutional Networks for Biomedical Image Segmentation\n\n","categories":["机器学习"],"tags":[]},{"title":"论文笔记：用于语义分割的全卷积网络 （fully convolutional networks for semantic segmentation）","url":"http://tanqingbo.cn/2018/10/06/论文笔记：用于语义分割的全卷积网络 （fully convolutional networks for semantic segmentation）/","content":"介绍\n通常CNN网络在卷积层之后会接上若干个全连接层，将卷积层产生的特征图（feature map）映射成一个固定长度的特征向量，以AlexNet为代表的经典CNN结构适合图像级的分类和回归任务，因为最后得到整幅图像的的数值描述，比如AlexNet的ImageNet模型输出一个1000维的向量表示输入图像属于每一类的概率(softmax归一化)。\n例子：AlexNet网中输入是下图中猫的图片，输出的结果是一个向量，表示输入图像属于每一类的概率，其中“tabby cat”这一统计概率最高。\n\n\n![](https://i.imgur.com/exK9PHx.png)\n\n\n\n而在本文中建立了一种可以接受任意大小图像，并输出与输入等大小的图像的全卷积神经网络，在文章中作者定义了全卷积神经网络（FCN）的空间结构，解释了FCN在空间密集型预测任务上的应用并且给出了他与之前其他网络之间的联系，之后通过迁移学习的方法进行微调（finetune），以此来完成所需要的分割任务。此外作者还定义了跳跃结构，通过结合来自于深的、粗糙层的语义信息和来自浅、细层的表征信息来产生准确和精细的分割。\n\n相关工作\n卷积网络在识别领域前进势头很猛，卷积网不仅在全图式的分类上有所提高，在结构化输出的局部任务上也取得了进步。包括检测目标边框、关键点预测和局部通信的进步。\n\n在以往的分割方法中，主要有两大类缺点：\n\n基于图像块分割的效率低，往往需要前期或后期处理；\n语义分割面临在语义和位置的内在张力问题：全局信息解决的是什么。局部信息解决的是在哪里。\n\n\n为了解决上面这两个问题，本文主要有三个创新点：\n\n将分类网络结果重新解释为全卷积神经网络结构，这里面具体包括两点，一个是全连接层转化为卷积层，还有就是通过反卷积进行上采样。\n使用迁移学习的方法进行 finetune ，因为很明显通过第一点可知可以将 VGG 这类有预训练权重的分类网络重新解释为 FCN\n使用跳跃结构使得，使得深的粗的语义信息可以结合浅的细的表征信息，产生准确和精细的分割。\n\n\n以往的方法主要有以下的缺点：\n\n限制容量和感受野的小模型；\n分块训练；\n超像素投影的预处理，随机场正则化、滤波或局部分类；\n对于密集输出采用输入移位和输出交错的方法；\n多尺度金字塔处理；\n饱和双曲线正切非线性；\n集成\n\n\n基于 FCN 的方法没有以上缺点。\n传统的基于CNN的分割方法：为了对一个像素分类，使用该像素周围的一个图像块作为CNN的输入用于训练和预测。这种方法有几个缺点：一是存储开销很大。例如对每个像素使用的图像块的大小为15x15，然后不断滑动窗口，每次滑动的窗口给CNN进行判别分类，因此则所需的存储空间根据滑动窗口的次数和大小急剧上升。二是计算效率低下。相邻的像素块基本上是重复的，针对每个像素块逐个计算卷积，这种计算也有很大程度上的重复。三是像素块大小的限制了感知区域的大小。通常像素块的大小比整幅图像的大小小很多，只能提取一些局部的特征，从而导致分类的性能受到限制。\n\n\n\n全连接网络（fully convolutional networks，FCN）\n好了，本文的重点终于要出来了。前面说通常CNN在接收图片输入时，输出是一个向量，代表图像属于哪一类的概率，而在FCN可以接受任意尺寸的输入图像，采用反卷积层对最后一个卷积层的feature map进行上采样, 使它恢复到输入图像相同的尺寸，从而可以对每个像素都产生了一个预测, 同时保留了原始输入图像中的空间信息, 最后在上采样的特征图上进行逐像素分类。如下图：\n\n\n\n可以看到在最后得输出层的通道数为21，但这不是最后得分割结果，取21个通道中像素值所属类别概率最大的那个值作为每个位置像素的分类结果，即上图中最右边的图。\n\nCombining what and where（结合“是什么”和“在哪里”）\n虽然上述方法取得较好的结果，但是分割结果看起来依旧很粗糙，所以采用跳跃连接结构对分割进行细化，即结合最后预测层和具有更小步长的跨层信息，该方法结合了精细层和粗糙层，让模型能做出遵从全局结构的局部预测。如下图：\n\n\n\n通过一个16像素步长层预测。我们增加了一个1*1的卷积层在pool4的顶部来产生附加的类别预测。我们将输出和预测融合在conv7（fc7的卷积化）的顶部以步长32计算，通过增加一个2×的上采样层和预测求和（见上图）。我们初始化这个2×上采样到双线性插值，但是允许参数能被学习，最后，步长为16的预测被上采样回图像，我们把这种网结构称为FCN-16s。FCN-16s用来学习端到端，能被最后的参数初始化。这种新的、在pool4上生效的参数是初始化为0的，所以这种网结构是以未变性的预测开始的。这种学习速率是以100倍的下降的。\n上面是原文叙述的原话，我没怎么看懂，不过我理解的过程是这样的：第一行的 pool4 画了一个箭头直接指向第二行的 pool4，这不是直接拿过来用，而是在第一行的 pool4 上面增加一个 1x1 的卷积层使其与conv7之后的feature map的通道数相同。之后将 conv7 进行两倍的上采样，这里采用双线性插值的方法（实际上是反卷积），插值的权重是可学习的。然后将第二行的 pool4 与 2x conv7 相加，在进行 16 倍的上采样（反卷积）就可以得到最后的结果。这里 1x1 的卷积初始化为 0，保持其原来的分割结果，注意哦，不是随机初始化，而是初始化为0，然后通过学习更新这个卷积核即 FCN-16s。我理解的，上采样的过程都是使用双线性插值的方法进行初始化的。使用类似的方法可以得到 FCN-8s。\n注：上面的conv7表示经过conv7卷积之后的feature map。\n实验结果如下：\n\n\n![](https://i.imgur.com/mNYmTfu.png)\n\n\n\n由实验结果可以发现，FCN-8S的效果最好，当上采样的步长降低到8时，效果已经不是很明显了，即收益递减，可以不用融合更多浅层特征了。\n\n实现细节查看源码的时候，发现首层的pad值为100，为什么要令pad=100呢？\n![](https://i.imgur.com/49lVTmL.png)\n\n\n\n100像素输入填充可确保网络输出可与给定数据集中任何输入大小的输入对齐。\n\n至于为什么可以，我们可以看下下面的推导过程。假设是一般的VGG16结构,第一个卷积层只pad 1，并且假设输入图片的高度是h，根据我们的卷积公式：\n\n![](https://i.imgur.com/YMQVkFb.png)\n\n由于在VGG中缩小输出map只在池化层，所以下面我们忽略卷积层，计算公式如下：\n\n![](https://i.imgur.com/aLYPv5p.png)\n\n  \n很明显，feature map的尺寸缩小了32倍，接下来是卷积化的fc6层，如下图：\n\n![](https://i.imgur.com/yhwGug6.png)\n\n\n注意fc6层中，pad=0,kernel_size=7,所以计算公式与前面6层稍有不同。\n\n接下来还有两个卷积化的全连接层,fc7以及score_fr，但他们都是1*1的卷积核，对输出的尺寸并不会有影响，所以最终在输入反卷积之前的feature map尺寸就是(h-192)/2^5.\n\n推导到这里pad 100的作用已经很明显了，如果不进行padding操作，对于长或宽不超过192像素的图片是没法处理的，而当我们pad 100像素之后:\n\n![](https://i.imgur.com/ssajLaj.png)\n\n\n这样就解决了以上问题，但是毋庸置疑，这会引入很多噪声。同样这样的输出会使得上采样得到的图像与输入图像不等大，所以以计算必要的精确 offset参数 并消除这种填充量。\n\n\n文章的创新点与不足创新点\n实际上理解好这篇文章，只需要理解好一下三点即可\n将分类网改写为用于分割的像素点分类网。具体的包括两个方面，即将全连接层改写为卷积层，和使用反卷积完成上采样的过程；\n使用跳跃连接的结构，将深的粗糙的信息与浅的精细的信息相结合，产生准确和精细的分割；\n使用微调进行实验。 \n\n\n\n缺点\n在这里我们要注意的是FCN的缺点：   (1) 分割结果不够精细。进行8倍上采样虽然比32倍的效果好了很多，但是上采样的结果还是比较模糊和平滑，对图像中的细节不敏感。   (2) 是对各个像素进行分类，没有充分考虑像素与像素之间的关系。忽略了在通常的基于像素分类的分割方法中使用的空间规整（spatial regularization）步骤，缺乏空间一致性。\n\n参考\n论文原地址：fully convolutional networks for semantic segmentation\nCSDN-独孤呆博：论文精读及分析：Fully Convolutional Networks for Semantic Segmentation\nCSDN-Colie-Li：用于语义分割的全卷积网络 （fully convolutional networks for semantic segmentation）\n博客园-代码初学者：全卷积网络 FCN 详解\n\n","categories":["机器学习"],"tags":[]},{"title":"简历修改了100遍，却仍然没有找到满意的工作，你可能需要看一下这篇文章","url":"http://tanqingbo.cn/2018/10/04/简历修改了100遍，却仍然没有找到满意的工作，你可能需要看一下这篇文章/","content":"简历修改了100遍，却仍然没有找到满意的工作，你可能需要看一下这篇文章最近恰逢秋招，身边很多朋友都跟我抱怨说，简历投出去了不少，可是很多都是石沉大海，没有了回音。于是就急的不行，纷纷跑过来请教简历制作大法。\n话说为啥问我这个没找过工作且非人力资源专业的人呢？我啥也不懂啊，于是便向我的某知名外企HR朋友请教。\n她说，你的朋友有时间去了解你，可是HR没有，顶多给你一分钟的展示时间。如果你的简历内容明确，精致表现，能够快速让HR了解到你的特点和优势，那么这份简历就是出色的，赢面也就更大。\n杨澜说过，没有人有义务必须透过连你自己都毫不在意的邋遢外表去发现你优秀的内在，对简历来说也适用。\n所以检验一份好的简历的标准就是看HR是否看了就想约你面试。那么怎样在写简历的时候都有哪些坑需要我们去避开的呢？我的这位HR朋友说，她在看了几千份简历后，很多人的简历都存在以下几个问题：\n问题一：一份简历从头用到尾不同的岗位有不同的岗位需求，因此每投一个岗位、一个公司，简历都要经过修改，我想这应该是常识吧。可是我的朋友听我说这句话的时候，她只回了我两个字：呵呵！\n你看，就是会有这么不走心的同学，所以如果你的简历总是频频被刷，那就赶紧反省一下自己是否偷懒了。毕竟老是被刷，你心里应该有数了。\n问题二：简历过于繁琐由于HR每天需要审阅大量的简历，查看你的个人简历的时候可能只花了很短的时间就决定是否召见你，所以一页纸的简历效果是最好的。朋友说她亲眼看过一份超三页纸的简历在她老大手里没超过2秒就直接next one了。\n一些人在写简历的时候习惯把所有个人资料都罗列上（政治面貌、健康状况、血型、星座、婚姻状况等）。这样不仅使简历啰嗦冗长，一些个人信息还可能成为获得面试机会的障碍，可以说是“偷鸡不成蚀把米”。\n问题三：求职照太过随意都说这是个看脸的世界，HR也不例外。 朋友说她有一次看到有人直接拿用自拍的头像来作为简历照片，也是很勇敢了！！\n所以，敲黑板划重点了，简历上一定要放有职业感的照片，如果没有，那就花几十块钱去照相馆拍一张，那种学校打印店10块钱拍一次的那种证件照还是别拿出来了。\n简历制作的一些小技巧在千篇一律的简历面前，一点小心思有时候说不定就能有大惊喜。朋友她总结了一下之前见到过的心思小技巧，拿来分享给大家！\n不要用表格式模板，看起来千篇一律，显得死板；过多的框框给人一种束缚感。\n也不建议采用密集文字式模板，过多文字使得简历看上去不清晰。\n死得快型选手\n看简历都想录用型选手\n▲用结果强调工作经验\n\n个人工作经历过程很重要，但是结果才是最能体现你个人能力的证明。因此，在描述自己的工作经验时，一定要写上结果来证明你的能力。\n\n▲关键词突出醒目\n\n个人简历的外表一定要醒目，重点可以使用斜体、大写、下划线、首字突出或箭头等标示出来。\n\n▲定位精准\n\nHR一般很忙的，如果不能很快找到想要的信息，你就很可能变成谢谢参与了。因此，每个人都要为自己的简历精准定位，突出重点。\n\n▲字句文法不能出错\n\nHR一般很讨厌个人简历中有错别字，没有之一。所以简历写完之后记得全面检查一遍。\n\n▲简历命名一目了然\n\nHR每天招的职位很多，直接在文件命名的时候就能准确传递重要信息，给HR省不少功夫。很多不省心的求职者，非得让HR打开邮件下载简历才能看到你的基本信息。如没有特殊要求，简历文件命名一般是姓名+投递职位+地区，这样HR对你的印象分就不会低。\n\n如果看完上面这些，你还是不知道怎么编辑你的简历，那也没有关系，我有几个在大厂做HR的朋友，实验室也有不少BAT、微软等大厂offer都拿到手的大神， 你可以加我微信，我让他们一对一、手把手教你如何打造一份出色的简历，并教你在面试中如何应对面试官的问题。因为我也是请人办事，所以这个服务可能得收取部分酬劳。99元一位，可能还不够下馆子请人吃一顿饭的钱，如果不收钱的话，你们也不会相信我们会认真指导，所以暂且定这个价吧~\n我一直都觉得，如果一个人琢磨的话，不知道要撞多少回南墙，也不一定能找的到出路，但如果有一个人能带你一下，说不定能起到打通任督二脉的效果，帮你瞬间缩短探索的时间和试错的成本。\n我要做的就是，在你求职的过程中，请一些职场大牛，帮你完善简历，带你避开一些求职的坑，缩短你的试错成本，助你找到理想的工作。\n此外，为了给大家谋取更多的福利，同时让更多的人了解我们的这个服务，如果你能拉来一个朋友来关顾我们的服务，给你打5折，拉两个朋友过来，打2折，拉3个朋友过来的话，免费给你修改简历和指导~\n我的微信\n","categories":["漂来漂去"],"tags":[]},{"title":"基于pandas的数据预处理总结","url":"http://tanqingbo.cn/2018/09/07/基于pandas的数据预处理总结/","content":"\n参加kaggle数据挖掘比赛，就第一个赛题Titanic的数据，学习相关数据预处理以及模型建立，本博客关注基于pandas进行数据预处理过程。包括数据统计、数据离散化、数据关联性分析\n引入包和加载数据      import pandas as pd\n      import numpy as np\n      train_df =pd.read_csv(&#39;../datas/train.csv&#39;)  # train set\n      test_df  = pd.read_csv(&#39;../datas/test.csv&#39;)   # test  set\n      combine  = [train_df, test_df]\n函数的含义      print(train_df.columns.values)  # 查看表格数据中的属性名字\n\n输出：\n      [&#39;PassengerId&#39; &#39;Survived&#39; &#39;Pclass&#39; &#39;Name&#39; &#39;Sex&#39; &#39;Age&#39; &#39;SibSp&#39; &#39;Parch&#39; &#39;Ticket&#39; &#39;Fare&#39; &#39;Cabin&#39; &#39;Embarked&#39;]\n\n      #查看object属性数据统计情况\n      print train_df.describe(include=[&#39;O&#39;])  \n      # 统计Title单列各个元素对应的个数\n      print train_df[&#39;Title&#39;].value_counts() \n      # 属性列删除\n      train_df = train_df.drop([&#39;Name&#39;, &#39;PassengerId&#39;], axis=1)  \n\n\n缺省值处理        # 直接丢弃缺失数据列的行\n        print df4.dropna(axis=0,subset=[&#39;col1&#39;])  # 丢弃nan的行,subset指定查看哪几列 \n        print df4.dropna(axis=1)  # 丢弃nan的列\n        # 采用其他值填充\n        dataset[&#39;Cabin&#39;] = dataset[&#39;Cabin&#39;].fillna(&#39;U&#39;) \n        dataset[&#39;Title&#39;] = dataset[&#39;Title&#39;].fillna(0) \n        # 采用出现最频繁的值填充\n        freq_port = train_df.Embarked.dropna().mode()[0]\n        dataset[&#39;Embarked&#39;] = dataset[&#39;Embarked&#39;].fillna(freq_port)\n        # 采用中位数或者平均数填充\n        test_df[&#39;Fare&#39;].fillna(test_df[&#39;Fare&#39;].dropna().median(), inplace=True)\n        test_df[&#39;Fare&#39;].fillna(test_df[&#39;Fare&#39;].dropna().mean(), inplace=True)\n数值属性离散化，object属性数值化        # 创造一个新列，AgeBand，将连续属性Age切分成5份\n        train_df[&#39;AgeBand&#39;] = pd.cut(train_df[&#39;Age&#39;], 5)\n        print(train_df[[&#39;AgeBand&#39;, &#39;Survived&#39;]].groupby([&#39;AgeBand&#39;], as_index=False).mean().sort_values(by=&#39;AgeBand&#39;,ascending=True))\n\n输出：\n               AgeBand  Survived\n      0  (-0.08, 16.0]  0.550000\n      1   (16.0, 32.0]  0.337374\n      2   (32.0, 48.0]  0.412037\n      3   (48.0, 64.0]  0.434783\n      4   (64.0, 80.0]  0.090909\n\n其它代码：\n      # 查看切分后的属性与target属性Survive的关系\n      train_df[[&#39;FareBand&#39;, &#39;Survived&#39;]].groupby([&#39;FareBand&#39;], as_index=False).mean().sort_values(by=&#39;FareBand&#39;, ascending=True)\n      # 建立object属性映射字典  \n      title_mapping = &#123;&quot;Mr&quot;: 1, &quot;Miss&quot;: 2, &quot;Mrs&quot;: 3, &quot;Master&quot;: 4, &quot;Royalty&quot;:5, &quot;Officer&quot;: 6&#125;\n      dataset[&#39;Title&#39;] = dataset[&#39;Title&#39;].map(title_mapping)\n\nDataFrame()函数功能\n      models = pd.DataFrame(&#123;\n          &#39;Model&#39;: [&#39;Support Vector Machines&#39;, &#39;KNN&#39;, &#39;Logistic Regression&#39;,\n                    &#39;Random Forest&#39;, &#39;Naive Bayes&#39;, &#39;Perceptron&#39;,\n                    &#39;Stochastic Gradient Decent&#39;, &#39;Linear SVC&#39;,\n                    &#39;Decision Tree&#39;],\n          &#39;Score&#39;: [acc_svc, acc_knn, acc_log,\n                    acc_random_forest, acc_gaussian, acc_perceptron,\n                    acc_sgd, acc_linear_svc, acc_decision_tree]&#125;)\n      print(models.sort_values(by=&#39;Score&#39;, ascending=False))\n\n输出：\n                                  Model  Score\n          3               Random Forest  86.64\n          8               Decision Tree  86.64\n          1                         KNN  84.06\n          0     Support Vector Machines  83.50\n          2         Logistic Regression  81.26\n          7                  Linear SVC  79.46\n          5                  Perceptron  78.79\n          4                 Naive Bayes  76.88\n          6  Stochastic Gradient Decent  76.77\n\n\n","categories":["机器学习"],"tags":[]},{"title":"Python刷题总结","url":"http://tanqingbo.cn/2018/09/05/Python刷题总结/","content":"lambda表达式\nlambda表达式是起到一个函数速写的作用。允许在代码内嵌入一个函数的定义。它只是一个表达式，函数体比def简单很多。\n\n3个数求和的例子：\n  &gt;&gt;&gt;f = lambda x,y,z:x+y+z\n  &gt;&gt;&gt;f(1,2,3)\n  &gt;&gt;&gt;6\n\n而如何要用正常函数实现上述功能的话，需要先用def定义函数名，代码如下:\n  &gt;&gt;&gt;def f(x,y,z):\n  &gt;&gt;&gt;     return x+y+z\n  &gt;&gt;&gt;n = f(1,2,3)\n  &gt;&gt;&gt;6\n\n\nfilter()、map()和reduce()函数的区别\nfilter（）函数\n\n包括两个参数，分别是function和list。该函数根据function参数返回的结果是否为真来过滤list参数中的项，最后返回一个新列表，如下例所示：\n  &gt;&gt;&gt;a=[1,2,3,4,5,6,7]\n  &gt;&gt;&gt;b=filter(lambda x:x&gt;5, a)\n  &gt;&gt;&gt;print b\n  &gt;&gt;&gt;[6,7]\n\n如果filter参数值为None，就使用identity（）函数，list参数中所有为假的元素都将被删除。如下所示：\n  &gt;&gt;&gt;a=[0,1,2,3,4,5,6,7]\n  b=filter(None, a)\n  &gt;&gt;&gt;print b\n  &gt;&gt;&gt;[1,2,3,4,5,6,7]\n\nmap（）函数\n\nmap()的两个参数一个是函数名，另一个是列表或元组。\n  &gt;&gt;&gt;map(lambda x:x+3, a) #这里的a同上\n  &gt;&gt;&gt;[3,4,5,6,7,8,9,10]\n\n  #另一个例子\n  &gt;&gt;&gt;a=[1,2,3]\n  &gt;&gt;&gt;b=[4,5,6]\n  &gt;&gt;&gt;map(lambda x,y:x+y, a,b)\n  &gt;&gt;&gt;[5,7,9]\n\n在刷题的过程中，map()函数通常可以结合输入一起使用，例如在一行中输入3个整数，可用如下语句：\n  a,b,c = map(int, input().split())\n\nreduce()函数\n\nreduce()函数接收的参数和 map()类似，一个函数 f，一个list，但行为和 map()不同，reduce()传入的函数 f 必须接收两个参数，reduce()对list的每个元素反复调用函数f，并返回最终结果值。\n\n例如，编写一个f函数，接收x和y，返回x和y的和：\n\n\n    def f(x, y):\n        return x + y\n\n调用 reduce(f, [1, 3, 5, 7, 9])时，reduce函数将做如下计算：\n先计算头两个元素：f(1, 3)，结果为4；\n再把结果和第3个元素计算：f(4, 5)，结果为9；\n再把结果和第4个元素计算：f(9, 7)，结果为16；\n再把结果和第5个元素计算：f(16, 9)，结果为25；\n由于没有更多的元素了，计算结束，返回结果25。\n\n\n\nrange() 函数用法\nrange() 函数可创建一个整数列表，一般用在 for 循环中。语法如下：\n  range(start, stop, step)\n\n实例：\n      &gt;&gt;&gt;range(10)        # 从 0 开始到 10\n      [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n      &gt;&gt;&gt; range(1, 11)     # 从 1 开始到 11\n      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n      &gt;&gt;&gt; range(0, 30, 5)  # 步长为 5\n      [0, 5, 10, 15, 20, 25]\n      &gt;&gt;&gt; range(0, 10, 3)  # 步长为 3\n      [0, 3, 6, 9]\n      &gt;&gt;&gt; range(0, -10, -1) # 负数\n      [0, -1, -2, -3, -4, -5, -6, -7, -8, -9]\n      &gt;&gt;&gt; range(0)\n      []\n      &gt;&gt;&gt; range(1, 0)\n      []\n\nrange 在 for 中的使用：\n  for i in range(n):      # 正序遍历，表示i的取值从0到n-1\n  for i in range(n,0,-1): # 倒序遍历，表示i的取值从n到1\ndict字典\ndict字典使用键-值（key-value）存储，具有极快的查找速度。在Java中也称为map。\n\n举个例子，假设要根据同学的名字查找对应的成绩，如果用list实现，需要两个list：\n      names = [&#39;Michael&#39;, &#39;Bob&#39;, &#39;Tracy&#39;]\n      scores = [95, 75, 85]\n\n给定一个名字，要查找对应的成绩，就先要在names中找到对应的位置，再从scores取出对应的成绩，list越长，耗时越长。\n\n如果用dict实现，只需要一个“名字”-“成绩”的对照表，直接根据名字查找成绩，无论这个表有多大，查找速度都不会变慢。用Python写一个dict如下：\n  &gt;&gt;&gt; d = &#123;&#39;Michael&#39;: 95, &#39;Bob&#39;: 75, &#39;Tracy&#39;: 85&#125;\n  &gt;&gt;&gt; d[&#39;Michael&#39;]\n  95\n\n我在刷题的时候，遇到一个问题就是需要在循环中动态往dict添加数据，但是没有找到添加的函数，其实不用插入函数，循环中动态往dict添加数据也很简单，如下所示：\n      dt = &#123;&#125;  #先定义一个字典，注意是&#123;&#125;，如果定义数组是[]\n      for i in range(n):\n          dt[key[i]] = value[i]\n\n\nsort与sorted的排序问题\nsort参数说明\n  L.sort(cmp=None, key=None, reverse=False) \n\nsorted参数说明\n  sorted(iterable, cmp=None, key=None, reverse=False) –&gt; new sorted list\n\niterable：是可迭代类型，通常为一个集合; \ncmp：用于比较的函数，比较什么由key决定,有默认值，迭代集合中的一项; \nkey：用列表元素的某个属性和函数进行作为关键字，有默认值，迭代集合中的一项; \nreverse：排序规则. reverse = True 表示降序 或者 reverse = False 表示升序，默认值为False。\n\n\n使用sort()方法对list排序会修改list本身,不会返回新list，使用方法如下：\n  my_list = [3, 5, 1, 4, 2]\n  my_list.sort()    \n  print my_list\n\n  #输出： [1, 2, 3, 4, 5]\n\n而使用sorted()方法排序时会返回一个新的list：\n  my_list = [3, 5, 1, 4, 2]\n  result = sorted(my_list)   #返回一个新的list\n  print result\n\n  #输出： [1, 2, 3, 4, 5]\n\n\n常用的一些零散的小知识\n求实数的多少次幂\n\n正常在java和C语言中，求一个数的幂需要调用一个求幂的函数，但是Python中直接一个运算符就可以搞定了：\n  #Python求幂\n  10**2  #10的平方\n  10**4  #10的4次方\n\n\n\nprint(‘xx’,end=’’)中end问题\n\nend是print（）函数的一个参数。end 是输出语句结束以后附加的字符串，它的默认值是换行（’\\n’）。如果输出的时候不需要换行需要显示的给end赋值。\n\n例如输出一个数组，每个数之间以空格隔开，可以用如下语句：\n      for i in range(n):\n          print(data[i],end=&#39; &#39;)  #end值为空格\n\n如果只是单纯的想要输出不换行，可以令end=&#39;&#39;，end值为空字符串\n\n// 与 / 的区别\n\n“ / “  表示浮点数除法，返回浮点结果;\n\n“ // “ 表示整数除法,返回不大于结果的一个最大的整数\n\n【code】\n  print(&quot;6 // 4 = &quot; + str(6 // 4))\n  print(&quot;6 / 4 =&quot; + str(6 / 4))\n\n【result】\n  6 // 4 = 1\n  6 / 4 =1.5\n\n记得用set去除重复元素\n\n如果一个数组中有很多重复元素，根据需求需要去除重复元素的话，可以使用set集合，类似于Java的HashSet。\n\n语法很简单，只需一行代码就可以去重，如下所示：\n\n【code】\n  a = [1,1,2,2,3,4,5]\n  a = set(a)\n  print(a)\n\n【result】\n  &#123;1, 2, 3, 4, 5&#125;\n\n\n","categories":["技术博客"],"tags":[]},{"title":"Kaggle初学者五步入门指南，七大诀窍助你享受竞赛","url":"http://tanqingbo.cn/2018/08/31/Kaggle初学者五步入门指南，七大诀窍助你享受竞赛/","content":"\n文章转自机器之心\n\nKaggle 是一个流行的数据科学竞赛平台，已被谷歌收购，参阅《业界 | 谷歌云官方正式宣布收购数据科学社区 Kaggle》。作为一个竞赛平台，Kaggle 对于初学者来说可能有些难度。毕竟其中的一些竞赛有高达 100 万美元的奖金池和数百位参赛者。顶级的团队在处理机场安全提升或卫星数据分析等任务上拥有数十年积累的经验。为了帮助初学者入门 Kaggle，EliteDataScience 近日发表了一篇入门介绍文章，解答了一些初学者最常遇到的问题。机器之心对这篇文章进行了编译介绍，另外也增加了一些机器之心之前发过的文章作为补充资源。\n\n一些初学者会犹豫要不要参加 Kaggle 竞赛，这并不让人奇怪，他们通常有以下顾虑：\n\n我该如何开始？\n我要和经验丰富的博士研究者比赛吗？\n如果没有获胜的机会，还值得参与吗？\n这就是数据科学吗？（如果我在 Kaggle 上表现不好，我在数据科学领域还有希望吗？）\n未来我该如何提升我的排名？\n\n\n如果你有其中任何问题，你就看对了文章。在这篇指南中，我们会解读上手 Kaggle、提升技能和享受 Kaggle 所需要了解的一切。\n\n\nKaggle vs.「经典的」数据科学\n首先，我们要清楚了解：\nKaggle 竞赛和「经典的」数据科学有一些重要的不同之处，但只要你以正确的心态接触它，就也能收获有价值的经验。\n\n\n\nKaggle 竞赛\n本质上，带有奖金池的竞赛必须满足一些标准：\n\n问题必须困难：竞赛不应该是一个下午就能解决的任务。为了得到最好的投资回报，主办公司会提交他们最大最难的问题。\n解决方案必须新：要赢得最新的竞赛，你通常需要进行扩展研究、定制算法、训练先进的模型等等。\n表现必须能比较：竞赛必须要决出优胜者，所以你和其他对手的解决方案必须要被评分。\n\n\n\n「经典的」数据科学\n相对而言，日常所用的数据科学并不需要满足这些标准。\n\n问题可能简单。实际上，数据科学家应该尽力确认易于实现的成果：可以快速解决的富有成效的项目。\n解决方案可以是成熟的。大多数常见任务（比如探索分析、数据清理、A/B 测试、经典算法）都已经有了已得到证明的框架。没必要重新发明轮子。\n表现可以是绝对的。即使一个解决方案只是简单地超越了之前的基准，那也非常有价值。\n\n\nKaggle 竞赛鼓励你竭尽所能，而经典数据科学则推崇效率和最大化的业务效果。\n\n\nKaggle 竞赛值得参加吗？\n尽管 Kaggle 和经典数据科学之间存在差异，但 Kaggle 仍然是一种很好的入门工具。\n\n每个竞赛都是独立的。无需设置项目范围然后收集数据，这让你有时间专注其它技能。\n\n练习就是实践。学习数据科学的最好方法是在做中学。只要没有每场竞赛都获胜的压力，你就可以练习各种有趣的问题。\n\n讨论和获胜者采访很有启发性。每个竞赛都有自己的讨论板块与获胜者简报。你可以窥见更有经验的数据科学家的思考过程。\n\n\n怎样入门 Kaggle？\n接下来，我们将给出一个按步进行的行动规划，然后慢慢上升到 Kaggle 竞赛中。第一步：选择一种编程语言\n\n首先，我们推荐你选择一种编程语言，并坚持使用。Python 和 R 在 Kaggle 和更广泛的数据科学社区上都很流行。\n如果你是一个毫无经验的新手，我们推荐 Python，因为这是一种通用编程语言，你可以在整个流程中都使用它。\n\n参考：数据科学领域 R vs Python：http://elitedatascience.com/r-vs-python-for-data-science如何为数据科学学习 Python：http://elitedatascience.com/learn-python-for-data-science深度 | R vs Python：R 是现在最好的数据科学语言吗？业界 | 超越 R，Python 成为最受欢迎的机器学习语言\n\n第二步：学习探索数据的基础加载、浏览和绘制你的数据（即探索性分析）的能力是数据科学的第一步，因为它可以为你将在模型训练过程中做的各种决策提供信息。\n如果你选择了 Python 路线，那么我们推荐你使用专门为这个目的设计的 Seaborn 库。其中有高层面的绘图函数，可以绘制许多最常见和有用的图表。\n\n参考：Seaborn 库：https://seaborn.pydata.org/Python Seaborn 教程：http://elitedatascience.com/python-seaborn-tutorial资源 | 2017 年最流行的 15 个数据科学 Python 库\n\n第三步：训练你的第一个机器学习模型在进入 Kaggle 之前，我们推荐你先在更简单更容易管理的数据集上训练一个模型。这能让你熟悉机器学习库，为以后的工作做铺垫。\n关键在于培养良好的习惯，比如将你的数据集分成独立的训练集和测试集，交叉验证避免过拟合以及使用合适的表现评价指标。\n对于 Python，最好的通用机器学习库是 Scikit-Learn。\n\n参考：Scikit-Learn 库：http://scikit-learn.org/stable/Python Scikit-Learn 教程：http://elitedatascience.com/python-machine-learning-tutorial-scikit-learn7 天应用机器学习速成课：http://elitedatascience.com/只需十四步：从零开始掌握 Python 机器学习（附资源）教程 | Kaggle CTO Ben Hamner ：机器学习的八个步骤\n\n第四步：解决入门级竞赛现在我们已经准备好尝试 Kaggle 竞赛了，这些竞赛分成几个类别。最常见的类别是：\nFeatured：这些通常是由公司、组织甚至政府赞助的，奖金池最大。Research：这些是研究方向的竞赛，只有很少或没有奖金。它们也有非传统的提交流程。Recruitment：这些是由想要招聘数据科学家的公司赞助的。目前仍然相对少见。Getting Started：这些竞赛的结构和 Featured 竞赛类似，但没有奖金。它们有更简单的数据集、大量教程和滚动的提交窗口让你可以随时输入。Getting Started 竞赛非常适合初学者，因为它们给你提供了低风险的学习环境，并且还有很多社区创造的教程：https://www.kaggle.com/c/titanic#tutorials\n第五步：比赛是为了更好地学习，而不是赚钱有了上面的基础，就可以参与到 Featured 竞赛中了。一般来说，为了取得好排名，通常需要远远更多的时间和精力。\n因此，我们建议你明智地选择参与项目。参加竞赛能帮你深入到你希望长期参与的技术领域中。\n尽管奖金很诱人，但更有价值（也更可靠）的回报是为你的未来事业所获得的技能。\n享受 Kaggle 的小诀窍最后，我们将介绍几个参与 Kaggle 的最受欢迎的诀窍，希望能帮你享受你的 Kaggle 时光。\n诀窍 1：设置循序渐进的目标如果你曾经玩过什么让人上瘾的游戏，你就知道循序渐进的目标的重要性。那就是好游戏让人着迷的诀窍。每一个目标都要足够大，以便带来成就感；但也不能太大，不然无法实现。\n大多数 Kaggle 参与者都没赢过任何一场竞赛，这完全正常。如果把获胜作为第一个里程碑，你可能会失望，尝试几次之后可能就会失去动力。循序渐进的目标会让你的旅程更加愉快。比如：\n提交一个超越基准解决方案的方案\n\n在一场竞赛中进入排名前 50%\n在一场竞赛中进入排名前 25%\n在三场竞赛中进入排名前 25%\n在一场竞赛中进入排名前 10%\n赢得一场竞赛！这种策略让你可以一路衡量你的进展和进步。\n\n诀窍 2：查阅得票最多的 kernelKaggle 有一个非常厉害的功能：参与者可以提交 kernel，即用于探索一个概念、展示一种技术或分享一种解决方案的短脚本。\n当你开始一场竞赛或感觉进步停滞时，查阅受欢迎的 kernel 或许能给你带来灵感。\n诀窍 3：在论坛中提问不要害怕问「愚蠢的」问题。\n提问能遇到的最糟糕的事情是什么？也许你会被忽视……仅此而已。\n另一方面，你能得到很多回报，包括来自经验更丰富的数据科学家的建议和指导。\n诀窍 4：独立发展核心技能开始的时候，我们建议你独自工作。这将迫使你解决应用性机器学习流程中的每一步，包括探索性分析、数据清理、特征工程和模型训练。\n如果过早地和人组队，你就可能会错失发展这些基本技能的机会。\n诀窍 5：组队以拓展你的极限虽然太早组队不好，但在未来的比赛中组队让你能向其他人学习，进而拓展你的极限。过去的许多获胜者都是团队，这让他们可以结合彼此的知识共同施展力量。\n此外，一旦你掌握了机器学习的技术技能，你就可以与其他可能比你有更多领域知识的人合作，进一步扩展你的机遇。\n诀窍 6：记住 Kaggle 可以成为你的垫脚石记住，你不一定要成为一个长期的 Kaggle 人。如果发现你不喜欢这种形式，也没什么大不了的。\n实际上，许多人在做自己的项目或成为全职数据科学家之前都会使用 Kaggle 作为自己的垫脚石。\n所以你的关注重点应该是尽可能地学习。长远来看，参与能给你带来相关经验的竞赛比参加有最高奖金的竞赛更好。\n诀窍 7：不要担心排名低有些初学者担心低排名出现在他们的个人资料中，结果一直没有开始。当然，比赛焦虑是很正常的现象，并不只限于 Kaggle。\n但是，排名低真的没什么关系。没人会因此贬低你，因为他们曾经某个时候也是初学者。\n即便如此，如果仍然担心个人资料里的低排名，你可以再单独创建一个练习账号。一旦觉得自己能力不错了，就可以开始用你的「主帐号」来建立丰功伟绩了。（再说一下，这么做毫无必要！） \n结论\n在这篇指南中，我们分享了上手 Kaggle 的 5 大步骤：\n\n选择一种编程语言\n学习探索数据的基础\n训练第一个机器学习模型\n解决入门级竞赛\n比赛是为了更好地学习，而不是赚钱\n\n\n最后，我们分享了享受这个平台的 7 个诀窍：\n\n设置循序渐进的目标\n查阅得票最多的 kernel\n在论坛中提问\n独立发展核心技能\n组队以拓展你的极限\n记住 Kaggle 可以成为你的垫脚石\n不要担心排名低\n\n\n\n","categories":["机器学习"],"tags":[]},{"title":"你还年轻，不要被习惯束缚","url":"http://tanqingbo.cn/2018/07/30/你还年轻，不要被习惯束缚/","content":"\n记得以前我家附近的那马路上有一条减速带，每回我骑着摩托车从那里路过的时候都会颠一下，慢慢的也就习惯了，只要路过那个减速带的时候我的脑海都会提前告诉我，待会在前面会颠一下，后来有一天减速带撤走了，我再次路过的时候却把我吓了一跳：“为什么和我预期的不太一样？”习惯的力量可见一斑。\n\n之前也看到有朋友早朋友圈抱怨说：难道只有我一个人觉得Java的一些东西的声明和定义太繁琐了吗？我还是喜欢用Python。这位朋友应该是和我一样，被习惯给绑架了。学习任何一样新的东西的时候，我们总是能够轻易的找出几个这个东西的所谓缺点出来，然后在心里说服自己说：A不行，我还是接着用B吧！当心里出现这种想法的时候，就应该惊醒，自己是不是被习惯束缚了。\n\n类似的例子在生活中还有很多，比如，我见过很多人现在仍然用着WinXP系统，问其原因：XP用习惯了，用不惯高版本的系统；还有用惯了360浏览器，不习惯用Chrome；用惯了eclipse，觉得MyEclipse很别扭；用惯了iPhone，再用Android的时候觉得特别不顺手；用惯了Windows，就算买了台Mac也要想办法再装个Windows系统；用惯了一门编程语言，就不想再碰第二门编程语言……\n\n类似的例子还有很多，如果我们不去打破一些习惯的话，别说我们个人，一个公司，乃至整个社会都不会进步的。\n\n作为一个年轻人，应该要乐于去尝试一些新的东西，当我们在学习新的东西的过程中不顺手，或者难受的时候，记得要提醒一下自己：是不是被习惯束缚了。有句话怎么说来着：当我们在学习新的东西的时候感到很费劲，恰恰说明我们正在进步。\n\n所以不要去抗拒那些让你不适应的东西，有可能这正好是最需要的东西，能给你到来益处。（这个不适应，仅仅指在学习上的不适应）\n\n你还年轻，不要被习惯束缚~\n\n\n","categories":["漂来漂去"],"tags":[]},{"title":"说说心里话：很高兴遇见你们","url":"http://tanqingbo.cn/2018/07/30/说说心里话：很高兴遇见你们/","content":"\n从今年3月末开始运营公众号到现在，4个多月的时间关注我的读者已经增长到1万多了，真的很高兴能够在这里和大家相遇。在这个过程中我自己成长了很多，也认识了很多新的朋友，因此有些心里话想和大家说一说：\n\n在这个互联网时代，随着用户的增加通常都会遇到一些奇奇怪怪的人，比如说“杠精”、比如说“喷子”。这种人我在知乎上遇到过不少，让我印象最深刻的一次是有一位朋在我的文章下面把我骂完一顿之后，又在他的知乎想法里面把我挂出来，骂我一顿，理由是我分享的干货不够全。但是在这4个多月的时间里，在我的公众号上从来没有遇到过这种情况，大家都在友善的沟通和交流，这应该算是我的幸运，也感谢大家多我的包容。希望大家再以后也能够接着包容我，如果我有什么不对的地方也请及时指出。\n\n\n很多人喜欢把积累的用户称作粉丝，但我觉得我们之间不是粉丝与博主的关系，你们在那么多的公众号里面发现了我的公众号，说明我们是有共同语言的，说明我们是能够交流，能对话的，所以我们是朋友的关系。在这个时代，谁都不傻，读者只会去挑选适合自己的公众号去阅读。既然你们选择了我，我以后也会努力输出有用的内容，希望不会辜负你们的期待。\n\n腾讯给微信公众号加的广告词是：再小的个体也需要有自己的品牌。从最开始做公众号开始，我就想着去打造一个属于自己的个人品牌。所以我想在这里给自己立一个flag，也算是对读者的承若：坚持原创，打造一个原创类型的公众号。\n\n其实做一个号，还保持持续输出这件事情很简单，只需要去各个平台转载和自己主题相关的文章就可以了，但是我觉得这样有点偏离了自己的初衷：输出的内容全都不是自己的，何谈人格品牌。我不想把它变成一个圈钱的工具，我希望在运营公众号的过程中和大家一起成长，一起进步，我希望我的内容能够帮助到大家。\n\n\n\n最后，写在2018年8月，相信只有写过文字或做过微信公众号的人才能体会其中的种种。今天过后，全部归零，因为有你们，我会继续写下去~\n\n希望大家能够多多支持我，或点赞、或打赏、或转发、或点广告，都是对我的一份鼓励和认可，感恩~\n\n\n","categories":["漂来漂去"],"tags":[]},{"title":"我想聊聊商业共赢模式和核心竞争力，就因为我出门打了个车","url":"http://tanqingbo.cn/2018/07/28/打完车回来，我想聊聊商业共赢模式和核心竞争力/","content":"\n前两天从外面打车回学校，上车之后和师傅闲聊了一会，之后他给我分享了一个二维码，我一看是一个叫XX出行的logo(为避免广告嫌疑我就不说具体名字了)，师傅说扫一下这个二维码车费能够减免5-15块。我一想这是好事啊，经确认安全后就扫了那个码。\n\n然后我就问师傅，你给我推荐这个平台的app，你有什么好处吗？他说，他正常载客该拿的钱平台会一分不少的给他，此外推荐新用户使用这个软件的话还会有额外的奖励。我一听就明白了，谁得钱都是不天下掉下来的，平台即奖励了司机，又奖励了乘客自有他的道理。为什么要推出这种模式呢？我仔细想了一下，大概有以下这几个原因：\n\n出租车司机该拿的钱没有少，反而还有奖励，自然乐意向大家推荐这款产品，乘客得到了优惠，企业获得了更多的用户，使自身更具有竞争力，长远来看这是一个三方共赢的局面，也是一个很不多的商业模式；\n相信大家都经历过支付宝和微信的支付大战，为了抢夺对方的用户，一到节假日，各种手段，各种支付红包补贴，我作为一个穷逼用户都能闻到硝烟的气息。其实在这个互联网时代，不光支付宝和微信在打仗，各个平台都竞争的特别激烈，如果不具备核心竞争力，不能推出好的战略在留住现有用户的同时吸引更多的新用户的话，早晚有一天会被对手一口吃掉；\n对于我们个人而言，其实也是一样，不管是在校大学生和研究生，或者是已经工作的同学，也得时刻具有危机感，想要脱颖而出，让更多的人注意到你，就必须不断的学习，提高自身的价值与竞争力。强者通吃会越来越成为每个行业的规律。\n\n\n说了这么多，其实我主要想说的是：MD，打车真的要比挤公交爽很多，哈哈~\n\n好像找到了新的奋斗目标了，为出门打得起车而奋斗，怀挺~\n\n\n","categories":["漂来漂去"],"tags":[]},{"title":"我是学计算机的，觉得自己很弱，要不要考虑换个专业？","url":"http://tanqingbo.cn/2018/07/26/我是学计算机的，觉得自己很弱，要不要考虑换个专业？/","content":"之前有个学计算机的大一的小朋友加我微信，跟我抱怨说：“自己的专业里面很多大神，有的同学在还没上大学之前就已经打过ACM比赛了，而我现在连编程是个什么概念都还没搞明白，感觉自己真的很弱，要不要考虑换个专业？”\n其实这种感觉我当时也经历过，当我还在努力记住“int”类型和“char”类型的区别的时候，我们专业已经有人在刷ACM官网上的算法题了，太变态了吧！后来慢慢熟悉之后，才发现那个刚入学算法题就刷的贼溜的朋友，他爸也是个程序员，在他们高中的时候也有开设过计算机相关的课程，所以并不是你不行，而是人家学的比你早。\n我相信很多刚上大学的朋友都会萌生这种想法：专业大神甩我好几十条街，这么菜的我要不要考虑转专业。今天就来聊聊这个问题，帮上大学之前没学过编程的同学打打气吧！\n首先你要清楚的是，高中的学习和大学的学习不太一样，在高中的时候有家长和班主任追在屁股后面催你学习，条件好的家庭还可以请家教培养你各种兴趣爱好和编程能力，所以当你刚进入大学校园的时候，你感觉你不如人家牛逼的时候并不能代表你不行，可能只是代表你的家庭条件或者母校没有人家好，但能考到同一所学校，说明智商都是一样的。\n第二点就是，大学是一场马拉松，我见过很多同学入学的时候各种牛逼，当我们还在努力弄清楚什么是编程的时候，他们已经能做一些小项目了，可是有一部分“大一时候的大佬”等到毕业的时候也没见到他们比入学的时候强多少，因为大学是一个开放的学习环境，再也没有人像高中班主任那样这么上心的催你学习了，全靠自己的自制能力，有的同学可能习惯被管着的学习方式，一旦没有人管了，就放弃治疗了，所以只要你的自制能力比较强的话，4年的时间，足够你追上任何一个大佬（一些特殊的变态除外）。\n还有就是想给学计算机的同学提个建议，编程实践能力真的很重要，在大学期间千万不要为了让自己的卷面成绩考的很漂亮而放弃了自己的动手能力，毕竟你以后是要去公司给公司带来效益的，而不是看你考试成绩打多少分。\n暂时只想到这些，欢迎大家接着补充和反驳~\n","categories":["漂来漂去"],"tags":[]},{"title":"好用的软件辣么多你的电脑装得下吗？云端超级应用空间免费给你用","url":"http://tanqingbo.cn/2018/07/26/好用的软件辣么多你的电脑装得下吗？云端超级应用空间免费给你用/","content":"今天给大家推荐一个超级好用的云端超级应用空间http://UZER.ME，不需要安装，就可以在线编辑Office，使用PS、Visio、Xmind、Matlab、Jupyter等等大型软件。\n以前还有CAD、WPS、SPSS等，不过最近下架了，但是不用担心，他们目前已经把服务迁移到阿里云上了，未来的服务肯定会更稳定，功能也会更多的。有了它，我们的PC上就不需要装那么多软件了。这个网站很简洁，使用方法也非常简单，下面给大家简单介绍下。\n官方网站https://uzer.me/\n网站截图及使用方法\n\n首先打开网站，或者下载客户端安装，留作工作备用，目前支持PC端、MAC端、手机端。\n\n\n然后，点击注册，完成资料填写，进行基础设置或者直接用微信扫码登陆。\n\n\n登陆之后可以看到各种软件的端口，大家可以看到这里提供的软件非常多，并且无需安装，运行不占本地内存，打开的时间可能会有点长，稍微等下就可以使用了。\n\n\n举个例子，比如我想使用visio画个流程图，直接点击visio打开应用。画完以后，选择保存到云文档库。然后回到首页，选择云文档库，找到已保存的文件，即可下载。当然，你也可以上传文档，进行在线编辑。据说还可以发送链接给好友，就可以和他一起写PPT，一起用PS 作图。不过我还没用过这个功能，大家可以试试~~\n\n好啦，今天就介绍到这了，如果发现没有你们想要的应用软件，也不要失望，可以去论坛留言，说不定不久就会出现来了，目前他们团队正在招测试用户，感觉未来会发展的很好的。\n","categories":["资源分享"],"tags":[]},{"title":"博士在读一周年，我能谈点什么呢？","url":"http://tanqingbo.cn/2018/07/24/博士在读一周年，我能谈点什么呢？/","content":"实验室最近来了两个新入学的师弟，尽管在心里还是百般的不想承认，终究无法回避这个事实：我已经博士在读一周年了。白天的时候还没什么感觉，可是晚上在刷朋友圈的时候，发现学弟学妹们在晒毕业照和毕业感言，顿时又把我拉回了一年前。\n一年前毕业的时候，为了毕业旅行，没来得及参加毕业典礼的我提前离校了，一个人背着包去了大理，虽然古镇的民谣很好听，洱海的风景很美，但也错过了很多，没有在毕业典礼上被校长拨过流苏，没来得及和老师同学好好的道别，现在想起来多多少少还是会觉得有点遗憾，毕竟，大学只有那么一次，毕业也只有那么一次，应该好好珍惜的。\n在毕业之后的这一年里，我经历了很多，也学会了很多东西，一年前的我怎么也不会想到我们宿舍10个人，最后只剩下我一个南方人还留在哈尔滨。在这一年里我被保送到哈工大直博，开始接触科研，我也在这一年里尝试着去学习摄影，虽然现在拍的仍然不怎么样，但是还是会有一些朋友会约我出去拍拍人像和毕业照。我开始利用空闲时间试着去做自媒体，公众号在3个多月内被将近9K用户订阅……..\n这一年真的教会了我很多，也有一些话想和大家分享，不一定有用，权当我是在闲聊就行：\n1、执行能力真的很重要。我始终相信贵人相助的这个说法，可是在贵人帮助你之前，你必须得展现出你配的上人家帮助的这个能力啊，有朋友见我的公众号做的还不错，也想整一个，我说好啊，我可以帮你，可是从那天之后朋友就再也没有动静了。\n不少人心中有一个想法的时候，都只是停留在想一想的阶段，想要去旅行、想要学好英语、想要写博客、想要做自媒体，可是永远都停留在想一想的阶段，不去行动的话，你就永远都只能站在门外，门内的一切精彩都与你无关。\n2、主动性真的很重要。这一点在我博士的这一年中感受尤为深切。通常一个导师都会同时带好几个学生，他没有那么多的精力对每一个学生面面俱到，如果你能主动的跟老师汇报近期的工作，并经常和他讨论一些想法的话，老师肯定会对你特别留心，有什么好处也会优先考虑到你的。如果事事都要等老师来找你，那你离被抛弃也就不远了。\n毕竟我们都是成年人了，没有谁会一直在你的背后催着你说，你要做这个，你要做那个。越早学会主动性，就越早把主动权掌握在自己的手里，不要做那个被剩下的人。\n3、积极承担责任很重要。小时候，家庭作业没做完的时候会撒谎说作业忘家里了，某件事办砸的时候，会用各种各样的借口来论证这个锅与我无关。\n但那时候我们还是小孩子，有被包容的权利，就算被识破也不会怎么样。但是现在我们不再是小孩子了，再找各种各样的借口来为自己开脱责任的话，只会让人觉得你这个人不靠谱，不值得深交。\n扯的有点多，现在回首想来，感觉时间过得飞快，一眨眼的功夫一年就过去了，庆幸的是这一年没有让时间流走太多，一直在奋斗一直在加油。\n最好的祝福送给这一年来给与我帮助的同学和老师。同样送给正在拼搏的你。\n","categories":["漂来漂去"],"tags":[]},{"title":"推荐一款特别厉害的在线工具，程序员的百宝箱","url":"http://tanqingbo.cn/2018/07/22/推荐一款特别厉害的在线工具，程序员的百宝箱/","content":"\n今天发现了一款特别厉害的程序员在线工具网站，堪称程序员的百宝箱。可支持在线运行php、c、c++、go、python、java等主流语言，页面简单明了，通俗易懂。\n\n\n此外还提供在线js美化、解压缩、混淆；在线css美化、格式化、压缩；在线编辑json；语法检查；转php,go类；还支持图片base64编码；常用进制转换工具；html转markdown；在线时间戳转换；一键推广外链等等，功能齐全强大。\n\n\n还有更多的功能可以自己去挖掘发现，在线工具页面如下图所示：\n\n\n\n官网：https://tool.lu/\n\n","categories":["资源分享"],"tags":[]},{"title":"说几件无关紧要的小事","url":"http://tanqingbo.cn/2018/07/20/说几件无关紧要的小事/","content":"1、最近来了不少新的读者，所以想向大家做一次正式的自我介绍，我谭庆波，有时候也叫厂长，如果你在这个号里面看到的文章作者叫谭庆波或者叫厂长的话，那么这个人肯定是我了。\n这个公众号里面的内容可能会经常出现在我的知乎（ID：谭庆波）上，如果你发现了的话，请不要大惊小怪，要是愿意顺手进去帮我点个赞的话我会很感激的。\n2、这个号是由我一个人在运营，定稿、排版、推送等一切工作都是我一个人在做，但是同时我还是一个在读的博士生，我有我的科研任务，所以请原谅我不能保证每天都推送一篇文章，我尽量保证一周推送3-4篇。此外我的文章不需要大家的赞赏，如果你觉得还不错的话，点一下文末的广告支持一下我就好了。\n3、为了减少我自己的压力，同时给大家提供一个展示自己的平台，我决定面向大家征稿，是的我准备征稿了。\n目前我的每篇推送的访问量在700-1500左右，也就是说你的文章一经被录用，至少会有700人看到你的文章，你可以在文章中留下你的个人网站链接和联系方式，让更多的人认识你。\n此外，文章被录用的话，我会提供20元稿费，阅读量到700之后，每增加200阅读量，稿费增加5元，统计周期为1周，一周之后结算稿费，投稿要求如下：\n原谅我是一个穷逼，只能付得起这些稿费，等用户数变多的时候，稿费会涨，我保证！\n所以，说了这么多，如果你觉得有兴趣的话，就给我投稿吧，把你的文章、姓名、联系方式发送至我的邮箱：&#49;&#x34;&#54;&#49;&#x38;&#x35;&#53;&#x35;&#52;&#53;&#64;&#113;&#113;&#46;&#x63;&#x6f;&#x6d;\n","categories":["漂来漂去"],"tags":[]},{"title":"你有被世界杯期间“脑残式广告”洗脑吗？","url":"http://tanqingbo.cn/2018/06/30/你有被世界杯期间“脑残式广告”洗脑吗？/","content":"你有被世界杯期间“脑残式广告”洗脑吗？\n世界杯期间最好看当然是激动人心的球赛了，想必前两天卫冕冠军德国队0：2输给韩国队的那场比赛很多人都记忆深刻，这场比赛至少可以让韩国吹上4年。\n\n关于这场比赛，在网上还看到一个球迷特别有技术含量的分析：\n      “\n      中国VS韩国  2：0\n      韩国VS德国  2：0\n      德国VS巴西  7：1\n      那么中国VS巴西比分应该是14：1\n      ”\n\n感觉的分析的好有道理，这个网友不愧是个资深的球迷，我现在好期待看中国和巴西踢的那场，如果有人知道中国和巴西哪天晚上踢，麻烦留言告诉我一声哈，啤酒花生米都准备好了，就等着看中国虐巴西了~\n##\n哈哈，作为一个伪球迷还是不和你们分析球赛了，想和大家来说（吐槽）一下世界杯期间出现过的那些洗脑的广告。\n\n首先必须要说（吐槽）的就是黄轩的马蜂窝广告，如果大家不记得了的话，我先帮大家复习一下：\n\n\n\n\n\n黄轩还没把“旅游之前”的台词念完，唠叨界的始祖唐僧，就站在黄轩旁边一直念叨“为什么要先上马蜂窝”，接着重复“哦哦哦”，后接片尾曲“嗡嗡嗡”。\n\n我室友看球的时候，每回一看到这个广告就暴跳如雷，可见它的功力。黄轩没有把唐僧暴揍一顿，或者是像《大话西游》里面的两头牛妖一样自行了断，我猜一定是马蜂窝的广告费给的很足。\n\n还有一个让我痛心疾首的广告就是刘昊然拍的那个知乎世界杯广告，不知道是不是也感染了世界杯的这波病毒，广告硬生生把刘昊然从小鲜肉拍成了老腊肉，在十多秒的广告中一直在问：“你知道吗？你确定你知道吗？你确定你真的知道吗？”\n\n\n\n\n\n直到我在知乎想法中看到了知乎CEO周源大大转发的某个网友的想法，我才明白这其中的深意，看来我这么多年的程序员白当了。\n\n\n\n其实任何的广告宣传都体现了商家对自身的考量和对客户的洞察，但这两个广告从观众的反应来看，这个洞察并不是很正确，似乎并没有取到“哗众取宠”的效果。\n当然也还有另外一个原因，互联网广告与传统电视广告不同的是，互联网网的广告可以用大数据和深度学习来锁定目标群体，你认为这些广告脑残、奇葩，可能仅仅只是因为你并不是它要找的观众。\n所以也有可能广告并不脑残，只是我不是它要找的观众罢了（你看我最后又圆回来了，黄轩和刘昊然的粉丝，你看咱现在可以把刀放下了吗~）\n\n","categories":["漂来漂去"],"tags":[]},{"title":"window下运行VTK程序","url":"http://tanqingbo.cn/2018/06/29/window下运行VTK程序/","content":"window下运行VTK程序\n通常一个简单的VTK工程由两部分组成，一个是C++的源码文件，后缀通常是“.cxx”或”.cpp”，这个文件中是编写的VTK程序代码。还有一个是CMakeLists.txt配置文件，每一个VTK工程都必须有一个名字为CMakeLists.txt的配置文件，方便程序在编译的时候找到VTK库。\n![](https://i.imgur.com/YCDpwKA.png)\n\n打开CMake软件，在Where is the source code:和Where to build the binaries:这两个框中选中VTK工程的目录（也就是包含上面两个文件的目录），如下图所示：\n\n\n![](https://i.imgur.com/Lb7L3d8.png)\n\n\n\n点击左下角Configure按钮，选择默认的编译器，等几十秒之后再中间部分会出现三行红色的文字，将CMAKE_INSTALL_PREFIX后面的目录改成源程序的路径，也就是和Where is the source code:后面的路径一致，同时将VTK_DIR的路径改成VTK_build所在的路径，然后再重新点击左下角Configure按钮，之后再点击Generte按钮，若最下面的框框中显示Configuring done和Generating done字样，就表示程序配置编译成功了。如下图：\n\n![](https://i.imgur.com/zyXF6VI.png)\n\n\n此时源程序的文件夹中就会多了很多文件，双击打开后缀为.sln的文件，VS会自动打开该文件。\n\n![](https://i.imgur.com/iDRlXG5.png)\n\n\n之后比那可以在VS中自由修改代码以及运行程序了。\n\n\n\n![](https://i.imgur.com/KSqj72S.png)\n","categories":["技术博客"],"tags":[]},{"title":"Linux诞生故事以及不同版本的区别","url":"http://tanqingbo.cn/2018/06/23/Linux诞生故事以及不同版本的区别/","content":"\n原文链接：http://www.bewindoweb.com/122.html\n\n\n                \n                    一、Linux的诞生Multics计划上世纪六十年代，人们还在用批处理计算机，也就是一次性给一批任务到计算机，然后等待结果，中途不能和计算机进行交互，而且准备作业需要耗费大量时间。于是1965年，贝尔实验室（Bell），麻省理工学院（MIT）和通用电气（GE）准备联手开发“分时多任务处理系统”，即300台以上终端机可以同时连接一台大型计算机进行作业，并取名为Multics（Multiplexed Information and Computing System，多路信息计算系统）。但由于项目进度落后，资金短缺，1969年，贝尔实验室放弃了这个项目，决定退出（后来Multics成功开发完成，尽管没有再被重视）。Unix的诞生与打飞机游戏调回到贝尔实验室的工程师看到费时的批处理机器，十分怀念先进的Multics。一位工程师Ken Thompson在研发Multics的时候，写了一个叫太空大战（SpaceTravel），是飞机发射子弹那种类型的游戏，然而这个游戏只能运行在Multics上面，他很想要移植这个游戏继续玩。1969年8月，Thompson在库房发现了一台闲置的PDP-7，刚好此时休假并且妻儿都去加利福尼亚探亲度假去了，经过四个星期的努力，用BCPL（Basic Combined Programming Language，基本组合编程语言）汇编语言编写了一组内核程序，还包括内核工具程序，以及一个小的文件系统。完成之后，Thompson激动地把身边的同时叫过来，让他们来玩他的游戏。由于这个系统是由Multics简化而来，同事们就戏称这个系统为\"UNiplexed Information and Computing Service”，即没路信息计算系统，缩写为Unics，取其谐音Unix。这时已经是1970年了，于是就将1970年定为Unix元年，现代计算机的计时也就是这个时候开始的（比如mysql数据库的TIMESTAMP）。Thompson使用的DEC PDP-7计算机Unix的发展Unix实在太好用了，这套系统在Bell实验室广为流传。但Unix是用汇编语言写的，高度依赖硬件，于是Thompson和Dennis Ritchie合作准备用更高级的语言改写，提高可移植性。Thompson改进了BCPL，称为了B语言，然而这套语言在内存方面有限制，一筹莫展。又和Ritchie尝试了Pascal，发现编译出来的内核性能并不好。最终Ritchie决定再对B语言进行改进，成为了大名鼎鼎的C语言，重新改写了Unix。1974年7月，Bell实验室公开了Unix，引起了学术界的广泛讨论，并大量应用于教育目的。1978年学术界老大伯克利大学，推出了以Unix第六版为基础并加入改进的新Unix，并命名为BSD（Berkeley Software Distribution伯克利分发版），于是Unix的分支BSD系列就诞生了。由于Unix的高度可移植性与强大的性能，加上当时并没有版权的纠纷，所以让很多商业公司开始了Unix操作系统的开发。然而当时Bell属于AT&amp;T，AT&amp;T被《谢尔曼反托拉斯法》规定了不能销售除了电话机电报机等之外的商品，后来随着AT&amp;T的分解，Bell可以卖出Unix了，第七版Unix明确提出“不可对学生提供源码”，Unix走向了商业化。高昂的授权费导致很多大学停止了对Unix的研究。Minix操作系统Unix进行了商业化，教师们都用不起了，1987年，身为ACM和IEEE两会资深会员的荷兰数学与计算机科学系统教授Andrew S. Tanenbaum开发了Minix操作系统，是Unix的缩小版，用于学生学习操作系统原理，很多技术大牛希望改进Minix，但遭到了AST教授的丑拒，他认为Minix就是为了教学，让学生一学期学完，并不想被加入杂乱的东西。GNU计划Richard M.Stallman看不惯版权收费，于1984年创立自由软件体系GNU（Gun is Not Unix），拟定了普遍公用版权协议（General &nbsp;Public License，GPL），所有GPL协议下的自由软件都遵循着Copyleft（非版权）原则：自由软件允许用户自由拷贝、修改和销售，但是对其源代码的任何修改都必须向所有用户公开 。GNU希望开发一个类似UNIX并且是自由软件的完整操作系统——GNU系统。到90年代初，GNU项目开发出许多高质量的免费软件，包括emacs编辑器（已经在博哥的带领下中毒……）、bash shell程序、gcc系列编译程序、gdb调试程序。POSIX标准POSIX（Portable Operating System Interface for Computing Systems）是由IEEE 和ISO/IEC 开发的一簇标准，该标准是基于现有的UNIX 实践和经验，描述了操作系统的调用服务接口，用于保证编制的应用程序可以在源代码一级上在多种操作系统上移植和运行。Linux终于诞生了此时，IBM公司开发的MS-DOS操作系统、Apple公司开发的Mac操作系统，Unix操作系统，Minix操作系统全都要收费。GNU尽管已经开发出最受期盼的GNU C编译器，开发的操作系统HURD却进度缓慢，渴求一款自由软件操作系统诞生来证明自己存在的价值。与此同时，Linus利用圣诞的压岁钱和贷款购买了一台386兼容电脑，并从没过邮购了一套Minix系统软件，在等待邮寄到达的期间，Linus认真学习了有关Intel 80386的硬件知识。为了能通过Modem拨号连接到学校的主机上，他使用汇编语言并利用80386CPU的多任务特性编制出了相关程序。甚至为了将老式电脑的软件复制到新电脑上，为一些硬件编写了驱动程序。Linus逐渐认识到了Minix的诸多限制，产生了自己编写一个新的操作系统的想法。1991年4月，Linus花费了全部时间研究Minix-386系统，并尝试移植GNU的gcc、bash、gdb到新系统上。1991年4月13日，Linus在comp.os.minix上发布信息说自己成功将bash移植到了Minix上，而且已经爱不释手，离不开这个shell软件了。1991年7月3日，Linus在comp.os.minix上透露了正在进行Linux系统的开发，并已经开始考虑POSIX的兼容了。1991年8月25日，Linus在comp.os.minix上发布了“What would you like to see in minix?”，透露出正在开发一个免费的386操作系统，新开发的系统会移植bash和gcc，并且声明他开发的操作系统没有用一行Minix的源代码。1991年10月5日，Linus在comp.os.minix上发布消息，正式向外宣布Linux内核诞生（Free minix-like kernel sources for 386-AT）。Linux遵循GPL协议，也给GNU运动送上了一份最好的礼物。Linux提供内核，GNU提供外围软件，GNU/Linux就成了密不可分的体系。&nbsp;二、Linux不同版本的区别linux官网提供下载的linux版本Red Hat系列点此进入官网1991年的Linux只是一个内核，安装这个操作系统需要进行交叉编译，入门难度实在太高了，于是出现了这样的公司，他们将公开好的内核加上开源的周边软件编译成二进制文件放到网上供人使用。Red Hat就是这样的一家公司，盈利方式则是提供打补丁、安装等收费服务。Red Hat一般以RPM包和YUM包进行管理，包分发方式是编译好的二进制文件。【运用建议】我们的操作系统实验就是在Red Hat上完成的，因为操作系统的老师好像十分喜欢Red Hat……反正我是感觉比较老……不想用……CentOS点此进入官网既然有人收费，那又有人不高兴了。于是有一个社区把Red Hat源码拿过来，然后编译成操作系统放出去，并且Red Hat补丁包出来一个月后，就放出补丁包，这就是Cent OS。然而2014年Red Hat收编了Cent OS团队。【运用建议】搭建VPS用这个用得比较多，因为稳定。FedoraFedora是Red Hat的桌面版本发展而来，免费，稳定性较差。【运用建议】没用过。Debian点击进入官网apt-get/dpkg/deb包管理，deb会自动的分析依赖关系，力争获取所有的依赖包。是迄今为止最遵循GNU规定的linux系统，最早于1993年创立，有三个版本分支：stable（稳定）、testing（测试，相对稳定）、unstable（不稳定，最新）。Red Hat的YUM也是在模仿APT。【运用建议】实习用过，非常好用，力荐。Ubuntu点此进入官网属于debian系列，是基于Debian的unstable版本加强而来，\n\n&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 30px;=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;apt-get/dpkg/deb包管理&nbsp;，适合桌面系统，衍生版本Kubuntu（桌面采用KDE，比较华丽），Xubuntu（要求配置较低），eubuntu（面向儿童和教育）。【运用建议】大学用来搭建Hadoop集群，感觉不太好用，适合新手和用windows用习惯了的用户。Gentoo点此进入官网最年轻的发行版本，被称为最完美的Linux发行版本之一，首个稳定版发行于2002年，拥有FreeBSD广受美誉的ports系统——Portage包管理系统，APT和YUM都是二进制文件分发的包管理系统，而Portage是基于源代码分发的，必须编译后才能运行，能将机器性能发挥到极致。【运用建议】没用过，据说Linux老鸟用起来非常顺手。&lt;spanhelvetica neue’,=”” helvetica,=”” ‘pingfang=”” sc’,=”” 微软雅黑,=”” tahoma,=”” arial,=”” sans-serif;=”” font-size:=”” 14px;=”” font-style:=”” normal;=”” font-variant:=”” font-weight:=”” letter-spacing:=”” line-height:=”” 30px;=”” orphans:=”” auto;=”” text-align:=”” start;=”” text-indent:=”” 0px;=”” text-transform:=”” none;=”” white-space:=”” widows:=”” word-spacing:=”” -webkit-text-stroke-width:=”” display:=”” inline=”” !important;=”” float:=”” background-color:=”” rgb(255,=”” 255,=”” 255);”=””&gt;&nbsp;                \n        &lt;/div&gt;\n","categories":["Linux"],"tags":[]},{"title":"邻域近似随机森林（NAF）对二维图像分割的源码解释","url":"http://tanqingbo.cn/2018/06/20/邻域近似随机森林（NAF）对二维图像分割的源码解释/","content":"软件\nmatlab2018a（2015版本以上最好，有的函数旧版本不兼容）, vlfeat-0.9.18\n源码结构0globalset\n0globalset/makeGlobalConst.m：记录程序要用到的全部目录路径、参数设置，点击运行，参数就会更新，并保存到const.mat中。一般只需要根据自己的本机情况修改根目录路径：\n        %% 根目录\n        FP_WORK = &#39;E:\\文献\\2DNAF\\&#39;;\n\n0globalset/addConstpath.m：把文件夹内的全部路径加入到环境变量（否则有的跨文件夹函数就找不到）。\n\n\nNAF\nNAFmain.m是程序运行的入口，参见代码的注释可以知道采用NAF的方法分割具体需要哪些步骤。\n\n数据预处理（preprocess.m）：\n\n首先将训练数据的img和label都存到train.mat中，变量名为：trainimgdata。并存在2DNAF\\database\\oridata\\oritrain文件夹中。\n\n之后再按照步长宽和步长分别为NPX、NPX、NIX、NIY对数据进行切分，切分成重叠的像素块，因为重叠是核心的方法，如果不重叠，就没有容错率，KNN判出来是什么就必须是什么，如下图：\n\n![](https://i.imgur.com/3gifREb.png)\n\n\n比如这个，如果没有重叠，会少标记3个像素，多标记1个像素；如果重叠，哪怕每个块像素都有漏分或者多分，也能产生一个投票数目，通过设定一个阈值就能更平滑地去分割。\n\n比如阈值设为2，也就是被2次判定为目标像素的才真的判定为目标像素，这样的话就是完美的分割；阈值设为1，只是多标记了2个像素而已。\n\n对img和label分块好的数据存放在trainpatches.mat中，和train.mat放在同一个文件夹中，trainpatches.mat包含如下信息：\n          patches(patchidx).imgpatch = imgpatch;%灰度图像快\n          patches(patchidx).gtpatch = gtpatch;%label图像快\n          patches(patchidx).fileidx = fileidx;%所属的图像文件ID\n          patches(patchidx).mx = mx;%相对左上坐标X\n          patches(patchidx).my = my;%相对左上坐标Y\n          patches(patchidx).ctrx = ceil(mx+px/2 -1);%相对中心X坐标\n          patches(patchidx).ctry = ceil(my+py/2 -1);%相对中心Y坐标\n          patches(patchidx).gtcl = culgtcl(gtpatch,1);%对应存入的标签，返回像素为1的像素值个数占总像素个数的比例\n          patches(patchidx).pid = patchidx;%PID\n\n之后再按照像素为1的像素值个数占总像素个数的比例（gtcl）将块数据分成11类，只要是因为数据太多，内存装载不下，所以需要分11次处理，视情况而定，可以多分一些类，名字为i_trainpatches.mat.\n\n\n\nmakeFeaPos.m:外部特征提取，采邻域样本特征值。FW为邻域的宽度，要大于块的长度。生成的随机领域坐标存在database\\feature_aux\\NAFfpos.mat中。\n\nNAFtrain()：训练NAF。\n\nextNAFFeature：训练之前需要先提取块（patches）的特征向量，先像素归一化，然后提取均值 / 标准差 / 最小值 / 最大值 / 中位数 / 中心3×3的纹理特征(LBP) / 邻域特征。提取向量特征的时候是提取上一步分好成11类中每一类的特征，并保存在i_trainFea.mat中。\n\n之后再将已经分成11类的i_trainpatches.mat中的label矩阵存储方式变成向量，方便计算，存储在\\feature_aux\\gtmat.mat中。\n\n随机选择特征值，即随机选择i_trainFea.mat中的值，保存在features变量中（第一列是pid，第2-7是那些均值之类的特征，剩下的都是邻域特征），然后计算pairdist距离，因为KNN是根据距离来找到最相似的图像的。距离公式和过程如下：\n\n![](https://i.imgur.com/Nw6Mtki.png)\n![](https://i.imgur.com/AP10ffe.png)\n\n\nL0 范数，含义为矩阵含0 的个数，分数下侧为块像素的大小。pairdist 的值越大，说明两个块像素的GT 图像差异越大，块像素越不相似；反之，如果pairdist 的值越小，则说明两个块像素的GT 图像值几乎相同，块像素相似程度越高。\n\n将pairdist距离和随机选择的特征传到构造树的函数中就可以训练树了。\n\n\n\nmakeNAFtree.m构建树：\n\n随机取阈值t，按照特征值得大小将块的特征分成左右两个子树，训练树，通过学习获得阈值t使得熵Eq取得最大值，Eq的计算公式如下：\n\n\n\n\n![](https://i.imgur.com/esBkSpz.png)\n\n\n\n+ 其中，Nleft、Nright 分别左侧和右侧的儿子节点， AvgDist 表示在节点Ni 处内部的块像素聚集程度。块像素越聚集，AvgDist 应该越小，块像素越分散，AvgDist 应该越大，所以定义AvgDist 为“距离”的平均值：\n\n![](https://i.imgur.com/TDPKeTo.png)\n\n\n\n找到使得熵Ep取得最大值的特征和阈值，就近似地将距离接近的块像素分到了一堆去。\n\n测试\n同样需要先将测试数据分块，再分成11类，然后提取均值 / 标准差 / 最小值 / 最大值 / 中位数 / 中心3×3的纹理特征(LBP) / 邻域特征等特征，保存在testFea.mat中。\n再将测试数据的特征传入之前训练好的树，再将每个块像素遍历INARF，每棵INAT都会得到它的KNN 训练块像素编号，把这些编号进行计数后由大到小排序，前KNN_K 个块像素就是被多棵INAT 都判定为相似的最相似训练块像素。如图4-7 所示为一个红色块像素PA 遍历INARF 的3 棵树的过程。第一棵树INAT1测试了N1 处的特征后，认为应该分到N3，再在N3 处测试特征后，认为应该分到N4，N4 是叶子节点，存储着“1，3，5，6”，它们都是具有和PA 相似特征的块像素。INAT2 在N3 处给出了“3，5，7，9”的结果，INAT3 在N5 处给出了“3，5，9，10”的结果，最后通过统计，输入块像素被三棵树判定为和“3”、“5”相似，被两棵树判定为和“9”相似，其余都仅被一棵树认为相似，如果KNN_K取4，那么最相似的四个块像素可能为“3，5，9，1”，“可能”的意思是，“1”、“6”、“7”、“10”都可能被选为第四相似的块像素。在这里不能仅仅根据这个统计数字来对最终相似块像素做一个判断，比如“3”、“5”块像素都被三棵树认为相似，只是因为排序算法的特性巧合地让“3”排到了“5”前面，它们的相似程度都是相同的。增加树的数目可以让被选中次数更加有辨别力，但是会增加训练和测试的复杂程度，并且总可能会发生被选中次数相同的情况。\n\n\n![](https://i.imgur.com/SxFQs2G.png)\n\n\n\n为了解决这个问题，INARF 的测试采用协相关系数来比较当前测试块像素和KNN 训练块像素之间的相似程度。协相关系数（correlation coefficient, CC）,计算公式如下：\n\n\n![](https://i.imgur.com/X8yAvlf.png)\n\n\n\n其中，mean 表示取均值，PA、PB 的尺寸都是L×W 的。注意分母不能为0，就要求PA、PB 的都不能是像素值全相同的矩阵，因此一旦检测到块像素的值全相同，则随机在模板上的一个位置增加0.0001。如果PA、PB 非常相似，那么CC 会趋近于1；如果PA、PB 反色非常相似，则CC 会趋近于-1；而如果PA、PB 不相似，CC 会趋近于0。只要找出“3，5，9，1”中和测试块像素计算CC 后绝对值最大的一个训练块像素，就是最相似块像素。再将这个最相似块像素的GT 图像作为测试块像素的GT 图像，作为分类结果。 \n\n","categories":["东搞西搞"],"tags":[]},{"title":"分享两个可供练手的Javaweb网站源码","url":"http://tanqingbo.cn/2018/06/09/分享两个可供练手的Javaweb网站源码/","content":"\n本科大二的时候记得有一回实验课，系主任给我们代的课。当时我特别认真的坐在第一排敲代码，老师可能是觉得我写代码的姿势特别的帅气，于是过来和我聊天，然后我凭借三寸不烂之舌成功把老师忽悠，下课之后就要邀请我去了他的实验室。\n老师的实验室很多同学都是做Javaweb开发，于是便开始跟着师兄们开始做网站开发，虽然现在已经转行， 但是还是很感谢那个老师把我拽进实验室，也由此锻炼了我还算可以的coding能力。\n今天我就把当时写的网站系统分享给大家来参考和学习，用到了spring、hibernate、bootstrap、dwr等技术，我自认为我写的代码可读性还算可以，因此在这里把源码提供给大家练手。\n在入手之前可能需要一些Javaweb的预备知识，可以先提前参考这篇文章再阅读源码：Java学习视频教程一网打尽\n\n博客网站\n这是一个类似于CSDN的博客网站，用户可以发表博客，智能检索博客，同时还带有文件上传与下载、在线预览等功能，方便大家实现资源共享；部分系统截图如下：\n\n源码地址：https://github.com/tqb4342/blog\n\n\n基于javaweb的众筹网\n这个网站是帮同学做的一个毕业设计，参考的是目前主流的众筹网站，包括发起众筹项目、赞助某个项目、资金管理、智能检索等功能，部分截图如下图：\n\n\n\n源码地址：https://github.com/tqb4342/Crowdfunding\n\n说明\n类似这种网站写过很多，这两个网站风格差别有点大，因此很适合用来给大家练手，之前买的服务器过期了，不然大家可以直接在线浏览这两个网站，我使用的是MySQL数据库，eclipse作为开发软件，而且代码需要使用的jar都包含再里面。\n\n用hibernate连接的数据库，它自带建表功能，只要程序运行起来，它会根据你的代码逻辑自动在数据库中建好系统所需要的表，在大家运行代码的时候，只需要修改一下WebContent/WEB-INF/applicationContext.xml文件中的MySQL用户名和密码就行。如下图：\n\n此外，还需要在MySQL中建立一个和applicationContext.xml配置文件中数据库名字一致的数据库，到此代码就可以顺利运行了，剩下的就得靠自己好好消化代码了。祝顺利！\n\n\n","categories":["资源分享"],"tags":[]},{"title":"实用且堪称神器的Chrome插件推荐","url":"http://tanqingbo.cn/2018/05/27/实用且堪称神器的Chrome插件推荐/","content":"\n\n\n\n\n\n\n\n\n实用且堪称神器的Chrome插件推荐\n\n\n\n\n\n\n\n\n精品软件推荐\n\n\n\n\n\n\n\n\n\n\n  \n\n前言相信很多人都在使用 Chrome 浏览器，其流畅的浏览体验得到了不少用户的偏爱，但流畅只是一方面， Chrome 最大的优势还是其支持众多强大好用的扩展程序（Extensions）。最近为了更好的利用谷歌浏览器，博主整理了一些常用的谷歌插件，分享给大家，考虑到一些无法翻墙的童鞋，给力的博主当然是顺便给出离线安装文件。\n正文闲话不多说，直接上推荐的插件，可以翻墙的直接点击标题跳转谷歌商店下载，不信的我下面也给出离线安装文件\n通用类插件1、OneTab：将无数 Tab 合并在一个页面很多时候我们在一个窗口打开太多的tab，每一个tab太小不容易管理，这时候使用OneTab能够把所有tab收起放在一个页面，点击就可打开该tab，非常方便。离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237428194\n2、Momentum：美到爆表的新标签页受够了新建页面时候的空白页的话可以试试，Momentum每天都会提供一张高清大图，都很好看。\n离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237426016\n3、markdown here超好用的一款插件，强烈推荐！！有个它再也不用担心编辑器不支持markdown语法了，写好以后直接一键转换。而且也是一个跨平台神器，比如我们可以把简书写好的文章（带md语法）直接复制到微信公众号，然后一键转换，格式几乎无变化！\n\n离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237430000\n4、Adblock Plus：免除广告困扰只要是使用 Chrome 的人都应该安装的一款扩展应用，可以帮助你屏蔽几乎大部分网页广告，如果存在漏网之鱼，还可以手动添加到屏蔽列。离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237412331\n5、LastPass：密码管理软件LastPass，全球知名在线密码管理工具之一，采用军事级加密算法，支持自动填充网站用户名和密码，与朋友分享登录信息等实用功能，且在全平台同步免费，无需订阅 Premium，即可在手机、网页、电脑端同步你的所有 LastPass 信息。离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237429060\n6、关灯看视频有时候网速太差，全屏以后分辨率很低，可以试试这个，可以让周围页面变暗从而达到最好的视觉效果。\n\n离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237427954\n7、二维码(QR码)生成器在线的二维码生成器。可以把当前的网页直接生成二维码，进行编辑。还可以把文字生成二维码，这个很重要！\n离线版下载地址：href=”https://u14797164.pipipan.com/fs/14797164-237430273“\n8、下载+Chrome的下载管理在二级菜单里，进去很不方便。装了这个插件就可以直接看和管理，很好用。\n\n离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237427303\n9、一键管理所有扩展Chrome其实很占内存，尤其当插件装多了以后会卡顿。不过有个这个就不用担心，用不到的时候把插件关掉就行了，随时开随时关。\n离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237427408\n10、购物党在线的比价工具，网购的时候可以看价格历史记录，以及各大网站的价格对比，也有查快递的快捷方式。经常剁手的童鞋要注意了~~\n离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237427693\n11、右键搜Chrome默认的搜索是谷歌搜索，没有翻墙的童鞋可能用起来不方便，但有这个这个就不用担心了。\n离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237427843\n12、印象笔记剪藏大象官方的一个插件，可以直接把当前网页直接保存的evernote，非常方便。\n离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237429322\n13、AlloyDesignerAlloyDesigner是来自Tencent AlloyTeam的前端开发工具，其只出现开发阶段的一定时期，可以在制作时期，也可以在开发测试期，旨在提高前端开发的效率，获得更加便捷的开发体验。AlloyDesigner的主要功能是加载Web页面的视觉稿，结合开发者工具(F12)进行页面的开发和调整。使用AlloyDesigner进行页面开发，基本上可以舍弃Photoshop进行页面的测量，以视觉稿做为背景蓝本进行开发，可以使开发体验更加便捷、高效，其结果页面也更高。AlloyDesigner也可以做为页面开发完成后，对页面进行细微调整，达到更加贴近视觉稿的目的。\n离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237430320\n14、新浪微博图床简单好用的新浪微博图床,支持选择/拖拽/粘贴上传图片,并生成图片地址,HTML,UBB和Markdown等格式,支持浏览和删除历史记录。离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237430064\n15、Cloudbleed Bookmark Checker：检测书签是否有死链\n对于书签收藏的狂魔同志，收藏夹里的网页肯定有很多都无法访问了吧！这款扩展就是来检测书签是否有死链的。因为不怎么常用，所以才三颗星。 \n离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237429807\n16、Infinity：功能强大的新建标签页扩展功能强大的新建标签页扩展！做的界面很美，每日壁纸质量也很高！有同步笔记、代办事项等，同时，喜欢它的网页图标，提供了很多常用网站的图标，自定义书签时很好看~唯一的缺点，就是感觉启动比较慢~离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237429572\n17、crxMouse Chrome Gestures对于国产浏览器自带鼠标手势的功能，真觉得很方便！这款扩展也是必装啊！离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237429513\n18、Imagus图片放大镜的功能！在体验了360浏览器、猎豹浏览器之后，特地去找的扩展！微博党的利器！这个不管能鼠标悬停放大图片，同时，对链接等也有预览。提供很多功能选项进行设置。离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237429468\n19、Save to Pocket\n看到感兴趣的先收藏着，然后走哪儿都能看，因为它提供了全平台的APP，方便管理。Pocket也是手机端我必装的APP之一。\n离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237429417\n20、网页截图:注释&amp;批注在安装了一堆截图扩展之后，最后剩下了它，满足了截图所有的需求，截取可见网页，选择区域，整个网页，另外，还有对截图的标记\n离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237429237\n21、眼不见心不烦（新浪微博）Chrome就是满分评价，可见这扩展真是良心扩展啊！微博党的福音！在浏览器端，自己通过这个插件进行设置，可以将热门微博、会员推广等等内容窗口都给屏蔽了！还我们一个干净、舒服的微博环境！推荐！！！\n离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237428838\n22、Image Downloader Chrome下载页面图片的工具，很棒离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237421737\n23、WhatRunsWhatRuns是一款用于了解网站技术的chrome网站技术分析工具，主要能通过分析网站页面所使用的框架、代码等技术以及页面所使用的样式等方面，让使用者能直观的了解网站的整体技术信息。在安装了这款插件后，使用者可以通过点击WhatRuns图标来打开插件窗口，通过该窗口使用者可以轻松了解网站的技术信息离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237421488\n24、Google翻译Google翻译是一款由谷歌公司提供的网页划词翻译插件，是Google Chrome的翻译扩展工具，由Google官方发布。安装后，会在Chrome浏览器菜单栏中添加一个按钮，可以方便的在任何时候点击翻译你当前正在访问的页面。离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237419781\n25、FireShot 任意方式截取网页的截图插件捕捉网页截图，编辑并将它们保存为PDF，JPEG，GIF，PNG或BMP；上传，打印，在Photoshop中打开，复制到剪贴板或电子邮件离线版下载地址：https://u14797164.pipipan.com/dir/14797164-26887957-b5742f/\n26、Lucidchart Diagrams - Desktop：在线绘制多种图表这个扩展程序是一款多功能绘制程序，支持绘制流程图，思维导图，版面设计等，并且有在线和离线两种模式，可谓功能强大。\n离线版下载地址：https://u14797164.pipipan.com/fs/14797164-238588636\n27、Trackr：追踪你的上网习惯这个扩展程序做的事情就是记录你使用 Chrome 上网的习惯，包括上了哪些网站、每个网站呆多长时间，并且还用图表的形式反馈出来，总之装了这个扩展程序就不要上奇奇怪怪的网站了。离线版下载地址：https://u14797164.pipipan.com/fs/14797164-238588363\n28、Reader View：Chrome 也有 Safari 的阅读模式将网页转换成 Safari 阅读模式的样式，让你更方便舒适的阅读网页文字，当你访问文章网页的时候，扩展程序的按钮会显示在地址栏末端，点击就能轻松享受更好的阅读模式。离线版下载地址：https://u14797164.pipipan.com/fs/14797164-238588468\n29、DrumUp：个性化的浏览推荐当你打开一个网页的时候，为您推荐与现在浏览的网页内容相似或者相关的内容，对于英文的支持比较好，每天阅读很多的人能找到很多关联的感兴趣内容。离线版下载地址：https://u14797164.pipipan.com/fs/14797164-238588751\n30、Mainichi：学习日语，每页一词学习日语的新方式，每当你打开一个新标签页对会显示一个日文单词，并且配有一张简洁的图片、假名及其读音，不知道有多少朋友在学习日语呢？离线版下载地址：https://u14797164.pipipan.com/fs/14797164-238589647\n31、New Tab Startup Quotes：学习成功人士的格言想学习成功人士的精神和智慧，这个扩展程序可以帮到你，每当你打开一个标签页，它都会显示一位成功人士的格言，不得不说熬得一锅好鸡汤。离线版下载地址：https://u14797164.pipipan.com/fs/14797164-238590300\n32、Unsplash Instant每次打开一个新标签页都会显示一张来自 Unsplash 的摄影作品，全高清的分辨率和专业的摄影元素，Unsplash 的作品都是满满的文艺范儿，非常适合文艺青年。离线版下载地址：https://u14797164.pipipan.com/fs/14797164-238590385\n33、Search by Image：强大的以图搜图Chrome 又一神器，结合 Google 以图搜图，可以快速让你找到一张图片的来源、其他尺寸、或者寻找到相似的图片，毕竟在搜索方面，还是 Google 做的最好。离线版下载地址：https://u14797164.pipipan.com/fs/14797164-238590409\n33、Instapaper：稍后阅读神器全球两大稍后阅读神器之一 (另外一款为 Pocket)，自从被 Pinterest 收购后，Instapaper 所有高级订阅功能完全免费，令人称道！当你对某个网页内容感兴趣，却没时间马上阅读，点击 Instapaper 图标或使用快捷键 (Cmd+Shift+S)，一键保存至 Instapaper，方便你随时随地进行查看。离线版下载地址：https://u14797164.pipipan.com/fs/14797164-238590481\n34、为什么你们就是不能加个空格呢 每次看到文章中的英文、数字、中文写在一起，你知道我的内心是什么样吗？你们能不能在它们之间加个空格呢？！不过自从装上了「为什么你们就是不能加个空格呢？」，插件会自动把网页中所有中文、英文、数字、符号之间插入一个空格，从此告别此痛苦，又能和大家好好玩耍啦。离线版下载地址：https://u14797164.pipipan.com/fs/14797164-238590634\n35、Clear Cache点击图标即可清除缓存、cookie等，开发必备！\n离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237429862\n开发类插件36、JSON ViewerJSONView 是一个方便查看 Json 结构的插件，展开，折叠，可以非常方便的查看接口返回数据。离线版下载地址：https://u14797164.pipipan.com/fs/14797164-238591310\n37、Postman\n相信开发者朋友一定知道这款插件，这是一款强大的 API &amp; HTTP 请求调试工具，它不仅可以调试简单的 HTML、CSS 以及脚本等简单的网页基本信息，这款 Chrome 插件甚至还能发送几乎所有的 HTTP 请求，可谓是 Web 开发者的一大利器。\n离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237420917\n38、Octotreegithub上查看代码的时候总是一层层进入再出来，有点麻烦，没关系，有Octotree。安装Octotree之后，浏览托管在Github上的项目，可看到左侧的树形结构，更方便查看代码。离线版下载地址：https://u14797164.pipipan.com/fs/14797164-238591356\n39、VimiumVimium 这个名字其实是 Vim 和 Chromium 的合体。可能很多童鞋已经猜到她是干嘛的了，她继承了Vim的常用操作，完全脱离鼠标来控制浏览器，是一款黑客级别的Chrome插件。对熟悉linux的同学来说，简直是神器。\n离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237429953\n40、Tampermonkey俗称‘油猴子’，是一款功能非常强大的插件，他包含：方便的脚本管理、脚本概览、设置多样性、脚本自动更新、安全、兼容性、Chrome 同步、CodeMirror 编辑器、JSHint 语法检查、快速开发、卸载等功能。 其官方描述只一句 The world’s most popular userscript manager。足见其优秀。离线版下载地址：https://u14797164.pipipan.com/fs/14797164-238591505\n41、Code Cola Code Cola是一个可视化编辑在线页面css样式的chrome插件。\n离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237430108\n42、WEB前端助手FE助手：包括字符串编解码、图片base64编码、代码压缩、美化、JSON格式化、正则表达式、时间转换工具、二维码生成器、编码规范检测、页面性能检测、栅格检测、JS运行效率分析等。\n\n离线版下载地址：https://u14797164.pipipan.com/fs/14797164-237430197\n总结整这个真是体力活，好几个小时才整理完，后面发现新的好玩的插件再补充进来，希望对你们有用。离线安装谷歌插件方法也很简单：1、打开谷歌浏览器输入：chrome://extensions/2、打钩开发者模式3、把下载的后缀为crx的文件拖进来即可安装\n\n\n  \n\n  ","categories":["资源分享"],"tags":[]},{"title":"结构学习","url":"http://tanqingbo.cn/2018/05/26/结构学习/","content":"1、什么是结构学习\n所谓结构学习就是输入或输出是有结构的数据，比如说语句、列表、树和边界框（bounding box）.而通常的网络学习之中，输入和输出都是向量。而在结构学习中，我们需要学习的是一个函数F，它的输入是一种形式，输出是另外一种形式，比如输入的是你语音，输出对应的文本、输入中文，输出英文，输入图像，输出bounding box，等等。\n2、结构学习统一框架\n结构学习具有一个统一的框架，可以表示为下图中的形式：\n\n![](https://i.imgur.com/yiBHXt3.png)\n\n\n在训练的过程中，我们希望找到一个这样的函数f，用它来评价我们的输入与我们的输出目前有多匹配，在测试的过程中，给定了一个x，我们穷举所有的y，使得F(x,y)最大的y即位测试结果。\n2.1 目标检测\n目标检测所要达到的目的是。输入一张图片，我们使用一个边界框在图像中标注出确定目标的位置。具体的训练的框架如下所示：\n\n![](https://i.imgur.com/FVIo0ip.png)\n\n\n在这里训练的过程就是在估计边界框与目标之间的匹配程度。\n\n\n2.2  生成摘要\n摘要生成的结构学习与上面的目标检测十分相似，首先训练一个函数 F使得摘要和文本的匹配程度最好，之后在测试阶段，穷举所有的摘要，从中选择得分最高的那一个。 \n\n3、 从统计的角度看待统一框架\n结构学习的统一框架与概率模型之间有着如下的对应关系：\n\n![](https://i.imgur.com/rH0Zuro.png)\n\n\n其中学习到的函数 F因为是在评估 x,y 之间的匹配程度的，所以可以认为是 x,y 同时出现的概率；而给定x 找最匹配的结果实际上可以认为是再找给定 x 的一个最大后验概率，所以这个过程实际上课贝叶斯分类的过程是十分相像的。\n\n但是使用概率的方法有有点也有缺点。优点在于概率模型是可解释的，有意义的；缺点在于并不是多有的东西都可以用概率进行描述，其次对于一个连续函数对所有的可能的结果进行求和是没有办法实现的。\n\n\n4、 结构学习与DNN之间的关系\nDNN实际上可以看作是结构学习的一个特例，两者之间的关系如下图所示：\n\n![](https://i.imgur.com/0aUYuhu.png)\n\n\n在上面的神经网络中，我们将 x 输入神经网络中，将输出与 y 做交叉熵，那F就是两者交叉熵的相反数，然后在测试的时候，穷举所有的标签，带入F中找使他最大的y。\n\n\n5、结构学习统一框架要解决的三个问题\n问题1 ：估计输入间的相似程度应该用什么方法，也就是说 F(x,y)应该长成什么样子 ；\n问题2：如何解决那个穷举所有找出最大的问题； \n问题3：给定了训练数据，怎么样找打合适的 F(x,y)。\n如下图所示：\n![](https://i.imgur.com/J7aOUNH.png)\n\n\n\n\n5.1 问题1：F(x,y) 的具体形式\nF(x,y) 的具体形式如下图所示 \n\n![](https://i.imgur.com/oC3HzwW.png)\n\n\n其中 ϕ(x,y)表示通过输入的数据和输出的共同构成的特征，而 w是对应的权重，这里通过权重与特征的线性组合，然后将这些线性组合以向量的点积的形式表示出来，就得到了 F(x,y) 。\n\n其中 ϕ(x,y)可以是自己定义的特征，也可以是通过深度学习得到的特征。\n\n\n问题2：如何解决那个穷举所有找出最大的问题\n这里假设已经得到如下的一个标签：\n\n![](https://i.imgur.com/PTDPzQ4.png)\n\n\n在这里我们假设是可以通过穷举或者某一种方式得到 y 。\n\n\n问题3：如何训练得到一个 F(x,y)\n因为在问题1中我们已经知道了这个 F(x,y) 是关于 w的函数，通过训练我们应该使我们的模型满足下面的条件：\n\n![](https://i.imgur.com/PhgqrHE.png)\n\n\n也就是说正确的标签所得到的函数值要大于所有非正确的标签的函数值。\n\nF(x,y) 的训练过程实际上十分简单，如下图所示：\n\n![](https://i.imgur.com/YYwArkY.png)\n\n\n输入是训练数据，输出模型的权重，在这里首先将 w初始化为0，一直重复以下操作直到 w不能被更新。\n\n对于某一组数据 (xr,y^r)，找到使 w⋅ϕ(xr,y)最大的 y˜r，如果得到的 y˜r≠y^r，就执行如上的更新。\n\n其实这个更新的原则也很好理解，就是让w离正确的值越来越近。\n\n\n","categories":["机器学习"],"tags":[]},{"title":"支持向量机：SVM","url":"http://tanqingbo.cn/2018/05/21/支持向量机：SVM/","content":"介绍\n支持向量机主要由两部分组成：折页损失函数(Hinge Loss)和核方法(Kernel Method)。损失函数\n假设我们输入的数据格式如下：\n\n\n![](https://i.imgur.com/WBALRcA.png)\n\n\n\n其中x表示数据向量，y表示数据标签，标签分为两类，即+1和-1.在这里去模型函数为：\n\n\n![](https://i.imgur.com/mVwb4YL.png)\n\n\n\n所以分类用的损失函数为：\n\n\n![](https://i.imgur.com/WIAa5MX.png)\n\n\n\n其中定义当计算出的函数值于标签不相等的时候取1，相等的时候取0，但是这样得到的函数有一点不好，它无法进行微分，即无法进行梯度下降。所以我们采用了另外一种函数作为损失函数，即：\n\n\n![](https://i.imgur.com/WLfnuIp.png)\n\n\n对各种损失函数的讨论\n在下面我们将讨论各种损失函数的特性，如下图所示：\n\n![](https://i.imgur.com/ivbr0M2.png)\n\n\n在上图中，横坐标是,如果预测的符号于原始标签的符号是相同的，那么它们的损失值为0，如果符号相反则损失值为1，其中黑色的线是理想损失函数曲线，但是可以明显的看到这是一个不可微分的函数，所以我们使用了近似损失函数进行代替，这个近似损失函数可以由多种选择，下面将对每一种可能的选择进行讨论：\n\n其中红色曲线是二次函数曲线，其损失函数的表达式为:\n\n\n\n![](https://i.imgur.com/MGHXKJr.png)\n\n\n\n我们可以看到当数据的标签值是 +1 的时候，预测值为 +1 可以达到最小的损失；当标签值为 -1 的时候，预测值为 -1 可以达到最小的损失。所以当 y^nf(xn)=1 的时候取到最小的损失函数值，但是在后面这个函数就是不合理的，因为随着预测值逐渐变大，损失函数的取值居然越来越大，这明显是不合理的。\n\n接下来我们考虑使用sigmoid+square loss作为损失函数，其函数曲线是蓝色的那一条，具体的损失函数如下：\n\n![](https://i.imgur.com/WEz0D2e.png)\n\n\n画出损失函数曲线如上图所示，这个方法的效果并没有使用交叉熵的效果好，具体原因如下：\n\n![](https://i.imgur.com/9PzPKez.png)\n\n\n从表达式可以看出，如果 ，那么整体的函数值将趋近于 ln1=0，如果 ，那么整体的函数值将趋近于 ∞，所以函数曲线如上图。这个函数曲线是合理的，因为随着 y^nf(xn) 的增加函数值会逐渐下降。对比 sigmoid + square loos 作为损失函数的方法，我们可以看到，当自变量（横坐标对应的值）取到负无穷的时候， sigmoid + cross entropy 会有很大的梯度值，而 sigmoid + square loos 的梯度值几乎为0，也就是说，前者在梯度下降的过程中，主要努力就会得到回报，而后者没有回报，所以也很有可能不想努力。另一点，在这里我们将交叉熵的函数值除以了 ln2，主要目的是希望可以得到理想损失函数的一个上界。\n\n最后我们来考虑折页损失函数(Hinge Loss)，具体表达式以及函数曲线如下图所示：\n\n\n\n![](https://i.imgur.com/QPi15kK.png)\n\n\n\n如上的损失函数，我们可以看到，对于一个正例，如果 f(x)&gt;1，那么便得到了一个完美的分类结果，如果是反例的话，如果 f(x)&lt;−1，那么便得到了一个完美的分类结果。所以x 不用太大，因为大了函数值也是相同的。观察函数曲线可以知道，当  的时候，就已经够好了，但是它们同向却在 penalty 认为实际上还不够好，虽然可以正确分类了，但是损失函数仍然或让自变量向右移动变得更好，这个区间也就是所谓的边界(margin)。其中损失函数中取 1 的原始，它可以得到理想损失函数的一个紧致的上界。\n\n如果我们对比交叉熵函数和折页损失函数的话，它们最大的区别在于对待已经正确分类的例子的态度。如果将图中的黑点从1 的位置移动到 2 的位置，我们可以看到交叉熵损失函数的函数值会继续下降，也就是说它在已经得到好的结果之后还希望得到更好的结果；但是折页函数是一种及格就好的函数，当大于margin的时候就好了。在实际的使用中，折页函数略优于交叉熵损失函数，就是说没有领先的很多。但是折页函数更能够顾全全局，当进行多分类的时候得到的效果会更好。\n\n\n线性SVM分类器\n线性的SVM的步骤主要如下图所示分为三部：\n\n![](https://i.imgur.com/BkgBMs2.png)\n\n\n第一部分是目标函数，这里使用如上图所示的目标函数，它可以表示为两个向量之间的点积运算，进而可以表示为权重的转置与输入 x 的相乘。\n\n第二步，构建损失函数，这里使用的是折页损失函数和 L2 的正则项，因为前面的损失函数明显是一个凸函数，后面的正则化项也明显是一个凸函数，所以这些的组合也是一个凸函数；\n\n这样在第三步就可以使用梯度下降的方法更新参数。有的人可能会想，这个函数是分段线性的可以使用梯度下降嘛，可以的。想想之前的RElu，也是这样的啊，同样可以使用梯度下降的方法进行训练。\n\n在这里我们可以看到，实际上逻辑回归和线性的 SVM 之间的区别就在于 损失函数的不同。另一方面，通过第一步我们可以看出，实际上SVM与神经网络之间是相通的，所以在2013年的ICML中有一篇文章是“Deep Learning Using Linear Support Vector Machines”。\n\n\n使用梯度下降训练SVM\n首先我们将损失函数中折页损失函数取出，并判断下面两个等式是否相等：\n\n\n![](https://i.imgur.com/eHB326w.png)\n\n\n\n实际上仅仅考虑这两个等式，他们之间是不相等的，但是同时考虑最小化如下的损失函数的话，两者就是相同的了：\n\n\n![](https://i.imgur.com/FaynAVz.png)\n\n\n\n这个时候我们用 ϵ 代替原来的折页损失函数，这里 ϵ 满足之前红色框框内的两个不等式，所以在这里我们认为他是松弛变量，而这样的问题可以使用二次规划的方法进行求解。\n\n核方法对偶表示\n最后分类函数的权重实际上是输入数据的线性组合，如下图所示 \n\n\n![](https://i.imgur.com/6Cw01WG.png)\n\n\n\n造成这种结果的原始，实际上可以通过之前所讲的利用梯度下降的方法更新参数的角度进行考虑。如上图所示，我们将所有的权重更新的过程合并成一个向量，其中的折页损失函数的导数记为 cn(w)，他的具体表达式也如上图所示。如果我们将权重的初始值设为0 的话，那么参数 w 实际上就是输入数据的线性组合，另外因为对于折页损失函数来讲，它里面有很多零的值，所以系数 α 中有很多的0，这样权重实际上是输入数据的稀疏组合，其中稀疏不为零所对应的数据点称为支持向量。这样的结果导致模型的鲁棒性更强，即使有离群值的点或者不合理的点，只要不选取它们作为支持向量，那么对于分类结果的影响并不大。\n由于在上面的部分已经证明了，SVM的权重实际上是通过输入点的线性组合得到，因此它可以表示为如下的形式：\n\n\n![](https://i.imgur.com/muKckUf.png)\n\n\n\n这里是将原来的求和转变为了向量相乘的形式，这个表达方式在机器学习中是常常使用的。在得到了的权重的对偶表达方式之后，第一步是进行变量替代，如下图所示\n\n\n![](https://i.imgur.com/gQ3zKcM.png)\n\n\n\n将 w 带入之后可以看到 f(x) 主要这三部分组成，第一部分是系数 α ，他是一个行向量，一共有 N 列，后面的两项可以使用矩阵乘法的结合律，得到一个列向量，一共有 N 行。所以 f(x) 可以表示为上图那种形式，将其中的  可以表示为 ，我们将K称为核方法。\n如下图所示，经目标函数表达为系数与  的线性组合之后，接下来的任务就是最小化损失函数：\n\n\n![](https://i.imgur.com/t0z0dSY.png)\n\n\n\n其中需要注意的是，虽然后一项中有 n 还有 n′ ，但是这两个的求和范围是相同的，只不过先对 n′ 进行求和运算再对 n 进行求和运算。在这里我们不是真的需要知道向量 xn，只需要知道向量 xn 与 xn′ 的内部关系即可。这种方法就叫做核技巧(Kernel Trick)。\n\n核技巧（Kernel Trick）\n当我们将原来的数据点映射到高维空间的时候，这个时候使用核技巧往往是十分有用的，如下图所示:\n\n![](https://i.imgur.com/ckjkiSd.png)\n\n\n如上图中我们将 x 映射到 Φ(x)，这个时候我们计算转化到高维再做点积，通过化简可以知道这个过程等价于先对原始数据进行点积，之后再平方。这种方式主要在输入数据是高维数据的时候可以减少大量的计算量，如下图所示:\n\n![](https://i.imgur.com/fY8XwY8.png)\n\n\n如果首先做高维映射的话，需要进行 乘法得到高维数据的点，之后再让高维的点之间进行点积，一共需要 3× 次乘法。但是如果首先进行内积运算在进行平方运算的话，需要计算 k+1 次乘法。这个计算量明显要小很多。所以核技巧的主要作用是减少计算量。\n\n下面再以径向基核(Radial Basis Function Kernel)为例进行介绍 \n\n![](https://i.imgur.com/HZHrMhu.png)\n\n\n我们可以看到如果将径向基函数用泰勒公式展开的话,我们可以看到是无穷多项的求和，所以是没有办法通过先向高维映射，之后在进行点积的方法求解的。另外通过上面的过程我们也可以了解到，实际上RBF(Radial Basis Function)核实际上是一种在无穷维上的分类器，虽然效果比较好，但是也十分容易过拟合。\n\n接着我们以 Sigmoid 核为例进行介绍\n\n\n\n![](https://i.imgur.com/xYYY2YO.png)\n\n\n\n我们实际上可以看到 f(x) 的计算过程可以通过如下的神经网络进行计算，对于输入的数据 x ，它首先与 x1 做点积，这个过程实际上即使在计算第一个神经元的加权输入，一共有 n 个这样的神经元，它们与对应的系数相乘再相加就可以可到目标函数 f(x)。因此使用 Sigmoid 核的SVM实际上是一个只包含一个隐层，激活函数为 Sigmoid 函数的神经网络。\n并不是所有的先对向量做点积再做其他操作都有对应的核函数，只有满足Mercer’s theory can check的才可以。\n\n深度学习与支持向量机的关系\n深度学习与支持向量机在原理上有很大的相关性，具体如下图所示:\n\n![](https://i.imgur.com/TvwTxJT.png)\n\n\n深度学习前面的隐层实际上是在做特征的高维映射，最后使用一个线性的分类器进行分类；\n\n而SVM使用核方法对数据进行非线性映射，之后在使用线性分类器进行分类。\n\n两者都是先特征映射再做分类的方法，这里实际上SVM的核方法也是可学习的，但是它们没有办法学习到深度学习那种程度。\n\n当你使用多个核函数的时候，对于两个核之间的连接的权重是可以学习的，就好像之前的SVM只有一个隐层，当使用多核方法的时候就相当于有多个隐层，那么它们之间权重就是可学习的了。\n\n\n","categories":["机器学习"],"tags":[]},{"title":"迁移学习（Transfer Learning）","url":"http://tanqingbo.cn/2018/05/18/迁移学习（Transfer Learning）/","content":"迁移学习（Transfer Learning）什么是迁移学习？\n通常对于同一类型的事业,我们不用自己完全从头做, 可以借鉴别人的经验, 往往能节省很多时间. 有这样的思路, 机器学习也能偷偷懒, 不用花时间重新训练一个无比庞大的神经网络, 借鉴借鉴一个已经训练好的神经网络就行.这就叫迁移学习。\n比如这样的一个神经网络, 我花了两天训练完之后, 它已经能正确区分图片中具体描述的是男人, 女人还是眼镜. 说明这个神经网络已经具备对图片信息一定的理解能力. 这些理解能力就以参数的形式存放在每一个神经节点中. 不巧, 领导下达了一个紧急任务,要求今天之内训练出来一个预测图片里实物价值的模型. 我想这可完蛋了, 上一个图片模型都要花两天, 如果要再搭个模型重新训练, 今天肯定出不来呀. #这时, 迁移学习来拯救我了. 因为这个训练好的模型中已经有了一些对图片的理解能力, 而模型最后输出层的作用是分类之前的图片, 对于现在计算价值的任务是用不到的, #所以我将最后一层替换掉, 变为服务于现在这个任务的输出层. #接着只训练新加的输出层, 让理解力保持始终不变. 前面的神经层庞大的参数不用再训练, 节省了我很多时间, 我也在一天时间内, 将这个任务顺利完成。\n\n如何做迁移学习？\n在实践中，我们通常不会完全从头开始随机初始化训练 DCNN，这是因为有能满足深度网络需求的足够大小的数据集相当的少见。作为代替，常见的是在一个大型数据集上预训练一个 DCNN，然后使用这一训练的 DCNN 的权重作为初始设置或作为相关任务的固定的特征提取器。 举个例子，我们知道Imagnet是目前最大的图像识别数据库，目前已经有很多基于imagenet数据训练的网络模型，如inceptionv3、v4等，假如现在给你一个任务，希望你能做一个车系识别，你有两个选择：\n\n一是搜集大量的车系数据，对这些车系数据进行模型训练；\n二是基于imagenet训练好的网络模型，然后把搜集好的车系数据加到基于之前训练好的模型继续训练，进行fine-tuning（微调）。\n\n\n传统的做法都是第一种，但是这就会遇到一个问题，一是车系的图片够不够多，体量够不够大？如果数据量不够，最后训练的效果会不会很不好？其实我们可以通过 把ImageNet 或其他大型数据集学习到的网络特征运用于一个图片分类或其他基于图片特征的任务，这就是迁移学习的思想。其实可以这样理解，如果从零开始训练，那么初始化权重一般情况下要么是都为0，要么随机设置，当我们导入了在大规模数据集上训练好的模型后，相当于在以这个模型现有的参数作为初始化的权重，不过至于在具体的任务上的泛化能力如何，还是得看具体的场景。\n\n\n迁移学习为什么能work？\n通常我们在做深度学习的时候，网络的每一个layer分别提取训练集上的不同特征，假如我们要用NN去做大象识别，可能第一层的NN的作用是判断图片上的动物是否有腿，第二层判断是否有尾巴….然后剩下的每一层都分别提取图片上的不同特征，当所有的特征都满足时则判断为大象，如果有特征不满足的话，则判断为不是大象，如下图所示：\n\n\n![](https://i.imgur.com/6XnZQoS.png)\n\n\n\n所以当我们要重新训练一个网络去识别其它动物的时候，例如识别猫与狗，我们就可以不用重新训练这个网络，可以把大象的那个NN前面几层拿过来，猫与狗他们有某些相同的特征，例如都有腿、都有尾巴、都有耳朵，因此我们把识别相同特征的layer直接拿过来用，相当于借鉴前人已有的经验，借鉴过来的网络不用训练，因为参数在之前已经训练好了，我们只需要训练新加的layer就好了，这样可以大量的节省网络训练的时间，而且就算我们的训练数据不足也能取得很好的性能。\n\n迁移学习的限制\n上文提到我们在迁移学习中会使用预训练的网络，所以我们在模型架构方面受到了一点点限制。比如说，我们不能随意移除预训练网络中的卷积层。但由于参数共享的关系，我们可以很轻松地在不同空间尺寸的图像上运行一个预训练网络。这在卷积层和池化层和情况下是显而易见的，因为它们的前向函数（forward function）独立于输入内容的空间尺寸。在全连接层（FC）的情形中，这仍然成立，因为全连接层可被转化成一个卷积层。所以当我们导入一个预训练的模型时，网络结构需要与预训练的网络结构相同，然后再针对特定的场景和任务进行训练。\n\n迁移学习相关资料\n对迁移学习感兴趣的同学，可以关注这个github repo：transferlearning,里面所有的资料与数据集都是由王晋东所整理。\n\n","categories":["机器学习"],"tags":[]},{"title":"无监督学习之生成模型","url":"http://tanqingbo.cn/2018/05/17/无监督学习之生成模型/","content":"什么是生成模型\n什么是生成（generation）？就是模型通过学习一些数据，然后生成类似的数据。让机器看一些动物图片，然后自己来产生动物的图片，这就是生成。\n\n以前就有很多可以用来生成的技术了，比如auto-encoder（自编码器），你训练一个encoder，把input转换成code，然后训练一个decoder，把code转换成一个image，然后计算得到的image和input之间的MSE（mean square error），训练完这个model之后，取出后半部分NN Decoder，输入一个随机的code，就能generate一个image。\n\n生成模型主要分为以下三种：\n\n2016年的PixelRNN;\n2014年Variational Autoencoder(VAE)\n2013年的Generative Adversarial Network(GAN)\n\n\n\nPixelRNN\nPixelRNN方法的主要过程如下图所示：\n\n![](https://i.imgur.com/bh1kg0q.png)\n\n\n在训练的过程中，首先输入图像的第一个像素，这个时候网络输出的是图像的第二个像素，然后将第一第二个像素作为第二次伸进网络的输出，输出为第三个像素点，以此类推，对网络进行训练。\n\n根据这个原理，我们可以输入半幅图像，通过该网络预测另外一半的样子。 \n\n假设我们给出了图像的一半，如下图，最左侧是原始图像，中间为输入遮挡一般的图像，希望补全另一半图像。后面是得到的三种结果。\n\n\n\n![](https://img-blog.csdn.net/20180117152002394?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZHVndWRhaWJv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n\n\n在训练上面这个网络的时候，一个直观的方法是将图像的 RGB 三个通道作为输入，但是这种方法得到的测试结果往往会偏灰色和棕色，这是因为神经网络的输出常常使得输出的三个值在数值上十分接近。因此在这里利用 1 of N encoding 对颜色进行编码，但是如果对所有颜色进行编码的话，总共有256256256种编码，维数过高，所以首先对颜色进行聚类，对聚在一类的颜色使用相同的编码，大大降低了编码的维数。\n\nVariational Autoencoder(VAE)\nAutoencoder在之前的博客无监督学习：深度自编码器中已经介绍了，主要过程如下所示：\n\n\n![](https://i.imgur.com/9MR0qlL.png)\n\n\n\n如果随机产生 code 然后经过 decode 之后是可以产生图像，但是要产生需要的图像，这个时候就需要VAE的帮助了。VAE的主要过程如下图所示 \n\n\n![](https://i.imgur.com/e3G8XgG.png)\n\n\n\n它的过程与 Aotuencoder 十分相似，前面的编码和后面的解码部分没有变化，中间的部分是添加的部分。首先如果你中间的编码部分希望得到的维数是3维的话，那么就会输出一个三维的 m 和一个三维的 σ，同时利用正态分布生成一个相同维数的向量 e ，经过计算得到编码 c（计算过程如上图所示），然后是解码的过程，**最终的损失函数是同时最小化重建误差和下面的累加求和。 **\n下面是VAE的实验结果：\n\n\n![](https://i.imgur.com/20C36LF.png)\n\n\n\n可以看出来 VAE 想画点什么东西出来，但是并不知道 VAE 具体想画什么出来。\n那么他与pixel Rnn 的区别在于哪呢？在 VAE 中，可以如下图所示 \n\n\n![](https://img-blog.csdn.net/20180117155640554?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZHVndWRhaWJv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n\n\n假如我们中间编码的是一个十维的向量，那么可以保持其中的八维不变，变化其中的两维，看看这两维对于图像的影响是怎样的。具体的实验结果如下图所示:\n\n\n![](https://img-blog.csdn.net/20180117155942835?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZHVndWRhaWJv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n\n为什么要用VAE的直观解释\n从直观的理解为什么使用VAE，与之前的自编码的区别在于哪里呢？ \n\n![](https://img-blog.csdn.net/20180117162133291?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZHVndWRhaWJv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n\n如上图，左侧是自编码过程，右侧是VAE过程。如果在左图中，取满月和弦月编码的之间点，输出的结果是怎么样的，会不会是介于两者之间的月相是不好说的。但是如果采用VAE的方法，他实际上相当于在编码的时候向里面加入了噪声，使得含有噪声的图像仍然可以恢复为原来的图像，那么加入取两者中间重叠的点，这个时候由于损失函数要使得恢复的误差最小，这样就需要综合满月和弦月的图像，很有可能就得到介于两者之间的图像。\n\n加入噪声的原理如下图所示 \n\n\n\n![](https://img-blog.csdn.net/20180117163356417?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZHVndWRhaWJv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n\n\n其中的 m 可以认为是原始的编码，而 σ 认为是方差，e 本身是从正太分布得到的，所以本身有固定的方差，将两者相乘相当于向编码中加入方差为某一个值的噪声，其中e 要取指数，这个时候就可以保证所得到的方差是整数的，而且又由于 σ 是通过网络得到的，所以网络在学习中可以自动调节噪声方差的大小。\n在训练这个网络时，不仅仅只是用之前的重建误差最小，还需要加入如上图黄色框中的那一项最小。因为如果让网络自己随便学习的话，他会倾向于不在网络中加入噪声，如果这样的话他就与之前的自编码器没有区别了，所以需要加入如下图的惩罚项。\n\n\n![](https://img-blog.csdn.net/20180117164610618?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZHVndWRhaWJv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n\n\n其中蓝色的那一项如图中的蓝色的曲线所示，途中红色的项如图中红色的曲线所示，两项相减得到的结果如图中的绿色曲线所示。我们可以看到，如果要使这一项取到最小值需要使得 σi 的值为0，这个时候 exp（σi）的值为1，而不是零，这样就可以保证加入模型中的方差不是0，即有噪声加入网络中。其中的 m 直接认为是正则项就好，可以增强模型鲁棒性。\n\n从VAE的原理解释为什使用VAE\n回到问题的本身，我们实际上是希望生成图像。假如我们将图像看作是高维空间上的一个点，那么我们需要的就是估计这些点在高维空间的分布，这个概率分布的大概的形式应该如下图所示：\n\n\n![](https://img-blog.csdn.net/20180118204254602?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZHVndWRhaWJv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n\n\n它在有宝可梦存在的地方的概率应该比较高，在没有宝可梦的区域应该比较低。所以可以从概率比较高的部分进行抽样，生成新的数据。\n\n而估计概率这件事情可以使用高斯混合模型。高斯混合模型可以大概表示为下图的样子 \n\n![](https://img-blog.csdn.net/20180118212820216?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZHVndWRhaWJv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n\n其中黑线是高斯混合模型的概率密度曲线，它是由许许多多个高斯模型按照一定的权重混合得到的。那如何从这样的混合模型中进行采样呢？首先我们选取从组成高斯混合模型的若干个高斯分布中选择使用哪一个高斯分布，然后对于选定的某一个高斯分布，他有着自己的均值和方差 μm,Σm ，根据他的均值和方差，就可以从中采样。\n\n对于高斯混合模型中参数的估计，实际上可以利用数据通过EM算法进行估计。\n\n实际上，之前有讲过，对数据进行聚类的话，不如对数据进行分布式的表示，有多少的概率属于A，有多少的概率属于B等等……而本质上，VAE就是高斯混合模型的分布表示的形式。\n\n![](https://img-blog.csdn.net/20180118214807380?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZHVndWRhaWJv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n\n假设 z 服从某一个标准概率分布，从这样的分布中采样若干个点，其中 z 可能是一个多维的向量，每一个维度代表一个属性。以一个 1 维的高斯分布为例，我们从中采样出一个 z ，然后根据 z 决定所对应的高斯分布的均值和方差 μ(z),σ(z) ，在这里我们的 z 有无穷种可能，不想之前的混合模型中只是几种高斯模型的混合。所以现在给定了某一个 z 那么如何得到对应的均值和方差呢？这里我们假设均值和方差是通过一个函数得到的，就是说给定一个输入 z 就会得到一个均值和方差（实际上就是一个高斯分布）。所以可以认为它们是通过一个神经网络的均值和方差（也就是说输入一个 z 输出可一个对应的高斯分布）。所以 P(x) 的表示方式就如上图所示。\n\n在下面的这个用来采样的分布不一定非要是一个标准的高斯分布，可以是任何分布。因为NN是powerful 的，它可以通过神经网络得到。\n\n\nVAE存在的问题\nVAE主要的问题在于，他一直希望能够模仿已经存在的数字，而不是希望真正的生成一张图像，如下图所示：\n\n![](https://img-blog.csdn.net/20180118230522610?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZHVndWRhaWJv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)\n\n\n假设生成的图像与原始的图像只有一个像素的差距，这个像素的位置有如图中的两种可能，可以明显看出左侧的那个图是更现实的，而右侧的图明显比较假，但是对于VAE来说这两张图象之间的loss很有可能是一样的，所以才会导致这样的问题。为了解决这个问题，才有后文的 GAN 模型。\n\n\n生成对抗网络（GAN）\n大名鼎鼎的GAN是如何生成图片的呢？首先大家都知道GAN有两个网络，一个是generator，一个是discriminator，通过两个网络互相对抗来达到最好的生成效果。流程如下：\n\n![](https://i.imgur.com/rw5YgTE.png)\n\n\n主要流程类似上面这个图。首先，有一个一代的generator，它能生成一些很差的图片，然后有一个一代的discriminator，它能准确的把生成的图片，和真实的图片分类，简而言之，这个discriminator就是一个二分类器，对生成的图片输出0，对真实的图片输出1。\n\n接着，开始训练出二代的generator，它能生成稍好一点的图片，能够让一代的discriminator认为这些生成的图片是真实的图片。然后会训练出一个二代的discriminator，它能准确的识别出真实的图片，和二代generator生成的图片。以此类推，会有三代，四代。。。n代的generator和discriminator，最后discriminator无法分辨生成的图片和真实图片，这个网络就拟合了。\n\n\n","categories":["机器学习"],"tags":[]},{"title":"我是如何从三本选手逆袭到哈工大计算机系博士的","url":"http://tanqingbo.cn/2018/04/17/我是如何从三本选手逆袭到哈工大计算机系博士的/","content":"我是如何从三本选手逆袭到哈工大计算机系博士的刚上高中的时候，我的目标是能考上一所三本院校，圆了大学梦就知足了。\n毕竟村里的娃，只要能上大学就算光耀门楣了，这波不亏～\n于是为了实现这个目标，我用了很多的办法来增加自己的筹码:\n想过要去当一个艺术生，可是作为一个胖穷，即没钱，也没艺术天分，遂放弃\n也在校体育队待过2年，可是一所连教学器材都缺的高中，哪还有体育设备供你训练啊，所以高二下的时候退出了体育队\n就在距高考还有一年的时间，终于意识到，还是老老实实学习比较靠谱，于是开始收心认真学习，要知道付出总是会有回报的，我开始能听懂英语老师念的那个单词是啥意思了，似乎好像也懂了那个一元二次方程应该怎么解了\n卧槽，原来我这么厉害的，既然我都这么厉害了，说不定我再努力一点能上个二本呢\n功夫不负有心人，后来高考的时候，我以压线的分数上了一所还不错的211\n有时事情往往就是这样，当你认真对待的时候，它能给你反馈一个意想不到的惊喜~\n刚上大学的时候，在学院门口看到两张海报，分别介绍的是刚毕业的两名优秀毕业生，他们一个保送了哈工大，一个保送了北航\n当时我的分数距这两所学校还差一张试卷的分数呢，这两位师兄简直就是偶像啊，激动的我赶紧和海报上的师兄合了张影\n当时的内心想法时：我只要能考上隔壁哈工程的研究生就行了，哈工大和北航就不想了\n其实自知之明我还是有的，但是有一样东西我没有，我没有钱啊，穷啊，为了养活自己，只好继续努力学习，挣点奖学金\n可是在自己的提升过程中，你就会慢慢的发现，原来我距那传说当中的国奖国励其实也不是很远，再努力一点，说不定就够着了\n原来通过自己的努力，我貌似也可以争取到保研名额，当年师兄能做到的，说不定我也能做到，或者做的更好\n人一旦在心里萌发出这种想法，就会想尽一切办法去浇灌它，让它生根发芽，开花结果～\n事实证明，上天不会亏待努力的人，后来在保研的过程中我分别收到了华科、西交、哈工大、中科院、重大抛过来的橄榄枝，如你所见，现在我来到了哈工大\n当年在高中最后一年开始努力学习的时候，我遇到了一位和我一样都是学渣并且准备在最后一年再挣扎一下的人，我们相互监督和鼓励，想方设法把一切能节省的时间都放在学习上，要是没有遇到这样一位同样渣的人，懒惰的我肯定也会坚持不下来，也就不会考上现在的母校\n大二的时候因为编程能力还行，被老师选进了实验室，因为被老师挑进来的人都还算优秀，大家相互促进，后来实验室同一届的同学，找工作的都去了BAT，保研的人都去了985，考研的人没有。\n准备保研的时候，认识一个同样保送哈工大的朋友，因为我就在哈尔滨上学，所以给他提供了很多帮助，后来研究生正式入学的时候，他说他去了清华，不来哈工大了，虽然在心里狠狠的骂了他一顿，但是还是很开心，因为这突然让我意识到，原来清华也不是遥不可及，踮起脚尖，再努力一点，应该也能触摸得到\n实验室里去年冬天毕业的博士师兄刚刚拿到了国家自然科学基金，今年马上要毕业的博士师兄去了一家创业公司当CTO，整天和我厮混在一起的胖穷硕士们，今天刚刚过了腾讯机器学习岗的二面，虽然渣渣的我现在依然一事无成，但一想到上面这些还是会很开心～\n这确实是一位以考上三本为梦想的考生的故事，\n所以，为什么要努力？因为努力会让你见识到更多不一样的风景，会让你发现，原来世界这么大却又无限可能~\n愿每个人都能享受到这种风景~\n","categories":["漂来漂去"],"tags":[]},{"title":"无监督学习之邻域嵌入法（Neighbor Embedding）","url":"http://tanqingbo.cn/2018/04/05/无监督学习之邻域嵌入法（Neighbor Embedding）/","content":"流行学习（Manifold Learning）\n流行学习（Manifold Learning）是机器学习、模式识别中的一种方法，再维数简约方面具有广泛的应用。他的主要思想是将高维的数据映射到低维，使该低维的能够放映高维数据的某些本质特征。\n\n流行学习的前提使有一种假设，假设某些高维数据实际是一种低维的流行结构嵌入再高维空间中。流行学习的目的是将其映射回低维空间中，揭示其本质。\n\n下图可以特别形象的解释流行学习：\n\n![](https://i.imgur.com/EId8APW.png)\n\n\n因为只有在同一维中，欧式距离才具有比较的意义，在上面这样的高维空间中式欧式距离并不能将不同的点进行很好的区分。\n\n在流行学习中认为上面这种情况实际上是将低维数据强行塞进了一个高维空间，所以我们应该将这个高维数据摊平，以便于后面的聚类或者接下来的有监督学习。更常用的应用是将它们可视化。\n\n接下来将依次介绍如下几种常用的将高维数据进行降维的方法：\n\n局部线性嵌入（Locally Linear Embedding，LLE）.\n拉普拉斯特征映射（Laplacian Eigenmaps）.\nt分布随机邻居嵌入（T-distributed Stochastic Neighbor Embedding，t-SNE）.\n\n\n\n局部线性嵌入（Locally Linear Embedding，LLE）\n如下图所示，首先对于某个数据点xi选择它附近若干个点xj，用wij代表xi和xj之间的关系，通过最小化下面的式子获得对应的权重：\n\n![](https://i.imgur.com/kns1GEM.png)\n\n\n在这个式子中，对于某个数据点xi认为它可以通过它周围的所有点的线性组合进行标识，令所有的点xj的线性表示与实际点xi的距离最小，得到点之间的权重wij，然后用得到的权重wij进行降维。\n\n![](https://i.imgur.com/fVZHLut.png)\n\n\n在找到wij之后，固定wij，然后通过上式找到对应的zj得到降维后的点。\n\n需要注意的是在这里对于整个降维过程并没有一个显示的表达，假如我们不知道x的具体值，只知道wij是可以进行操作的，另外还有一点需要注意的是，在邻域里选择几个xj点也是需要实验才能得到的一个超参数，如下图所示：\n\n![](https://i.imgur.com/RnJHLb6.png)\n\n\nK的值是选择的邻域点个数，如上图，当选择的邻域点数过少时，降维效果并不好，可能时因为无法表达点之间的关系；\n\n当邻域的点数过多时降维效果也不好，主要时因为这个方法的假设时基于局部线性假设，当选择邻域过大时，很有可能不满足局部线性的假设。\n\n\n拉普拉斯特征映射（Laplacian Eigenmaps）\n这是一种基于图的方法，首先根据数据点之间的相似性建立一个图，比如说相似性大于某个值就连接在一起，小于某个值就不连接。这时候如下图所示：\n\n![](https://i.imgur.com/BPg5cfm.png)\n\n\n这个时候两个点之间的距离就可以根据图上的连接来近似。\n\n回顾之前的半监督学习，在这里我们的损失函数定义为如下图所示的形式：\n\n![](https://i.imgur.com/w4TNiyY.png)\n\n\n这里使用有标签数据和无标签数据，其中无标签的数据的那一项更像是正则项，它刻画了标签到底有多平滑。将它应用到我们这里：\n\n![](https://i.imgur.com/HTTK1Qo.png)\n\n\n但是仅仅有这个表达式是不够的，因为我们只需要将所有的z都集中在同一个点，就可以达到最小值，所以还需要对这个等式添加约束：\n\n![](https://i.imgur.com/o8T6TYj.png)\n\n\n\n\nt分布随机邻域嵌入（T-distributed Stochastic Neighbor Embedding，t-SNE）\n上面的方法确实可以对高维非线性数据进行降维，但是它们只强调了要将相似数据放在一起，并没有强调将不相关的数据分开，所以常常会出现如下现象：\n\n![](https://i.imgur.com/j36eWlF.png)\n\n\n可以看到，相似的数据已经聚集在一起了，但是不同的数据也聚在一起，所以性能有局限性，这个时候就需要t-SNE了。\n\n具体的做法如下：\n![](https://i.imgur.com/9hJRFSM.png)\n\n\n\n\n对于降维之前的数据，计算两点之间的相似度，并将相似度进行归一化，对于降维之后数据点也是一样的。之后通过将两个之间的KL散度最小化得到降维之后的点向量。\n\n这里的相似度计算方法主要根据下面这种方式：\n![](https://i.imgur.com/ZNuZ6dt.png)\n\n\n\n\n其中原高维数据的相似性人根据RBF函数进行计算，这种距离的计算方式可以保证距离比较远的点之间相似性可以快速下降；\n\n在介绍t-SNE的相似性计算方法之前首先介绍SNE相似性的计算方法。SNE的相似性计算方法与之前的高维数据间的相似性的计算方法相同，但是t-SNE改用了下面的T分布的一种表达式，将两种计算相似性的方法曲线进行比较，我们可以知道，对于距离比较近的数据之间，它们经过计算相似性之后任保持着较为相近的距离，但是距离较远的点会变得更远，所以在保证将相似性的点放在一起的同时将不相同的点区分的较好，实验结果如下图所示：\n\n![](https://i.imgur.com/XyEpavS.png)\n\n\n从上图可以看到不同数据之间区分的很开。\n\n注意很少直接对高维数据进行t-SNE降维，因为计算高维数据之前，你的相似性是十分难确定的，因此首先利用常用的线性降维方法降维进行降维（如PCA），之后再利用t-SNE进行降维。\n\n\n","categories":["机器学习"],"tags":[]},{"title":"无监督学习之词嵌入or词向量(Word Embedding)","url":"http://tanqingbo.cn/2018/04/04/无监督学习：Word Embedding/","content":"为什么要使用词嵌入（Word Embedding）\n在词嵌入之前往往采用 1-of-N Encoding 的方法，如下图所示:\n\n\n![](https://i.imgur.com/XaPkO7B.png)\n\n\n\n使用这种1-of-N Encoding 的方法有两种缺点：\n\n词向量是正交的，因为正交的属性不能体现出相似属性的词之间的关系。\n这种方式编码的向量太长，若有10万个单词的话，就需要用长度为10万的向量进行编码，计算量和内存消耗都特别大。\n\n\n为了克服以上缺点，我们引入Word Embedding的方法。这种方法将词映射到高维之中（但是维数仍比 1-of-N Encoding 低很多），相似的词性的单词会聚集在一起，而不同词性 的单词会分开；每个坐标轴可以看作是区分这些单词的一种属性，比如说在上图中，横坐标可以认为是生物与其他的区别，纵坐标可以认为是会动和不会动的区别。\n\n因为在进行学习的过程中，我们只知道输入的是词的一种编码，输出的是词的另一种编码，但是并不知道具体应该是怎样的一种编码，**所以是Word Embedding无监督学习。 **\n\n\n词嵌入（Word Embedding）的两种方法\n词嵌入（Word Embedding）主要有基于统计（Count based ）和基于预测（Perdition based）的两种方法。\n\n基于统计（Count based ）的方法\n基于统计的主要思想是：两词向量共同出现的频率比较高的话，那么这两个词向量也应该比较相似。如下图：\n\n\n![](https://i.imgur.com/fbs22fw.png)\n\n\n基于预测（Count based ）的方法\n在这里神经网络的输入是前一个单词 wi−1 的词向量（ 1-of-N Encoding ）形式，经过神将网络他的输出应该是下一个可能出现的单词 wi 是某一个词的几率，因为是 1-of-N Encoding 形式，所以输出的每一维代表是某一个词的概率。然后取第一层的权值输入 z 作为词向量。如下图：\n\n\n![](https://i.imgur.com/2HO7A0v.png)\n\n\n\n在实际使用中，往往找的不仅仅是一个词与下一个词之间的关系，而是通过前面一堆词推出后面的一个词，在训练的过程中有类似于权值共享的行为，如下图所示：\n\n\n![](https://i.imgur.com/8lqmnMf.png)\n\n\n\n其中我们可以看到位于相同位置的输入神经元有着相同的权值（在途中用相同颜色的线表示出来），这样做的原因主要保证两点，首先在要保证对于在同一批输入的同一个位置的单词具有同样的编码（即相同的权重）；\n\n其次权值共享可以减少模型中参数的个数。\n\n那么如何保证在训练的过程中它们具有相同的权重呢？如下图所示：\n\n\n\n![](https://i.imgur.com/qKXRUPi.png)\n\n\n\n在梯度更新的过程中，首先对共享的权值参数设置相同的初始值，其次在更新的过程中不仅仅要减去自己对应的梯度，还应该减去另一个相同位置神经元的梯度，保证两个参数之间的更新过程是相同的。\n\n除了可以根据之前的词推出后面的词，还可以根据两边的词推出中间的词，或者从中间的词推出两边的词，如图：\n\n\n\n![](https://i.imgur.com/XA0UGEh.png)\n\n\n\n在这里虽然用了神经网络，但是并没有用deep learning，而只是用了一层的 linear hidden layer，主要是因为过去虽然有用过deep的方法，但是很难训练，并且实际上用一层就可以达到的效果。\n\n","categories":["机器学习"],"tags":[]},{"title":"【无监督学习之线性降维】Unsupervised Learning-Linear Dimension Reduction","url":"http://tanqingbo.cn/2018/04/04/【无监督学习】Unsupervised Learning-Linear Dimension Reduction/","content":"介绍\n本节主要介绍了两种线性降维的方法：Cluster和PCA,并从两个角度解释了PCA。\n\n聚类(Cluster)\n聚类的基本思想是将数据集中的样本划分为若干个通常是不相交的子集，每个子集称为一个**”簇”(cluster)**。K均值算法（K-means）\n\n\n随机初始化K个样本(点)，称之为簇中心(cluster centroids)；\n簇分配: 对于所有的样本，将其分配给离它最近的簇中心；\n移动簇中心：对于每一个簇，计算属于该簇的所有样本的平均值，移动簇中心到平均值处；\n重复步骤2和3，直到找到我们想要的簇.\n如下图演示了特征量个数和簇数均为2的情况：\n\n\n![](https://images2015.cnblogs.com/blog/788978/201605/788978-20160515010206539-637882739.gif)\n\n\n分层凝聚聚类（Hierarchical Agglomerative Clustering,HAC）原理\n顾名思义就是要一层一层地进行聚类，可以从下而上地把小的cluster合并聚集，也可以从上而下地将大的cluster进行分割。似乎一般用得比较多的是从下而上地聚集，因此这里我就只介绍这一种。\n所谓从下而上地合并cluster，具体而言，就是每次找到距离最短的两个cluster，然后进行合并成一个大的cluster，直到全部合并为一个cluster。整个过程就是建立一个树结构，类似于下图。 \n\n\n![](https://img-blog.csdn.net/20160601212744464)\n\n\n\n层次聚类最大的优点，就是它一次性地得到了整个聚类的过程，只要得到了上面那样的聚类树，想要分多少个cluster都可以直接根据树结构来得到结果，改变cluster数目不需要再次计算数据点的归属。层次聚类的缺点是计算量比较大，因为要每次都要计算多个cluster内所有数据点的两两距离。另外，由于层次聚类使用的是贪心算法，得到的显然只是局域最优，不一定就是全局最优，这可以通过加入随机效应解决，这就是另外的问题了。\n\n主成分分析(Principle Component Analysis,PCA)\nPCA降维原理可以从两个角度来考虑：\n基于最大方差原理，样本点在这个超平面上的投影尽可能分开。\n基于最小化误差原理，样本点到这个超平面距离都足够近。\n\n\n\n基于最大方差原理\n需要找到一个投影矩阵W，使得x在W上的投影方差尽可能大，其中W是由多个向量组成，其中W是由多个向量组成(w1,w2,w3…),希望x在w1上的投影的方差最大，w2上的投影的方差其次…..依次类推。\n\n![](https://i.imgur.com/rvlJPsm.png)\n\n\n并且，W是一个单位正交矩阵，即（w1,w2,w3,…）相互正交，且都是单位向量。\n\n![](https://i.imgur.com/2LWLhMU.png)\n\n\nPCA达到的效果就是decorrelation（去关联），所以最后投影之后得到z的协方差矩阵D是对角矩阵； \n\n投影矩阵W是单位正交矩阵。\nW就是x协方差矩阵S的特征向量。\n\n\n\n\n![](https://i.imgur.com/PNxZK3S.png)\n\n\n基于最小化误差原理\n基本思想：将近似看成由多个u组成，求解最小化他们之间的error时的系数c和分量u。\n其中向量(u1,u2,u3…)表示一个Basic component,如下图：\n\n\n![](https://i.imgur.com/ihgYAOa.png)\n![](https://i.imgur.com/pJugCGi.png)\n\n\n\n为了求解c和u（component），可以将X做奇异值分解SVD，用分解后的U代替u，ΣxV代替系数c其中U就是XXT的特征向量 \n有时候只选取特征值比较大的component。\nPCA相当于只含一层hidden layer的网络。\n\n\n![](https://i.imgur.com/ZejRQSr.png)\n\n\nPCA与LDA(Linear Discriminant Analysis)的比较\nPCA是无监督的，LDA是有监督的；\nPCA基本思想是方差最大，LDA基本思想是让不同类别分的尽可能开；\nPCA和LDA都是线性映射；\n对于结构比较复杂的降维，只能采用非线性流行学习比如局部线性嵌入(Locally Linear Embedding，LLE)等方法.\n\nPCA和非负矩阵分解(Non-negative Matrix Factorization,NMF)比较\nNMF分解之后的component的系数都是正的，就拿image来说，也就是说分解之后的component像是原始image的一部分;\n而PCA的系数可正可负，涉及到component的“加加减减” .\n\n","categories":["机器学习"],"tags":[]},{"title":"机器学习之半监督学习（Semi-supervised learning）","url":"http://tanqingbo.cn/2018/04/03/机器学习之半监督学习/","content":"介绍\n什么是半监督学习？既有有标记数据 xr，又有无标记数据 xu，一般无标记数据的数量远大于有标记数据。半监督学习又可以分为两种：\n**Transductive learning:**无标记数据就是Testing data.\n**Inductive learning:**无标记数据不是 testing data，假设在训练时不知道 testing set.\n\n\n为什么要用半监督学习（Semi-supervised learning）？\n因为收集数据比较容易，但是收集label数据的代价却很昂贵。半监督学习下的 generative model\n\n\n为了更直观的了解半监督学习下的生成模型，我们先介绍一下全监督学习下的生成模型，好让大家有个对比。\n\n全监督学习下的生成模型\n首先，估计 prior probability P(Ci)，再估计出每一类有标记数据的分布 P(x|Ci)，假设数据的分布为共用协方差矩阵的高斯分布，因此只需要估计出就行，之后就可以估计某个数据属于某一类的概率了，计算公式如下：\n\n\n![](https://i.imgur.com/pEZpzZL.png)\n\n\n半监督学习下的生成模型\n前面部分与监督学习的操作一样，先使用有监督的数据估计出 P(Ci)、μi 和 Σ，接下来使用未标记的数据 xu 来对这些参数重新估计，以二分类问题为例，估计过程主要分为如下两个步骤：\n初始化 θ={P(C1),P(C2),μ1,μ2,Σ}，（可以随机初始化，也可以根据已有的标记数据估计出来）。\nstep1：根据初始化的参数计算无标记数据的后验概率Pθ(C1|xu) 。\nstep2：更新模型参数：\n\n\n\n\n![](https://i.imgur.com/esLORLP.png)\n\n\n\n接着再返回step1，直到参数收敛为止。\n其实上面这个过程，我们用到了再机器学习领域一个超级NB的算法的思想，它就是EM(Expectation-maximization),step1就是 E，step2就是 M. 这样反复下去，在最终一定会收敛.\n\n半监督学习之低密度分离假设（Low-density Separation）\n在用这个假设的时候，需要假设有一个很明显的区域(Low-density),能够把数据分开。Self-training\n先对有标记数据训练出一个模型f*,这个可以模型可以用任何方法训练。\n用这个 f∗ 来预测无标记的数据，预测出的就叫 pseudo label.\n接下来，就用无标记数据中拿出一部分数据，放到有标记数据中，怎么选出这部分是自己定的，也可以对每一个数据提供一个权重。新加入了这些数据之后，就可以再重新训练一个 f∗，往复进行。 \n这招用在 regression 中，是没有用的，因为用预测出来的数字重新用来做训练，并不会影响模型的参数。\n在做 self-training 时，其实就是把某个未标记数据指定一个分类，而在 generative model 中，其实就是把未标记数据对应于各个分类的概率计算出来。\n\n基于熵的正则化(Entropy-based Regularization)\n假如未标记数据数据 xu 经过某一组参数估计后属于某一类的概率如下：\n\n\n![](https://i.imgur.com/cdqFgMG.png)\n\n\n\n又边红圈中的公式为熵的计算公式。由上图可知 xu 属于某一类的概率越大，熵的值E就越小，因此重新定义损失函数，其中E(yu)可以微分，我们可以直接用梯度下降法来求解。\n\nSemi-supervised SVM\n将未标记数据穷举所有的分法，然后对每一种分法都进行 SVM，具有最大的间隔和最小误差的那一种。但是，如果有 10000 个未标记数据，那么就会有 210000 种分法来穷举，Transductive Inference for Text Classification using Support Vector Machines 中提出的解决办法是，每次只改一个数据，看一下能否让间距变大，变大了就改。\n\n平滑假设(smoothness assumption)\n做出如下假设：\nx的分布不均匀，在有些地方集中，有些地方分散，若x1和x2在一个high density region内很接近，那么 y^1 就与 y^2 相同，那么什么是high density region呢？请看下图：\n\n\n\n\n![](https://i.imgur.com/zYSZZGN.png)\n\n\n\n在图中，虽然x2与x3比较接近，但是x1与x2在同一块high density region，所以 y^1 与 y^2 相同,y^2 与 y32 不相同。\n\n基于图的方法(Graph-based Approach)\n首先需要定义相似度，一般可以用 Gaussian Radial Basis Function (RBF) 来定义：，这个函数可以让相似度随着距离的增加而迅速减小。 \n定义完相似度之后，就可以逐渐把数据点之间相连的边加上去，加边可以用 kNN 或者 e-Neighborhood 的方法来做。然后设置边的权重，和 s(xi,xj) 成比例。 \n然后，定义在图上的标记的平滑因子(smoothness)S:，该式可以写成 ，y 是 R+U 维的向量（所有的有标记和无标记数据），L=D−W，W 是所有数据之间两两的连接权重，D 是对角矩阵，对角线上的值是每个数据点所有的连接的权重之和。之后，就可以定义出 loss function:\n![](https://i.imgur.com/oS2nken.png)\n\n\n","categories":["机器学习"],"tags":[]},{"title":"廖雪峰历时3个月打磨出价值1980的数据分析教程，终终终于免费啦！","url":"http://tanqingbo.cn/2018/03/30/廖雪峰历时3个月打磨出价值1980的数据分析教程，终终终于免费啦！/","content":"对比互联网各个岗位的裁员程度可以发现，数据分析相关岗位正在不断的扩招，已经成为了这波逆流中的黑马，什么原因导致的数据分析人才如此紧缺？\n因为数据分析是大势所趋，未来的发展空间会大有可为。随着5G网络即将商用，企业每天将会产生海量的数据，BAT日均数据更是达到了PB的级别，数据分析相关岗位才会存在着巨大的需求缺口。\n长此以往，企业要用尽可能少的人才，来满足尽可能多岗位的诉求，可以这么说，数据分析将会是每个程序员个人能力最重要的补充，也是BAT这类大公司急招人才的必备技能。\n但是一提数据分析，很多人就觉得无从下手，知识点零散总是抓不住重点，学习起来相当吃力。\n别急，这有一份由开课吧提供赞助，并由廖雪峰大神历时3个月打磨出来的《数据分析必备技能》的视频学习资料，由浅入深系统化的讲解，内容详尽，基本囊括了平时学习工作中经常用到的分析方式，特别适合对数据分析感兴趣想要入门提高的人学习。这份不可或缺的宝贵资料**原价值1980元**，现在小编为大家争取到了**28个免费领取名额（仅限前28名哦**）。\n学完这套资料你将得到哪些收获？\n1. 44个知识点纯干货内容，每天2小时，5天掌握数据分析必备技能；\n2. 对照自己掌握知识点进行查缺补漏，帮助你扫除知识盲区、重构知识体系。\n具体详细的资料内容：\n1、基础-Excel数据可视化\n\\1. Excel经典10种数据表\n\\2. Excel函数offset的3种动态图表\n\\3. Matplotlib 5个必会基础用法\n\\4. Matplotlib 5种常用图表绘制\n\\5. Matplotlib2种三维图形绘制\n2、基础-Python数据可视化\n\\1. JIE BA分词绘制词云图\n\\2. Pandas中的绘图函数\n\\3. 统计与机器学习-散点图矩阵\n\\4. 统计与机器学习-逻辑回归\n\\5. 3步轻松绘制决策树               \n3、进阶-使用SQL实现数据操作\n\\1. SQL基础语法\n\\2. SQL表连接\n\\3. SQL普通函数\n\\4. SQL窗口函数\n\\5. SQL优化 \n4、进阶-K-means聚类分析\n\\1. 利用K-Means聚类分析做客户分群\n\\2. 利用客户关系模型对客户进行细分\n\\3. 3种工具快速实现客户价值分析\n\\4. 案例：互联网金融行业客户价值分析\n5、高级-数据挖掘逻辑回归\n\\1. 数据挖掘应用前景 \n\\2. 逻辑回归预测算法\n\\3. 信用评分卡 \n\\4. 建立评分模型流程和统计量\n\\5. 生成信用评分模型\n此次仅有10个免费报名vip视频的权限（超额之后需要付费观看），机会难得，需要的朋友请尽快报名！\n \n\n\n扫码添加微信 \n仅限前28名免费领取\n廖雪峰的原价值1980元的视频资料\n此外，开课吧还联合Python教父廖雪峰老师及一线企业大牛一起，历经5个月精心打磨了付费课程《数据分析全栈工程师》，课程深度对标阿里P6+，可以帮助大家系统性地掌握数据分析技能和提升数据分析思维，实现升职加薪梦！课程火热报名中，欢迎各位和你身边有需要的小伙伴一起扫描上面二维码咨询哦！\n","categories":["技术博客"],"tags":[]},{"title":"深度神经网络(DNN)","url":"http://tanqingbo.cn/2018/03/28/深度神经网络(DNN)/","content":"深度神经网络(DNN)\n当我们训练网络的时候，通常会出现如下两种情况：\n第一种情况：训练数据表现不好，这种时候通常可以使用新的激活函数，或者调整学习率。\n第二种情况：训练数据表现的很好，但是测试数据的表现很差，这个时候可以提前终止、数据正则化和Dropout的方法来改善情况。\n\n\n\n\n![](https://i.imgur.com/wLGhv8P.png)\n\n\n\n不一定网络越深，performance越好。\n接下来我们先讨论针对以上两种情况，具体如何改善：\n对于训练数据表现不好时，用新的激活函数（New Activation function），再讨论**调整学习率(Adaptive Learning Rate)**。\n训练数据表现的很好，但是测试数据的表现很差时：提前终止、数据正则化和Dropout的方法来改善情况。\n\n\n\n第一种情况之激活函数梯度消失问题\n网络在做梯度下降时，如果我们用sigmoid作为激活函数，在接近输出的地方梯度很大，学习速度快，通过反向传播，在接近出入层的地方，梯度会变得很缓，学习效率很慢。这就是梯度消失的问题。\n因为sigmoid在接近0和1的地方会突然变得很缓慢。如图：\n\n\n![](https://i.imgur.com/q2ayj85.png)\n\n\n\n为了解决这个问题，我们引入其它激活函数。\n\n整流线性单元（ReLU）\n很自然的，我们会想到能不能引入一个变换均匀的激活函数，这样就能减缓梯度消失的问题了。于是我们引入了ReLU,它的函数图像如下：\n\n\n![](https://i.imgur.com/x8rRcmZ.png)\n\n\n\n小于0的部分函数值为0，大于0的部分函数为a=z。\nReLU的变种，有人觉得z值小于0的部分函数值为0，这个还是不好，没有梯度了。于是引入ReLU的变种。令z&lt;0的部分函数值为a = αz,其中α 也可以根据gradient descent学习出来，这样激活函数就变得更加合理了，可以在一定程度上减少训练时间。函数图像如下：\n\n\n![](https://i.imgur.com/T9CJIgZ.png)\n\n\nMaxout\n顾名思义，输出最大值，使用这种激活函数时，需要两个及以上结点组成一组，从下图中我们可以看出Maxout是如何工作的。\n\n\n![](https://i.imgur.com/PugJlvI.png)\n\n\n\nMaxout是可学习的激活函数，它可以是任何分段线性凸函数。有几段取决于每一组中元素的个数。\n\n\n![](https://i.imgur.com/jzP6tCO.png)\n\n\n第一种情况之学习率\n前面在讲梯度下降的时候讲到了Adagrad的方法，就是将每个参数的学习率除以其先前导数的均方根当作步长，在深度神经网络中，要介绍一种与Adagrad类似的学习率调整方法：RMSProp。\n\nRMSProp\n使用RMSProp方法的权值更新公式如下：\n\n\n![](https://i.imgur.com/We5pOBI.png)\n\n\n\n可以通过调整α使得下一次的权值调整是受当前梯度倒数gt的影响都一些还是受前面的调整多一些。如果α接近0，则受当前梯度倒数gt影响多一些。\n而且α的值还可以通过gradient descen的方法学习出来。\n但是这种方法很难找到全局最优值，通常在遇到局部最优点的时候就停止了。\n\n动量(Momentum)\n现实生活中，当一个球从高处滚落下来，在遇到平坦处和低谷处时，由于惯性的原因有可能还会继续滚动，直到到达全局最低点的位置。因此在机器学习中，通过学习率更新权值时，能不能也引入一个惯性，使迭代到达局部最优时，还有有一个动量继续向前，直到到达全局最优呢？\n基于这个想法，接下来开始Momentum方法：使移动的方向不仅基于当前求导的方向，还要参考上一次移动的方向。参数的更新过程如下：\n\n\n![](https://i.imgur.com/WbmAuOZ.png)\n\n\n\n加入了动量之后权值更行的过程中运动轨迹如下，在遇到平坦处和低谷时，由于受到上一次方向的影响，还会继续向前。\n\n\n![](https://i.imgur.com/4gZ7QvF.png)\n\n\n\nAdam：RMSProp + Momentum称为Adam。\n\n第二种情况Early Stopping\n网络在训练的过程中，可能训练的时间越长，对Training set的performance就越好，但是用训练时间很长得到的参数作用于Testing set时，有可能并不会得到预期中的好结果，反而提前结束训练得到的参数作用于Testing set能得到相对满意的结果。\n\n\n![](https://i.imgur.com/JFCOpx8.png)\n\n\n\n所以我们在训练时，有时需要提前结束，至于到底什么时候结束，我们也不清楚，这个时候，验证集的作用就体现出来了。\n在Training set分出一部分数据用来做Validation set，当获得的参数在Validation set取得好结果的时候，就停止训练，再将参数作用于Testing set。\n\n正则化(Regularization)\n权值更新公式如下：\n\n\n![](https://i.imgur.com/KpKXdg4.png)\n\n\n\n其中sgn(x)时符号函数，x为正数时值为1，x值为负数时，值为-1，x为0时，值为0.\n\nDropout\n在每次训练之前，都摘掉p%和神经元，如下图所示：\n\n\n![](https://i.imgur.com/1PlUDfj.png)\n\n\n\n这样训练没循环一次我们都是使用新的网络结构在训练。如果训练时神经元的摘除率为p%，则最后所哦于权值都乘以1-p%。\n假设dropout rate为50%，如果通过训练得到的权值为w=1，则最后令w=0.5作用于Testing set。\n\n\n","categories":["机器学习"],"tags":[]},{"title":"Java大牛带你从0到企业级项目开发","url":"http://tanqingbo.cn/2018/03/27/Java大牛带你从0到企业级项目开发/","content":"Java大牛带你从0到企业级项目开发前言\n前几天有个小师弟一脸委屈的跟我抱怨说，他特别认真的学完了C语言，可是学完之发现还是什么都不会，怎么可以这么快就结束了呢？我都还不会做网页，还不会写游戏呢！就连最后做的那个C语言大作业：学生管理系统都是长下面这个样子的，跟学校的那个管理系统完全不一样，什么鬼，感觉自己被骗了。\n\n\n\n我听完之后简直能笑出猪叫声，哈哈，这里没有黑C语言的意思，只是觉得这个段子很好笑。\n\n正文\n但是如果你真的想学习网站开发的话，我觉得还是学Java比较合适，毕竟现在几个的巨头互联网公司后端的代码要么就是Java写的，要么正在转成Java，下面这个问题在知乎可是火了很久的。\n\n\n\n所以我花了几天时间整理了一下Java网站开发方面的资料，从0到企业级项目开发，一共70多集视频教程，还包括项目的源码供大家学习和参考。\n\n\n\n获取方式\n获取的方式很简单，在我的微信公众号【轮子工厂】后台回复【javaweb开发】就可以免费获取这份大礼包了~\n\n","categories":["技术博客"],"tags":[]},{"title":"Deep Learning","url":"http://tanqingbo.cn/2018/03/24/Deep Learning/","content":"深度学习的三个步骤\n建立函数集合，即建立神经网络模型；\n训练模型；\n找出对数据表现最好的参数，作为模型的参数。\n\n\n![](https://i.imgur.com/qm0LVZS.png)\n\n\n全连接前向网络\n输入向量x与第一层神经元相连，将wx+b（其中w与权重，b为变差）经过激活函数（sigmoid或其它函数）的运算得到的结果作为下一层的输入，如此一直运算下去，直到得到整个网络的输出，该种模型称为全连接前向网络。如下图：\n\n\n![](https://i.imgur.com/AvboXu2.png)\n\n\n\n可以把不带权重和偏差的网络结构当作一个函数集合，通过训练学习到参数的网咯可以当作针对某一数据集的best函数。\n矩阵运算：\n网络的输入为一个向量X,对应的权重w是一个矩阵，因此在网络中的运算通常都是矩阵运算。\n\n\n\n\n![](https://i.imgur.com/xV2eN1T.png)\n\n\n\n因为时矩阵运行，可以通过并行计算的技术加速运算速度。\n\n交叉熵（Cross-Entropy）\n介绍交叉熵之前，需要先介绍一下信息量。举个例子：\n\n可以理解为，一个事件发生的概率越大，则它所携带的信息量就越小，而当p(x0)=1时，熵将等于0，也就是说该事件的发生不会导致任何信息量的增加。举个例子，小明平时不爱学习，考试经常不及格，而小王是个勤奋学习的好学生，经常得满分，所以我们可以做如下假设：事件A：小明考试及格，对应的概率P(xA)=0.1，信息量为I(xA)=−log(0.1)=3.3219事件B：小王考试及格，对应的概率P(xB)=0.999，信息量为I(xB)=−log(0.999)=0.0014可以看出，结果非常符合直观：小明及格的可能性很低(十次考试只有一次及格)，因此如果某次考试及格了（大家都会说：XXX竟然及格了！），必然会引入较大的信息量，对应的I值也较高。而对于小王而言，考试及格是大概率事件，在事件B发生前，大家普遍认为事件B的发生几乎是确定的，因此当某次考试小王及格这个事件发生时并不会引入太多的信息量，相应的I值也非常的低。\n熵其实是信息量的期望值，它是一个随机变量的确定性的度量。熵越大，变量的取值越不确定，反之就越确定。\n\n\n因此深度学习网络中，损失函数的网络就可以有交叉熵来定义，值越小，确定性越大，越准确。\n\n\n\n![](https://i.imgur.com/5JxoKHa.png)\n![](https://i.imgur.com/7w103l0.png)\n\n\n\n目标便是寻找一组最优的参数，使损失函数L最小，使用的方法就是我们熟悉的Gradient Descent。\n\n","categories":["机器学习"],"tags":[]},{"title":"判别模型(Discriminative model)和生成模型(Generative model)","url":"http://tanqingbo.cn/2018/03/22/判别模型(Discriminative model)和生成模型(Generative model)/","content":"前言\n前面讲的都是用线性回归模型预判某件事是否会发生，这一节讲回归用于分类。\n\n二分类问题\n我们以二分类为例子，定义模型输出大于0时，属于class1，小于0时属于class2.此时如果我们依然用y=b+wx作为我们的回归方程的话，就会出现如下的问题：\n\n![](https://i.imgur.com/Q27PGAb.png)\n\n\n当样本如图一所示的时候，程序能够很准确找出两类的边界，但是样本是像图二分布的话，程序找出来的分界线就会像紫色线那样，&gt;&gt;1的样本会被当成误差很大的样本点，实际上在分类问题中这类样本并不属于误差点。\n\n因此在分类问题中我们需要重新寻找模型函数，使得输入为样本x，F输出为为类别class，这类模型可以用感知器(perceptron)和SVM,但我们今天先讲另外一种模型。\n\n损失函数L可以定义为错误分类的次数，即L越小，分类错误数越小。如图：\n\n\n\n![](https://i.imgur.com/4LpKy5W.png)\n\n\nGaussain Distribution and Bayes’s theorem\n我们假设已知的训练样本满足高斯分布(Gaussain Distribution),当然假设样本时其他分布也行，比如二值特征还可以用伯努利分布(Bernoulli Distribution),但是在现实中高斯分布比较常见，我先假设样本满足高斯分布，可以减少工作量。高斯分布函数如下：\n\n\n![](https://i.imgur.com/7F4RzsF.png)\n\n\n\n由高斯函数求出来的是样本的先验概率P(X|C1)，根据贝叶斯(Bayes)公式：\n\n\n![](https://i.imgur.com/ywxAYYc.png)\n\n\n\n我们就能求出样本的后验概率P(C1|X)，即测试样本的概率。现在我们的问题就转化为根据训练样本求高斯函数的参数,一般我们采用最大似然估计法(Maximum Likelihood)求解这两个参数。有关最大似然估计法(Maximum Likelihood)可以参考我的这篇文章：从最大似然估计|贝叶斯估计|EM算法浅解|线性判别分析。\n我们整理一下上图的后验概率公式，可以得到一个sigmoid函数：\n\n\n![](https://i.imgur.com/YS4BcTh.png)\n\n\n\n把高斯函数代入z中，经过一系列的数学变换，可以把Z整理成wx+b的形式。 其中的w与b和前面用最大似然估计求出来的有关。求出来的结果如下：\n\n\n![](https://i.imgur.com/0nMHDV5.png)\n\n\n\n整理成wx+b的形式了大家是不是已经很熟悉了，因为我们在前面的线性回归案例中用的回归方程就是这种形式啊，那么是不是我们也可以用Gradient Descent的方法来求w与b呢，整最大似然法不是舍近求远了吗？\n这两种求w与b的方法分别对应我们题目所说的判别模型(Discriminative model)和生成模型(Generative model)，说了这么多，终于提到了和文章标题有关的东西了好难啊！用Gradient Descent的是判别模型，用最大似然法求解高斯参数的是生成模型。Logistic Regression\n上面的回归过程我们大致可以这样描述：某个事物有i个属性组成一个vector:(x1,x2,…,xi)，在某个节点处进行wx+b操作，得到的结果作为sigmoid函数的输入，函数的输出为即为事物的类别。我们把这整个这一组合的操作定义为函数f(x),过程如图：\n\n\n![](https://i.imgur.com/6EINn7S.png)\n\n\n\n假设已知w与b,给定一组Training data的特征和标签如下：\n\n\n![](https://i.imgur.com/0QZUw9T.png)\n\n\n\n则上图的序列出现的概率为，如果我们的模型越准确，则这个概率值越大，对其取反就变成模型越准确，值越小，正好满足loss function的要求。因此我们对前面的公式取反整理一下就变成：，从下图我们可以看出Logistic Regression与Linear Regression的异同：\n\n\n![](https://i.imgur.com/2l3VHak.png)\n\n\n\n到这一步的时候，问题就来了，为什么我们不能像Linear Regression一样用均方根差当作误差呢？我们用均方根差当作误差当作我们的loss function：\n\n\n![](https://i.imgur.com/iwhqekG.png)\n\n\n\n这样求偏导的时候，会出现如下情况，当超级接近目标时，梯度方向导数为0，即停止迭代。但是距目标超级远的时候也会出现梯度方向导数为0的情况，这就是我们不想要的结果了。所以在逻辑回归时，不能使用均方根差当作误差。数学推导过程如下：\n\n\n![](https://i.imgur.com/dSlc2V1.png)\n\n\n判别模型(Discriminative model) VS 生成模型(Generative model)\n我们用相同的Training data，分别用判别模型(Discriminative model) 和 生成模型(Generative model)求出w和b。然后比较他们的perfermance,实验结果为，生成模型模型准确率为：73%，判别模型准确率为79%。\n\n生成模型的优点\n因为训练前假设了数据分布模型，可以用较少的数据量训练出性能比较好的模型；\n因为训练前假设了数据分布模型，使其对噪音更加具有鲁棒性；\n\n判别模型的优点\n通过学习大量的Training data，一般准确率要略高于生成模型。\n\n","categories":["机器学习"],"tags":[]},{"title":"机器学习之Bias and Variance","url":"http://tanqingbo.cn/2018/03/21/机器学习之Bias and Variance/","content":"前言\n在上一节《机器学习之回归案例研究》中说过，在机器学习的模型中并不是越复杂越好，也不是越简单越好，都有可能在Testing data上造成较大的误差。那么这些误差到底是怎么造成的呢？我们这一节来讨论一下。\n\nBias and Variance of Estimator\n假设Testing data样本的均值为u,模型估计出来的均值为m,则u与m之间的距离为偏差（bias），设模型估计出来的标准差（Variance）为s。\n因为没有100%准确的模型，所以u不等于m.\n模型估计有点类似于打靶，虽然每个model瞄准的都是靶心，但是实际射中的地方一般都是距靶心有一定的距离，而我们要做的工作就是寻找一个方法使我们射出的目标距靶心更近。如下图所示：\n\n\n![](https://i.imgur.com/lh3s0wg.png)\n\n\n\n从下图我们可以得知，一般简单的模型都会有small Variance but large Bias的情况，而复杂的模型通常会有small Bias but large Variance，而且简单的模型受数据量的影响较少。\n\n\n![](https://i.imgur.com/VwFH4CG.png)\n\n\nUnderfitting and Overfitting\nUnderfitting:**如果如果模型不能拟合训练样本，产生较大的偏差，称为Underfitting**。\nOverfitting:**如果模型可以拟合训练数据，但是在Testing data上有较大的误差，则是Variance较大的原因，称为Overfitting**。\nOK！现在我们知道了模型估计偏差（bias）较大和标准差（Variance）分别是由什么原因引起的了，下一步我们就可以对症下药，根据不同情况做不同的调整了。\n对于Large Bias，也就是Underfitting，我们通常做如下处理：\n重新设计模型方程；\n增加更多的特征作为输入；\n设计一个更复杂的模型。\n\n\n对于Large Variance，也就是过拟合，我们通常做如下处理：\n增加训练数据，使模型学习到更多的特征；\n训练之前对数据进行Regularization（正则化），以减少Variance（标准差）。\n将训练集分为Training set and Validation set,如下图所示：\n\n\n\n\n![](https://i.imgur.com/x1SX7lJ.png) \n\n\n\n将training set分成3份，一次让其中2份Training，一份用来验证(Validation)，最后让每一份都当作一次验证集，求出3次训练的平均误差，取模型中平均误差最小的模型去处理测试集。\n\n","categories":["机器学习"],"tags":[]},{"title":"机器学习之梯度下降方法优化","url":"http://tanqingbo.cn/2018/03/20/机器学习之梯度下降方法优化/","content":"前言\n上一节《机器学习之回归案例研究》中简单介绍了回归方程和过拟合。这一节详细介绍一下梯度下降法。\nlearning rate\n学习率n与梯度下降的步长有关，若步长太短，则收敛数据太慢，若步长太长，则有可能错过错误率最低的点。如下图：\n\n![](https://i.imgur.com/84BrvLD.png)\n\n\n图中黄色与绿色的步长便错过了最小的误差点。\n\n因此有一个简单的想法：为了不错过最小的误差点，同时还保持一定的收敛效率，我们可以对学习率做如下操作：\n\n在开始时，我们里目标很远，斜率比较陡的时候，设置学习率大一点；\n等快要接近目标时，便减少学习率，以免跳过目标点，因此可以将学习率n定义为迭代次数t的函数，如下图：\n\n\n\n\n![](https://i.imgur.com/8IXhrkZ.png)\n\n\n\n但是又有一个问题，如果用这一个规则的学习率去求解所有回归问题问题的参数有点不太合理，能不能将参数w、b和学习率n的函数结合起来共同设置步长，这样处理不同问题的时候，更能适应相应的场合。\nAdagrad Gradient Descen\n将每个参数的学习率除以其先前导数的均方根。如图：\n\n![](https://i.imgur.com/J5OjASD.png)\n![](https://i.imgur.com/NLzigco.png)\n![](https://i.imgur.com/WVlRKjs.png)\n\n\n图中gt为损失函数的导数，看着是不是很不厉害的样子，但是却有一个矛盾的地方，在前面我们讲在开始时，我们里目标很远，斜率比较陡的时候，设置学习率大一点，等快要接近目标时，便减少学习率，以免跳过目标点。\n\n可是在上图的公式中，gt很大时，步长的分母也很大，即步长很小，这与上面的叙述看起来矛盾，如图：\n\n\n\n![](https://i.imgur.com/jNNw59X.png)\n\n\n\n这为什么呢？什么原因要这样设置呢？直观的原因时造成反差效果，在某次迭代中，gt可能会由某个很小的值变成一个特别大的值，或者由某个很大的值突然变成一个很小的值。如图：\n\n![](https://i.imgur.com/lgDwscc.png)\n\n\n这还有一个疑问，大的梯度，真的需要大的步长吗？我们看一个图：\n\n![](https://i.imgur.com/Bmh69e6.png)\n\n\na点的梯度比c点的梯度小，但是很明显a点距最优点比c点距最优点要远，所以不一定就是大的梯度对应大的步长。\n\n假设上图中，a的横坐标为x0，曲线方程为y=ax^2 + bx + c。则a点到最优点的步长为：\n\n\n\n![](https://i.imgur.com/xD5CNN9.png)\n\n\n\n其中(2ax+b)为y的一阶导，2a为y的二阶导。因此我们有理由假设最优步长等于损失函数的一阶导除以二阶导，再乘以学习率n。但是对于很多比较复杂的损失函数来说，求二阶导的计算量非常大，因此我们用先前导数均方根的和近似二阶导，如图所示：\n\n\n![](https://i.imgur.com/QdYvGDn.png)\n\n\nStochastic Gradient Descen\nStochastic梯度下降法是每计算一次样本更新一次参数，而普通梯度下降法是计算所有的样本之后才更新参数。\n![](https://i.imgur.com/2894dV2.png)\n\n\n\n\nFeature Scaling\n当样本的两个特征数值规模相差有点大时，为了节省训练时间，可以先对样本特征正则化，再进行训练。\n正则化的公式如下：\n\n\n![](https://i.imgur.com/fioS9ED.png)\n\n\n\n其中xi为每个对应特征的样本值，mi为样本均值。\n\n","categories":["机器学习"],"tags":[]},{"title":"机器学习之线性回归案例研究","url":"http://tanqingbo.cn/2018/03/20/机器学习之回归案例研究/","content":"前言\n在机器学习中，回归则是根据样本研究其两个（或多个）变量之间的依存关系，是对于其趋势的一个分析预测。\n比如说根据当前的股市行情预测接下来的股票走势；\n根据消费者过去的消费习惯预测他将来会购买某物；\n\n\n\n样例分析\n根据当前pokemon的cp值以及其他属性，预测它进化之后的cp值。\nStep1：create Model（创建模型）\n建立回归方程，假设方程为线性的：\n\n![](https://i.imgur.com/PuiOyEK.png)\n\n其中xi为pokemon的特征（feature），wi:权重(weight);b:偏差(bias)；y为预测的升级之后pokemon的Cp值。\n\n假设现在只考虑pokemon当前cp值这一个feature，于是方程可以变成：\n\n![](https://i.imgur.com/Bt4N3HK.png)\n\n现在问题变成如何找到偏差b与权值w使得预测出来的y接近真实值y，首先想到的是穷举负无穷到正无穷之间的数，从而找到最优的b和w.这显然不可能。于是，我们想能不能从已有的真实数据集上学习出我们想要的偏差b与权值w？\nstep2:loss function（损失函数）\n假设我们已经知道了，10组pokemon的cp值以及升级后的cp值，根据回归方程，我们定义损失函数L。\n\n![](https://i.imgur.com/zBHaFys.png)\n\n损失函数L的结果等于真实值减去方程预测出来的值，上图红线部分为预测值，显然L是w和b的函数，现在我们的目标变成寻找使损失函数L最小的w和b。\nStep 3: Gradient Descent（梯度下降）\n这回我们当然不能再用穷举法求w和b了。我们可以用一个稍微高级一点的方法了，叫做梯度下降法，我们先以单个变量讲解度下降法，先只考虑W。\n\n![](https://i.imgur.com/ErXwfVt.png)\n\n图为损失函数L的曲线，只需要找到使L最小的W值，在图中可以很容易的看出，L的最小值在谷底取得，但是我们不知道此时W取何值，所以需要先随机初始化w，再沿着曲线下降的方向慢慢调整w,直到L取到最小值，此时的w就为我们求的w.\n\n曲线下降，我们很容易想到该点的斜率，即斜率小于0，则曲线下降，可以加大w，斜率大于0，则曲线上升，减少w。\n\n斜率就是在该点求导咯，于是w可以按如下公式调整：\n\n![](https://i.imgur.com/rfl2WQm.png)\n\n这样我们就能相对快一点找到使L最小的W了。\n\n刚刚只是考虑W一个参数，考虑w和b两个参数的话，就让L同时对w和l求偏导，再按偏导符号调整就可以了。如图：\n\n![](https://i.imgur.com/3kdhTJs.png)\n\n\n如下公式即位损失函数L的梯度：\n\n![](https://i.imgur.com/ZcWDXOF.png)\n\n### over fitting（过拟合） ###\n当我们令回归方程为一次时，即方程形式如下：\n\n![](https://i.imgur.com/Bt4N3HK.png)\n\n用梯度下降的方法求出b和w,再去预测pokemon的测试数据时，平均误差为35.当我们将回归方程设为2次时：\n\n![](https://i.imgur.com/YwXZJ3h.png)\n\n用梯度下降法求出W和b,再去预测pokemon的测试数据时，平均误差为18.于是猜想是不是回归方程的次数越高，对测试数据的预测就越准确呢？\n\n![](https://i.imgur.com/n67wT90.png)\n![](https://i.imgur.com/z1aqG6f.png)\n\n上图分别是当回归方程是2、3、4、5次时，回归方程预测的曲线图，最后一张是对training data 和 testing data的误差，由图可知，虽然回归方程越复杂，对训练数据效果越好，但是对测试数据可能会更差，这就是over fiting。\n\n\n","categories":["机器学习"],"tags":[]},{"title":"函数式（Functional）模型","url":"http://tanqingbo.cn/2018/03/17/Functional模型/","content":"前言\nkeras的函数式模型接口是用户定义多输出模型，非循环有向模型或具有共享层的模型。只要你的模型多于一个输出，你就应该选择函数式模型。它是最广泛的一种模型。\n\n几个概念\n层对象接受张量为参数，返回一个张量；\n输入是张量，输出也是张量的一个框架就是一个模型，通过model定义。\n利用函数式模型的接口，我们可以很容易的重用已经训练好的模型：你可以把模型当作一个层一样，通过提供一个tensor来调用它。注意当你调用一个模型时，你不仅仅重用了它的结构，也重用了它的权值。\n这种方式可以允许你快速的创建能处理序列信号的模型，你可以很快将一个图像分类的模型变为一个对视频分类的模型。\n层“节点”的概念：\n无论何时，当你在某个输入上调用层时，你就创建了一个新的张量（即该层的输出），同时你也在为这个层增加一个“（计算）节点”。这个节点将输入张量映射为输出张量。当你多次调用该层时，这个层就有了多个节点，其下标分别为0，1，2…\n\n\n\n","categories":["机器学习"],"tags":[]},{"title":"编程语言类电子书整理","url":"http://tanqingbo.cn/2018/03/17/编程语言类电子书整理/","content":" 编程语言类电子书整理 \n提取码在链接的后面，手机打开可能看不到，用电脑打开就能看到了。\n\n序号资源名百度云链接密码\n1 python电子书籍  https://pan.baidu.com/s/1ycKn3Zug_rMjg5uqyEPS6A     密码: 7xmm\n2 C++经典书籍  [https://pan.baidu.com/s/1lsRSkl4B4XrL6N0qyFepzg](https://pan.baidu.com/s/1lsRSkl4B4XrL6N0qyFepzg) 密码: 7sx4\n3  Java相关最全图书 [https://pan.baidu.com/s/1NiTqJDavmOcRuCJcJMyR8g](https://pan.baidu.com/s/1NiTqJDavmOcRuCJcJMyR8g) 密码: yfpu\n4  Java必看精简版 https://pan.baidu.com/s/1nkWeFRqBCCNOuB8zxTCRGg 密码: u6g6\n\n\n\n\n\n电子书的名单如下\n","categories":["技术博客"],"tags":[]},{"title":"序贯（Sequential）模型接口","url":"http://tanqingbo.cn/2018/03/16/Sequential模型接口/","content":"前言\n序贯模型是多个网络层的线性堆叠，也就是“一条路走到黑”。\n\n可以向Sequential模型中传递Dense类构造给模型。\n\n我将以一段代码的形式先简单介绍一下如何用python编写Sequential模型。\n样例\n开始一个序贯模型一般有4个步骤：\n\n定义模型；\n通过compile对模型进行编译；\n准备训练数据；\n模型训练。\n\n\n在下面的代码中，我简单的介绍了一下这4个过程，详情请见注释：\n      # 从keras中到入库\n      from keras.models import Sequential\n      from keras.layers import Dense,Activation\n      # 定义Sequential模型\n      model = Sequential()\n      model.add(Dense(32, activation=&#39;relu&#39;, input_dim=100))   # 全连接层\n      model.add(Dense(1, activation=&#39;sigmoid&#39;))     #激活函数\n      # 通过compile对模型进行编译，编译的时候一般有三个参数optimizer、loss、metrics，后续会讲到\n      model.compile(optimizer=&#39;rmsprop&#39;,\n                    loss=&#39;binary_crossentropy&#39;,\n                    metrics=[&#39;accuracy&#39;])\n\n      # 准备训练数据；\n      import numpy as np  \n      data = np.random.random((1000, 100))  # 生成一个1000*100的矩阵，数值在0～1之间\n      labels = np.random.randint(2, size=(1000, 1))    # 为每一行加上0\\1标签\n\n      # Train the model, iterating on the data in batches of 32 samples\n      model.fit(data, labels, epochs=10, batch_size=32)   # 将数据加入fit函数，epochs=10表示循环10次，批大小为32\n\n\nSequential模型方法\n在上面的代码中，Sequential模型方法的一些常见的方法基本都登场了，下面详细介绍一下这些方法以及参数的作用。add\n向模型中添加一个层，如果需要多个层的话，就多add几次。pop\n与add方法相对应，作用是弹出模型的最后一层。\n\ncompile\n用来编译模型，配置模型的学习过程。\ncompile方法有几个参数，含义分别如下：\noptimizer：定义优化器名或优化器对象，一般为字符串；\nloss：预定义损失函数名或目标函数；\nmetrics：指标列表，指标可以是一个预定义指标的名字,也可以是一个用户定制的函数.指标函数应该返回单个张量,或一个完成metric_name - &gt; metric_value映射的字典.典型用法是metrics=[&#39;accuracy&#39;]。\n\n\n\nfit    fit(data, labels, epochs=10, batch_size=32, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0)\n\ndata:输入数据。如果模型只有一个输入，那么data的类型是numpy array，如果模型有多个输入，那么x的类型应当为list，list的元素是对应于各个输入的numpy array.\nlabel:对应的data的标签。\nepochs：它就是训练的总轮数。\nbatch_size：指定进行梯度下降时每个batch包含的样本数。训练时一个batch的样本会被计算一次梯度下降，使目标函数优化一步。\nverbose：日志显示，0为不在标准输出流输出日志信息，1为输出进度条记录，2为每个epoch输出一行记录\ncallbacks：list，其中的元素是keras.callbacks.Callback的对象。这个list中的回调函数将会在训练过程中的适当时机被调用；\nvalidation_split：0~1之间的浮点数，用来指定训练集的一定比例数据作为验证集。验证集将不参与训练，并在每个epoch结束后测试的模型的指标，如损失函数、精确度等。\nvalidation_data：形式为（X，y）的tuple，是指定的验证集。此参数将覆盖validation_spilt。\nshuffle：布尔值或字符串，一般为布尔值，表示是否在训练过程中随机打乱输入样本的顺序。\nclass_weight：字典，将不同的类别映射为不同的权值，该参数用来在训练过程中调整损失函数（只能用于训练）。\ninitial_epoch: 从该参数指定的epoch开始训练，在继续之前的训练时有用。\nsample_weight：权值的numpy array，用于在训练时调整损失函数。\n\nevaluate\n本函数按batch计算在某些输入数据上模型的误差，其参数有：\n  evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None)\n\nx：输入数据，与fit一样，是numpy array或numpy array的list\ny：标签，numpy array\nbatch_size：整数，含义同fit的同名参数\nverbose：含义同fit的同名参数，但只能取0或1\nsample_weight：numpy array，含义同fit的同名参数\n\n\n\npredict\n本函数按batch获得输入数据对应的输出，其参数有：\n   train_on_batch(self, x, y, class_weight=None, sample_weight=None)\n\n\ntest_on_batch\n本函数在一个batch的样本上对模型进行测试\n  predict_on_batch(self, x)\nfit_generator  fit_generator(self, generator, steps_per_epoch, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_q_size=10, workers=1, pickle_safe=False, initial_epoch=0)\n\n利用Python的生成器，逐个生成数据的batch并进行训练。生成器与模型将并行执行以提高效率。例如，该函数允许我们在CPU上进行实时的数据提升，同时在GPU上进行模型训练.\n\n\nevaluate_generator\n本函数使用一个生成器作为数据源评估模型，生成器应返回与test_on_batch的输入数据相同类型的数据。该函数的参数与fit_generator同名参数含义相同，steps是生成器要返回数据的轮数。\n\npredict_generator\n本函数使用一个生成器作为数据源预测模型，生成器应返回与test_on_batch的输入数据相同类型的数据。该函数的参数与fit_generator同名参数含义相同，steps是生成器要返回数据的轮数。\n\n","categories":["机器学习"],"tags":[]},{"title":"关于keras模型","url":"http://tanqingbo.cn/2018/03/16/关于keras模型/","content":"关于keras模型\nKeras有两种类型的模型，序贯模型（Sequential）和函数式模型（Model），函数式模型应用更为广泛，序贯模型是函数式模型的一种特殊情况。\n\n两类模型有一些方法是相同的：\n\nmodel.summary():打印出模型概况，它实际调用的是keras.utils.print_summary。\n\nmodel.get_config()：返回包含模型配置信息的Python字典。模型也可以从它的config信息中重构回去。\n      config = model.get_config()\n      model = Model.from_config(config)\n      # or, for Sequential:\n      model = Sequential.from_config(config)\n\nmodel.get_layer()：依据层名或下标获得层对象。\n\nmodel.get_weights()：返回模型权重张量的列表，类型为numpy array。\n\nmodel.set_weights()：从numpy array里将权重载入给模型，要求数组具有与model.get_weights()相同的形状。\n\nmodel.to_json：返回代表模型的JSON字符串，仅包含网络结构，不包含权值。可以从JSON字符串中重构原模型：\n      from models import model_from_json\n      json_string = model.to_json()\n      model = model_from_json(json_string)\n\nmodel.to_yaml：与model.to_json类似，同样可以从产生的YAML字符串中重构模型。\n      from models import model_from_yaml\n      yaml_string = model.to_yaml()\n      model = model_from_yaml(yaml_string)\n\nmodel.save_weights(filepath)：将模型权重保存到指定路径，文件类型是HDF5（后缀是.h5）\n\nmodel.load_weights(filepath, by_name=False)：从HDF5文件中加载权重到当前模型中, 默认情况下模型的结构将保持不变。如果想将权重载入不同的模型（有些层相同）中，则设置by_name=True，只有名字匹配的层才会载入权重。\n\n\n\n\n","categories":["机器学习"],"tags":[]},{"title":"keras新手指南","url":"http://tanqingbo.cn/2018/03/15/keras新手指南/","content":"一些基本概念\n张量：张量可以看作是向量、矩阵的自然推广，我们用张量来表示广泛的数据类型。\n\n张量的阶数有时候也称为维度，或者轴，轴这个词翻译自英文axis。譬如一个矩阵[[1,2],[3,4]]，是一个2阶张量。\n\n函数式模型：\n\n在Keras 0.x中，模型其实有两种，一种叫Sequential，称为序贯模型，也就是单输入单输出，一条路通到底，层与层之间只有相邻关系，跨层连接统统没有。这种模型编译速度快，操作上也比较简单。\n第二种模型称为Graph，即图模型，这个模型支持多输入多输出，层与层之间想怎么连怎么连，但是编译速度慢。可以看到，Sequential其实是Graph的一个特殊情况。\n\n\nbatch：现在一般采用的是一种折中手段，mini-batch gradient decent，小批的梯度下降，这种方法把数据分为若干个批，按批来更新参数，这样，一个批中的一组数据共同决定了本次梯度的方向，下降起来就不容易跑偏，减少了随机性。另一方面因为批的样本数与整个数据集相比小了很多，计算量也不是很大。所以Keras的模块中经常会出现batch_size，就是指批的大小。\n\nepochs指的就是训练过程中数据将被“轮”多少次。\n\n\nBN层（batch normalize）、LN层（Layer Normalization）\n在BN中，是通过将activation规范为均值和方差一致的手段使得原本会减小的activation的scale变大。\n，在神经网络训练时遇到收敛速度很慢，或梯度爆炸等无法训练的状况时可以尝试BN来解决。另外，在一般使用情况下也可以加入BN来加快训练速度，提高模型精度。\nBN通过mini-batch的输入样本近似的计算normalize中的均值和方差，既同一个minibatch中的输入拥有相同的均值和方差。\nBN于LN不同的是，LN中同层中所有的神经元输入都拥有相同的均值和方差。\n在传统RNN中，recurrent unit经过累加求和后的输入（summed input）的量级会随着训练进行发生波动，导致梯度爆炸或梯度消失发生。加入LN之后，Normalization term会对summed input的进行尺度变换，使RNN在training和inference时更加稳定。\n实践证明，LN用于RNN进行Normalization时，取得了比BN更好的效果。但用于CNN时，效果并不如BN明显。\n\nWN层（weight normalization）\n对深度学习网络权值W进行normalization的操作公式如下：\n\n\n\n通过一个标量g和一个向量V对权重向量W进行尺度变换。标量g的值一般为||W||，即权重W的大小。\n如此便解耦了权重向量的范数和方向，加速了收敛，保证了gradient的稳定，不会爆炸或者消失；同时解决了BN的数据依赖性，计算开销也降低了许多；\n\n","categories":["机器学习"],"tags":[]},{"title":"医学图像分析中的深度学习调查","url":"http://tanqingbo.cn/2018/03/13/医学图像分析中的深度学习调查/","content":"一、前言\n深度学习算法：由许多层组成的网络，将输入数据（例如图像）转换为输出，同时学习越来越高级别的特征。\n迄今为止最成功的图像分析模型是卷积神经网络（CNN）。 CNN包含很多层，可以在很小程度上利用卷积滤波器来转换它们的输入。\n在计算机视觉领域，深度卷积网络现在已成为首选技术。医学影像分析界已经注意到这些关键的发展。但是，从使用手工功能的系统转换到从数据中学习功能的系统进度很慢。\n在AlexNet的突破之前，许多不同的学习功能的技术很受欢迎：它们包括主成分分析，图像补丁聚类，字典方法等等。\n第2节：介绍用于医学图像分析的主要深度学习技术；\n第3节：描述了深度学习对医学图像分析中典型任务的影响：分类，检测，分割，配准，检索，图像生成和增强；\n第4节：讨论了在不同应用领域获得的结果和开放挑战：神经，眼科，肺部，数字病理和细胞成像，乳房，心脏，腹部，肌肉骨骼和其他杂项应用。\n\n\n\n二、Overview of deep learning methods\n随机梯度下降的最大似然是目前最常用的拟合参数的方法。\n以无监督的方式（预训练）逐层训练DNN通过对堆叠网络进行有监督的微调，可以获得良好的性能。以这种方式训练的两种流行体系结构是堆叠自动编码器（SAE）和深度置信网络（DBN）。但是，这些技术相当复杂，需要大量工程才能产生令人满意的结果。\n目前，最受欢迎的模型是以受监督的方式进行端对端训练，极大地简化了训练过程。 最流行的体系结构是卷积神经网络（CNN）和递归神经网络（RNN）。 尽管RNN越来越受欢迎，但CNN目前在（医学）图像分析中应用最广泛。\nMLP与CNN的区别：\n网络中的权重以对图像执行卷积操作的方式共享，这样，模型不需要为在图像中不同位置出现的同一对象分别检测单独的检测器，从而使网络在输入的平移方面等同。它也大大减少了需要学习的参数的数量（即权重的数量不再取决于输入图像的大小）\n\n\n\nDeep CNN Architectures\nAlexNet或VGG等其他简单模型很受医学数据的欢迎。尽管最近的标志性研究都使用GoogleNet的一个名为Inception v3的版本\n将深度学习技术应用于医疗领域的挑战往往在于将现有架构适应于不同的输入格式，例如三维数据。 在CNN早期应用于这样的体积数据时，通过将感兴趣体积（VOI）分成切片并将其作为不同的流馈送到网络来规避全3D卷积和由此产生的大量参数。\n分割是自然和医学图像分析中的一项常见任务，为了解决这个问题，CNN可以简单地用于分别对图像中的每个像素进行分类，方法是在特定像素周围提取补丁。\n\nRecurrent Neural Networks (RNNs)\nRNN是为离散序列分析而开发的。 它们可以看作是MLP的泛化，因为输入和输出的长度都是不同的，这使得它们适用于诸如机器翻译这样的任务，其中源语言和目标语言的句子是输入和输出。\nRBMs是一种马尔科夫随机场（MRF），它构成输入层或可见层x =（x1; x2;：：; xN），隐层h =（h1; h2;：： ：; hM）携带潜在特征表示。 节点之间的连接是双向的，因此给定一个输入向量x，可以获得潜在特征表示h，反之亦然。\n最近，引入了两种新颖的无监督体系结构：变分自动编码器（VAE）（Kingma和Welling，2013）和生成对抗网络（GAN）（Goodfellow等，2014）。 目前还没有同行评议的论文将这些方法应用于医学图像，但在自然图像中的应用是有希望的。\nGPU的发展和开源软件包促进了深度学习在图像处理领域的发展。目前最流行的软件开源包有：\n**Caffe:**提供C ++和Python接口，由加州大学伯克利分校的研究生开发。\n**Tensorflow:**提供C ++和Python接口，由Google开发。\nTheano：提供python接口，由蒙特利尔MILA实验室开发。\nTorch：提供一个Lua接口。\n\n\n两个重要的深度学习库：\nLasagne：https://github.com/tqb4342/Lasagne；\nKeras：https://keras.io/。\n\n\n\nDeep Learning Uses in Medical Imaging分类\n转移学习本质上是使用预先训练的网络来尝试解决大数据集的需求。\n\n确定了两种转移学习策略：\n\n（1）使用预先训练的网络作为特征提取器，不需要训练深度网络，从而可以轻松地将提取的特征插入现有的图像分析流水线。；\n（2）对医疗数据的预先训练的网络进行微调。\n\n\n在最近的使用CNN的论文中，作者也经常从头开始训练他们自己的网络架构，而不是使用预先训练好的网络。\n\n在图像分类中，CNN是当前的标准技术。尤其是对自然图像进行预训练的CNN显示出惊人的强大成果，在一些任务中挑战了人类专家的准确性。\n\n但是在通用深度学习架构中，组合病变外观和病变位置信息，这种组合通常室不可能的，一些作者使用多流体系结构以多尺度的方式解决这个问题， Shen et al等人使用了三个CNN，每个CNN以不同比例的结节补丁作为输入。然后将三个CNN的结果特征输出串联起来形成最终特征向量。\n\n几乎所有最近的论文都倾向于使用经过端到端培训的CNN。\n\nCSAE和经典CNN之间的主要区别在于使用无监督预先训练和稀疏自动编码器。\n\n在对象注释生成训练数据昂贵的情况下，可以使用多实例学习（MIL）和深度学习的集成。\n\n\n分割\n分割的任务通常被定义为识别组成感兴趣对象的轮廓或内部的体素集。\n分割是将深度学习应用于医学成像的论文中最常见的主题；\n新型CNN架构中最着名的医学图像分析是由Ronneberger等人发表的U-net。U-net中的两个主要建筑创新是等量上采样和下采样层的组合。\nRNN最近在分割任务中变得越来越流行。\nfCNN也已扩展到3D。\n病灶分割可以看成对象检测和器官分割方法的混合。\n\n配准\n医学图像的配准（即空间对齐）是一种常见的图像分析任务，其中从一个医学图像到另一个医学图像计算坐标变换。\n当前文献中普遍存在两种策略：\n（1）使用深度学习网络来估计两幅图像的相似性度量以推动迭代优化策略;\n（2）使用深度回归网络直接预测变换参数。\n与分类和分割相比，研究界似乎还没有确定将深度学习技术整合到配准方法中的最佳方法。\n\n其它\n基于内容的图像检索（CBIR）是一种在大量数据库中进行知识发现的技术。\nCBIR方法开发中的主要挑战是从像素级信息中提取有效的特征表示，并将它们与有意义的概念联系起来。\n\n腹部\n大多数腹部文件旨在定位和分割器官，主要是肝脏，肾脏，膀胱和胰腺。\n要注意的是两个分割的挑战 - SLIVER07肝和PROMISE12前列腺。\n\n生物医学图像分析中的重大挑战\nhttps://grand-challenge.org/\n\n","categories":["图像处理"],"tags":[]},{"title":"Medical Data for Machine Learning","url":"http://tanqingbo.cn/2018/03/06/Medical Data for Machine Learning/","content":"Medical Data for Machine LearningThis is a curated list of medical data for machine learning.This list is provided for informational purposes only, please make sure you respect any and all usage restrictions for any of the data listed here.\nCT数据库\n癌症成像档案（TCIA）中的图像数据被组织成专门构建的集合。典型的收集包括来自几个科目（患者）的研究。在一些收藏中，每个主题可能只有一项研究。在其他收藏中，可能会随着时间的推移对主题进行跟踪，在这种情况下，每个主题都会有多项研究。受试者通常具有疾病和/或特定的解剖部位（肺，脑等）。  \nhttps://wiki.cancerimagingarchive.net/display/Public/Collections\n\n脑部MRI数据库（BrainWeb：模拟大脑数据库）\nhttp://brainweb.bic.mni.mcgill.ca/brainweb/selection_normal.html\n\n以下是Andrew L. Beam整理的网上医学公共数据库集\n链接：https://github.com/tqb4342/medical-data1. Medical Imaging DataThe National Library of Medicine presents MedPix®Database of 53,000 medical images from 13,000 patients with annotations. Requires registration.Information: https://medpix.nlm.nih.gov/home  \n\n\nABIDE: The Autism Brain Imaging Data Exchange: towards a large-scale evaluation of the intrinsic brain architecture in autism.Function MRI images for 539 individuals suffering from ASD and 573 typical controls. These 1112 datasets are composed of structural and resting state functional MRI data along with an extensive array of phenotypic information. Requires registration.Paper: http://www.ncbi.nlm.nih.gov/pubmed/23774715Information: http://fcon_1000.projects.nitrc.org/indi/abide/Preprocessed version: http://preprocessed-connectomes-project.org/abide/  \n\nAlzheimer’s Disease Neuroimaging Initiative (ADNI)MRI database on Alzheimer’s patients and healthy controls. Also has clinical, genomic, and biomaker data. Requires registration.Paper: http://www.neurology.org/content/74/3/201.shortAccess: http://adni.loni.usc.edu/data-samples/access-data/\n\nDigital Retinal Images for Vessel Extraction (DRIVE)The DRIVE database is for comparative studies on segmentation of blood vessels in retinal images. It consists of 40 photographs out of which 7 showing signs of mild early diabetic retinopathy.Paper: http://www.isi.uu.nl/Research/Publications/publicationview/id=855.htmlAccess: http://www.isi.uu.nl/Research/Databases/DRIVE/download.php  \n\nAMRG Cardiac AtlasThe AMRG Cardiac MRI Atlas is a complete labelled MRI image set of a normal patient’s heart acquired with the Auckland MRI Research Group ‘s Siemens Avanto scanner. The atlas aims to provide university and school students, MR technologists, clinicians…\nCongenital Heart Disease (CHD) AtlasThe Congenital Heart Disease (CHD) Atlas represents MRI data sets, physiologic clinical data and computer models from adults and children with various congenital heart defects. The data have been acquired from several clinical centers including Rady…\nDETERMINEDefibrillators to Reduce Risk by Magnetic Resonance Imaging Evaluation, is a prospective, multicenter, randomized clinical trials in patients with coronary artery diseases and mild-to-moderate left ventricular dysfunction. The primary objective…\nMESAMulti-Ethnic Study of Atherosclerosis, is a large-scale cardiovascular population study (&gt;6,500 participants) conducted in six centres in the USA. It aims to investigate the manifestation of subclinical to clinical cardiovascular disease before…\n\nOASISThe Open Access Series of Imaging Studies (OASIS) is a project aimed at making MRI data sets of the brain freely available to the scientific community. Two datasets are available: a cross-sectional and a longitudinal set.\n\nCross-sectional MRI Data in Young, Middle Aged, Nondemented and Demented Older Adults: This set consists of a cross-sectional collection of 416 subjects aged 18 to 96.  For each subject, 3 or 4 individual T1-weighted MRI scans obtained in single scan sessions are included.  The subjects are all right-handed and include both men and women.  100 of the included subjects over the age of 60 have been clinically diagnosed with very mild to moderate Alzheimer’s disease (AD).  Additionally, a reliability data set is included containing 20 nondemented subjects imaged on a subsequent visit within 90 days of their initial session.\nLongitudinal MRI Data in Nondemented and Demented Older Adults: This set consists of a longitudinal collection of 150 subjects aged 60 to 96. Each subject was scanned on two or more visits, separated by at least one year for a total of 373 imaging sessions. For each subject, 3 or 4 individual T1-weighted MRI scans obtained in single scan sessions are included. The subjects are all right-handed and include both men and women. 72 of the subjects were characterized as nondemented throughout the study. 64 of the included subjects were characterized as demented at the time of their initial visits and remained so for subsequent scans, including 51 individuals with mild to moderate Alzheimer’s disease. Another 14 subjects were characterized as nondemented at the time of their initial visit and were subsequently characterized as demented at a later visit.\n\nAccess: http://www.oasis-brains.org/ \n\nSCMR Consensus DataThe SCMR Consensus Dataset is a set of 15 cardiac MRI studies of mixed pathologies (5 healthy, 6 myocardial infarction, 2 heart failure and 2 hypertrophy), which were acquired from different MR machines (4 GE, 5 Siemens, 6 Philips). The main objectives…\nSunnybrook Cardiac DataThe Sunnybrook Cardiac Data (SCD) , also known as the 2009 Cardiac MR Left Ventricle Segmentation Challenge data, consist of 45 cine-MRI images from a mixed of patients and pathologies: healthy , hypertrophy , heart failure with infarction and heart…\nAccess: http://www.cardiacatlas.org/studies/\n\nLung Image Database Consortium (LIDC)\nPreliminary clinical studies have shown that spiral CT scanning of the lungs can improve early detection of lung cancer in high-risk individuals. Image processing algorithms have the potential to assist in lesion detection on spiral CT studies, and to assess the stability or change in lesion size on serial CT studies. The use of such computer-assisted algorithms could significantly enhance the sensitivity and specificity of spiral CT lung screening, as well as lower costs by reducing physician time needed for interpretation.\nThe intent of the Lung Imaging Database Consortium (LIDC) initiative was to support a consortium of institutions to develop consensus guidelines for a spiral CT lung image resource and to construct a database of spiral CT lung images. The investigators funded under this initiative created a set of guidelines and metrics for database use and for developing a database as a test-bed and showcase for those methods. The database is available to researchers and users through the Internet and has wide utility as a research, teaching, and training resource.\nSpecifically, the LIDC initiative aims were to provide:\n\na reference database for the relative evaluation of image processing or CAD algorithms and\na flexible query system that will provide investigators the opportunity to evaluate a wide range of technical parameters and de-identified clinical information within this database that may be important for research applications.\n\nThis resource will stimulate further database development for image processing and CAD evaluation for applications that include cancer screening, diagnosis, and image guided intervention, and treatment. Therefore, the NCI encourages investigator-initiated grant applications that utilize the database in their research. NCI also encourages investigator-initiated grant applications that provide tools or methodology that may improve or complement the mission of the LIDC.\nAccess: http://imaging.cancer.gov/programsandresources/informationsystems/lidc\n\nTCIA Collections\nCancer imaging data sets across various cancer types (e.g. carcinoma, lung cancer, myeloma) and various imaging modalities.The image data in The Cancer Imaging Archive (TCIA) is organized into purpose-built collections of subjects. The subjects typically have a cancer type and/or anatomical site (lung, brain, etc.) in common. Each link in the table below contains information concerning the scientific value of a collection, information about how to obtain any supporting non-image data which may be available, and links to view or download the imaging data. To support reproducibility in scientific research, TCIA supports Digital Object Identifiers (DOIs) which allow users to share subsets of TCIA data referenced in a research manuscript. \nAccess: http://www.cancerimagingarchive.net/\n\nBelarus tuberculosis portal\nTuberculosis (TB) is a major problem of Belarus Public Health .Recently situation has been complicated with emergence and development of MDR/XDR TB and HIV/TB which require long-term treatment. Many and the most severe cases usually disseminate across the country to different TB dispensaries. The ability of leading Belarus TB specialists to follow such patients will be greatly improved by using a common database containing patients’ radiological images, lab work and clinical data. This will also significantly improve adherence to the treatment protocol and result in a better record of the treatment outcomes.Criteria for inclusion clinical cases in the database of the portal - patients admitted to the MDR-TB department of RSPC of Pulmonology and Tuberculosis with diagnosed or suspected of MDR-TB, which conducted CT – study (± 2 months from the date of registration)Belarus dataset have both chest X-rays and CT scans of the same patient. \nAccess: http://tuberculosis.by/\n\nDDSM: Digital Database for Screening Mammography\n The Digital Database for Screening Mammography (DDSM) is a resource for use by the mammographic image analysis research community. Primary support for this project was a grant from the Breast Cancer Research Program of the U.S. Army Medical Research and Materiel Command. The DDSM project is a collaborative effort involving co-p.i.s at the Massachusetts General Hospital (D. Kopans, R. Moore), the University of South Florida (K. Bowyer), and Sandia National Laboratories (P. Kegelmeyer). Additional cases from Washington University School of Medicine were provided by Peter E. Shile, MD, Assistant Professor of Radiology and Internal Medicine. Additional collaborating institutions include Wake Forest University School of Medicine (Departments of Medical Engineering and Radiology), Sacred Heart Hospital and ISMD, Incorporated. The primary purpose of the database is to facilitate sound research in the development of computer algorithms to aid in screening. Secondary purposes of the database may include the development of algorithms to aid in the diagnosis and the development of teaching or training aids. The database contains approximately 2,500 studies. Each study includes two images of each breast, along with some associated patient information (age at time of study, ACR breast density rating, subtlety rating for abnormalities, ACR keyword description of abnormalities) and image information (scanner, spatial resolution, …). Images containing suspicious areas have associated pixel-level “ground truth” information about the locations and types of suspicious regions. Also provided are software both for accessing the mammogram and truth images and for calculating performance figures for automated image analysis algorithms. \nAccess: http://marathon.csee.usf.edu/Mammography/Database.html\n\nProstate\nProstate cancer (CaP) has been reported on a worldwide scale to be the second most frequently diagnosed cancer of men accounting for 13.6% (Ferlay et al. (2010)). Statistically, in 2008, the number of new diagnosed cases was estimated to be 899, 000 with no less than 258, 100 deaths (Ferlay et al. (2010)).\nMagnetic resonance imaging (MRI) provides imaging techniques allowing to diagnose and localize CaP. The I2CVB provides a multi-parametric MRI dataset to help at the development of computer-aided detection and diagnosis (CAD) system.Access: http://i2cvb.github.io/\n\nAccess: http://www.medinfo.cs.ucy.ac.cy/index.php/downloads/datasets\n\nMRI Lesion Segmentation in Multiple Sclerosis Database\n\nEmergency Tele-Orthopedics X-ray Digital Library\n\nIMT Segmentation\n\nNeedle EMG MUAP Time Domain Features\n\n\n\nDICOM image sample setsThese datasets are exclusively available for research and teaching. You are not authorized to redistribute or sell them, or use them for commercial purposes.\nAll these DICOM files are compressed in JPEG2000 transfer syntax.\nAccess: http://www.osirix-viewer.com/resources/dicom-image-library/\n\nSCR database: Segmentation in Chest Radiographs\nThe automatic segmentation of anatomical structures in chest radiographs is of great importance for computer-aided diagnosis in these images. The SCR database has been established to facilitate comparative studies on segmentation of the lung fields, the heart and the clavicles in standard posterior-anterior chest radiographs.\nIn the spirit of cooperative scientific progress, we freely share the SCR database and are committed to maintaining a public repository of results of various algorithms on these segmentation tasks. On thes pages, instructions can be found on downloading the database and uploading results, and benchmark results of various methods can be inspected. \nAccess: http://www.isi.uu.nl/Research/Databases/SCR/\n\nMedical Image Databases &amp; Libraries\nAccess: http://www.omnimedicalsearch.com/image_databases.html\n General Category\n\ne-Anatomy.org - Interactive Atlas of Anatomy - e-anatomy is an anatomy e-learning web site. More than 1500 slices from normal CT and MR exams were selected in order to cover the entire sectional anatomy of human body. Images were labeled using Terminologia Anatomica. A user-friendly interface allows to cine through multi-slice image series combined with interactive textual information, 3D models and anatomy drawings.\n\nMedical Pictures and Definitions - Welcome to the largest database of medical pictures and definitions on the Internet. There are many sites sites that provide medical information but very few that provide medical pictures. As far as we know we are the only one that provides a medical picture database with basic information about each term pictured. Editor’s Note: Nice website with free access &amp; no pesky registration to 1200+ health and medical related images with definitions.\n\nNucleus Medical Art - Medical Illustrations, Medical Art. Includes 3D animations. “Nucleus Medical Art, Inc. is a leading creator and distributor of medical illustrations, medical animations, and interactive multimedia for publishing, legal, healthcare, entertainment, pharmaceutical, medical device, academia and other markets, both in the U.S. and abroad. Editors Note: Great website.\n\nMedical Image Databases on the Internet (UTHSCSA Library) - A directory of links to websites with topic specific medical related images.\n\nSurgery Videos - A National Library of Medicine MedlinePlus collection of links to 100s and 100s of different surgical procedures. You must have RealPlayer media player on your computer to view these videos which are free of charge.\n\nThe ADAM Medical Encyclopedia with Illustrations. Perhaps one of the best illustrated medical works on the internet today, the ADAM Medical Encyclopedia includes over 4,000 articles about diseases, tests, symptoms, injuries, and surgeries. It also contains an extensive library of medical photographs and illustrations to back up those 4,000 articles. These illustrations and articles are free to the public.\n\nHardin MD - Medical and Disease Pictures, is a Free and established resource that has been offered by the University of Iowa for quite some time. The home page is in directory style where users will have to drill down to find the images they are looking for, many of which go offsite. Nevertheless, Hardin MD is an excellent gateway to 1,000s of detailed medical photos and illustrations.\n\nHealth Education Assets Library (HEAL) - Health on the Net Foundation Media Gallery Headquartered in Switzerland, (HON) is an international body that seeks to encourage ethical provision of online health information. “HONmedia (the image gallery) is an unique repository of over 6’800 medical images and videos, pertaining to 1,700 topics and themes. This peerless database has been created manually by HON and new image links are constantly being added from the world-wide Web. HON encourages users to make their own image links available via the Submit an image link.” Library includes anatomical images, visual affects of diseases and conditions and procedures.\n\nPublic Health Image Library (PHIL) Created by a Working Group at the Centers for Disease Control and Prevention (CDC), the PHIL offers an organized, universal electronic gateway to CDC’s pictures. We welcome public health professionals, the media, laboratory scientists, educators, students, and the worldwide public to use this material for reference, teaching, presentation, and public health messages. The content is organized into hierarchical categories of people, places, and science, and is presented as single images, image sets, and multimedia files.\n\nImages from the History of Medicine - This system provides access to the nearly 60,000 images in the prints and photograph collection of the History of Medicine Division (HMD) of the U.S. National Library of Medicine (NLM). The collection includes portraits, pictures of institutions, caricatures, genre scenes, and graphic art in a variety of media, illustrating the social and historical aspects of medicine.\n\nPozemedicale.org - Collection of medical images in Spanish, Italian, Portuguese and Italian.\n\nOld Medical Pictures: Hundreds of fascinating and interesting old, but high quality photographs and images from the late 19th and early 20th century.\n\n\nSubject Speciality Image Libraries and Collections\n\nAnatomy of the Human Body by Henry Gray - The Bartleby.com edition of Gray’s Anatomy of the Human Body features 1,247 vibrant engravings—many in color—from the classic 1918 publication.\n\nThe Crookston Collection - A collection of medical slides taken by Dr. John H. Crookston that have been digitized and are available to the public and doctors.\n\nDAVE Project - A searchable library of gastrointestinal endoscopic video clips covering a wide spectrum endoscopic imaging.\n\nDermnet - Browsable collection of over 8,000 high quality, dermatology images.\n\nInteractive Dermatology Atlas - Image reference source for common and uncommon skin problems.\n\nThe Multi-Dimensional Human Embryo is a collaboration funded by the National Institute of Child Health and Human Development (NICHD) to produce and make available over the internet a three-dimensional image reference of the Human Embryo based on magnetic resonance imaging.\n\nGastroLab Endoscopy Archives Was initiated in 1996 with the goal of maintaining an endoscopic image gallery free to use for all interested health care personals.\n\nMedPix Is a Radiology and Medical Picture Databases resource tool. The home page interface is confusing and the entire website design is not user-friendly and has a mid 1990s feel to it. However, if you have the time (patience) it could prove to be an important resource for some.\n\nOBGYN.net Image Library - This site is devoted entirely to providing access to images of interest to women’s health. In addition to providing you with access to OBGYN.net images we also point to other women’s health related images on the Internet. Because of the graphic nature of the material some individuals may prefer not to view these images.They are provided for educational purposes only. \n\n\n\nVIA Group Public Databases\n Documented image databases are essential for the development of quantitative image analysis tools especially for tasks of computer-aided diagnosis (CAD). In collaboration with the I-ELCAP group we have established two public image databases that contain lung CT images in the DICOM format together with documentation of abnormalities by radiologists. Please access the links below for more details:\nAccess: http://www.via.cornell.edu/databases/\n\nCVonline: Image DatabasesAccess: http://homepages.inf.ed.ac.uk/rbf/CVonline/Imagedbase.htm\n\nThe USC-SIPI Image Database The USC-SIPI image database is a collection of digitized images. It is maintained primarily to support research in image processing, image analysis, and machine vision. The first edition of the USC-SIPI image database was distributed in 1977 and many new images have been added since then.\nThe database is divided into volumes based on the basic character of the pictures. Images in each volume are of various sizes such as 256x256 pixels, 512x512 pixels, or 1024x1024 pixels. All images are 8 bits/pixel for black and white images, 24 bits/pixel for color images. The following volumes are currently available:\nTextures     Brodatz textures, texture mosaics, etc.\nAerials     High altitude aerial images\nMiscellaneous     Lena, the mandrill, and other favorites\nSequences     Moving head, fly-overs, moving vehicles\nAccess: http://sipi.usc.edu/database/\n\n2. Challenges/Contest DataVisual Concept Extraction Challenge in Radiology Manually annotated radiological data of several anatomical structures (e.g. kidney, lung, bladder, etc.) from several different imaging modalities (e.g. CT and MR). They also provide a cloud computing instance that anyone can use to develop and evaluate models against benchmarks.\nAccess: http://www.visceral.eu/\n\nGrand Challenges in Biomedical Image Analysis\nA collection of biomedical imaging challenges in order to facilitate better comparisons between new and existing solutions, by standardizing evaluation criteria. You can create your own challenge as well. As of this writing, there are 92 challenges that provide downloadable data sets.\nAccess: http://www.grand-challenge.org/ \n\nDream Challenges\nDREAM Challenges pose fundamental questions about systems biology and translational medicine. Designed and run by a community of researchers from a variety of organizations, our challenges invite participants to propose solutions — fostering collaboration and building communities in the process. Expertise and institutional support are provided by Sage Bionetworks, along with the infrastructure to host challenges via their Synapse platform. Together, we share a vision allowing individuals and groups to collaborate openly so that the  “wisdom of the crowd” provides the greatest impact on science and human health.\n\nThe Digital Mammography DREAM Challenge.\nICGC-TCGA DREAM Somatic Mutation Calling RNA Challenge (SMC-RNA)\nDREAM Idea Challenge \nThese were the active challenges at the time of adding, many more past challenges and upcoming challenges are present!\n\nAccess: http://dreamchallenges.org/\n\nKaggle diabetic retinopathy\nHigh-resolution retinal images that are annotated on a 0–4 severity scale by clinicians, for the detection of diabetic retinopathy. This data set is part of a completed Kaggle competition, which is generally a great source for publicly available data sets.\nAccess: https://www.kaggle.com/c/diabetic-retinopathy-detection\n\nCervical Cancer Screening\nIn this kaggle competition, you will develop algorithms to correctly classify cervix types based on cervical images. These different types of cervix in our data set are all considered normal (not cancerous), but since the transformation zones aren’t always visible, some of the patients require further testing while some don’t.\nAccess: https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening/data\n\nMultiple sclerosis lesion segmentation\n challenge 2008. A collection of brain MRI scans to detect MS lesions.\nAccess: http://www.ia.unc.edu/MSseg/\n\nMultimodal Brain Tumor Segmentation Challenge\nLarge data set of brain tumor magnetic resonance scans. They’ve been extending this data set and challenge each year since 2012.\nAccess: http://braintumorsegmentation.org/\n\nCoding4Cancer\nA new initiative by the Foundation for the National Institutes of Health and Sage Bionetworks to host a series of challenges to improve cancer screening. The first is for digital mammography readings. The second is for lung cancer detection. The challenges are not yet launched.\nAccess: http://coding4cancer.org/\n\nEEG Challenge Datasets on Kaggle\n\nMelbourne University AES/MathWorks/NIH Seizure Prediction - Predict seizures in long-term human intracranial EEG recordings \n\nAccess: https://www.kaggle.com/c/melbourne-university-seizure-prediction\n\nAmerican Epilepsy Society Seizure Prediction Challenge - Predict seizures in intracranial EEG recordings \n\nAccess: https://www.kaggle.com/c/seizure-prediction\n\nUPenn and Mayo Clinic’s Seizure Detection Challenge - Detect seizures in intracranial EEG recordings\n\nAccess: https://www.kaggle.com/c/seizure-detection\n\nGrasp-and-Lift EEG Detection - Identify hand motions from EEG recordings \n\nAccess: https://www.kaggle.com/c/grasp-and-lift-eeg-detection\n\nChallenges track in MICCAI Conference\nThe Medical Image Computing and Computer Assisted Intervention. Most of the challenges would’ve been covered by websites like grand-challenges etc. You can still see all of them under the “Satellite Events” tab of the conference sites.\n\n2017 - http://www.miccai2017.org/satellite-events\n2016 - http://www.miccai2016.org/en/SATELLITE-EVENTS.html\n2015 - https://www.miccai2015.org/frontend/index.php?page_id=589\n\nAccess: http://www.miccai.org/ConferenceHistory\n\nInternational Symposium on Biomedical Imaging (ISBI)\nThe IEEE International Symposium on Biomedical Imaging (ISBI) is a scientific conference dedicated to mathematical, algorithmic, and computational aspects of biomedical imaging, across all scales of observation. Most of these challenges will be listed in grand-challenges. You can still access it by visiting the “Challenges” tab under “Program” in each year’s website.\n\n2017 - http://biomedicalimaging.org/2017/challenges/\n2016 - http://biomedicalimaging.org/2016/?page_id=416\n\nAccess: http://biomedicalimaging.org\n\n3. Data derived from Electronic Health Records (EHRs)Building the graph of medicine from millions of clinical narrativesCo-occurence statistics for medical terms extracted from 14 million clinical notes and 260,000 patients.Paper: http://www.nature.com/articles/sdata201432Data: http://datadryad.org/resource/doi:10.5061/dryad.jp917  \n\nLearning Low-Dimensional Representations of Medical ConceptLow-dimensional embeddings of medical concepts constructed using claims data. Note that this paper utilizes data from Building the graph of medicine from millions of clinical narrativesPaper: http://cs.nyu.edu/~dsontag/papers/ChoiChiuSontag_AMIA_CRI16.pdfData: https://github.com/clinicalml/embeddings  \n\nMIMIC-III, a freely accessible critical care databaseAnonymized critical care EHR database on 38,597 patients and 53,423 ICU admissions. Requires registration.Paper: http://www.nature.com/articles/sdata201635Data: http://physionet.org/physiobank/database/mimic3cdb/  \n\n4. National Healthcare DataCenters for Disease Control and Prevention (CDC)Data from the CDC on many areas, including:  \n\nBiomonitoring\nChild Vaccinations\nFlu Vaccinations\nHealth Statistics\nInjury &amp; Violence\nMMWR\nMotor Vehicle\nNCHS\nNNDSS\nPregnancy &amp; Vaccination\nSTDs\nSmoking &amp; Tobacco Use\nTeen Vaccinations\nTraumatic Brain Injury\nVaccinations\nWeb Metrics\n\nLanding page: https://data.cdc.govData Catalog: https://data.cdc.gov/browse  \n\nMedicare DataData from the Centers for Medicare &amp; Medicaid Services (CMS) on hospitals, nursing homes, physicians, home healthcare, dialysis, and device providers.Landing page: https://data.medicare.govExplorer: https://data.medicare.gov/data  \n\nTexas Public Use Inpatient Data FileData on 11 Million inpatient visits with diagnosis, procedure codes and outcomes from Texas between 2006 &amp; 2009.\nLink: https://www.dshs.texas.gov/thcic/hospitals/Inpatientpudf.shtm\n\nDollars for DoctorsPropublica investigation of money paid by pharmaceutical companies to doctors.Information: https://www.propublica.org/series/dollars-for-docsSearch tool: https://projects.propublica.org/docdollars/Data request: https://projects.propublica.org/data-store/sets/health-d4d-national-2   \n\nDocGraphPhysician interaction network obtained through a freedom of information act request. Covers nearly 1 million entities.Main page: http://www.docgraph.comInformation: http://thehealthcareblog.com/blog/2012/11/05/tracking-the-social-doctor-opening-up-physician-referral-data-and-much-more/Data: http://linea.docgraph.org  \n\n5. UCI DatasetsLiver Disorders Data SetData on 345 patients with and without liver disease. Features are 5 blood biomarkers thought to be involved with liver disease.Data: https://archive.ics.uci.edu/ml/datasets/Liver+Disorders  \nThyroid Disease Data SetData: https://archive.ics.uci.edu/ml/datasets/Thyroid+Disease  \nBreast Cancer Data SetData: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer  \nHeart Disease Data SetData: https://archive.ics.uci.edu/ml/datasets/Heart+Disease  \nLymphography Data SetData: https://archive.ics.uci.edu/ml/datasets/Lymphography  \n6. Biomedical LiteraturePMC Open Access SubsetCollection of all the full-text, open access articles in Pubmed central.Information: http://www.ncbi.nlm.nih.gov/pmc/tools/openftlist/Archived files: http://www.ncbi.nlm.nih.gov/pmc/tools/ftp/#Data_Mining  \nPubMed 200k RCT\nCollection of pubmed abstracts from randomized control trials (RCTs). Annotations for each sentence in the abstract are available.\nPaper: https://arxiv.org/abs/1710.06071\nData: https://github.com/Franck-Dernoncourt/pubmed-rct\n6. TREC Precision Medicine / Clinical Decision Support TrackText REtrieval Conference (TREC) is running a track on Precision Medicine / Clinical Decision Support from 2014. \n2014 Clinical Decision Support TrackFocus: Retrieval of biomedical articles relevant for answering generic clinical questions about medical records.Information and Data: http://www.trec-cds.org/2014.html\n2015 Clinical Decision Support TrackFocus: Retrieval of biomedical articles relevant for answering generic clinical questions about medical records.Information and Data: http://www.trec-cds.org/2015.html\n2016 Clinical Decision Support TrackFocus: Retrieval of biomedical articles relevant for answering generic clinical questions about medical records. Actual electronic health record (EHR) patient records are be used instead of synthetic cases.Information and Data: http://www.trec-cds.org/2016.html\n2017 Clinical Decision Support TrackFocus: Retrieve useful precision medicine-related information to clinicians treating cancer patients.Information and Data: http://www.trec-cds.org/2017.html\n","categories":["图像处理"],"tags":[]},{"title":"GPU医学图像处理应用","url":"http://tanqingbo.cn/2018/03/01/GPU医学图像处理应用/","content":"前言\n通常情况下GPU（图像处理单元）与CPU（中央处理单元）的理论性能相差10倍，GPU强于CPU。\nGPU是多数据并行设计，性能取决于给定算法的并行化成程度。它主要用于苛刻的重建算法、医学图像、超声波、光学成像、显微技术。\n本文主要介绍GPU用于医学图像处理的4个方面：\n基本的图像处理操作，如滤波和插值\n医学成像中最常用的算法： 图像配准，图像分割和图像去噪\n讨论特定于不同形式（例如，CT，MRI和超声波）的算法和实现\nGPU加速医学成像的未来挑战和可能性的讨论\n\n\n\nGPU用于基本的图像处理操作\nCUDA（Compute Unified Device Architecture），是显卡厂商NVIDIA推出的运算平台。 CUDA™是一种由NVIDIA推出的通用并行计算架构，该架构使GPU能够解决复杂的计算问题。滤波\n由滤波卷积公式可知，卷积非常适合并行处。\nGPU可以高效地加速多维FFT，因为每个GPU线程可以独立处理沿着2D或3D图像的每个单独行的数据。相比之下，基于GPU的一维FFT通常需要非常大量的样本才能提高速度。\n通过应用和组合许多小的可分离滤波器而不是一个大的不可分离滤波器来加速卷积。理论上，这可以将2D所需乘法次数减少5倍，3D减少25次，4D减少300次。\n基于GPU的过滤已经完成了大量的工作。 但是，在2,3和4维中仍然不存在可分离和不可分离卷积的免费库。\n\n插值\n插值是GPU实现最大优势的应用程序。 由于计算机图形很大程度上依赖于插值计算，GPU已经被赋予了特殊的专用硬件支持（纹理存储器）来加速这些操作。 在医学成像中，对于从图像配准到重建CT数据的算法，插值是一个重要的处理步骤。\nLjung等人（2006）因此在GPU上执行了块间插值以提高可视化的质量。 Kraus等人（2007）使用GPU加速实现了边缘定向图像插值，以实现实时升频采样而不会产生振动伪像。\n\n距离变换\n距离计算可以针对每个元素独立执行，因此非常适合GPU实现。\n\nGPU用于算法图像配准\n图像配准是医学成像中最常见的算法之一，也是GPU实现最多的算法之一。 其中一个原因是GPU对线性插值的硬件支持，从而可以非常高效地转换图像和体积。\n\n图像分割\n分割仍然是一个活跃的研究领域，目前还没有发现可以解决所有问题的单一分割算法。\n\n基于GPU的图像分割可以用于三个目的:\n\n快速比较多个候选分割算法。\n一旦建立了工作分割算法，GPU可以加速大数据集的自动分割。\nGPU还可以执行交互式分割和可视化，用户可以帮助算法提供令人满意的结果。\n\n\n组合的交互式分割和可视化非常适合GPU，因为已经在GPU内存中的数据可以非常高效地渲染。\n\n\nGPU讨论\n全球显存的尺寸目前为1GB（例如Nvidia GTX 285）至6GB（例如Nvidia GTX Titan）用于消费者显卡，4-8GB用于专业显卡。\n对于工作站，CPU内存容量可以很容易地从4 GB到128 GB不等。对于2D图像处理来说，6GB的全局内存通常就足够了，但对于3D图像处理而言，它可能太少。\n\n编程语言和库\nCUDA编程语言显然使得为通用计算编程GPU变得更加容易。 CUDA的主要缺点是它只支持Nvidia GPU。\nOpenCL（全称Open Computing Language，开放运算语言）是第一个面向异构系统通用目的并行编程的开放式、免费标准。\n使用CUDA和OpenCL编写的代码可以产生不同的性能。 CUDA目前提供的更大优势是Nvidia致力于为其专有平台提供高度优化的库。\n\n","categories":["图像处理"],"tags":[]},{"title":"linux下安装并使用java开发opencv的配置","url":"http://tanqingbo.cn/2017/12/23/linux下安装并使用java开发opencv的配置/","content":"安装jdk\nJava环境可选择 Oracle 的 JDK，或是 OpenJDK,为图方便，这边直接通过命令安装 OpenJDK 8。\n  sudo apt-get install openjdk-7-jre openjdk-7-jdk\n\n通过上述命令安装 OpenJDK，默认安装位置为 /usr/lib/jvm/java-8-openjdk-amd64\n\n接着需要配置一下 JAVA_HOME 环境变量，为方便，我们在 ~/.bashrc 中进行设置\n  vim ~/.bashrc\n\n在文件最前面添加如下单独一行（注意 = 号前后不能有空格），并保存：\n  export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n\n接着还需要让该环境变量生效，执行如下代码：\n  source ~/.bashrc    # 使变量设置生效\n\n\nlinux编译安装opencv\n安装gcc以及cmake等等乱七八糟的软件,opencv的版本建议使用2.4.x的版本，新出的版本好多方法都没法用了，需要重新编译其他源码包，比较麻烦。例如基于surf和sift匹配算法在2.4以上的版本里面就没有了。\n  sudo apt-get install build-essential python-dev cmake\n\n下载opencv并解压缩\n  tar -zxvf opencv.tar.gz\n\n创建编译目录，并在此目录下执行如下命令：\n      cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local ..\n\n上面的CMAKE_BUILD_TYPE =RELEASE指明编译的版本是Release版，CMAKE_INSTALL_PREFIX=/usr/local指明编译后的可执行程序的存放目录。\n\n执行make和install：\n      make\n      sudo make install\n\n如果没有出错的话，OpenCV的整个编译过程就完成了！ 如果有错误，那就复制错误内容，到网上查找解决办法，一般来说这是个很痛苦的过程，所以希望你有好运气，一次编译就能过.\n\n\n","categories":["图像处理"],"tags":[]},{"title":"我攒一地的雪花祝你圣诞节快乐","url":"http://tanqingbo.cn/2017/12/17/我攒一地的雪花祝你圣诞节快乐/","content":"我攒一地的雪花祝你圣诞节快乐\n我不知道你过不过圣诞节，我只知道，一年的某一天，你会希望收到一个系着蝴蝶结的礼物。\n\n记得上初中的时候，在圣诞节的这一天，大家习惯互送卡片，我们会在卡片上写着类似于“在这思念好友、美梦成真的时刻，祝你——圣诞节快乐！”这样的句子送给最好的朋友。或者在卡片上抄小一段言情小说上的文字送给暗恋的姑娘，然后赶紧跑开躲在角落里久久不能平静。那时圣诞卡片于我们来说就像现在的悄悄话，一些不好意思当面说的话，都可以在上面说。为了营造节日氛围，我们用便条纸在班级绿色的四扇窗玻璃窗上贴上“圣诞快乐”四个大字，偷偷买聚会用的那种可以喷出五颜六色泡沫的气罐瓶在下晚自习之后到处喷人，嘴上笑得没心没肺，睡觉之前听一首光良的《童话》，似懂非懂，想象着明早起来圣诞老人已经把礼物送到我的枕边了吧，然后美美的睡去。\n\n上高中的时候，圣诞节像是一次军事演习，我们通常会在这天叫上几个好友一起合伙骗过学校守门的大爷，偷偷跑到水果店里买一堆苹果，然后精心包装起来，赶在晚自习之前送出去。上晚自习的时候，把头埋在一大堆复习资料书的后面，心惊胆颤的用QQ和朋友聊天，幻想着大学的圣诞节是什么样子，会不会真的可以和电影里一样：在那个飘雪的圣诞夜里，亲手为她准备一个打着蝴蝶结的礼物，然后牵着她一起去看电影。那时候学的校广播喜欢循环播放杨培安的《我相信》，就像歌词说的：“我相信我就是我，我相信明天，我相信青春没有地平线，在日落的海边，热闹的大街，都是我心中最美的乐园。”那时候的我们也相信一定能考上大学，在大学的校园里享受自己的圣诞节。\n\n后来，我来到了哈尔滨，我一直固执的认为下雪的圣诞才算是完美的圣诞节，我也曾不止一次的期待着圣诞夜的飘雪，虔诚地期盼着一个皑皑白雪的圣诞。但年复一年，结果总是事与愿违，为了感受飘雪的圣诞夜，也算是我来哈尔滨上学的原因之一吧！所以当我在某个圣诞夜里突然看到下雪的时候，便迫不及待的拨通了她的号码：你知道吗？下雪的圣诞真的好美，满天飘散的雪花，原木色的小屋，火红的圣诞袜、五彩缤纷的圣诞树、还有那永不褪色的《Jingle Bell》…….我高兴的像个孩子一样手舞足蹈的跟她描绘眼前的景色，通话结束后，耳机里正好响起周杰伦的《简单爱》，第一次发现原来这首歌的旋律是如此的让人心动。以至于后来分手之后，这段记忆依旧让我印象深刻。\n\n现在，马上又要迎来我研究生阶段的第一个圣诞节，不知道还会不会下雪，不过这回的圣诞节我应该会听陈奕迅的《圣诞结》：\n     “merry merry christmas\n  　　lonely lonely christmas \n  　　想祝福不知该给谁\n  　　爱被我们打了死结  \n      lonely lonely christmas\n  　　merry merry christmas\n  　　写了卡片能寄给谁\n  　　心碎得像街上的纸屑”\n\n我又突然开始盼望一场正好的大雪，最好下在圣诞节的晚上，趁着异乡人对那串号码说，圣诞快乐；灯对影子说，圣诞快乐；正方形对三角形说，圣诞快乐；我也想收集这满天的雪花对你说，圣诞快乐！\n\n嘿~圣诞节快乐！\n\n\n","categories":["漂来漂去"],"tags":[]},{"title":"基于SIFT与ransac的全景图像拼接","url":"http://tanqingbo.cn/2017/12/13/基于SIFT特征的全景图像拼接/","content":"前言\n全景图像拼接主要分为如下几个步骤\n\n读入两张图片并分别提取SIFT特征；\n利用k-d tree和BBF算法进行特征匹配查找；\n利用RANSAC算法筛选匹配点并计算变换矩阵；\n图像融合。实验环境\n\n\nvs2017、QT的版本是Qt5.6.3，OpenCV版本是2.4.9.\nSIFT特征提取\n直接调用RobHess源码(RobHess的SIFT源码分析：综述)中的sift_features()函数进行默认参数的SIFT特征提取，主要代码如下：\n      img1_Feat = cvCloneImage(img1);//复制图1，深拷贝，用来画特征点  \n      img2_Feat = cvCloneImage(img2);//复制图2，深拷贝，用来画特征点  \n\n      //默认提取的是LOWE格式的SIFT特征点  \n      //提取并显示第1幅图片上的特征点  \n      n1 = sift_features( img1, &amp;feat1 );//检测图1中的SIFT特征点,n1是图1的特征点个数  \n      export_features(&quot;feature1.txt&quot;,feat1,n1);//将特征向量数据写入到文件  \n      draw_features( img1_Feat, feat1, n1 );//画出特征点  \n      cvNamedWindow(IMG1_FEAT);//创建窗口  \n      cvShowImage(IMG1_FEAT,img1_Feat);//显示  \n\n      //提取并显示第2幅图片上的特征点  \n      n2 = sift_features( img2, &amp;feat2 );//检测图2中的SIFT特征点，n2是图2的特征点个数  \n      export_features(&quot;feature2.txt&quot;,feat2,n2);//将特征向量数据写入到文件  \n      draw_features( img2_Feat, feat2, n2 );//画出特征点  \n      cvNamedWindow(IMG2_FEAT);//创建窗口  \n      cvShowImage(IMG2_FEAT,img2_Feat);//显示  \n\n评价两幅图像中特征点的品质重要的指标是重复度，基于SIFT提取特征点如下所示：\n\n![](https://i.imgur.com/1twyToM.jpg)  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ![](https://i.imgur.com/HV9MWBY.jpg)\n\n\n\n\n利用k-d tree和BBF算法进行特征匹配查找\n特征点检测出来后，使用最近距离比次近距离算法（BBF）做特征点匹配。\n\n主要思想是先将图像1中的特征点建立k-d树，找到图像2中每个特征点到与图像1中点的最近邻距离d0和次近邻距离d1，淘汰d0/d1大于某个阈值的点，再把两幅图像中剩下的对应特征点匹配起来。\n\n也是调用RobHess源码中的函数，加上之后的一些筛选处理，主要代码如下：\n      //根据图1的特征点集feat1建立k-d树，返回k-d树根给kd_root  \n      kd_root = kdtree_build( feat1, n1 );  \n      Point pt1,pt2;//连线的两个端点  \n      double d0,d1;//feat2中每个特征点到最近邻和次近邻的距离  \n      int matchNum = 0;//经距离比值法筛选后的匹配点对的个数  \n      //遍历特征点集feat2，针对feat2中每个特征点feat，选取符合距离比值条件的匹配点，放到feat的fwd_match域中  \n      for(int i = 0; i &lt; n2; i++ )  \n      &#123;  \n          feat = feat2+i;//第i个特征点的指针  \n          //在kd_root中搜索目标点feat的2个最近邻点，存放在nbrs中，返回实际找到的近邻点个数  \n          int k = kdtree_bbf_knn( kd_root, feat, 2, &amp;nbrs, KDTREE_BBF_MAX_NN_CHKS );  \n          if( k == 2 )  \n          &#123;  \n              d0 = descr_dist_sq( feat, nbrs[0] );//feat与最近邻点的距离的平方  \n              d1 = descr_dist_sq( feat, nbrs[1] );//feat与次近邻点的距离的平方  \n              //若d0和d1的比值小于阈值NN_SQ_DIST_RATIO_THR，则接受此匹配，否则剔除  \n              if( d0 &lt; d1 * NN_SQ_DIST_RATIO_THR )  \n              &#123;   //将目标点feat和最近邻点作为匹配点对  \n                  pt2 = Point( cvRound( feat-&gt;x ), cvRound( feat-&gt;y ) );//图2中点的坐标  \n                  pt1 = Point( cvRound( nbrs[0]-&gt;x ), cvRound( nbrs[0]-&gt;y ) );//图1中点的坐标(feat的最近邻点)  \n                  pt2.x += img1-&gt;width;//由于两幅图是左右排列的，pt2的横坐标加上图1的宽度，作为连线的终点  \n                  cvLine( stacked, pt1, pt2, CV_RGB(255,0,255), 1, 8, 0 );//画出连线  \n                  matchNum++;//统计匹配点对的个数  \n                  feat2[i].fwd_match = nbrs[0];//使点feat的fwd_match域指向其对应的匹配点  \n              &#125;  \n          &#125;  \n          free( nbrs );//释放近邻数组  \n      &#125;  \n      //显示并保存经距离比值法筛选后的匹配图  \n      cvNamedWindow(IMG_MATCH1);//创建窗口  \n      cvShowImage(IMG_MATCH1,stacked);//显示\n\n匹配结果如下：\n![](https://i.imgur.com/XlwuW4Q.jpg)\n\n\n\n\n\n\n利用RANSAC算法筛选匹配点并计算变换矩阵\n利用随机采样一致算法（RANSAC），筛选匹配点，RANSAC算法是目前使用的很广泛的剔除误配点的方法。\n\n此部分最主要的是RobHess源码中的ransac_xform()函数，此函数实现了用RANSAC算法筛选匹配点，返回结果是计算好的变换矩阵，若能成功计算出变换矩阵，即两幅图中有共同区域，可以进行拼接。\n\n程序中计算出的变换矩阵H用来将img2中的点变换为img1中的点，无论img1和img2的左右顺序，计算出的变换矩阵H永远是将img2中的特征点变换为其匹配点，即将img2中的点变换为img1中的对应点。\n\n此部分中，我利用匹配点的坐标关系，对输入的两幅图像的左右关系进行了判断，并根据结果选择使用矩阵H或H的逆阵进行变换。\n\n所以读入的两幅要拼接的图像的左右位置关系可以随意，程序中可自动调整。\n\n主要代码如下：\n      //利用RANSAC算法筛选匹配点,计算变换矩阵H，  \n      //无论img1和img2的左右顺序，计算出的H永远是将feat2中的特征点变换为其匹配点，即将img2中的点变换为img1中的对应点  \n      H = ransac_xform(feat2,n2,FEATURE_FWD_MATCH,lsq_homog,4,0.01,homog_xfer_err,3.0,&amp;inliers,&amp;n_inliers);  \n      //若能成功计算出变换矩阵，即两幅图中有共同区域  \n      if( H )  \n      &#123;  \n          qDebug()&lt;&lt;tr(&quot;经RANSAC算法筛选后的匹配点对个数：&quot;)&lt;&lt;n_inliers&lt;&lt;endl; //输出筛选后的匹配点对个数  \n          int invertNum = 0;//统计pt2.x &gt; pt1.x的匹配点对的个数，来判断img1中是否右图  \n          //遍历经RANSAC算法筛选后的特征点集合inliers，找到每个特征点的匹配点，画出连线  \n          for(int i=0; i&lt;n_inliers; i++)  \n          &#123;  \n              feat = inliers[i];//第i个特征点  \n              pt2 = Point(cvRound(feat-&gt;x), cvRound(feat-&gt;y));//图2中点的坐标  \n              pt1 = Point(cvRound(feat-&gt;fwd_match-&gt;x), cvRound(feat-&gt;fwd_match-&gt;y));//图1中点的坐标(feat的匹配点)  \n              //qDebug()&lt;&lt;&quot;pt2:(&quot;&lt;&lt;pt2.x&lt;&lt;&quot;,&quot;&lt;&lt;pt2.y&lt;&lt;&quot;)---&gt;pt1:(&quot;&lt;&lt;pt1.x&lt;&lt;&quot;,&quot;&lt;&lt;pt1.y&lt;&lt;&quot;)&quot;;//输出对应点对  \n              //统计匹配点的左右位置关系，来判断图1和图2的左右位置关系  \n              if(pt2.x &gt; pt1.x)  \n                  invertNum++;  \n              pt2.x += img1-&gt;width;//由于两幅图是左右排列的，pt2的横坐标加上图1的宽度，作为连线的终点  \n              cvLine(stacked_ransac,pt1,pt2,CV_RGB(255,0,255),1,8,0);//在匹配图上画出连线  \n          &#125;  \n          cvNamedWindow(IMG_MATCH2);//创建窗口  \n          cvShowImage(IMG_MATCH2,stacked_ransac);//显示经RANSAC算法筛选后的匹配图  \n          /*程序中计算出的变换矩阵H用来将img2中的点变换为img1中的点，正常情况下img1应该是左图，img2应该是右图。 \n            此时img2中的点pt2和img1中的对应点pt1的x坐标的关系基本都是：pt2.x &lt; pt1.x \n            若用户打开的img1是右图，img2是左图，则img2中的点pt2和img1中的对应点pt1的x坐标的关系基本都是：pt2.x &gt; pt1.x \n            所以通过统计对应点变换前后x坐标大小关系，可以知道img1是不是右图。 \n            如果img1是右图，将img1中的匹配点经H的逆阵H_IVT变换后可得到img2中的匹配点*/  \n          //若pt2.x &gt; pt1.x的点的个数大于内点个数的80%，则认定img1中是右图  \n          if(invertNum &gt; n_inliers * 0.8)  \n          &#123;  \n              CvMat * H_IVT = cvCreateMat(3, 3, CV_64FC1);//变换矩阵的逆矩阵  \n              //求H的逆阵H_IVT时，若成功求出，返回非零值  \n              if( cvInvert(H,H_IVT) )  \n              &#123;  \n                  cvReleaseMat(&amp;H);//释放变换矩阵H，因为用不到了  \n                  H = cvCloneMat(H_IVT);//将H的逆阵H_IVT中的数据拷贝到H中  \n                  cvReleaseMat(&amp;H_IVT);//释放逆阵H_IVT  \n                  //将img1和img2对调  \n                  IplImage * temp = img2;  \n                  img2 = img1;  \n                  img1 = temp;  \n                  ui-&gt;mosaicButton-&gt;setEnabled(true);//激活全景拼接按钮  \n              &#125;  \n              else//H不可逆时，返回0  \n              &#123;  \n                  cvReleaseMat(&amp;H_IVT);//释放逆阵H_IVT  \n                  QMessageBox::warning(this,tr(&quot;警告&quot;),tr(&quot;变换矩阵H不可逆&quot;));  \n              &#125;  \n          &#125;  \n          else  \n              ui-&gt;mosaicButton-&gt;setEnabled(true);//激活全景拼接按钮  \n      &#125;  \n      else //无法计算出变换矩阵，即两幅图中没有重合区域  \n      &#123;  \n          QMessageBox::warning(this,tr(&quot;警告&quot;),tr(&quot;两图中无公共区域&quot;));  \n      &#125;\n\n经RANSAC筛选后的匹配结果如下图：\n\n\n\n![](https://i.imgur.com/iSkYnf0.jpg)\n\n\n图像融合\n这里的拼接的方法有两种：\n\n简易拼接方法的过程是：首先将右图img2经变换矩阵H变换到一个新图像中，然后直接将左图img1加到新图像中，这样拼接出来会有明显的拼接缝，但也是一个初步的成品了。\n\n另一种方法首先也是将右图img2经变换矩阵H变换到一个新图像中，然后图像的融合过程将目标图像分为三部分，最左边完全取自img1中的数据，中间的重合部分是两幅图像的加权平均，重合区域右边的部分完全取自img2经变换后的图像。加权平均的权重选择也有好多方法，比如可以使用最基本的取两张图像的平均值，但这样会有明显的拼接缝。这里首先计算出拼接区域的宽度，设d1，d2分别是重叠区域中的点到重叠区域左边界和右边界的距离，则使用如下公式计算重叠区域的像素值：\n , 这样就可以实现平滑过渡。\n\n\n\n主要代码如下：\n              //若能成功计算出变换矩阵，即两幅图中有共同区域，才可以进行全景拼接  \n              if(H)  \n              &#123;  \n                  //拼接图像，img1是左图，img2是右图  \n                  CalcFourCorner();//计算图2的四个角经变换后的坐标  \n                  //为拼接结果图xformed分配空间,高度为图1图2高度的较小者，根据图2右上角和右下角变换后的点的位置决定拼接图的宽度  \n                  xformed = cvCreateImage(cvSize(MIN(rightTop.x,rightBottom.x),MIN(img1-&gt;height,img2-&gt;height)),IPL_DEPTH_8U,3);  \n                  //用变换矩阵H对右图img2做投影变换(变换后会有坐标右移)，结果放到xformed中  \n                  cvWarpPerspective(img2,xformed,H,CV_INTER_LINEAR + CV_WARP_FILL_OUTLIERS,cvScalarAll(0));  \n                  cvNamedWindow(IMG_MOSAIC_TEMP); //显示临时图,即只将图2变换后的图  \n                  cvShowImage(IMG_MOSAIC_TEMP,xformed);  \n                  //简易拼接法：直接将将左图img1叠加到xformed的左边  \n                  xformed_simple = cvCloneImage(xformed);//简易拼接图，克隆自xformed  \n                  cvSetImageROI(xformed_simple,cvRect(0,0,img1-&gt;width,img1-&gt;height));  \n                  cvAddWeighted(img1,1,xformed_simple,0,0,xformed_simple);  \n                  cvResetImageROI(xformed_simple);  \n                  cvNamedWindow(IMG_MOSAIC_SIMPLE);//创建窗口  \n                  cvShowImage(IMG_MOSAIC_SIMPLE,xformed_simple);//显示简易拼接图  \n                  //处理后的拼接图，克隆自xformed  \n                  xformed_proc = cvCloneImage(xformed);  \n                  //重叠区域左边的部分完全取自图1  \n                  cvSetImageROI(img1,cvRect(0,0,MIN(leftTop.x,leftBottom.x),xformed_proc-&gt;height));  \n                  cvSetImageROI(xformed,cvRect(0,0,MIN(leftTop.x,leftBottom.x),xformed_proc-&gt;height));  \n                  cvSetImageROI(xformed_proc,cvRect(0,0,MIN(leftTop.x,leftBottom.x),xformed_proc-&gt;height));  \n                  cvAddWeighted(img1,1,xformed,0,0,xformed_proc);  \n                  cvResetImageROI(img1);  \n                  cvResetImageROI(xformed);  \n                  cvResetImageROI(xformed_proc);  \n                  cvNamedWindow(IMG_MOSAIC_BEFORE_FUSION);  \n                  cvShowImage(IMG_MOSAIC_BEFORE_FUSION,xformed_proc);//显示融合之前的拼接图  \n                  //采用加权平均的方法融合重叠区域  \n                  int start = MIN(leftTop.x,leftBottom.x) ;//开始位置，即重叠区域的左边界  \n                  double processWidth = img1-&gt;width - start;//重叠区域的宽度  \n                  double alpha = 1;//img1中像素的权重  \n                  for(int i=0; i&lt;xformed_proc-&gt;height; i++)//遍历行  \n                  &#123;  \n                      const uchar * pixel_img1 = ((uchar *)(img1-&gt;imageData + img1-&gt;widthStep * i));//img1中第i行数据的指针  \n                      const uchar * pixel_xformed = ((uchar *)(xformed-&gt;imageData + xformed-&gt;widthStep * i));//xformed中第i行数据的指针  \n                      uchar * pixel_xformed_proc = ((uchar *)(xformed_proc-&gt;imageData + xformed_proc-&gt;widthStep * i));//xformed_proc中第i行数据的指针  \n                      for(int j=start; j&lt;img1-&gt;width; j++)//遍历重叠区域的列  \n                      &#123;  \n                          //如果遇到图像xformed中无像素的黑点，则完全拷贝图1中的数据  \n                          if(pixel_xformed[j*3] &lt; 50 &amp;&amp; pixel_xformed[j*3+1] &lt; 50 &amp;&amp; pixel_xformed[j*3+2] &lt; 50 )  \n                          &#123;  \n                              alpha = 1;  \n                          &#125;  \n                          else  \n                          &#123;   //img1中像素的权重，与当前处理点距重叠区域左边界的距离成正比  \n                              alpha = (processWidth-(j-start)) / processWidth ;  \n                          &#125;  \n                          pixel_xformed_proc[j*3] = pixel_img1[j*3] * alpha + pixel_xformed[j*3] * (1-alpha);//B通道  \n                          pixel_xformed_proc[j*3+1] = pixel_img1[j*3+1] * alpha + pixel_xformed[j*3+1] * (1-alpha);//G通道  \n                          pixel_xformed_proc[j*3+2] = pixel_img1[j*3+2] * alpha + pixel_xformed[j*3+2] * (1-alpha);//R通道  \n                      &#125;  \n                  &#125;  \n                  cvNamedWindow(IMG_MOSAIC_PROC);//创建窗口  \n                  cvShowImage(IMG_MOSAIC_PROC,xformed_proc);//显示处理后的拼接图  \n                  /*重叠区域取两幅图像的平均值，效果不好 \n                      //设置ROI，是包含重叠区域的矩形 \n                      cvSetImageROI(xformed_proc,cvRect(MIN(leftTop.x,leftBottom.x),0,img1-&gt;width-MIN(leftTop.x,leftBottom.x),xformed_proc-&gt;height)); \n                      cvSetImageROI(img1,cvRect(MIN(leftTop.x,leftBottom.x),0,img1-&gt;width-MIN(leftTop.x,leftBottom.x),xformed_proc-&gt;height)); \n                      cvSetImageROI(xformed,cvRect(MIN(leftTop.x,leftBottom.x),0,img1-&gt;width-MIN(leftTop.x,leftBottom.x),xformed_proc-&gt;height)); \n                      cvAddWeighted(img1,0.5,xformed,0.5,0,xformed_proc); \n                      cvResetImageROI(xformed_proc); \n                      cvResetImageROI(img1); \n                      cvResetImageROI(xformed); //*/  \n                  /*对拼接缝周围区域进行滤波来消除拼接缝，效果不好 \n                      //在处理前后的图上分别设置横跨拼接缝的矩形ROI \n                      cvSetImageROI(xformed_proc,cvRect(img1-&gt;width-10,0,img1-&gt;width+10,xformed-&gt;height)); \n                      cvSetImageROI(xformed,cvRect(img1-&gt;width-10,0,img1-&gt;width+10,xformed-&gt;height)); \n                      cvSmooth(xformed,xformed_proc,CV_MEDIAN,5);//对拼接缝周围区域进行中值滤波 \n                      cvResetImageROI(xformed); \n                      cvResetImageROI(xformed_proc); \n                      cvShowImage(IMG_MOSAIC_PROC,xformed_proc);//显示处理后的拼接图 */  \n                  /*想通过锐化解决变换后的图像失真的问题，对于扭曲过大的图像，效果不好 \n                      double a[]=&#123;  0, -1,  0, -1,  5, -1, 0, -1,  0  &#125;;//拉普拉斯滤波核的数据 \n                      CvMat kernel = cvMat(3,3,CV_64FC1,a);//拉普拉斯滤波核 \n                      cvFilter2D(xformed_proc,xformed_proc,&amp;kernel);//滤波 \n                      cvShowImage(IMG_MOSAIC_PROC,xformed_proc);//显示处理后的拼接图*/  \n\n              &#125;  \n\n实验结果如下：\n\n![](https://i.imgur.com/AELS813.png)\n\n\n\n\n源码下载\n源码下载，基于SIFT与ransac的全景图像拼接，VS2017工程：http://download.csdn.net/download/tanqingbo/10170915\n\n","categories":["图像处理"],"tags":[]},{"title":"均值滤波和中值滤波去噪","url":"http://tanqingbo.cn/2017/12/13/均值滤波和中值滤波去噪/","content":"\n均值滤波和中值滤波的内容非常基础，均值滤波相当于低通滤波，有将图像模糊化的趋势，对椒盐噪声基本无能为力。中值滤波的优点是可以很好的过滤掉椒盐噪声，缺点是易造成图像的不连续性。在下面的代码中，中值滤波主要通过冒泡算法来实现。\n\n程序中值滤波    public void jMedian_ActionPerformed(ActionEvent e) &#123;      \n        if(flag_load)&#123;  \n            try&#123;  \n                  PixelGrabber pg = new PixelGrabber(im,0,0,iw,ih,pixels,0,iw);  \n                  pg.grabPixels();  \n              &#125;catch(InterruptedException e3)&#123;  \n                e3.printStackTrace();  \n              &#125;  \n            BufferedImage grayImage = new BufferedImage(iw, ih,   \n                      BufferedImage.TYPE_INT_RGB);  \n            ColorModel cm = ColorModel.getRGBdefault();  \n            int[] tpRed = new int[9];  \n            int[] tpGreen = new int[9];  \n            int[] tpBlue = new int[9];  \n            for(int i=1;i&lt;ih-1;i++)&#123;  \n                for(int j=1;j&lt;iw-1;j++)&#123;  \n                    tpRed[0] = cm.getRed(pixels[(i-1)*iw+j-1]);  \n                    tpRed[1] = cm.getRed(pixels[(i-1)*iw+j]);  \n                    tpRed[2] = cm.getRed(pixels[(i-1)*iw+j+1]);  \n                    tpRed[3] = cm.getRed(pixels[i*iw+j-1]);  \n                    tpRed[4] = cm.getRed(pixels[i*iw+j]);  \n                    tpRed[5] = cm.getRed(pixels[i*iw+j+1]);  \n                    tpRed[6] = cm.getRed(pixels[(i+1)*iw+j-1]);  \n                    tpRed[7] = cm.getRed(pixels[(i+1)*iw+j]);  \n                    tpRed[8] = cm.getRed(pixels[(i+1)*iw+j+1]);  \n                        for(int rj=0; rj&lt;8; rj++)&#123;  \n                        for(int ri=0; ri&lt;8-rj; ri++)&#123;  \n                            if(tpRed[ri]&gt;tpRed[ri+1])&#123;  \n                                int Red_Temp = tpRed[ri];  \n                                tpRed[ri] = tpRed[ri+1];  \n                                tpRed[ri+1] = Red_Temp;  \n                            &#125;  \n                        &#125;  \n                    &#125;  \n                    int medianRed = tpRed[4];  \n                    tpGreen[0] = cm.getGreen(pixels[(i-1)*iw+j-1]);  \n                    tpGreen[1] = cm.getGreen(pixels[(i-1)*iw+j]);  \n                    tpGreen[2] = cm.getGreen(pixels[(i-1)*iw+j+1]);  \n                    tpGreen[3] = cm.getGreen(pixels[i*iw+j-1]);  \n                    tpGreen[4] = cm.getGreen(pixels[i*iw+j]);  \n                    tpGreen[5] = cm.getGreen(pixels[i*iw+j+1]);  \n                    tpGreen[6] = cm.getGreen(pixels[(i+1)*iw+j-1]);  \n                    tpGreen[7] = cm.getGreen(pixels[(i+1)*iw+j]);  \n                    tpGreen[8] = cm.getGreen(pixels[(i+1)*iw+j+1]);  \n                    for(int rj=0; rj&lt;8; rj++)&#123;  \n                        for(int ri=0; ri&lt;8-rj; ri++)&#123;  \n                            if(tpGreen[ri]&gt;tpGreen[ri+1])&#123;  \n                                int Green_Temp = tpGreen[ri];  \n                                tpGreen[ri] = tpGreen[ri+1];  \n                                tpGreen[ri+1] = Green_Temp;  \n                            &#125;  \n                        &#125;  \n                    &#125;  \n                    int medianGreen = tpGreen[4];  \n                    tpBlue[0] = cm.getBlue(pixels[(i-1)*iw+j-1]);  \n                    tpBlue[1] = cm.getBlue(pixels[(i-1)*iw+j]);  \n                    tpBlue[2] = cm.getBlue(pixels[(i-1)*iw+j+1]);  \n                    tpBlue[3] = cm.getBlue(pixels[i*iw+j-1]);  \n                    tpBlue[4] = cm.getBlue(pixels[i*iw+j]);  \n                    tpBlue[5] = cm.getBlue(pixels[i*iw+j+1]);  \n                    tpBlue[6] = cm.getBlue(pixels[(i+1)*iw+j-1]);  \n                    tpBlue[7] = cm.getBlue(pixels[(i+1)*iw+j]);  \n                    tpBlue[8] = cm.getBlue(pixels[(i+1)*iw+j+1]);  \n                    for(int rj=0; rj&lt;8; rj++)&#123;  \n                        for(int ri=0; ri&lt;8-rj; ri++)&#123;  \n                            if(tpBlue[ri]&gt;tpBlue[ri+1])&#123;  \n                                int Blue_Temp = tpBlue[ri];  \n                                tpBlue[ri] = tpBlue[ri+1];  \n                                tpBlue[ri+1] = Blue_Temp;  \n                            &#125;  \n                        &#125;  \n                    &#125;  \n                    int medianBlue = tpBlue[4];  \n                    int rgb = 255&lt;&lt;24|medianRed&lt;&lt;16|medianGreen&lt;&lt;8|medianBlue;   \n                    grayImage.setRGB(j, i, rgb);  \n                &#125;     \n            &#125;  \n            tmp = grayImage;  \n            repaint();  \n        &#125;else&#123;  \n            JOptionPane.showMessageDialog(null, &quot;先点击“装载图像”，3Q！&quot;,&quot;提示：&quot;,  \n                    JOptionPane.WARNING_MESSAGE);  \n            &#125;  \n    &#125;\n均值滤波        public void jMean_ActionPerformed(ActionEvent e) &#123;      \n            if(flag_load)&#123;  \n                try&#123;  \n                      PixelGrabber pg = new PixelGrabber(im,0,0,iw,ih,pixels,0,iw);  \n                      pg.grabPixels();  \n                  &#125;catch(InterruptedException e3)&#123;  \n                    e3.printStackTrace();  \n                  &#125;  \n                BufferedImage grayImage = new BufferedImage(iw, ih,   \n                          BufferedImage.TYPE_INT_RGB);  \n                ColorModel cm = ColorModel.getRGBdefault();  \n                for(int i=1;i&lt;ih-1;i++)&#123;  \n                    for(int j=1;j&lt;iw-1;j++)&#123;  \n                        int red1 = cm.getRed(pixels[(i-1)*iw+j-1]);  \n                        int red2 = cm.getRed(pixels[(i-1)*iw+j]);  \n                        int red3 = cm.getRed(pixels[(i-1)*iw+j+1]);  \n                        int red4 = cm.getRed(pixels[i*iw+j-1]);  \n                        int red6 = cm.getRed(pixels[i*iw+j+1]);  \n                        int red7 = cm.getRed(pixels[(i+1)*iw+j-1]);  \n                        int red8 = cm.getRed(pixels[(i+1)*iw+j]);  \n                        int red9 = cm.getRed(pixels[(i+1)*iw+j+1]);  \n                        int meanRed = (red1+red2+red3+red4+red6+red7+red8+red9)/8;  \n                        int green1 = cm.getGreen(pixels[(i-1)*iw+j-1]);  \n                        int green2 = cm.getGreen(pixels[(i-1)*iw+j]);  \n                        int green3 = cm.getGreen(pixels[(i-1)*iw+j+1]);  \n                        int green4 = cm.getGreen(pixels[i*iw+j-1]);  \n                        int green6 = cm.getGreen(pixels[i*iw+j+1]);  \n                        int green7 = cm.getGreen(pixels[(i+1)*iw+j-1]);  \n                        int green8 = cm.getGreen(pixels[(i+1)*iw+j]);  \n                        int green9 = cm.getGreen(pixels[(i+1)*iw+j+1]);  \n                        int meanGreen = (green1+green2+green3+green4+green6+green7+green8+green9)/8;  \n                        int blue1 = cm.getBlue(pixels[(i-1)*iw+j-1]);  \n                        int blue2 = cm.getBlue(pixels[(i-1)*iw+j]);  \n                        int blue3 = cm.getBlue(pixels[(i-1)*iw+j+1]);  \n                        int blue4 = cm.getBlue(pixels[i*iw+j-1]);  \n                        int blue6 = cm.getBlue(pixels[i*iw+j+1]);  \n                        int blue7 = cm.getBlue(pixels[(i+1)*iw+j-1]);  \n                        int blue8 = cm.getBlue(pixels[(i+1)*iw+j]);  \n                        int blue9 = cm.getBlue(pixels[(i+1)*iw+j+1]);  \n                        int meanBlue = (blue1+blue2+blue3+blue4+blue6+blue7+blue8+blue9)/8;  \n                        int rgb = 255&lt;&lt;24|meanRed&lt;&lt;16|meanGreen&lt;&lt;8|meanBlue;   \n                        grayImage.setRGB(j, i, rgb);  \n                    &#125;     \n                &#125;  \n                tmp = grayImage;  \n                repaint();  \n            &#125;else&#123;  \n                JOptionPane.showMessageDialog(null, &quot;先点击“装载图像”，3Q！&quot;,&quot;提示：&quot;,  \n                        JOptionPane.WARNING_MESSAGE);  \n                &#125;  \n        &#125;  \n去噪效果高斯噪声\n椒盐噪声\n源码下载\nhttp://download.csdn.net/download/tanqingbo/10162135\n\n","categories":["图像处理"],"tags":[]},{"title":"图像处理之加噪声","url":"http://tanqingbo.cn/2017/12/13/图像处理之加噪声/","content":"前言\n图像处理的实验，用matlab捣鼓了一会最后还是觉得Java用的比较顺手，所以使用Java实现的给图像加噪声，分别给图像添加椒盐噪声、高斯噪声、泊松分布噪声。椒盐噪声（Salt And Pepper Noise）\n椒盐噪声是一种因为信号脉冲强度引起的噪声，信噪比（Signal NoiseRate）是衡量图像噪声的一个数字指标。\n给一副数字图像加上椒盐噪声的处理顺序应该如下：\n指定信噪比 SNR 其取值范围在[0, 1]之间\n\n\n计算总像素数目 SP， 得到要加噪的像素数目 NP = SP * (1-SNR)\n随机获取要加噪的每个像素位置P（i, j）\n指定像素值为255或者0。\n重复3, 4两个步骤完成所有像素的NP个像素\n输出加噪以后的图像\n\n\n\n代码如下：\n        /*\n         * 椒盐噪声\n         */\n        private BufferedImage addSaltAndPepperNoise(BufferedImage src, BufferedImage dst) &#123;  \n            int width = src.getWidth();  \n               int height = src.getHeight();  \n\n               if ( dst == null )  \n                   dst = createCompatibleDestImage( src, null );  \n\n               int[] inPixels = new int[width*height];  \n               getRGB( src, 0, 0, width, height, inPixels );  \n\n               int index = 0;  \n               int size = (int)(inPixels.length * (1-SNR));  \n\n               for(int i=0; i&lt;size; i++) &#123;  \n                int row = (int)(Math.random() * (double)height);  \n                int col = (int)(Math.random() * (double)width);  \n                index = row * width + col;  \n                inPixels[index] = (255 &lt;&lt; 24) | (255 &lt;&lt; 16) | (255 &lt;&lt; 8) | 255;  \n               &#125;  \n\n               setRGB( dst, 0, 0, width, height, inPixels );  \n               return dst;  \n        &#125;\n高斯噪声（Gaussian Noise）\n高斯噪声的密度取决于公式G(x, sigma) 其中X是代表平均值，sigma代表的标准方差，每个输入像素 Pin,一个正常的高斯采样分布公式G(d), 得到输出像素Pout.\n Pout = Pin + XMeans + sigma *G(d)\n\n其中d为一个线性的随机数，G(d)是随机数的高斯分布随机值。\n\n给一副数字图像加上高斯噪声的处理顺序如下：\n\n输入参数sigam 和 X mean\n\n\n系统时间为种子产生一个伪随机数\n将伪随机数带入G（d）得到高斯随机数\n根据输入像素计算出输出像素\n重新将像素值防缩在[0 ~ 255]之间\n循环所有像素\n输出图像\n\n\n代码如下：\n  /*\n   * 添加高斯噪声\n   */\n  private int addGNoise(int tr, Random random) &#123;  \n      int v, ran;  \n      boolean inRange = false;  \n      do &#123;  \n          ran = (int)Math.round(random.nextGaussian()*_mNoiseFactor);  //均值为0.0，标准差为1.0的高斯分布\n          v = tr + ran;  \n          // check whether it is valid single channel value  \n          inRange = (v&gt;=0 &amp;&amp; v&lt;=255);   \n          if (inRange) tr = v;  \n      &#125; while (!inRange);  \n      return tr;   \n  &#125;  \n\n  public static int clamp(int p) &#123;  \n      return p &gt; 255 ? 255 : (p &lt; 0 ? 0 : p);  \n  &#125;  \n\n\n泊松噪声\n泊松噪声，就是噪声分布符合泊松分布模型。泊松分布(Poisson Di)的公式如下：\n\n\n![](http://img.my.csdn.net/uploads/201212/04/1354634287_1117.png)\n![](http://img.my.csdn.net/uploads/201212/04/1354634287_1117.png)\n\n+ 关于泊松分布的详细解释看这里：[http://zh.wikipedia.org/wiki/泊松分佈](http://zh.wikipedia.org/wiki/泊松分佈).\n\n\n代码如下：\n       /*\n       * 泊松噪声\n       */\n      private int addPNoise(int pixel, Random random) &#123;  \n          // init:  \n          double L = Math.exp(-_mNoiseFactor * MEAN_FACTOR);  \n          int k = 0;  \n          double p = 1;  \n          do &#123;  \n              k++;  \n              // Generate uniform random number u in [0,1] and let p ← p × u.  \n              p *= random.nextDouble();  \n          &#125; while (p &gt;= L);  \n          double retValue = Math.max((pixel + (k - 1) / MEAN_FACTOR - _mNoiseFactor), 0);  \n          return (int)retValue;  \n      &#125;  \n程序效果\n原图\n\n\n\n\n高斯噪声\n\n\n\n椒盐噪声\n\n\n全部代码        package lab3;\n        import java.awt.image.BufferedImage;  \n        import java.util.Random;  \n        public class NoiseAdditionFilter extends AbstractBufferedImageOp &#123;  \n            public final static double MEAN_FACTOR = 2.0;  \n            public final static int POISSON_NOISE_TYPE = 2;  //泊松噪声\n            public final static int GAUSSION_NOISE_TYPE = 1;  //高斯噪声\n            public final static int Salt_NOISE_TYPE = 3;  //椒盐噪声\n            private double _mNoiseFactor = 100;   //高斯分布数值大小\n            private int _mNoiseType = 2;    //选择噪声\n            private static final double SNR = 0.5;   //椒盐噪声信噪比\n            public NoiseAdditionFilter() &#123;  \n                System.out.println(&quot;Adding Poisson/Gaussion Noise&quot;);  \n            &#125;  \n            public void setNoise(double power) &#123;  \n                this._mNoiseFactor = power;  \n            &#125;  \n            public void setNoiseType(int type) &#123;  \n                this._mNoiseType = type;  \n            &#125;  \n            @Override  \n            public BufferedImage filter(BufferedImage src, BufferedImage dest) &#123;  \n                int width = src.getWidth();  \n                int height = src.getHeight();  \n                Random random = new Random();  \n                if ( dest == null )  \n                    dest = createCompatibleDestImage( src, null );  \n                int[] inPixels = new int[width*height];  \n                int[] outPixels = new int[width*height];  \n                getRGB( src, 0, 0, width, height, inPixels );  \n                int index = 0;  \n                for(int row=0; row&lt;height; row++) &#123;  \n                    int ta = 0, tr = 0, tg = 0, tb = 0;  \n                    for(int col=0; col&lt;width; col++) &#123;  \n                        index = row * width + col;  \n                        ta = (inPixels[index] &gt;&gt; 24) &amp; 0xff;  \n                        tr = (inPixels[index] &gt;&gt; 16) &amp; 0xff;  \n                        tg = (inPixels[index] &gt;&gt; 8) &amp; 0xff;  \n                        tb = inPixels[index] &amp; 0xff;  \n                        if(_mNoiseType == Salt_NOISE_TYPE) &#123;\n                            return this.addSaltAndPepperNoise(src,dest);\n                        &#125;\n                        if(_mNoiseType == POISSON_NOISE_TYPE) &#123;  \n                            tr = clamp(addPNoise(tr, random));  \n                            tg = clamp(addPNoise(tg, random));  \n                            tb = clamp(addPNoise(tb, random));  \n                        &#125; else if(_mNoiseType == GAUSSION_NOISE_TYPE) &#123;  \n                            tr = clamp(addGNoise(tr, random));  \n                            tg = clamp(addGNoise(tg, random));  \n                            tb = clamp(addGNoise(tb, random));  \n                        &#125;  \n                        outPixels[index] = (ta &lt;&lt; 24) | (tr &lt;&lt; 16) | (tg &lt;&lt; 8) | tb;  \n                    &#125;  \n                &#125;  \n          System.out.println(&quot;fd&quot;);\n                setRGB( dest, 0, 0, width, height, outPixels );  \n                return dest;  \n            &#125;  \n            /*\n             * 添加高斯噪声\n             */\n            private int addGNoise(int tr, Random random) &#123;  \n                int v, ran;  \n                boolean inRange = false;  \n                do &#123;  \n                    ran = (int)Math.round(random.nextGaussian()*_mNoiseFactor);  //均值为0.0，标准差为1.0的高斯分布\n                    v = tr + ran;  \n                    // check whether it is valid single channel value  \n                    inRange = (v&gt;=0 &amp;&amp; v&lt;=255);   \n                    if (inRange) tr = v;  \n                &#125; while (!inRange);  \n                return tr;   \n            &#125;  \n\n            public static int clamp(int p) &#123;  \n                return p &gt; 255 ? 255 : (p &lt; 0 ? 0 : p);  \n            &#125;  \n            /*\n             * 泊松噪声\n             */\n            private int addPNoise(int pixel, Random random) &#123;  \n                // init:  \n                double L = Math.exp(-_mNoiseFactor * MEAN_FACTOR);  \n                int k = 0;  \n                double p = 1;  \n                do &#123;  \n                    k++;  \n                    // Generate uniform random number u in [0,1] and let p ← p × u.  \n                    p *= random.nextDouble();  \n                &#125; while (p &gt;= L);  \n                double retValue = Math.max((pixel + (k - 1) / MEAN_FACTOR - _mNoiseFactor), 0);  \n                return (int)retValue;  \n            &#125;  \n            /*\n             * 椒盐噪声\n             */\n            private BufferedImage addSaltAndPepperNoise(BufferedImage src, BufferedImage dst) &#123;  \n                int width = src.getWidth();  \n                   int height = src.getHeight();  \n                   if ( dst == null )  \n                       dst = createCompatibleDestImage( src, null );  \n                   int[] inPixels = new int[width*height];  \n                   getRGB( src, 0, 0, width, height, inPixels );  \n\n                   int index = 0;  \n                   int size = (int)(inPixels.length * (1-SNR));  \n\n                   for(int i=0; i&lt;size; i++) &#123;  \n                    int row = (int)(Math.random() * (double)height);  \n                    int col = (int)(Math.random() * (double)width);  \n                    index = row * width + col;  \n                    inPixels[index] = (255 &lt;&lt; 24) | (255 &lt;&lt; 16) | (255 &lt;&lt; 8) | 255;  \n                   &#125;  \n                   setRGB( dst, 0, 0, width, height, inPixels );  \n                   return dst;  \n            &#125;\n        &#125;  \n","categories":["图像处理"],"tags":[]},{"title":"分割精度性能度量","url":"http://tanqingbo.cn/2017/12/07/分割精度说明/","content":"介绍\n为了能对提出的方法的性能进行定量的评估。本文采用了和2007年医学影像计算与计算机辅助介入国际会议（MICCAI）医学图像分割竞赛[21]相同的两个基于体积的度量指标体积重叠率（Dice Similarity Coefficient，Dice）和基于表面距离的度量指标平均对称表面距离（Average Symmetric Surface Distance，ASD）来对分割结果A与手动分割金标准B进行比较。其中体积重叠率（Dice）与平均对称表面距离（ASD）的定义如下：\n（1）体积重叠率（Dice Similarity Coefficient，Dice）：在定义体积重叠率之前需要先定义分割结果A和金标准B的体积重叠率系数，也称Jaccard系数( Jaccard Index，JI )[22]:\n\n\n![](https://i.imgur.com/LeMgoui.png)\n\n\n\n其中，V(A)表示分割结果A的体素集合、V(B)表示金标准B的体素集合。相应的，体积重叠率（Dice）就可以定义为：\n\n![](https://i.imgur.com/eNf02xo.png)\n\n\n（2）平均对称表面距离（Average Symmetric Surface Distance，ASD）：它是基于表面距离的度量指标。定义为分割结果A的表面体素S(A)与金标准B的表面体素S(B)之间的平均距离：\n\n\n\n![](https://i.imgur.com/SEjWaWg.png)\n\n\n\n其中，d(v,S(X))定义为体素V到分割结果X表面体素的最小欧式距离：\n\n\n![](https://i.imgur.com/ZLAgllG.png)\n\n+ 这两个基于体积的度量指标体积重叠率（Dice）和基于表面距离的度量指标平均对称表面距离（ASD）的单位分别为%和mm，对于体积重叠率（Dice）来说，值越大表示分割结果越精确，对于平均对称表面距离（ASD）来说，值越小说明分割结果越精确。\n\n算法实现\n计算体积重叠率的时候，先计算分割结果和金标准的非零体素的总个数volume1+volume2，再计算体素重叠的个数intersection，用intersection/（volume1+volume2）得到JI，再用Dice计算公式得到Dice。\n\n部分代码如下：\n      // Tanimoto overlap metric\n        unsigned long volume1=0, volume2=0, intersection=0;\n        IteratorType resIt( resultImage, resRegion ), valIt( validationImage, valRegion );\n        for ( resIt.GoToBegin(), valIt.GoToBegin(); !resIt.IsAtEnd(); ++resIt, ++valIt ) &#123;\n          if (resIt.Get()!=0) &#123;\n            volume1++;\n            if (valIt.Get()!=0) &#123;\n              volume2++;\n              intersection++;\n            &#125;\n          &#125;\n          else &#123;\n            if (valIt.Get()!=0) volume2++;\n          &#125;\n        &#125;\n        double tanimotoVal = 100.0 * (double)(intersection) / ((double)(volume1+volume2-intersection));\n        double tanimotoError = 100.0 - tanimotoVal;\n       //求dice\n        double jiError = (100.0 - tanimotoError)/100.0;\n        double diceError = 2 * jiError/(1 + jiError) * 100;\n\n\n\n计算平均对称表面距离ASD的时候，需要先计算分割结果和金标准元素在同一个坐标系里面的全球坐标，再利用ANNkd_tree类求平均表面对称距离。\n\n部分代码如下：\n    ANNpointArray borderPts2 = annAllocPts( numBorderPts2, 3 );\n    numBorderPts2 = 0;\n    for ( it2.GoToBegin(); !it2.IsAtEnd(); ++it2 ) &#123;\n      if (it2.Get() != 0) &#123;\n        validationImage-&gt;TransformIndexToPhysicalPoint( it2.GetIndex(), pnt );   //将像素数组中的Index转换为物理空间中的坐标。\n        for (int d=0; d&lt;3; d++) borderPts2[numBorderPts2][d] = pnt[d];\n        numBorderPts2++;\n      &#125;\n    &#125;\n    ANNkd_tree *borderTree2 = new ANNkd_tree( borderPts2, numBorderPts2, 3 );\n    ANNidxArray  nnIdx = new ANNidx[1];\n    ANNdistArray dists = new ANNdist[1];\n\n    for(unsigned int idx1=0; idx1&lt;numBorderPts1; idx1++) &#123;\n      borderTree2-&gt;annkSearch( borderPts1[idx1], 1, nnIdx, dists);\n      avgSqrDistance += dists[0];\n      double d = sqrt( dists[0] ); //分割结果到金标准的最小欧式距离\n      avgDistance += d;\n      if (d&gt;maxDistance) maxDistance = d;\n    &#125;\n\n\n","categories":["东搞西搞"],"tags":[]},{"title":"我们都是好孩子","url":"http://tanqingbo.cn/2017/11/05/我们都是好孩子/","content":"我们都是好孩子\n![](https://mmbiz.qpic.cn/mmbiz_jpg/OerFSZj1cQJzsG81LpeZF4Czwn5YH7nzqNPQFnbhC6BEIicnuhZgKCGqxdnQNO01bibVSicZ5AE41h8QTibiau8biaicg/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1)\n\n\n\n高中时心底曾藏有一个女神，却因为勇气不足而错失良机。上大学填志愿的时候，填了一个离家万里的学校，每年才回一次家…… 但这些都不重要，因为学生年代是青春，少不了挫折与折腾，不必遗憾，这个世界有一点好就是，就是无论离开了谁，世界都一样正常运转。时至今日，当我再次回头认真看待过去时，发觉或许正是填了一个离家万里的学校，才开启了我精彩的人生。\n\n\n大学毕业的时候，我妈打电话问我什么时候可以离校，我说20号左右。但是临离校的前两天我都还没有买回家的票，我妈大概是猜到我又想先出去玩的心思，她开始着急了，说家里的好菜都给你备好了，但我坚持要晚一段时间才回家，她也就没说什么了，只是后来有点伤感。\n\n我就像一只在天空飞翔的风筝，一方面享受着被爸妈牵挂的安全感，另一方面又想飞的再高一点，多看一眼这片蓝天，我知道迟早有一天要被收回去，但是我真的想再多飞一会儿。\n\n\n\n突然想起了初中，那时的我还只是一个乖乖的学生，没有叛逆，好像除了读书之外没有其他任何想法，只是像绝大多数普通的孩子那样消耗着普通的青春，享受着单纯的欢愉。\n\n一直到初中毕业，作为这一阶段的结束总下要留下点什么纪念一下，于是大家纷纷买了同学录，给每个同学发一张。同学录里面有一栏里面要填的是“你的梦想是什么？”，可是“梦想”到底是个什么东西，那时的自己并不知道，于是就像抄作业一样，我抄了一个“当一名科学家”，反正没有正确答案，所以也没有对错之分，写完之后也就渐渐淡忘了。直到前两天，在上课的时候老师对我们说：“你们是博士，是未来的科学家啊！”我才突然在某一瞬间挖出前面那段深埋在童年记忆里的场景，而一旦回想起来，我仿佛穿越时空站在时光那头静观自己。世界是多么的美妙啊，兜兜转转大半圈，又重新回到了最初的那个航向。\n\n\n\n再来聊聊旅行！我从来都不是一个果敢的人，但旅行除外。\n\n在某次在逛书店的过程中认识一个朋友（之前认识，但不熟），由于都喜欢看书，我们便互相推荐自己最近看的书，久而久之便熟了起来。后来经常能在朋友圈里看到她在全国各地旅游的照片，那个时候就觉得这个姑娘太帅了，一个人就敢背着包全国各地跑，生活就应该活成这个样子。\n\n大一暑假的时候，我终于鼓足勇气，把攒下来的所有钱全都拿出来买了一套户外装备，跟着一群小伙伴去甘肃省徒步了，那是我第一次徒步，也是第一旅行，300多公里路，没想到我真的一步一步走完了。而在这一惊险刺激的旅程中的所见所悟于我而言像是打开了新世界的大门。\n\n虽然这是发生在好几年前的事情，但现在看来，我依然觉得它是我人生阶段的一个重要转折，也是从那时起，我喜欢上了旅行，我努力的攒奖学金，一发钱就一个人背着包去全国各地旅行。东南西北、高原沙漠，都一一去领略过它们的风采。在路上，你不知道接下来会发生什么，又会遇到怎样有趣的人，这种新鲜感很让我着迷。\n\n旅行确实是成为了我生命中不可或缺的一部分，但严格来讲，一直但现在，我都没有它列入我的梦想，因为我想做的仅仅是一步步、慢慢地走向自己真正想去的地方。\n\n\n\n当然，这些故事中也有一些小插曲。\n\n去年夏天的时候在爬泰山的时候认识了YXE，后来又因为行程一致，一起又在北京待了几天。泰山是真的好美，YXE也是真的去过不少地方，于是我问她：“下半年有什么行程吗？”他说去德国，录取通知书已经到了，她想在出国之前多去一些地方，并且让我有时间可以去德国找她玩。去德国的念头只是在我的脑海里一闪而过，更多的则是羡慕她不到20岁的年龄却一个人去了这么多地方的旅行经历。可未曾想在去年冬天的时候，我真的收到了她在德国寄来的信，让我有时间去欧洲看看，她全程免费导游。\n\n\n\n前段时间，我的室友搬出去，就剩我一个人住了，那天晚上我发了一条朋友圈：\n\n\n曾经也幻想过要是一个人住就好了，我可以在宿舍看电影的时候把外放声音调到最大，通宵学习也不怕打扰到别人。可是终于要一个人住的时候，心里却有一种说不上来的落魄感，终于晚上回来连个说话的人都没有了～\n\n\n第二天早上醒来，收到一朋友发来的微信：还好吗？看到这三个字的时候差点就哭了出来，在一堆调侃的信息当中，我庆幸的是至少还有人关心我到底过的好不好的。\n\n前两天跟一群博士吃饭的时候，我说我买了一台相机，想要拍一些好看的照片。对方很惊讶的问我说：“博士不是应该好好做科研工作吗？为什么还买相机呢？”说实话，听了这个问题之后我思考了好久，我承认来这边这么久了，我还从来没有把自己当作一个科研工作者全身心的投入工作，但我并不觉得摄影与科研矛盾，我害怕一成不变的生活，或许在枯燥的科研生活当中加上一点不那么靠谱的爱好进去也能够取得事半功倍的效果。\n\n每个人心中都有一根弦，都有一套属于自己的衡量世界的标准，我想在我的这根弦还没有绷紧之前，再多折腾一会，毕竟每个人的20岁只有一次，毕竟吹过的牛逼还没实现呢~\n\n\n","categories":["漂来漂去"],"tags":[]},{"title":"Windows和Ubuntu系统如何远程连接Linux服务器","url":"http://tanqingbo.cn/2017/10/20/xshell连接Linux服务器/","content":"前言\n首先要庆祝一下，抠门的老板终于给我们实验室整了一台工作站，这对们我实验室来说简直具有跨时代意义啊！\n因为很多实验都要在工作站上面运行，为了避免拿着装着数据的硬盘在自己电脑和工作站之间来回跑，我简单总结一下在windows和Ubuntu系统下远程访问Linux服务器的过程吧，也方便大家参考。\n\nWindows连接Ubuntu服务器准备工作xshell软件下载地址：\n链接：http://pan.baidu.com/s/1c1Woj2C \n密码：l6hg\n安装xshell:**正常安装就行，注意用途不要选择商业版，商业版收费，选择教学/学生版就行**。\n\nxshell连接Ubuntu安装openssh-server\n安装完xshell后要先在连接的Ubuntu主机下开启SSH服务，因为xshell是用ssh服务连接Ubuntu的，当然也可以配置免密码登陆Ubuntu，但那个稍微要复杂一点，我们只介绍用账号密码登陆。\n\n一般需要先安装openssh-server，才能开启ssh服务，在Ubuntu机器上运行：\n  sudo apt-get install openssh-server\n\n然后开启ssh服务：\n  ps -e | grep ssh\n\n一般建议服务器24小时开机，这样就不用每次都要启动ssh了.\n\n\nxshell会话\n打开xshell软件，点击左上角 新建，输入连接名称，Ubuntu机器的IP地址，注意协议选择ssh,端口是22.\n\n\n\n单击确定按钮，再单击连接按钮，之后会跳出一个窗口，让你输入用户名和密码，可以选择记住用户名和密码，这样省得下次重新输入了。\n\n\n\n然后单击确定按钮，就可以看到你已经连接上Ubuntu系统了。\n然后你对服务器的一切操作都可以再这个终端操作了。既然选择了Linux系统，应该适应这种纯命令行操作，熟悉之后效率会高很多。\n\n文件传输\n这是最重要的一部分，既然要在服务器上跑数据，那就得吧数据传到服务器上吧。\n\n文件传输得方法有很多，我之前用过filezilla传文件，后来我发现一种更简单的传文件方法。可以用上传下载工具包rz及sz上传和下载文件。\n\n先安装工具包，在xshell命令框种输入：\n  sudo apt-get install lrzsz\n\n安装完之后，从Windows上传文件，命令为rz,如图：\n\n\n\n\n从服务器上下载文件到Windows的命令为sz，后面要跟下载文件的文件名：\n  sz 2017-谭庆波.doc\n\n这条命令执行的时候会让你选择文件保存的路径，然后点击确定按钮就可以了。\n\n因为是局域网，用这种方法传大文件应该也没有什么压力。\n\n\nUbuntu连接Linux服务器\n在连接之前还是要保证Linux服务器上装有openssh-server啦，怎么安装参见上面~\n\n在Linux服务器上修改ssh的配置文件，这个文件 /etc/ssh/sshd_config，在里面将PermitRootLogin的值改成yes,然后在重启一下ssh服务。\n  PermitRootLogin yes\n  service sshd restart\n\n之后就可以在你的Ubuntu机器上远程登陆这台服务器了。方式如下：\n          ssh rootusername@IP\n\nrootusername是你服务器的用户名，IP是你服务器的IP地址，之后在输入密码，就可以登陆上去了。\nUbuntu文件传输\n上传文件：\n  scp 文件名 rootusername@IP：/tmp\n\n由于文件系统的权限问题，只能将本系统的文件上传到服务器的/tmp文件夹下，然后再从tmp文件夹中拷到需要的目录中去。\n\n下载文件：\n\n如果把文件从远程机器拷贝到本机当前目录用这个命令：\n     scp rootusername@IP:/home/a.tar.tz \n\n拷贝远程机器的整个目录下的文件：\n     scp -r rootusername@IP：/home/* ./\n\n注意，文件传输命令都是在本地机终端上运行。\n\n\n","categories":["技术博客"],"tags":[]},{"title":"GitHub是怎样一个存在","url":"http://tanqingbo.cn/2017/10/17/GitHub是怎样一个存在/","content":"\n先给大家分享一下Github Desktop for win 的客户端吧！​\n\n链接：http://pan.baidu.com/s/1qXHCzUk 密码：asnr\n\n\n安装好客户端之后，你就不用记一大堆Git命令，直接可以在客户端里以图形界面往仓库里push代码了。\n\n有人说GitHub是全球最大的男性交友平台,还说的有理有据，我简直没法反驳\n\n\n\n既然是同性的交友平台，暗号肯定很多, 一开始你可能很难介入, 但是只要有志气, 有耐心就一定能够在网络中的蛛丝马迹中找到, 并发掘出身边相同属性的同性工作者.\n而且GitHub还有一个巨大的好处就是免费开源，为所有用户提供免费提供私人服务，你可以在里面开一个名字叫做id.github.io的房间，开启你的博客之旅。\n所以，我的GitHub账号是：tqb4342，约吗？或则扫描一下下面的二维码也可以找到我哦~\n\n\n\n哈哈，不开玩笑了，刚刚在知乎上看到一个关于GitHub的回答，拿过来给大家分享一下吧，侵权了的话我就删了~\n在我看来，使用GitHub也存在如《人间词话》中的三重境界。\n第一重境界：昨夜西风凋碧树。独上高楼，望尽天涯路。作为一个小白用户，机缘巧合，你刚刚注册了GitHub的账号，还不知Git，Push，Pull，Pull Request，Repository为何物。懵懵懂懂，如一个单纯的小孩，来到了满是漂亮贝壳的沙滩，却还叫不出颜色的名字。朋友中只有自己一个人在玩GitHub，在浏览着网页的你，心中还有淡淡的孤独与忧伤。面对着被star过万遍的repositories，关注者以k计的id们，你发出一声长叹：什么时候我才能写出那样的名库，成为那样的牛人。\n\n\n\n\n第二重境界：衣带渐宽终不悔，为伊消得人憔悴。你创建了第一个repo，用来存放自己写过的小代码们。你创建了 你的http://id.github.io，用hexo或jekyll开始了自己的技术博客之旅。第一次pull request，第一次被别人pull request。第一次创建issue，第一次被别人创建issue。你想到了一个idea，在google search和stackoverflow的忠心辅佐下，攻克一个又一个技术难题，实现一个又一个feature，你的开源项目越来越像那么回事。一年有365天，你的GitHub上竟然就有365条打卡记录，无一天中断。别人在感叹，在技术上成长怎么那么难，你反问他：你见过GitHub凌晨四点的样子吗？\n\n\n第三重境界：众里寻他千百度，蓦然回首，那人却在灯火阑珊处。感谢时间这个好朋友，你有一天发现，你的followers也是以k计，你新开一个repository就引来了上百个watch。你给Apache贡献过代码，给Tensorflow实现过feature，给Linux修过bug。你在业界小有名气，很多人都知道你，你也认识很多人，你和你的朋友们在线上线下相遇，觥筹交错，谈笑风生。江湖上都称呼你为大牛，在一年一度的InfoQ北京峰会上，凤凰科技一个带黑框眼镜的长发美女记者问你，“在成长为大牛的道路上，你最感谢谁？” 眼前的这个妹妹好像在哪里见过，你用拇指和食指摸了摸下巴，看着她的眼睛，缓缓说道，“感谢爸妈，感谢GitHub。”\n\n\n最后再附一个在GitHub上直接预览网页的教程，在github上经常会托管一些存HTML的demo，想要直接在线预览demo里面HTML文件的预览效果可以参考如下教程：如何在github上预览网页效果\n\n","categories":["技术博客"],"tags":[]},{"title":"民国复辟风云","url":"http://tanqingbo.cn/2017/09/30/民国复辟风云/","content":"民国复辟风云　　或许每个朝代的结束都不是一下子就能彻底终结，就像东汉末年的乱世、明朝末年南京的弘光小朝廷。清朝的终结也是经历了一波三折，在民国的时候经历了袁世凯和张勋的复辟才算彻彻底底的结束。在不了解这段历史之前，我会觉得袁世凯和张勋就是个十恶不赦的大恶人，为了自己个人的利益，几乎中断了中国共和的进程。然而事实真的是这样吗？\n　　今天我就试着来和大家来分享一下这段民国有趣的复辟历史吧！\n袁世凯和他的北洋　　故事应该从袁世凯就任民国大总统说起，为什么孙中山发动革命，最后当上民国总统的人却是袁世凯呢？要解释这个问题首先得解释一下清朝北洋大臣这个官位，因为袁世凯就是当时清朝的北洋大臣。北洋大臣本来是清政府为了讨好洋人而专门设置的官位，顾名思义，北方负责洋人事物的大臣就叫北洋大臣，后来到了清朝末年，清政府为了更好的跪舔洋人，导致北洋大臣的权利越来越大，几乎独掌朝中得军政大权，一人之下，万人之上。袁世凯当时就处在这样得位置上，清朝几乎所有的军权都掌握在他得手上，当时有名的军阀像冯国璋、段祺瑞、吴佩孚、张勋等人都是袁世凯的部下。孙中山所领导的革命军根本不可能是袁世凯的对手，既然打不过那就谈判吧！但是谈判需要有筹码啊，于是在革命军拼死占领南京之后，孙中山就对袁世凯说，咱们谈谈吧！袁世凯也是个明白事理的人，他深知清朝政府确实没有把中国统治好，共和说不定是个更好的选择。于是他便对孙中山说，推翻清政府我是赞同的，但是有个条件，谁让皇帝下台，谁就当民国的大总统。孙中山没办法，一咬牙就答应了，谁让自己实力不如人家呢。\n　　让皇帝下台对于接触权利核心的袁世凯来说简直易如反掌，一回到北京没过多久就把皇帝赶下台了，按照之前的约定袁世凯便顺理成章的做起了民国的大总统，但是孙中山在和袁世凯做权利交接的时候，孙中山做了一个小动作，这也为袁世凯后来的复辟埋下了祸根。之前打下南京的时候，孙中山和南方各省的代表一起为民国制定了一部宪法，名字叫做《中华民国临时政府组织大纲》，当时孙中山对这部宪法还是很满意的，因为里面明确规定总统的权利很大，远大于责任内阁，革命这么多年终于当上了总统，如果权利不大，他当然不愿意了。但是后来把总统让给袁世凯的时候，为了制约袁世凯，他和参议院又重新制定了一部新的宪法《中华民国临时约法》，里面规定虽然总统的权利很大，但是责任内阁的权利也很大，由于《临时约法》制定的比较仓促，并没有明确说明到底谁的权利更大。但是袁世凯好像并不是很在意这些，欣然的接受了这部宪法，既然让我当上了总统，那其他的都好说。\n　　之后中国便走上了轰轰烈烈的共和道路，在袁世凯当政的时期，中国出现了短暂的复兴现象，其实在当时的那个时期，我相信大家心中应该都怀着一种把中国建设的更好的理想，袁世凯也不例外，他也希望中国更好，希望自己能名垂青史。如果事情一直这么顺利的发展下去的话，说不定他真的能带领着中国慢慢走向富强，因为袁世凯他真的是一个特别有能力的人，他是从底层慢慢爬上来的，会带兵打仗、做过外交大臣，懂外交、督建过铁路，懂经济。总的来说，他就是一个全能形人才，了解中国的国情，知道怎么才能让中国这个庞然大物高效的运转起来，不像孙中山那帮人，只懂得喊三民主义，对中国国情，经济建设等一概不知，这个可以参考共产党早期执政时期中国的的经济发展状况。高晓松曾在他的《晓说》里面说，如果当时只有一个人能让中国富强起来的话，那么这个人肯定是袁世凯，可见袁世凯的能力确实非常出众。所以在他最初执政的那几年，确实做了很多利国利民的好事，比如建立警署、督办铁路、发展新军、重视教育，建立了北洋大学等一批不错的学校，使民国最初的那几年中国的GDP增长了不少。而且他还促成中国历史上唯一一次全民选举，但也正是这次选举间接的断送了这大好的形式，选举的结果为国民党当选中国的第一大党，掌管内阁，当时国民党的领导是宋教仁，他觉得责任内阁的权利应该大于总统，一些国家大事应该都由内阁说了算，总统只负责盖章就行了，恰好宪法上也没有明确规定到底谁的权利大，这样一整袁世凯就不乐意了，原来共和是这样玩的啊？我辛辛苦苦推翻清政府，为建设共和出了这么多力，到头来这共和跟我没多大关系了。一开始袁世凯还想跟黄教仁商量着来，但是宋教仁根本不吃这一套，他把袁世凯甩在一边公开在媒体面前发表各种言论，畅谈自己的政治理想和承若颁发各种政策。时间一久袁世凯就彻底怒了，老子好歹也是一代枭雄，军阀的老大，走过的路比你走过的桥还多，竟然被你这个书生瞧不起，妈的！袁世凯越想越气愤，于是他做了一个决定，一个错误的决定：他让人刺杀了宋教仁。我觉得这也是军阀的一大缺点，以为把人杀了，事情解决了，然而事情根本没有这么简单。\n　　宋教仁一死，中国又开始变得混乱了，国会议员和国民党都开始闹事，袁世凯的亲信和儿子便趁机蛊惑袁世凯，让他称帝。袁世凯也觉得与其让这帮没有治国经验的人瞎折腾，不如把权利都收到自己手里来，于是他做了第二个错误的决定：自己当皇帝。说袁世凯复辟其实也不太准确，因为他并不打算照搬清朝的制度，而是想学英国的君主立宪制。但是他错估了中国当前的形势，全国上下辛辛苦苦办了五六年的共和，现在你突然想推翻这一切，要当皇帝，大家当然不乐意了，于是袁世凯一下就成了舆论的众矢之的，他的王朝没撑多久就被推翻了，下台之后的袁世凯没过多久就病死了。如果真有死不瞑目这一说法的话，我相信袁世凯应该是死不瞑目，辛辛苦苦推翻清政府，大力发展经济和教育，最后却落得一世骂名。客观的讲，虽然袁世凯在位的时候没做过什么惊天动力的大事，就连推翻清政府都是孙中山挑的头，但他确实为中国的发展做过很多实实在在的贡献，不能因为一次复辟而抹掉他所做的一切。\n黎元洪和张勋的发迹史　　袁世凯死后继任民国大总统的人是黎元洪，黎元洪也是一代传奇人物，在甲午战争的时候，他在“广甲”号上服役，后来“广甲”号被日本人打没之后，他逃到湖北投靠了当时的两江总督张之洞。由于黎元洪留过学，还当过海军和陆军，他的才识很受到了张之洞的赏识，让他创办军校，督办新军。当时很多有名的将领都是从黎元洪创办的军校里面毕业的，通过军校，黎元洪的势力慢慢壮大起来，张之洞死后，黎元洪便顺利成章的接替了他的位置。后来孙中山在南方闹革命的时候，同样接受过西方教育的黎元洪便不遗余力的支持孙中山。由于当时的湖北省真的非常的有钱，这些钱就都被黎元洪当成了革命的活动经费。他每天不停的给各个省的巡抚和布政使发电报，承诺他们，只要同意脱离清政府，宣布独立，就给你们省打钱。没想到还真有几个省同意了黎元洪的请求，宣布独立。所以说革命能成功，黎元洪应该是功不可没，不管是后来孙中山当总统还是袁世凯当总统，黎元洪都是副总统，可见大家对黎元洪的功劳还是挺认可的。在袁世凯死后，黎元洪的副总统终于熬成了正的。\n　　就在黎元洪受到张之洞赏识的时候，张勋的运气也不错，他在袁世凯的手下干活，袁老大给他安排了一个特别好的差事，至少在他自己看来这是一个号差事。当时八国联军打进北京，慈禧带着光绪皇帝跑了，后来签完《辛丑条约》之后，皇帝和太后回来，袁老大给张勋安排的好差事就是做好皇帝和太后的回銮工作，对于一个文盲出身的张勋来说，这可不得了啊，因为做回銮工作就意味着有机会面见圣上，这对于一个老百姓出身的人来说，简直就是祖上积德啊，所以他特别重视这个工作，袁世凯见回銮工作做的不错就直接让张勋来负责皇城的护卫工作，官职是紫禁城护卫总指挥，这个工作他也做的非常出色，并且还多次受到皇帝和太后的夸奖。对于张勋这样的大老粗来说，一辈子追求的就是这种皇恩浩荡的感觉，现在终于感受到了。所以后来民国的时候，他也总是怀念大清的好，民国之后都流行剪辫子，当全国的辫子都减的差不多的时候，只有张勋的部队里还都留着辫子，史称“辫子军”。他一辈子也没能转过这个弯来，始终都觉得清政府就是比民国好，其实这事也不怪他，因为他从小就习惯了皇权下的忠孝仁义，小时候给人家看大院、后来遇上战乱入伍打战，靠着军功一路爬到了现在，根本没有人告诉他民国到底是个什么东西，所以就算民国已经办了六年了，但他仍然想象着有一天能够重新回到清朝的统治，中国的老百姓已经在皇权的统治下生活几千年，虽然有不好的时候，但是大部分时候大家都还是能够幸福的生活的，恰好当时的民国又特别混乱，共和6年多时间了，中国依旧比较混乱，所以他觉得只要重新回到清朝的统治，一切又会重新变得好起来的，他坚信。\n　　虽然在这一点上张勋很不开窍，但是他的为人真的特别好，同系的其他北洋军阀们到他的地盘有办什么事情的时候，他都服务的特别周到，又是给钱、又是请戏班唱戏，所以军阀们要是有个什么聚会啥的都乐意来张勋的地盘来举办，恰好他又年长大家几岁，大家都尊称他一声老大哥，他自己也真的把自己当成了军阀们的老大哥，每次聚会的时候他都喜欢在酒桌上和大家自己的政治理想，梦想着有一天重回大清的统治。每当这个时候酒桌上的其他兄弟都会随声附和，说只要老大哥你带头复辟，我们都支持你。这给了张勋很大的自信，可是酒桌上的话又怎么能信呢？而且张勋老大哥你在偏远的徐州，距离权利中心十万八千里远，实力比你强的军阀也有很多，那轮得到你来复辟啊。可是历史就是这么调皮，机会很快就来了。\n　　黎元洪当总统的时候，跟他搭档的人是段祺瑞，段祺瑞是袁世凯的老部下，在北洋军阀当中也很有威信。一开始两人搭档的很好，民国看起来又要恢复生机了，在度过一段不长不短的蜜月期之后，一件事的发生打破了这个局面：一战爆发了。美国人跑过来对段祺瑞说，你们中国来参战吧！如果你们来参战的话，我就给你钱，还给你们提供经济上的扶持。段祺瑞拍脑门子想了一下，觉得这是个好事啊，不仅能得到美国的帮助，如果打赢了的话还能从德国手里收回青岛。于是他就去找黎元洪商量说，我们对德国宣战吧！黎元洪听了之后坚决不同意，因为中国当时的陆军大部分都是在德国军官的教导下成长起来，而且配的装备也都是德军装备，让这样的部队去和德军打，不是去送死吗？而且中国现在的局面还没完全稳定，根本没有经济实力来支撑这么一场大战，所以黎元洪死都不同意。但段祺瑞也比较倔强，一定要对德开战，既然你不同意，那我就撇开你自己干，反正你也管不了我（这就是孙中山后来修改宪法的后果）。这样做之后，两个人就彻底撕破脸皮了，黎元洪一怒之下就解除了段祺瑞的总理职务，但是黎元洪似乎低估了段祺瑞的威信，段祺瑞被解除总理之后，国务委员们也都纷纷递交辞呈，各地的军阀也都相继宣布独立，不听中央号令，但在这些军阀里面也有个例外，有一个军阀没有宣布独立，这个奇葩的例外就是张勋，不是因为他不想通电独立，而是他根本就没有资本去宣布独立，他虽然是安徽省的总督，却带着部队在江苏省的徐州呆着，为什么呢？因为安徽省在他的好兄弟倪嗣手里，不知道是不是因为打不过人家还是什么原因，张勋也没有太追究这件事情，就安心的待在徐州逍遥。所以他的军阀兄弟们相继在其他省份都宣布独立的时候，他就非常尴尬的没有附和了。但是远在中央的黎元洪却不这么看，黎元洪认为张勋是深明大义，国之柱石，而且据说张勋还是军阀们的老大哥，那么只要把他请到北京来，一定能震住当前的局面。相信黎元洪他自己都被这个英明的想法感动了，于是他立刻电召张勋率部队进京调停，以防不测。\n　　张勋做梦也没想到会收到一条这样的命令，幸福来的太突然了，只要带着部队进京，他就有机会把清朝的皇帝重新请出来，让中国重回到大清的统治了，加上之前在酒桌上他的兄弟们跟他说的话，使他变得更加自信了，他觉得只要率部队进京，他梦想和报复就能马上实现。\n　　于是张勋便乐呵呵的把部队带进了北京城，事情比他想象的还要顺利，很快他就控制了黎元洪，并把十来岁的傅仪请出来，对他说，皇上，咱复辟了，天下又是您的了。复辟之后张勋做的第一件事就是给自己封了个官职：直隶总督兼北洋大臣。这可是当年偶像袁世凯当过的官职啊，没想到有朝一日我张勋也能坐到这个位置上，人生真的是太美好了。可是张勋你做了直隶总督兼北洋大臣，你的那些兄弟能安心当你手下吗？叫你一声老大哥只是尊敬你的为人，要是真把自己当老大的话那可是要吃亏的啊，当年你的偶像袁世凯复辟都没有成功，你张大个子又怎么会成功呢？首先起来反抗就是他当年在酒桌上的那些兄弟，张大个子你算哪根葱啊？还想当我们的上司，啥也不说了，兄弟们一起上吧！本来张勋的实力就不行，现在这么多人一起来反抗他，那就更加招架不住了， 没过两天就被打扒下了。但是那些军阀们对战败的张勋也还算客气，没有真正要了他的性命，让他带着财产和家眷回天津当寓公去了。\n　　经过张勋这么一闹，中国就再也没有人真心的想要办共和了。想来还是觉得挺可惜的，中国的共和之路就这么断送在了张勋这个奇葩的人物手中。\n　　但后来又释然了，我想每一个朝代的结束，都不是一下子就能终结的吧，就像宋朝灭亡之前还整出一个南宋来。明朝的崇祯皇帝在煤山殉国之后明朝也没有真正的终结，而是在南京办了一个弘光小朝廷之后才算彻底结束。要是从从这个角度想的话，那么因为袁世凯和张勋的复辟而导致中国的共和之路中断就不觉得那么可惜了，这是历史规律，规律不可违抗。\n","categories":["漂来漂去"],"tags":[]},{"title":"非参数估计法之Parzen窗估计和k最近邻估计","url":"http://tanqingbo.cn/2017/09/25/非参数估计法之Parzen窗估计和k最近邻估计/","content":"\n参考书籍：《模式分类》 作者：RichardO.Duda，PeterE.Hart，DavidG.Stork\n\n1.非参数化概率密度的估计\n对于未知概率密度函数的估计方法，其核心思想是：一个向量x落在区域R中的概率可表示为：\n\n ![](http://img.blog.csdn.net/20150425203407628)\n\n\n\n其中，P是概率密度函数p(x)的平滑版本，因此可以通过计算P来估计概率密度函数p(x)，假设n个样本x1,x2,…,xn，是根据概率密度函数p(x)独立同分布的抽取得到，这样，有k个样本落在区域R中的概率服从以下分布：\n\n ![](http://img.blog.csdn.net/20150425203436581)\n\n\n\n其中k的期望值为：\n\n ![](http://img.blog.csdn.net/20150425203412192)\n\n\n\nk的分布在均值附近有着非常显著的波峰，因此若样本个数n足够大时，使用k/n作为概率P的一个估计将非常准确。假设p(x)是连续的，且区域R足够小，则有：\n\n ![](http://img.blog.csdn.net/20150425203431895)\n\n\n\n如下图所示，以上公式产生一个特定值的相对概率，当n趋近于无穷大时，曲线的形状逼近一个δ函数，该函数即是真实的概率。公式中的V是区域R所包含的体积。综上所述，可以得到关于概率密度函数p(x)的估计为：\n\n \n\n\n\n\n\n\n在实际中，为了估计x处的概率密度函数，需要构造包含点x的区域R1,R2,…,Rn。第一个区域使用1个样本，第二个区域使用2个样本，以此类推。记Vn为Rn的体积。kn为落在区间Rn中的样本个数，而pn (x)表示为对p(x)的第n次估计：\n\n \n![](http://img.blog.csdn.net/20150425203822516)\n\n\n\n欲满足pn(x)收敛：pn(x)→p(x)，需要满足以下三个条件：\n\n \n![](http://img.blog.csdn.net/20150425203731716)\n\n\n\n有两种经常采用的获得这种区域序列的途径，如下图所示。其中“Parzen窗方法”就是根据某一个确定的体积函数，比如Vn=1/√n来逐渐收缩一个给定的初始区间。这就要求随机变量kn和kn/n能够保证pn (x)能收敛到p(x)。第二种“k-近邻法”则是先确定kn为n的某个函数，如kn=√n。这样，体积需要逐渐生长，直到最后能包含进x的kn个相邻点。\n\n \n![](http://img.blog.csdn.net/20150425203958098)\n\n\n2.Parzen窗估计法\n已知测试样本数据x1,x2,…,xn，在不利用有关数据分布的先验知识，对数据分布不附加任何假定的前提下，假设R是以x为中心的超立方体，h为这个超立方体的边长，对于二维情况，方形中有面积V=h^2，在三维情况中立方体体积V=h^3，如下图所示。\n\n \n![](http://img.blog.csdn.net/20150425204017810)\n\n\n\n根据以下公式，表示x是否落入超立方体区域中：\n\n \n![](http://img.blog.csdn.net/20150425203953271)\n\n\n\n估计它的概率分布：\n\n \n![](https://i.imgur.com/oXo23Ym.png)\n\n\n\n其中n为样本数量，h为选择的窗的长度，φ(.)为核函数，通常采用矩形窗和高斯窗。\n\n3.k最近邻估计\n在Parzen算法中，窗函数的选择往往是个需要权衡的问题，k-最近邻算法提供了一种解决方法，是一种非常经典的非参数估计法。基本思路是：已知训练样本数据x1,x2,…,xn而估计p(x)，以点x为中心，不断扩大体积Vn，直到区域内包含k个样本点为止，其中k是关于n的某一个特定函数，这些样本被称为点x的k个最近邻点。\n当涉及到邻点时，通常需要计算观测点间的距离或其他的相似性度量，这些度量能够根据自变量得出。这里我们选用最常见的距离度量方法：欧几里德距离。\n最简单的情况是当k=1的情况，这时我们发现观测点就是最近的（最近邻）。一个显著的事实是：这是简单的、直观的、有力的分类方法，尤其当我们的训练集中观测点的数目n很大的时候。可以证明，k最近邻估计的误分概率不高于当知道每个类的精确概率密度函数时误分概率的两倍。\n\nmatlab实现Parzen和k最近邻估计Parzen窗方法研究\n采用3类满足正太分布的样本数据（w1,w2,w3）作为训练样本，编写程序，使用Parzen 窗估计方法对一个任意的测试样本点x 进行分类。对分类器的训练则使用（w1,w2,w3）的三维数据。同时修改窗口h的值，多次实验。用于分类的样本点为x1(0.5,1.0,0.0)，x2(0.31,1.51,-0.50)，x3(-0.3,0.44,-0.1)。\n\n训练样本数据（w1,w2,w3）分别为：\n  w1 = [ 0.28  1.31  -6.2\n       0.07  0.58  -0.78\n       1.54  2.01  -1.63\n      -0.44  1.18  -4.32\n      -0.81  0.21   5.73\n       1.52  3.16   2.77\n       2.20  2.42  -0.19\n       0.91  1.94   6.21\n       0.65  1.93   4.38\n      -0.26  0.82  -0.96];\n  W2 = [0.011  1.03  -0.21\n       1.27  1.28   0.08\n       0.13  3.12   0.16\n      -0.21  1.23  -0.11\n      -2.18  1.39  -0.19\n       0.34  1.96  -0.16\n      -1.38  0.94   0.45\n      -0.12  0.82   0.17\n      -1.44  2.31   0.14\n       0.26  1.94   0.08];\n  W3 = [ 1.36  2.17  0.14\n       1.41  1.45 -0.38\n       1.22  0.99  0.69\n       2.46  2.19  1.31\n       0.68  0.79  0.87\n       2.51  3.22  1.35\n       0.60  2.44  0.92\n       0.64  0.13  0.97\n       0.85  0.58  0.99\n       0.66  0.51  0.88];\n\nh=0.1时：\n\n![](https://i.imgur.com/D2Sqdz2.jpg)\n\nh=0.5时：\n\n![](https://i.imgur.com/Q1et0iI.jpg)\n\nh=1时：\n\n![](https://i.imgur.com/maCnaIp.jpg)\n\n\n\n\nK最近邻方法研究\n采用3类满足正太分布的样本数据（w1,w2,w3）作为训练样本，为了使实验更具有说服力，我们令训练样本数据的个数分别为10、20、30、40个样本，进行4次实验，其中w1的均值为0.2，方差为0.2，w2的均值为0，方差为0.1，w3的均值为0.1，方差为0.1。实验的训练样本都是程序随机生成的，我们将在实验结果分析的最后给出每次实验的训练样本数据。\n\n源码            clear;\n            close all;\n            %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n            % Parzen窗估计和k最近邻估计\n            %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n            %         w1(:,:,1) =  .2+sqrt(0.2)*randn(20,[3,1]);  %均值为0.2，方差为0.2的训练样本\n            %         disp(w1(:,:,1));\n            %         w1(:,:,2) =  0+sqrt(0.2)*randn(20,[3,.1]);  %均值为0，方差为0.1的训练样本\n            %         disp(w1(:,:,2));\n            %         w1(:,:,3) =  .1+sqrt(0.3)*randn(20,[3,0]);  %均值为0.1，方差为0.1的训练样本\n            %         disp(w1(:,:,2));\n              w1(:,:,1) = [ 0.28  1.31  -6.2;...\n                         0.07  0.58  -0.78;...\n                         1.54  2.01  -1.63;...\n                        -0.44  1.18  -4.32;...\n                        -0.81  0.21   5.73;...\n                         1.52  3.16   2.77;...\n                         2.20  2.42  -0.19;...\n                         0.91  1.94   6.21;...\n                         0.65  1.93   4.38;...\n                        -0.26  0.82  -0.96];\n            w1(:,:,2) = [0.011  1.03  -0.21;...\n                         1.27  1.28   0.08;...\n                         0.13  3.12   0.16;...\n                        -0.21  1.23  -0.11;...\n                        -2.18  1.39  -0.19;...\n                         0.34  1.96  -0.16;...\n                        -1.38  0.94   0.45;...\n                        -0.12  0.82   0.17;...\n                        -1.44  2.31   0.14;...\n                         0.26  1.94   0.08];\n            w1(:,:,3) = [ 1.36  2.17  0.14;...\n                         1.41  1.45 -0.38;...\n                         1.22  0.99  0.69;...\n                         2.46  2.19  1.31;...\n                         0.68  0.79  0.87;...\n                         2.51  3.22  1.35;...\n                         0.60  2.44  0.92;...\n                         0.64  0.13  0.97;...\n                         0.85  0.58  0.99;...\n                         0.66  0.51  0.88];\n            x(1,:) = [0.5 1 0];\n            x(2,:) = [0.31 1.51 -0.5];\n            x(3,:) = [-0.3 0.44 -0.1];\n            h = 1; % 重要参数\n            p1 = Parzen(w1,x(1,:),h);\n            %num1 = find(p1 == max(p1));\n            p2 = Parzen(w1,x(2,:),h);\n            %num2 = find(p2 == max(p2));\n            p3 = Parzen(w1,x(3,:),h);\n            %num3 = find(p3 == max(p3));\n            disp([&#39;点：[&#39;,num2str(x(1,:)),&#39;]落在三个类别的概率分别为：&#39;,num2str(p1)]);\n            disp([&#39;点：[&#39;,num2str(x(2,:)),&#39;]落在三个类别的概率分别为：&#39;,num2str(p2)]);\n            disp([&#39;点：[&#39;,num2str(x(3,:)),&#39;]落在三个类别的概率分别为：&#39;,num2str(p3)]);\n            % 给定三类二维样本，画出二维正态概率密度曲面图验证h的作用\n            num =1; % 第num类的二维正态概率密度曲面图，取值为1，2，3\n            draw(w2,h,num); \n            str1=&#39;当h=&#39;;str2=num2str(h);str3=&#39;时的二维正态概率密度曲面&#39;;\n            SC = [str1,str2,str3];\n            title(SC);\n\n            % k近邻算法设计的分类器\n            % x1和y1为测试样本\n            x1 = [-0.91,0.32,0.48];\n            x2 = [0.14,0.72, 1.1];\n            x3 = [-0.81,0.61,-0.38];\n\n            % x1 = [-0.41,0.82,0.88];\n            % x2 = [0.14,0.72, 4.1];\n            % x3 = [-0.81,0.61,-0.38];\n            w = w1;\n            %w = w1(:,1,3);\n            k = 2;\n            kNearestNeighbor(w,k,x1);\n            kNearestNeighbor(w,k,x2);\n            kNearestNeighbor(w,k,x3);\n\n\n\n            % Parzen窗算法\n            % w：c类训练样本\n            % x：测试样本\n            % h：参数\n            % 输出p：测试样本x落在每个类的概率\n            function p = Parzen(w,x,h)\n\n            [xt,yt,zt] = size(w);\n\n            p = zeros(1,zt);\n\n            for i = 1:zt\n                hn = h;\n                for j = 1:xt\n                    hn = hn / sqrt(j);\n                    p(i) = p(i) + exp(-(x - w(j,:,i))*(x - w(j,:,i))&#39;/ (2 * power(hn,2))) / (hn * sqrt(2*3.14));\n                end\n                p(i) = p(i) / xt;\n            end\n\n\n\n            % k-最近邻算法\n            % w：c类训练样本\n            % x：测试样本\n            % k：参数\n            function p = kNearestNeighbor(w,k,x)\n            % w = [w(:,:,1);w(:,:,2);w(:,:,3)];\n            [xt,yt,zt] = size(w);\n            wt = [];%zeros(xt*zt, yt);\n            if nargin==2   %判断输入变量的个数\n            p = zeros(1,zt);\n                for i = 1:xt\n                    for j = 1:xt\n                    dist(j,i) = norm(wt(i,:) - wt(j,:));   % 计算向量范数（dist：欧式距离加权函数）\n                    end\n                    t(:,i) = sort(dist(:,i));\n                    m(:,i) = find(dist(:,i) &lt;= t(k+1,i)); % 找到k个最近邻的编号\n                end\n            end  \n            if nargin==3    %判断输入变量的个数\n                for q = 1:zt\n                wt = [wt; w(:,:,q)];  %  把3个训练样本放到一个矩阵中\n                [xt,yt] = size(wt);\n                end\n                    for i = 1:xt\n                    dist(i) = norm(x - wt(i,:));\n                    end\n                    t = sort(dist); % 欧氏距离排序\n                    [a,b] = size(t);\n                    m = find(dist &lt;= t(k+1)); % 找到k个最近邻样本的编号，存到向量m中\n                    num1 = length(find(m&gt;0 &amp; m&lt;11));\n                    num2 = length(find(m&gt;10 &amp; m&lt;21));\n                    num3 = length(find(m&gt;20 &amp; m&lt;31));\n            if yt == 3\n                    plot3(w(:,1,1),w(:,2,1),w(:,3,1), &#39;r.&#39;);\n                    hold on;\n                    grid on;\n                    plot3(w(:,1,2),w(:,2,2),w(:,3,2), &#39;g.&#39;);\n                    plot3(w(:,1,3),w(:,2,3),w(:,3,3), &#39;b.&#39;);\n            if (num1 &gt; num2) || (num1 &gt; num3)\n                plot3(x(1,1),x(1,2),x(1,3), &#39;ro&#39;);\n                disp([&#39;点：[&#39;,num2str(x),&#39;]属于第一类&#39;]);\n            elseif (num2 &gt; num1) || (num2 &gt; num3)\n                plot3(x(1,1),x(1,2),x(1,3), &#39;go&#39;);\n                disp([&#39;点：[&#39;,num2str(x),&#39;]属于第二类&#39;]);\n            elseif (num3 &gt; num1) || (num3 &gt; num2)\n                plot3(x(1,1),x(1,2),x(1,3), &#39;bo&#39;);\n                disp([&#39;点：[&#39;,num2str(x),&#39;]属于第三类&#39;]);\n            else\n                disp(&#39;无法分类&#39;);\n            end\n            end\n            if yt == 2\n                    plot(w(:,1,1),w(:,2,1), &#39;r.&#39;);\n                    hold on;\n                    grid on;\n                    plot(w(:,1,2),w(:,2,2), &#39;g.&#39;);\n                    plot(w(:,1,3),w(:,2,3), &#39;b.&#39;);\n            if (num1 &gt; num2) || (num1 &gt; num3)\n                plot(x(1,1),x(1,2), &#39;ro&#39;);\n                disp([&#39;点：[&#39;,num2str(x),&#39;]属于第一类&#39;]);\n            elseif (num2 &gt; num1) || (num2 &gt; num3)\n                plot(x(1,1),x(1,2), &#39;go&#39;);\n                disp([&#39;点：[&#39;,num2str(x),&#39;]属于第二类&#39;]);\n            elseif (num3 &gt; num1) || (num3 &gt; num2)\n                plot(x(1,1),x(1,2), &#39;bo&#39;);\n                disp([&#39;点：[&#39;,num2str(x),&#39;]属于第三类&#39;]);\n            else\n                disp(&#39;无法分类&#39;);\n            end\n            end\n            end\n            title(&#39;k-最近邻分类器&#39;);\n            legend(&#39;第一类数据&#39;,...\n                   &#39;第二类数据&#39;,...\n                   &#39;第三类数据&#39;,...\n                   &#39;测试样本点&#39;);\n","categories":["图像处理"],"tags":[]},{"title":"十一黄金周出游，掌握这几种构图方法让你拍的照片变得高大上起来","url":"http://tanqingbo.cn/2017/09/19/人家用手机也可以拍出很厉害的照片呢/","content":"\n很多同学对摄影有一个误区，认为想要拍出好看的照片必须单反加身，长焦、广角、微距镜头一个也不能少。所以每当自己拍出特别烂的照片的时候就安慰自己说：“哎呀！没钱买单反，都是设备的锅啦~”。其实不然，只要掌握以下几种构图的方法，手机一样可以拍出很厉害的照片哦。江湖常见的构图法则\n许多人接触拍照都是从手机开始，为了满足广大手机摄影爱好者的需求，一些零零散散的构图法则就运营而生了，一般江湖上常见的构图法则有这些：黄金分割点构图法、水平线构图法、对角线构图法和垂直线构图法。\n今天就和大家来分享一下如何运用这几种构图法使你拍的照片变得高大上起来，由于我也只是个业余手机摄影新手，如果出现常识错误还望大神指正。\n\n黄金分割点构图法\n不管是拍人还是拍风景，黄金分割点构图法都是最常见的构图法则，无论是在电视剧上或者生活拍摄中都能经常看到黄金构图拍摄的照片，例如下面这张《琅琊榜》的剧照。\n![](https://i.imgur.com/UqxleYB.png)\n\n那么什么是黄金分割点呢？简单点的说就是指把一条线段分割为两部分，使其中一部分与全长之比等于另一部分与这部分之比的数值是近似于0.618。 数学不好的同学要开始掀桌子了，憋着急，马上就给大家上图。\n黄金分割点构图的拍摄法可以分为两种：黄金螺旋和黄金三角。\n\n1. 黄金螺旋法\n相信大家都看出来了，上面的《琅琊榜》剧照就采用了黄金螺旋构图法，它把拍摄的主题放在放在黄金螺旋最紧的那一端，这样能够更好的吸引观者视线。上图梅长苏大大的小船就在黄金螺旋最紧的那一端。下图的花朵也是一样，在右螺旋的位置。\n![](https://i.imgur.com/IjUZWYR.png)\n\n\n\n\n2. 黄金三角法\n黄金三角是一种连接图片对角线，然后对角顶点与对角线长的0.618处相连而得到的，如下图，把拍摄主体与放在交点汇合处。\n\n\n![](https://i.imgur.com/89i0yWf.jpg)\n![地点：松花江  拍摄：老谭酸菜](https://i.imgur.com/za4sQQU.jpg)\n\n\n\n这样拍的好处是可以是照片看起来比较整洁，是观者一下就能找到照片中的主题。\n\n水平线构图法\n水平线构图是指在我们拍摄的景色中，有一条或者几条与地面平行的线，我们在拍摄的过程一定要好好利用这几条水平线，使它们在镜头中精准水平，这样可以使图片有种稳定舒服的感觉。如下图：\n\n![地点：大连星海广场  拍摄：老谭酸菜](https://i.imgur.com/MrzO7uN.jpg)\n![地点：大理古镇  拍摄：老谭酸菜](https://i.imgur.com/RCqsmFa.jpg)\n![地点：洱海  拍摄：老谭酸菜](https://i.imgur.com/iEyviqp.jpg)\n![地点：双廊  拍摄：老谭酸菜](https://i.imgur.com/qSb2pqa.jpg)\n\n\n用水平构图法的时候，一般使水平线位于图片的上1/3，或者下1/3位置，这样效果会更好一些。\n\n\n对角线构图法\n对角线构图的意思是指是拍摄的主题呈对角的关系，这样可以使图像显示出强烈的立体感，适合拍摄建筑、树枝等动感很强的东西。如下图：\n![](https://i.imgur.com/w19CNzs.png)\n![地点：大连星海广场  拍摄：老谭酸菜](https://i.imgur.com/tOyw1CE.jpg)\n\n\n\n\n垂直构图法\n垂直线就是拍摄的画面中有着垂直于地平线的线条，比如可以是大树，建筑楼房、路灯、人物等等。垂直线能够给人传达一种安静、稳定的情绪，同时垂直的线条也象征着庄严、坚强、有支撑力。如下图：\n\n![地点：松花江大桥  拍摄：老谭酸菜](https://i.imgur.com/iHl8QGo.jpg)\n![地点：洱海  拍摄：老谭酸菜](https://i.imgur.com/vJCLpLt.jpg)\n![地点：洱海  拍摄：老谭酸菜](https://i.imgur.com/eUi90dj.jpg)\n\n\n上述所有照片都是我用自己的破手机魅蓝metal拍的，所以作为一个业余选手，照片拍的好不好跟设备没有太大关系好不啦，手机一样可以拍出很厉害的照片~\n\n好啦！今天就到这了，如果超过500赞的话，下周就接着再更一些手机摄影的技巧。\n\n希望在留言区看到你们哦~\n\n\n","categories":["漂来漂去"],"tags":[]},{"title":"从最大似然估计|贝叶斯估计|EM算法浅解|线性判别分析","url":"http://tanqingbo.cn/2017/09/18/从最大似然到EM算法浅解/","content":"\n部分转载自：\nhttp://blog.csdn.net/zouxy09\n\n\n\n\n机器学习十大算法之一：EM算法。能评得上十大之一，让人听起来觉得挺NB的。什么是NB啊，我们一般说某个人很NB，是因为他能解决一些别人解决不了的问题。神为什么是神，因为神能做很多人做不了的事。那么EM算法能解决什么问题呢？或者说EM算法是因为什么而来到这个世界上，还吸引了那么多世人的目光。\n\n一、最大似然\n进入正题。假设我们遇到的是下面这样的问题：\n\n假设我们需要调查我们学校的男生和女生的身高分布。你怎么做啊？你说那么多人不可能一个一个去问吧，肯定是抽样了。假设你在校园里随便地活捉了100个男生和100个女生。他们共200个人（也就是200个身高的样本数据，为了方便表示，下面，我说“人”的意思就是对应的身高）都在教室里面了。那下一步怎么办啊？你开始喊：“男的左边，女的右边，其他的站中间！”。然后你就先统计抽样得到的100个男生的身高。假设他们的身高是服从高斯分布的。但是这个分布的均值u和方差∂2我们不知道，这两个参数就是我们要估计的。记作θ=[u, ∂]T。\n\n\n用数学的语言来说就是：在学校那么多男生（身高）中，我们独立地按照概率密度p(x|θ)抽取100了个（身高），组成样本集X，我们想通过样本集X来估计出未知参数θ。这里概率密度p(x|θ)我们知道了是高斯分布N(u,∂)的形式，其中的未知参数是θ=[u, ∂]T。抽到的样本集是X={x1,x2,…,xN}，其中xi表示抽到的第i个人的身高，这里N就是100，表示抽到的样本个数。\n\n由于每个样本都是独立地从p(x|θ)中抽取的，换句话说这100个男生中的任何一个，都是我随便捉的，从我的角度来看这些男生之间是没有关系的。那么，我从学校那么多男生中为什么就恰好抽到了这100个人呢？抽到这100个人的概率是多少呢？因为这些男生（的身高）是服从同一个高斯分布p(x|θ)的。那么我抽到男生A（的身高）的概率是p(xA|θ)，抽到男生B的概率是p(xB|θ)，那因为他们是独立的，所以很明显，我同时抽到男生A和男生B的概率是p(xA|θ)* p(xB|θ)，同理，我同时抽到这100个男生的概率就是他们各自概率的乘积了。用数学家的口吻说就是从分布是p(x|θ)的总体样本中抽取到这100个样本的概率，也就是样本集X中各个样本的联合概率，用下式表示：\n\n![](http://img.my.csdn.net/uploads/201301/24/1359003923_8916.jpg)\n\n\n\n\n这个概率反映了，在概率密度函数的参数是θ时，得到X这组样本的概率。因为这里X是已知的，也就是说我抽取到的这100个人的身高可以测出来，也就是已知的了。而θ是未知了，则上面这个公式只有θ是未知数，所以它是θ的函数。这个函数放映的是在不同的参数θ取值下，取得当前这个样本集的可能性，因此称为参数θ相对于样本集X的似然函数（likehood function）。记为L(θ)。\n\n这里出现了一个概念，似然函数。还记得我们的目标吗？我们需要在已经抽到这一组样本X的条件下，估计参数θ的值。怎么估计呢？似然函数有啥用呢？那咱们先来了解下似然的概念。\n\n\n直接举个例子：\n某位同学与一位猎人一起外出打猎，一只野兔从前方窜过。只听一声枪响，野兔应声到下，如果要你推测，这一发命中的子弹是谁打的？你就会想，只发一枪便打中，由于猎人命中的概率一般大于这位同学命中的概率，看来这一枪是猎人射中的。\n\n这个例子所作的推断就体现了极大似然法的基本思想。\n\n再例如：下课了，一群男女同学分别去厕所了。然后，你闲着无聊，想知道课间是男生上厕所的人多还是女生上厕所的人比较多，然后你就跑去蹲在男厕和女厕的门口。蹲了五分钟，突然一个美女走出来，你狂喜，跑过来告诉我，课间女生上厕所的人比较多，你要不相信你可以进去数数。呵呵，我才没那么蠢跑进去数呢，到时还不得上头条。我问你是怎么知道的。你说：“5分钟了，出来的是女生，女生啊，那么女生出来的概率肯定是最大的了，或者说比男生要大，那么女厕所的人肯定比男厕所的人多”。看到了没，你已经运用最大似然估计了。你通过观察到女生先出来，那么什么情况下，女生会先出来呢？肯定是女生出来的概率最大的时候了，那什么时候女生出来的概率最大啊，那肯定是女厕所比男厕所多人的时候了，这个就是你估计到的参数了。\n\n从上面这两个例子，你得到了什么结论？\n\n回到男生身高那个例子。在学校那么男生中，我一抽就抽到这100个男生（表示身高），而不是其他人，那是不是表示在整个学校中，这100个人（的身高）出现的概率最大啊。那么这个概率怎么表示？哦，就是上面那个似然函数L(θ)。所以，我们就只需要找到一个参数θ，其对应的似然函数L(θ)最大，也就是说抽到这100个男生（的身高）概率最大。这个叫做θ的最大似然估计量，记为：\n\n\n\n![](http://img.my.csdn.net/uploads/201301/24/1359003973_1560.jpg)\n\n\n\n有时，可以看到L(θ)是连乘的，所以为了便于分析，还可以定义对数似然函数，将其变成连加的：\n![](http://img.my.csdn.net/uploads/201301/24/1359003994_1029.jpg)\n\n\n\n\n\n\n好了，现在我们知道了，要求θ，只需要使θ的似然函数L(θ)极大化，然后极大值对应的θ就是我们的估计。这里就回到了求最值的问题了。怎么求一个函数的最值？当然是求导，然后让导数为0，那么解这个方程得到的θ就是了（当然，前提是函数L(θ)连续可微）。那如果θ是包含多个参数的向量那怎么处理啊？当然是求L(θ)对所有参数的偏导数，也就是梯度了，那么n个未知的参数，就有n个方程，方程组的解就是似然函数的极值点了，当然就得到这n个参数了。\n\n最大似然估计你可以把它看作是一个反推。多数情况下我们是根据已知条件来推算结果，而最大似然估计是已经知道了结果，然后寻求使该结果出现的可能性最大的条件，以此作为估计值。比如，如果其他条件一定的话，抽烟者发生肺癌的危险时不抽烟者的5倍，那么如果现在我已经知道有个人是肺癌，我想问你这个人抽烟还是不抽烟。你怎么判断？你可能对这个人一无所知，你所知道的只有一件事，那就是抽烟更容易发生肺癌，那么你会猜测这个人不抽烟吗？我相信你更有可能会说，这个人抽烟。为什么？这就是“最大可能”，我只能说他“最有可能”是抽烟的，“他是抽烟的”这一估计值才是“最有可能”得到“肺癌”这样的结果。这就是最大似然估计。\n\n好了，极大似然估计就讲到这，总结一下：\n\n极大似然估计，只是一种概率论在统计学的应用，它是参数估计的方法之一。说的是已知某个随机样本满足某种概率分布，但是其中具体的参数不清楚，参数估计就是通过若干次试验，观察其结果，利用结果推出参数的大概值。最大似然估计是建立在这样的思想上：已知某个参数能使这个样本出现的概率最大，我们当然不会再去选择其他小概率的样本，所以干脆就把这个参数作为估计的真实值。\n\n\n求最大似然函数估计值的一般步骤：\n\n\n（1）写出似然函数；\n（2）对似然函数取对数，并整理；\n（3）求导数，令导数为0，得到似然方程；\n（4）解似然方程，得到的参数即为所求；\n二、EM算法\n好了，重新回到上面那个身高分布估计的问题。现在，通过抽取得到的那100个男生的身高和已知的其身高服从高斯分布，我们通过最大化其似然函数，就可以得到了对应高斯分布的参数θ=[u, ∂]T了。那么，对于我们学校的女生的身高分布也可以用同样的方法得到了。\n\n再回到例子本身，如果没有“男的左边，女的右边，其他的站中间！”这个步骤，或者说我抽到这200个人中，某些男生和某些女生一见钟情，已经好上了，纠缠起来了。咱们也不想那么残忍，硬把他们拉扯开。那现在这200个人已经混到一起了，这时候，你从这200个人（的身高）里面随便给我指一个人（的身高），我都无法确定这个人（的身高）是男生（的身高）还是女生（的身高）。也就是说你不知道抽取的那200个人里面的每一个人到底是从男生的那个身高分布里面抽取的，还是女生的那个身高分布抽取的。用数学的语言就是，抽取得到的每个样本都不知道是从哪个分布抽取的。\n\n这个时候，对于每一个样本或者你抽取到的人，就有两个东西需要猜测或者估计的了，一是这个人是男的还是女的？二是男生和女生对应的身高的高斯分布的参数是多少？\n\n只有当我们知道了哪些人属于同一个高斯分布的时候，我们才能够对这个分布的参数作出靠谱的预测，例如刚开始的最大似然所说的，但现在两种高斯分布的人混在一块了，我们又不知道哪些人属于第一个高斯分布，哪些属于第二个，所以就没法估计这两个分布的参数。反过来，只有当我们对这两个分布的参数作出了准确的估计的时候，才能知道到底哪些人属于第一个分布，那些人属于第二个分布。\n\n这就成了一个先有鸡还是先有蛋的问题了。鸡说，没有我，谁把你生出来的啊。蛋不服，说，没有我，你从哪蹦出来啊。（呵呵，这是一个哲学问题。当然了，后来科学家说先有蛋，因为鸡蛋是鸟蛋进化的）。为了解决这个你依赖我，我依赖你的循环依赖问题，总得有一方要先打破僵局，说，不管了，我先随便整一个值出来，看你怎么变，然后我再根据你的变化调整我的变化，然后如此迭代着不断互相推导，最终就会收敛到一个解。这就是EM算法的基本思想了。\n\n不知道大家能否理解其中的思想，我再来啰嗦一下。其实这个思想无处在不啊。\n\n例如，小时候，老妈给一大袋糖果给你，叫你和你姐姐等分，然后你懒得去点糖果的个数，所以你也就不知道每个人到底该分多少个。咱们一般怎么做呢？先把一袋糖果目测的分为两袋，然后把两袋糖果拿在左右手，看哪个重，如果右手重，那很明显右手这代糖果多了，然后你再在右手这袋糖果中抓一把放到左手这袋，然后再感受下哪个重，然后再从重的那袋抓一小把放进轻的那一袋，继续下去，直到你感觉两袋糖果差不多相等了为止。呵呵，然后为了体现公平，你还让你姐姐先选了。\n\n\nEM算法就是这样，假设我们想估计知道A和B两个参数，在开始状态下二者都是未知的，但如果知道了A的信息就可以得到B的信息，反过来知道了B也就得到了A。可以考虑首先赋予A某种初值，以此得到B的估计值，然后从B的当前值出发，重新估计A的取值，这个过程一直持续到收敛为止。\n\nEM的意思是“Expectation Maximization”，在我们上面这个问题里面，我们是先随便猜一下男生（身高）的正态分布的参数：如均值和方差是多少。例如男生的均值是1米7，方差是0.1米（当然了，刚开始肯定没那么准），然后计算出每个人更可能属于第一个还是第二个正态分布中的（例如，这个人的身高是1米8，那很明显，他最大可能属于男生的那个分布），这个是属于Expectation一步。有了每个人的归属，或者说我们已经大概地按上面的方法将这200个人分为男生和女生两部分，我们就可以根据之前说的最大似然那样，通过这些被大概分为男生的n个人来重新估计第一个分布的参数，女生的那个分布同样方法重新估计。这个是Maximization。然后，当我们更新了这两个分布的时候，每一个属于这两个分布的概率又变了，那么我们就再需要调整E步……如此往复，直到参数基本不再发生变化为止。\n\n这里把每个人（样本）的完整描述看做是三元组yi={xi,zi1,zi2}，其中，xi是第i个样本的观测值，也就是对应的这个人的身高，是可以观测到的值。zi1和zi2表示男生和女生这两个高斯分布中哪个被用来产生值xi，就是说这两个值标记这个人到底是男生还是女生（的身高分布产生的）。这两个值我们是不知道的，是隐含变量。确切的说，zij在xi由第j个高斯分布产生时值为1，否则为0。例如一个样本的观测值为1.8，然后他来自男生的那个高斯分布，那么我们可以将这个样本表示为{1.8, 1, 0}。如果zi1和zi2的值已知，也就是说每个人我已经标记为男生或者女生了，那么我们就可以利用上面说的最大似然算法来估计他们各自高斯分布的参数。但是它们未知，因此我们只能用EM算法。\n\n咱们现在不是因为那个恶心的隐含变量（抽取得到的每个样本都不知道是从哪个分布抽取的）使得本来简单的可以求解的问题变复杂了，求解不了吗。那怎么办呢？人类解决问题的思路都是想能否把复杂的问题简单化。好，那么现在把这个复杂的问题逆回来，我假设已经知道这个隐含变量了，哎，那么求解那个分布的参数是不是很容易了，直接按上面说的最大似然估计就好了。那你就问我了，这个隐含变量是未知的，你怎么就来一个假设说已知呢？你这种假设是没有根据的。呵呵，我知道，所以我们可以先给这个给分布弄一个初始值，然后求这个隐含变量的期望，当成是这个隐含变量的已知值，那么现在就可以用最大似然求解那个分布的参数了吧，那假设这个参数比之前的那个随机的参数要好，它更能表达真实的分布，那么我们再通过这个参数确定的分布去求这个隐含变量的期望，然后再最大化，得到另一个更优的参数，……迭代，就能得到一个皆大欢喜的结果了。\n\n这时候你就不服了，说你老迭代迭代的，你咋知道新的参数的估计就比原来的好啊？为什么这种方法行得通呢？有没有失效的时候呢？什么时候失效呢？用到这个方法需要注意什么问题呢？呵呵，一下子抛出那么多问题，搞得我适应不过来了，不过这证明了你有很好的搞研究的潜质啊。呵呵，其实这些问题就是数学家需要解决的问题。在数学上是可以稳当的证明的或者得出结论的。那咱们用数学来把上面的问题重新描述下。（在这里可以知道，不管多么复杂或者简单的物理世界的思想，都需要通过数学工具进行建模抽象才得以使用并发挥其强大的作用，而且，这里面蕴含的数学往往能带给你更多想象不到的东西，这就是数学的精妙所在啊）\n\n\n三、EM算法推导\n假设我们有一个样本集{x(1),…,x(m)}，包含m个独立的样本。但每个样本i对应的类别z(i)是未知的（相当于聚类），也即隐含变量。故我们需要估计概率模型p(x,z)的参数θ，但是由于里面包含隐含变量z，所以很难用最大似然求解，但如果z知道了，那我们就很容易求解了。\n\n对于参数估计，我们本质上还是想获得一个使似然函数最大化的那个参数θ，现在与最大似然不同的只是似然函数式中多了一个未知的变量z，见下式（1）。也就是说我们的目标是找到适合的θ和z让L(θ)最大。那我们也许会想，你就是多了一个未知的变量而已啊，我也可以分别对未知的θ和z分别求偏导，再令其等于0，求解出来不也一样吗？\n\n\n\n![](http://img.my.csdn.net/uploads/201301/24/1359004165_6698.jpg)\n\n\n\n本质上我们是需要最大化（1）式（对（1）式，我们回忆下联合概率密度下某个变量的边缘概率密度函数的求解，注意这里z也是随机变量。对每一个样本i的所有可能类别z求等式右边的联合概率密度函数和，也就得到等式左边为随机变量x的边缘概率密度），也就是似然函数，但是可以看到里面有“和的对数”，求导后形式会非常复杂（自己可以想象下log(f1(x)+ f2(x)+ f3(x)+…)复合函数的求导），所以很难求解得到未知参数z和θ。那OK，我们可否对（1）式做一些改变呢？我们看（2）式，（2）式只是分子分母同乘以一个相等的函数，还是有“和的对数”啊，还是求解不了，那为什么要这么做呢？咱们先不管，看（3）式，发现（3）式变成了“对数的和”，那这样求导就容易了。我们注意点，还发现等号变成了不等号，为什么能这么变呢？这就是Jensen不等式的大显神威的地方。\n\nJensen不等式：\n设f是定义域为实数的函数，如果对于所有的实数x。如果对于所有的实数x，f(x)的二次导数大于等于0，那么f是凸函数。当x是向量时，如果其hessian矩阵H是半正定的，那么f是凸函数。如果只大于0，不等于0，那么称f是严格凸函数。\n\nJensen不等式表述如下：\n\n如果f是凸函数，X是随机变量，那么：E[f(X)]&gt;=f(E[X])\n\n特别地，如果f是严格凸函数，当且仅当X是常量时，上式取等号。\n\n如果用图表示会很清晰：\n\n![](http://img.my.csdn.net/uploads/201301/24/1359004230_7889.jpg)\n\n\n图中，实线f是凸函数，X是随机变量，有0.5的概率是a，有0.5的概率是b。（就像掷硬币一样）。X的期望值就是a和b的中值了，图中可以看到E[f(X)]&gt;=f(E[X])成立。\n\n当f是（严格）凹函数当且仅当-f是（严格）凸函数。\n\nJensen不等式应用于凹函数时，不等号方向反向。\n\n\n\n\n回到公式（2），因为f(x)=log x为凹函数（其二次导数为-1/x2&lt;0）。\n\n（2）式中的期望，（考虑到E(X)=∑x*p(x)，f(X)是X的函数，则E(f(X))=∑f(x)*p(x)），又，所以就可以得到公式（3）的不等式了（若不明白，请拿起笔，呵呵）：\n\n![](http://img.my.csdn.net/uploads/201301/24/1359004457_8988.jpg)\n\n\nOK，到这里，现在式（3）就容易地求导了，但是式（2）和式（3）是不等号啊，式（2）的最大值不是式（3）的最大值啊，而我们想得到式（2）的最大值，那怎么办呢？\n\n现在我们就需要一点想象力了，上面的式（2）和式（3）不等式可以写成：似然函数L(θ)&gt;=J(z,Q)，那么我们可以通过不断的最大化这个下界J，来使得L(θ)不断提高，最终达到它的最大值。\n\n![](http://img.my.csdn.net/uploads/201301/24/1359004484_7944.jpg)\n\n\n\n见上图，我们固定θ，调整Q(z)使下界J(z,Q)上升至与L(θ)在此点θ处相等（绿色曲线到蓝色曲线），然后固定Q(z)，调整θ使下界J(z,Q)达到最大值（θt到θt+1），然后再固定θ，调整Q(z)……直到收敛到似然函数L(θ)的最大值处的θ*。这里有两个问题：什么时候下界J(z,Q)与L(θ)在此点θ处相等？为什么一定会收敛？\n\n首先第一个问题，在Jensen不等式中说到，当自变量X是常数的时候，等式成立。而在这里，即：\n\n\n\n![](http://img.my.csdn.net/uploads/201301/24/1359004517_4140.jpg)\n\n\n\n再推导下，由于（因为Q是随机变量z(i)的概率密度函数），则可以得到：分子的和等于c（分子分母都对所有z(i)求和：多个等式分子分母相加不变，这个认为每个样例的两个概率比值都是c），则：\n\n\n![](http://img.my.csdn.net/uploads/201301/24/1359004651_3922.jpg)\n\n\n\n至此，我们推出了在固定参数θ后，使下界拉升的Q(z)的计算公式就是后验概率，解决了Q(z)如何选择的问题。这一步就是E步，建立L(θ)的下界。接下来的M步，就是在给定Q(z)后，调整θ，去极大化L(θ)的下界J（在固定Q(z)后，下界还可以调整的更大）。那么一般的EM算法的步骤如下：\n\n\n\nEM算法（Expectation-maximization）：\n期望最大算法是一种从不完全数据或有数据丢失的数据集（存在隐含变量）中求解概率模型参数的最大似然估计方法。\n\nEM的算法流程：\n初始化分布参数θ；\n\n重复以下步骤直到收敛：\nE步骤：根据参数初始值或上一次迭代的模型参数来计算出隐性变量的后验概率，其实就是隐性变量的期望。作为隐藏变量的现估计值：\n\n![](http://img.my.csdn.net/uploads/201301/24/1359004674_9261.jpg)\n\n\nM步骤：将似然函数最大化以获得新的参数值：\n\n![](http://img.my.csdn.net/uploads/201301/24/1359004692_8552.jpg)\n  \n\n这个不断的迭代，就可以得到使似然函数L(θ)最大化的参数θ了。那就得回答刚才的第二个问题了，它会收敛吗？\n\n感性的说，因为下界不断提高，所以极大似然估计单调增加，那么最终我们会到达最大似然估计的最大值。理性分析的话，就会得到下面的东西：\n\n![](http://img.my.csdn.net/uploads/201301/24/1359004726_5955.jpg)\n  \n\n具体如何证明的，看推导过程参考：Andrew Ng《The EM algorithm》:http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006936.html\n\n\n四、EM算法另一种理解\n坐标上升法（Coordinate ascent）：\n\n![](http://img.my.csdn.net/uploads/201301/24/1359004760_8452.jpg)\n \n\n图中的直线式迭代优化的路径，可以看到每一步都会向最优值前进一步，而且前进路线是平行于坐标轴的，因为每一步只优化一个变量。\n\n这犹如在x-y坐标系中找一个曲线的极值，然而曲线函数不能直接求导，因此什么梯度下降方法就不适用了。但固定一个变量后，另外一个可以通过求导得到，因此可以使用坐标上升法，一次固定一个变量，对另外的求极值，最后逐步逼近极值。对应到EM上，E步：固定θ，优化Q；M步：固定Q，优化θ；交替将极值推向最大。\n\n\n五、EM的应用\nEM算法有很多的应用，最广泛的就是GMM混合高斯模型、聚类、HMM等等。具体可以参考JerryLead的cnblog中的Machine Learning专栏：\n\n（EM算法）The EM Algorithm\n\n混合高斯模型（Mixtures of Gaussians）和EM算法\n\nK-means聚类算法\n\n\n六、贝叶斯估计\n统计学里有两个大的流派，一个是频率派，一个是贝叶斯派。时至今日，这两派还未就各自的观点达成统一。我们前面提到的最大似然估计就是频率派的典型思路，接下来再看看贝叶斯派的思路，到底跟频率派估计有何不同。 \n\n先来看几个相关的小公式： \n\n两个随机变量x,y的联合概率p(x,y)的乘法公式： \n          p(x,y)=p(x|y)p(y)=p(y|x)p(x)\n\n如果x,y是独立随机变量，上面的式子可以表示为: \n          p(x,y)=p(x)p(y)=p(y)p(x)\n\n那么条件概率就可以表示为：\n          p(x|y)=p(x,y)/p(y)\n          p(y|x)=p(x,y)/p(x)\n\n\n\n对于一个完备事件组y1,y2,⋯,yn，可以使用全概率公式：\n\n\n![](https://i.imgur.com/LLhwgHj.png)\n\n+ 由以上这些，可以得出贝叶斯公式：\n\n![](https://i.imgur.com/QcxgeCc.png)\n\n\n\n其中，p(yi|x)是后验概率。p(x|yi)是条件概率，或者说似然概率，这个概率一般都可以通过历史数据统计得出。而p(yi)是先验概率，一般也是根据历史数据统计得出或者认为给定的，贝叶斯里的先验概率，就是指p(yi)。对于p(x)，我们前面提到可以用全概率公式计算得出，但是在贝叶斯公式里面我们一般不care这个概率，因为我们往往只需要求出最大后验概率而不需要求出最大后验的具体值。\n\n七、最大似然估计与贝叶斯估计的区别\n细心的同学通过观察MLE与Bayes的公式，发现Bayes公式比MLE公式里就多了一项p(yi)(咱们先抛开p(x)不考虑)，而条件概率或者说似然概率的表达式是一致的。从数学表达式的角度来说，两者最大的区别就在这里：贝叶斯估计引入了先验概率，通过先验概率与似然概率来求解后验概率。而最大似然估计是直接通过最大化似然概率来求解得出的。\n\n换句话说，最大似然估计没有考虑模型本身的概率，或者说认为模型出现的概率都相等。而贝叶斯估计将模型出现的概率用先验概率的方式在计算过程中有所体现。\n\n举个大家上学时候就遇到的例子： \n\n假如人们会感染一种病毒，有一种测试方法，在被测试者已感染这个病毒时，测试结果 为阳性的概率为95%。在被测试者没有感染这个病毒时，测试结果为阳性的概率为2%。现在，有一个人的测试结果为阳性，问这个人感染了病毒吗？ \n\n如果用最大似然估计的方法，既然感染了病毒出现阳性的概率为95%，没感染出现阳性的概率为2%，本着谁大像谁的原则，那我就认为这个人已经感染了病毒。 \n\n但是如果用贝叶斯方法进行估计，如果我们得知有一个先验概率，比如整体人群中只有1%的人会感染此种病毒，那么由贝叶斯公式：\n\n![](https://i.imgur.com/OtccPaH.png) \n\n其中，p(真阳性|检测为阳性)为后验概率，即我们通过检测出为阳性可以判断为真阳性的概率；p(真阳性)为先验概率，p(检测为阳性|真阳性)为条件概率，p(真阳性)p(检测为阳性|真阳性)+p(真阴性)p(检测为阳性|真阴性)为全概率，检测出为阳性是由一个完备事件组构成的：这个人要么是真阳性，要么是真阴性。 \n\n由此可见，在贝叶斯估计中，先验概率对结果的影响很大。在这种场景下，采用贝叶斯估计似乎更为合理一些。\n\n最后来个总结：从本质上来说，最大似然是对点估计，贝叶斯推断是对分布估计。即，假设求解参数θ，最大似然是求出最有可能的θ值，而贝叶斯推断则是求解θ的分布。\n\n\n八、线性判别分析\n参考这篇博文：线性判别分析（Linear Discriminant Analysis\n\n","categories":["图像处理"],"tags":[]},{"title":"SPHARM-PDM与MEPP","url":"http://tanqingbo.cn/2017/09/16/SPHARM-PDM与MEPP/","content":"SPHARM-PDM\n形状分析已经成为医学界日益增长的兴趣，因为它有可能精确地定位健康和病理结构之间的形态学变化。 SPHARM-PDM是一种使用参数边界描述计算基于点的模型来计算形状分析的工具。 \n使用SPHARM-PDM工具计算的基于点的模型可以与UNC设计的统计工具形状分析MANCOVA结合使用，以对特定位置的结构变化进行定量形态学评估。\n自2017年7月起，SPHARM-PDM现在可作为3D切片扩展（ http://www.slicer.org ）和SlicerSALT（salt.slicer.org）的一部分。 通过SlicerSALT传播SPHARM-PDM现在是下载新版本SPHARM-PDM的主要传播方式。 \n有关问题，请参阅nitrc论坛，网址为：https://www.nitrc.org/projects/spharm-pdm \n\n##•SegPostProcessCLP \n\n⇒填充内孔。 \n\n⇒执行最小平滑操作 确保球形拓扑。\nSegPostProcessCLP参数解释：      ./SegPostProcessCLP label.nii brain-segout/label-segout.vtk --space 1.5,1.5,1.5\n\nSegPostProcessCLP --help 可以查看各种参数的意思。\n\n--space x,y and z 的方向（默认：0.75,0.75,0.75）\n\n--iter &lt;int&gt;LS平滑的迭代次数,默认50次\n\n--Gauss 0/1: if selected, do a Gaussian Filtering\n\n--RMS &lt;double&gt;LS平滑的均方根值误差\n\n\n##•GenParaMeshCLP \n\n⇒处理二进制分段是 转换为原始表面网格。 \n\n计算球面参数。\nGenParaMeshCLP参数解释：      ./GenParaMeshCLP brain-segout/label-segout.vtk brain-meshout/label-para.vtk brain-meshout/label-surf.vtk --label 1\n\n--label 1输入图像中的标签ID\n\n--iter &lt;int&gt;选择迭代的次数,默认是500次 \n\n--outLogName &lt;std::string&gt;：Output Log txtFile\n\n--logFile：write a .txt file with a log of events \n\n\n•ParaToSPHARMMeshCLP\n⇒具有固有的SPHARM描述 \n\n然后从中计算出对应关系 网格及其球形参数化。 \n\n⇒对应的三角曲面 （SPHARM-PDM）。 \n\n二十面体的球面参数化\nParaToSPHARMMeshCLP参数解释： ./ParaToSPHARMMeshCLP brain-meshout/label-para.vtk brain-meshout/label-surf.vtk brain-align/label\n\n\nMEPP \nMEPP旨在围绕新的网格处理技术构建一个框架。 面向模块化，它面向开发人员和GUI用户。 \nMEPP是基于CGAL类“多面体”的平台开发环境，用于网格和网格序列的处理和可视化。它允许加载多个网格或网格序列，进行处理和可视化。 它旨在为工程师，研究人员，也为快速入门的学生提供建议。\n\n特征：\nC ++，开源（GNU GPL v3）， \n多平台（Windows，Linux，Mac OS X） \n用CMake编译， \n安装快捷方便， \n安装文件，用户手册， \nVMware虚拟机与Ubuntu Linux“准备启动”， \n从一个应用程序窗口或从浏览器拖放对象。支持格式：\nobj (Wavefront), \noff (Object File Format), \nply (Polygon File Format), \nsmf (3D World Studio), \nx3d (XML based royalty-free open standard file format), \n3ds (3ds Max), \ndae (Collada), \nlwo (LightWave).\n\nExport：\n图像捕获， \n视频截取。\n\n显示功能：\n管理一个或多个窗口中的多个对象， \n使用“显示列表”加速显示。\n\nMEPP平台允许两种类型的加载：\n模式“空间”，其中将几个对象加载到同一场景中， \n模式“时间”，其中将几个对象作为网格序列加载。 \n\n然后可以通过VCR 3D + t可视化序列。\n组件 ：\n实现为具有自动检测和加载的插件， \n在编译时选择组件， \n从示例中轻松创建新组件。\n\n可用组件：\n基本网格处理：三角剖分，细分，简化， \n曲率分析， \n布尔运算：联合，交集，减法， \n分割（变形形状近似）， \n逐行压缩/水印， \n视觉质量指标， \nremeshing：规范简化， \n数学形态学， \n网格修复 \n\n通过创建新的组件来为平台做出贡献的可能性。\n组件“布尔运算”：\n组件“分割”：\n组件“曲率”：\n\n有关问题，请参观mepp的官网，网址：https://liris.cnrs.fr/mepp/\n\noff文件格式(Object File Format)\nObject File Format(off)文件通过描述物体表面的多边形来表示一个模型的几何结构。这些多边形可以包含任意数量的顶点。Princeton Shape Benchmark的off文件遵从以下标准：\n\noff文件为ASCII文件，以OFF关键字开头。\n\n下一行是该模型的顶点数，面数和边数。边数可以忽略，对模型不会有影响(可以为0)。\n\n顶点以x，y，z坐标列出，每个顶点占一行。\n\n在顶点列表之后是面列表，每个面占一行。对于每个边，首先指定其包含的顶点数，随后是这个面所包含的各顶点在前面顶点列表中的索引。\n\n\n\n下面是一个立方体的例子：\n      OFF \n      8 6 0 \n      -0.500000 -0.500000 0.500000 \n      0.500000 -0.500000 0.500000 \n      -0.500000 0.500000 0.500000 \n      0.500000 0.500000 0.500000 \n      -0.500000 0.500000 -0.500000 \n      0.500000 0.500000 -0.500000 \n      -0.500000 -0.500000 -0.500000 \n      0.500000 -0.500000 -0.500000 \n      4 0 1 3 2 \n      4 2 3 5 4 \n      4 4 5 7 6 \n      4 6 7 1 0 \n      4 1 7 5 3 \n      4 6 0 2 4\n\n参考地址：http://shape.cs.princeton.edu/benchmark/documentation/off_format.html\n\n\n","categories":["图像处理"],"tags":[]},{"title":"图像处理类的期刊整理","url":"http://tanqingbo.cn/2017/09/15/图像处理类的期刊整理/","content":"图像处理类的期刊整理中国计算机学会推荐国际学术会议和期刊目录中国计算机学会推荐国际学术刊物 \n（计算机图形学与多媒体）\n\n\n一、A类\n        \n            序号\n            刊物简称\n            刊物全称\n            出版社\n            网址\n        \n        \n            \n            1\n            \n            \n            TOG\n            \n            \n            ACM Transactions on Graphics\n            \n            \n            ACM\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/journals/tog/\n            \n        \n        \n            \n            2\n            \n            \n            TIP\n            \n            \n            IEEE Transactions on Image Processing\n            \n            \n            IEEE\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/journals/tip/\n            \n        \n        \n            \n            3\n            \n            \n            TVCG\n            \n            \n            IEEE Transactions on Visualization and\nComputer Graphics\n            \n            \n            IEEE\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/journals/tvcg/\n            \n        \n\n\n\n\n二、B类\n    \n        \n            序号\n            刊物简称\n            刊物全称\n            出版社\n            网址\n        \n        \n            \n            1\n            \n            \n            TOMCCAP\n            \n            \n            ACM Transactions on Multimedia Computing,Communications and Application\n            \n            \n            ACM\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/journals/tomccap/\n            \n        \n        \n            \n            2\n            \n            \n            CAD\n            \n            \n            Computer-Aided Design\n            \n            \n            Elsevier\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/journals/cad/\n            \n        \n        \n            \n            3\n            \n            \n            CAGD\n            \n            \n            Computer Aided Geometric Design\n            \n            \n            Elsevier\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/journals/cagd/\n            \n        \n        \n            \n            4\n            \n            \n            CGF\n            \n            \n            Computer Graphics Forum\n            \n            \n            Wiley\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/journals/cgf/\n            \n        \n        \n            \n            5\n            \n            \n            GM\n            \n            \n            Graphical Models\n            \n            \n            Elsevier\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/journals/cvgip/\n            \n        \n        \n            \n            6\n            \n            \n            TCSVT\n            \n            \n            IEEE Transactions on Circuits and Systems for\nVideo Technology\n            \n            \n            IEEE\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/journals/tcsv/\n            \n        \n        \n            \n            7\n            \n            \n            TMM\n            \n            \n            IEEE Transactions on Multimedia\n            \n            \n            IEEE\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/journals/tmm/\n            \n        \n        \n            \n            8\n            \n            \n            JASA\n            \n            \n            Journal of The Acoustical Society of America\n            \n            \n            AIP\n            \n            \n            &nbsp;http://scitation.aip.org/content/asa/journal/jasa\n            \n        \n        \n            \n            9\n            \n            \n            SIIMS\n            \n            \n            SIAM Journal on Imaging Sciences\n            \n            \n            SIAM\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/journals/siamis/\n            \n        \n        \n            \n            10\n            \n            \n            Speech Com\n            \n            \n            Speech Communication\n            \n            \n            Elsevier\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/journals/speech/\n            \n        \n    \n\n\n\n三、C类\n    \n        \n            序号\n            刊物简称\n            刊物全称\n            出版社\n            网址\n        \n        \n            \n            1\n            \n            \n            CAVW\n            \n            \n            Computer Animation and Virtual Worlds\n            \n            \n            Wiley\n            \n            \n            &nbsp;http://onlinelibrary.wiley.com/journal\n            /10.1002/(ISSN)1546-427X\n            \n        \n        \n            \n            2\n            \n            \n            C&amp;G\n            \n            \n            Computers &amp; Graphics-UK\n            \n            \n            Elsevier\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/journals/cg/\n            \n        \n        \n            \n            3\n            \n            \n            CGTA\n            \n            \n            Computational Geometry: Theory and\n          Applications\n            \n            \n            Elsevier\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/journals/comgeo/\n            \n        \n        \n            \n            4\n            \n            \n            DCG\n            \n            \n            Discrete &amp; Computational Geometry\n            \n            \n            Springer\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/journals/dcg/\n            \n        \n        \n            \n            5\n            \n            \n            IET-IPR\n            \n            \n            IET Image Processing\n            \n            \n            IET\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/journals/iet-ipr/\n            \n        \n        \n            \n            6\n            \n            &nbsp;\n            \n            IEEE Signal Processing Letter\n            \n            \n            IEEE\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/journals/spl/\n            \n        \n        \n            \n            7\n            \n            \n            JVCIR\n            \n            \n            Journal of Visual Communication and Image Representation\n            \n            \n            Elsevier\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/journals/jvcir/\n            \n        \n        \n            \n            8\n            \n            \n            MS\n            \n            \n            Multimedia Systems\n            \n            \n            Springer\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/journals/mms/\n            \n        \n        \n            \n            9\n            \n            \n            MTA\n            \n            \n            Multimedia Tools and Applications\n            \n            \n            Springer\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/journals/mta/\n            \n        \n        \n            \n            10\n            \n            &nbsp;\n            \n            Signal Processing\n            \n            \n            Elsevier\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/journals/sigpro/\n            \n        \n        \n            \n            11\n            \n            \n            SPIC\n            \n            \n            Signal processing : image communication\n            \n            \n            Elsevier\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/journals/spic/\n            \n        \n        \n            \n            12\n            \n            \n            TVC\n            \n            \n            The Visual Computer\n            \n            \n            Springer\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/journals/vc/\n            \n        \n    \n\n\n\n\n\n中国计算机学会推荐国际学术会议（计算机图形学与多媒体）一、A类\n    \n        \n            序号\n            会议简称\n            会议全称\n            出版社\n            网址\n        \n        \n            \n            1\n            \n            \n            ACM MM\n            \n            \n            ACM International Conference on Multimedia\n            \n            \n            ACM\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/mm/\n            \n        \n        \n            \n            2\n            \n            \n            SIGGRAPH\n            \n            \n            ACM SIGGRAPH Annual Conference\n            \n            \n            ACM\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/siggraph/index.html\n            \n        \n        \n            \n            3\n            \n            \n            IEEE VIS\n            \n            \n            IEEE Visualization Conference\n            \n            \n            IEEE\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/visualization/index.html\n            \n        \n        \n            \n            4\n            \n            \n            VR\n            \n            \n            IEEE Virtual Reality\n            \n            \n            IEEE\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/vr/\n            \n        \n    \n\n\n\n二、B类\n    \n        \n            序号\n            会议简称\n            会议全称\n            出版社\n            网址\n        \n        \n            \n            1\n            \n            \n            ICMR\n            \n            \n            ACM SIGMM International Conference on\nMultimedia Retrieval\n            \n            \n            ACM\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/mir/\n            \n        \n        \n            \n            2\n            \n            \n            i3D\n            \n            \n            ACM Symposium on Interactive 3D Graphics\n            \n            \n            ACM\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/si3d/\n            \n        \n        \n            \n            3\n            \n            \n            SCA\n            \n            \n            ACM/Eurographics Symposium on Computer \n              Animation\n            \n            \n            ACM\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/sca/index.html\n            \n        \n        \n            \n            4\n            \n            \n            DCC\n            \n            \n            Data Compression Conference\n            \n            \n            IEEE\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/dcc/\n            \n        \n        \n            \n            5\n            \n            \n            EG\n            \n            \n            Eurographics\n            \n            \n            Wiley/ Blackwell\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/eurographics/\n            \n        \n        \n            \n            6\n            \n            \n            EuroVis\n            \n            \n            Eurographics Conference on Visualization\n            \n            \n            ACM\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/vissym/\n            \n        \n        \n            \n            7\n            \n            \n            SGP\n            \n            \n            Eurographics Symposium on Geometry Processing\n            \n            \n            &nbsp;Wiley/Blackwell\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/sgp/\n            \n        \n        \n            \n            8\n            \n            \n            EGSR\n            \n            \n            Eurographics Symposium on Rendering\n            \n            \n            Wiley/Blackwell\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/rt/\n            \n        \n        \n            \n            9\n            \n            \n            ICME\n            \n            \n            IEEE International Conference on Multimedia\n&amp; Expo\n            \n            \n            IEEE\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/icmcs/\n            \n        \n        \n            \n            10\n            \n            \n            PG\n            \n            \n            Pacific Graphics: The Pacific Conference on \n              Computer Graphics and Applications\n            \n            \n            Wiley/Blackwell\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/pg/index.html\n            \n        \n        \n            \n            11\n            \n            \n            SPM\n            \n            \n            Symposium on Solid and Physical Modeling\n            \n            \n            SMA/Elsevier\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/sma/\n            \n        \n        \n            \n            12\n            \n            \n            ICASSP\n            \n            \n            IEEE International Conference on Acoustics, \n              Speech and SP\n            \n            \n            IEEE\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/icassp/\n            \n        \n    \n\n\n\n三、C类\n    \n        \n            序号\n            会议简称\n            会议全称\n            出版社\n            网址\n        \n        \n            \n            1\n            \n            \n            CASA\n            \n            \n            Computer Animation and Social Agents\n            \n            \n            Wiley\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/ca/\n            \n        \n        \n            \n            2\n            \n            \n            CGI\n            \n            \n            Computer Graphics International\n            \n            \n            Springer\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/cgi/\n            \n        \n        \n            \n            3\n            \n            \n            ISMAR\n            \n            \n            International Symposium on Mixed and Augmented Reality\n            \n            \n            IEEE/ACM\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/ismar/\n            \n        \n        \n            \n            4\n            \n            \n            PacificVis\n            \n            \n            IEEE Pacific Visualization Symposium\n            \n            \n            IEEE\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/apvis/\n            \n        \n        \n            \n            5\n            \n            \n            ICIP\n            \n            \n            International Conference on Image Processing\n            \n            \n            IEEE\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/icip/\n            \n        \n        \n            \n            6\n            \n            \n            MMM\n            \n            \n            International Conference on Multimedia Modeling\n            \n            \n            Springer\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/mmm/index.html\n            \n        \n        \n            \n            7\n            \n            \n            GMP\n            \n            \n            Geometric Modeling and Processing\n            \n            \n            Elsevier\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/gmp/\n            \n        \n        \n            \n            8\n            \n            \n            PCM\n            \n            \n            Pacific-Rim Conference on Multimedia\n            \n            \n            Springer\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/pcm/\n            \n        \n        \n            \n            9\n            \n            \n            SMI\n            \n            \n            Shape Modeling International\n            \n            \n            IEEE\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/smi/\n            \n        \n        \n            \n            10\n            \n            \n            INTER\n              SPEECH\n            \n            \n            Conference of the International Speech Communication Association\n            \n            \n            &nbsp;\n            \n            \n            &nbsp;http://dblp.uni-trier.de/db/conf/interspeech/index.html\n            \n        \n        \n            \n            11\n            \n            \n            &nbsp;\n            \n            \n            ACM Symposium on Virtual Reality Software and Technology\n            \n            \n            ACM\n            \n            \n            &nbsp;http://dblp2.uni-trier.de/db/conf/vrst/\n            \n        \n    \n\n\n          \n\n\n\n\n\n\n\n\nTop Journals for Image Processing &amp; Computer Vision(图像处理与计算机视觉热门期刊)\n\n\n&lt;div class=&quot;grey myshad&quot; style=&quot;margin-bottom:15px;padding:1px;&quot;&gt;\n    &lt;table border=&quot;0&quot; width=&quot;100%&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot; style=&quot;margin:1px;padding:1px;&quot;&gt;\n      &lt;tbody&gt;&lt;tr&gt;\n           &lt;td width=&quot;35px&quot; style=&quot;&quot; class=&quot;mya1&quot;&gt;\n        &lt;center&gt;&lt;i style=&quot;font-size:18px;&quot;&gt;10&lt;/i&gt;&lt;/center&gt;\n        &lt;/td&gt;                          \n           &lt;td width=&quot;115px&quot; style=&quot;&quot; class=&quot;mya1&quot;&gt;\n        &lt;img style=&quot;vertical-align:middle;width:110px;max-height:30px;&quot; src=&quot;/img/IEEE_s.png&quot;&gt;\n        &lt;/td&gt;\n    &lt;td style=&quot;&quot; class=&quot;mya1&quot;&gt;&lt;h4 style=&quot;padding:1px;margin:1px;font-size:14px;&quot;&gt;&lt;a href=&quot;/?p=7904&quot;&gt;IEEE Transactions on Pattern Analysis and Machine Intelligence&lt;/a&gt;&lt;/h4&gt;\n                          &lt;div style=&quot;padding:0px;margin:0px;&quot;&gt;ISSN:0162-8828 , Monthly&lt;/div&gt;\n    &lt;!--      &lt;div style=&quot;padding:0px;margin:0px;font-size:11px;line-height:11px;&quot;&gt;&lt;a target=_blank href=&quot;https://www.computer.org/web/tpami&quot; style=&quot;font-size:11px;line-height:11px;margin:0px;padding:0px;&quot;&gt;https://www.computer.org/web/tpami&lt;/a&gt;&lt;/div&gt; --&gt;\n\n    &lt;/td&gt;\n    &lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;8.329&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n      &lt;/tr&gt;\n    &lt;/tbody&gt;&lt;/table&gt;\n&lt;/div&gt;\n\n    \n      \n           \n        11\n                                  \n           \n        \n        \n    International Journal of Computer Vision\n                          ISSN:0920-5691 , Monthly\n    <!--      http://www.springer.com/computer+science/image+processing/journal/11263 -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;8.222&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        22\n                                  \n           \n        \n        \n    ISPRS Journal of Photogrammetry and Remote Sensing\n                          ISSN:0924-2716 , Quarterly\n    <!--      https://www.journals.elsevier.com/isprs-journal-of-photogrammetry-and-remote-sensing -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;6.387&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        25\n                                  \n           \n        \n        \n    Remote Sensing of Environment\n                          ISSN:0034-4257 , Monthly\n    <!--      https://www.journals.elsevier.com/remote-sensing-of-environment -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;6.265&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        28\n                                  \n           \n        \n        \n    Information Fusion\n                          ISSN:1566-2535 , Quarterly\n    <!--      https://www.journals.elsevier.com/information-fusion -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;5.667&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        31\n                                  \n           \n        \n        \n    International Journal of Robotics Research\n                          ISSN:0278-3649 , Monthly\n    <!--      http://ijr.sagepub.com/ -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;5.301&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        44\n                                  \n           \n        \n        \n    IEEE Transactions on Image Processing\n                          ISSN:1057-7149 , Monthly\n    <!--      http://signalprocessingsociety.org/publications-resources/ieee-transactions-image-processing -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;4.828&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        47\n                                  \n           \n        \n        \n    Pattern Recognition\n                          ISSN:0031-3203 , Monthly\n    <!--      https://www.journals.elsevier.com/pattern-recognition -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;4.582&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        51\n                                  \n           \n        \n        \n    IEEE Transactions on Information Forensics and Security\n                          ISSN:1556-6013 , Monthly\n    <!--      http://signalprocessingsociety.org/publications-resources/ieee-transactions-information-forensics-and-security -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;4.332&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        56\n                                  \n           \n        \n        \n    Medical Image Analysis\n                          ISSN:1361-8415 , Bimonthly\n    <!--      https://www.journals.elsevier.com/medical-image-analysis -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;4.188&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        63\n                                  \n           \n        \n        \n    IEEE Transactions on Robotics\n                          ISSN:1552-3098 , Bimonthly\n    <!--      http://www.ieee-ras.org/publications/t-ro -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;4.036&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        68\n                                  \n           \n        \n        \n    IEEE Transactions on Medical Imaging\n                          ISSN:0278-0062 , Monthly\n    <!--      https://ieee-tmi.org/ -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;3.942&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        80\n                                  \n           \n        \n        \n    Journal of the American Medical Informatics Association : JAMIA\n                          ISSN:1067-5027 , Bimonthly\n    <!--      http://jamia.bmj.com/ -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;3.698&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        83\n                                  \n           \n        \n        \n    IEEE Transactions on Circuits and Systems for Video Technology\n                          ISSN:1051-8215 , Monthly\n    <!--      http://tcsvt.polito.it/ -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;3.599&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        104\n                                  \n           \n        \n        \n    IEEE Robotics and Automation Magazine\n                          ISSN:1070-9932 , Quarterly\n    <!--      http://www.ieee-ras.org/publications/ram -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;3.276&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        109\n                                  \n           \n        \n        \n    Photogrammetric Record\n                          ISSN:0031-868X , Quarterly\n    <!--      http://onlinelibrary.wiley.com/journal/10.1111/(ISSN)1477-9730 -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;3.256&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        139\n                                  \n           \n        \n        \n    IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing\n                          ISSN:1939-1404 , Monthly\n    <!--      http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=4609443 -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;2.913&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        156\n                                  \n           \n        \n        \n    IEEE Geoscience and Remote Sensing Letters\n                          ISSN:1545-598X , Monthly\n    <!--      http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8859 -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;2.761&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        166\n                                  \n           \n        \n        \n    Image and Vision Computing\n                          ISSN:0262-8856 , Monthly\n    <!--      https://www.journals.elsevier.com/image-and-vision-computing -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;2.671&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        190\n                                  \n           \n        \n        \n    Computer Vision and Image Understanding\n                          ISSN:1077-3142 , Monthly\n    <!--      https://www.journals.elsevier.com/computer-vision-and-image-understanding -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;2.498&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        191\n                                  \n           \n        \n        \n    Photogrammetric Engineering &amp; Remote Sensing\n                          ISSN:0099-1112 , Monthly\n    <!--      http://www.asprs.org/Photogrammetric-Engineering-and-Remote-Sensing/PE-RS-Journals.html -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;2.493&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        193\n                                  \n           \n        \n        \n    IEEE Transactions on Audio, Speech and Language Processing\n                          ISSN:1558-7916 , Monthly\n    <!--      http://signalprocessingsociety.org/publications-resources/ieeeacm-transactions-audio-speech-and-language-processing/ieeeacm -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;2.491&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        196\n                                  \n           \n        \n        \n    SIAM Journal on Imaging Sciences\n                          ISSN:1936-4954 , Quarterly\n    <!--      https://www.siam.org/journals/siims.php -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;2.485&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        233\n                                  \n           \n        \n        \n    Signal Processing: Image Communication\n                          ISSN:0923-5965 , Monthly\n    <!--      https://www.journals.elsevier.com/signal-processing-image-communication -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;2.244&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        244\n                                  \n           \n        \n        \n    Journal of Visual Communication and Image Representation\n                          ISSN:1047-3203 , Bimonthly\n    <!--      https://www.journals.elsevier.com/journal-of-visual-communication-and-image-representation -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;2.164&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        258\n                                  \n           \n        \n        \n    Journal of Real-Time Image Processing\n                          ISSN:1861-8200 , Quarterly\n    <!--      http://www.springer.com/computer+science/image+processing/journal/11554 -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;2.010&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        261\n                                  \n           \n        \n        \n    Machine Vision and Applications\n                          ISSN:0932-8092 , Bimonthly\n    <!--      http://www.springer.com/computer+science/image+processing/journal/138 -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;2.005&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        264\n                                  \n           \n        \n        \n    Pattern Recognition Letters\n                          ISSN:0167-8655 , Monthly\n    <!--      https://www.journals.elsevier.com/pattern-recognition-letters -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;1.995&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        265\n                                  \n           \n        \n        \n    Journal of Mathematical Imaging and Vision\n                          ISSN:0924-9907 , Monthly\n    <!--      http://www.springer.com/computer+science/image+processing/journal/10851 -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;1.994&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        269\n                                  \n           \n        \n        \n    Eurasip Journal on Advances in Signal Processing\n                          ISSN:1687-6180 , Irregular\n    <!--      http://asp.eurasipjournals.com/ -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;1.961&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        304\n                                  \n           \n        \n        \n    Digital Investigation\n                          ISSN:1742-2876 , Quarterly\n    <!--      https://www.journals.elsevier.com/digital-investigation -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;1.774&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        310\n                                  \n           \n        \n        \n    Eurasip Journal on Image and Video Processing\n                          ISSN:1687-5281 , Irregular\n    <!--      http://www.springer.com/engineering/signals/journal/13640 -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;1.742&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        312\n                                  \n           \n        \n        \n    International Journal of Remote Sensing\n                          ISSN:0143-1161 , Semimonthly\n    <!--      http://www.tandfonline.com/toc/tres20/current -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;1.724&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        337\n                                  \n           \n        \n        \n    Geocarto International\n                          ISSN:1010-6049 , Bimonthly\n    <!--      http://www.tandfonline.com/toc/tgei20/current -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;1.646&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        372\n                                  \n           \n        \n        \n    Multimedia Tools and Applications\n                          ISSN:1380-7501 , Monthly\n    <!--      http://www.springer.com/computer+science/information+systems+and+applications/journal/11042 -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;1.530&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        382\n                                  \n           \n        \n        \n    Journal of Intelligent and Robotic Systems: Theory and Applications\n                          ISSN:0921-0296 , Monthly\n    <!--      http://www.springer.com/engineering/robotics/journal/10846 -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;1.512&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        388\n                                  \n           \n        \n        \n    Earth Science Informatics\n                          ISSN:1865-0473 , Quarterly\n    <!--      http://www.springer.com/earth+sciences+%26+geography/computer+%26+mathematical+applications/journal/12145 -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;1.495&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        391\n                                  \n           \n        \n        \n    Visual Computer\n                          ISSN:0178-2789 , Bimonthly\n    <!--      http://www.springer.com/computer+science/image+processing/journal/371 -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;1.468&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        419\n                                  \n           \n        \n        \n    Multidimensional Systems and Signal Processing\n                          ISSN:0923-6082 , Quarterly\n    <!--      http://www.springer.com/engineering/circuits+%26+systems/journal/11045 -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;1.365&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        423\n                                  \n           \n        \n        \n    Pattern Analysis and Applications\n                          ISSN:1433-7541 , Quarterly\n    <!--      http://www.springer.com/computer+science/image+processing/journal/10044 -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;1.352&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        425\n                                  \n           \n        \n        \n    IETE Technical Review\n                          ISSN:0256-4602 , Bimonthly\n    <!--      http://www.tandfonline.com/loi/titr20#.VDUDmNaqrSY -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;1.330&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        426\n                                  \n           \n        \n        \n    BIOMETRICS\n                          ISSN:0006-341X , Quarterly\n    <!--      http://onlinelibrary.wiley.com/journal/10.1111/(ISSN)1541-0420 -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;1.329&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        433\n                                  \n           \n        \n        \n    IET Signal Processing\n                          ISSN:1751-9675 , Bimonthly\n    <!--      http://digital-library.theiet.org/content/journals/iet-spr -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;1.298&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        463\n                                  \n           \n        \n        \n    Journal of Visual Languages and Computing\n                          ISSN:1045-926X , Bimonthly\n    <!--      https://www.journals.elsevier.com/journal-of-visual-languages-and-computing -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;1.171&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        471\n                                  \n           \n        \n        \n    International Journal of Imaging Systems and Technology\n                          ISSN:0899-9457 , Quarterly\n    <!--      http://onlinelibrary.wiley.com/journal/10.1002/(ISSN)1098-1098 -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;1.139&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        472\n                                  \n           \n        \n        \n    Image Analysis and Stereology\n                          ISSN:1580-3139 , Tri-annual\n    <!--      http://www.ias-iss.org/ -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;1.135&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        479\n                                  \n           \n        \n        \n    Journal of Applied Remote Sensing\n                          ISSN:1931-3195 , Monthly\n    <!--      https://www.spiedigitallibrary.org/journals/journal-of-applied-remote-sensing?SSO=1 -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;1.107&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        481\n                                  \n           \n        \n        \n    Signal, Image and Video Processing\n                          ISSN:1863-1703 , Quarterly\n    <!--      http://www.springer.com/engineering/signals/journal/11760 -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;1.102&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        499\n                                  \n           \n        \n        \n    IET Image Processing\n                          ISSN:1751-9659 , Monthly\n    <!--      http://digital-library.theiet.org/content/journals/iet-ipr -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;1.044&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        520\n                                  \n           \n        \n        \n    International Journal of Pattern Recognition and Artificial Intelligence\n                          ISSN:0218-0014 , Bimonthly\n    <!--      http://www.worldscinet.com/ijprai/ijprai.shtml -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;0.994&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        534\n                                  \n           \n        \n        \n    International Journal on Document Analysis and Recognition\n                          ISSN:1433-2833 , Quarterly\n    <!--      http://www.springer.com/computer+science/image+processing/journal/10032 -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;0.902&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        537\n                                  \n           \n        \n        \n    Journal of Signal Processing Systems\n                          ISSN:1939-8018 , Monthly\n    <!--      http://www.springer.com/engineering/signals/journal/11265 -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;0.893&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        539\n                                  \n           \n        \n        \n    IET Computer Vision\n                          ISSN:1751-9632 , Bimonthly\n    <!--      http://digital-library.theiet.org/content/journals/iet-cvi -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;0.878&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        545\n                                  \n           \n        \n        \n    Photogrammetrie, Fernerkundung, Geoinformation\n                          ISSN:1432-8364 , Bimonthly\n    <!--      http://www.schweizerbart.de/journals/pfg -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;0.852&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        574\n                                  \n           \n        \n        \n    Journal of Electronic Imaging\n                          ISSN:1017-9909 , Quarterly\n    <!--      http://spie.org/x868.xml -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;0.754&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        596\n                                  \n           \n        \n        \n    Journal of Cellular Automata\n                          ISSN:1557-5969 , Quarterly\n    <!--      http://www.oldcitypublishing.com/journals/jca-home/ -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;0.696&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n    \n      \n           \n        646\n                                  \n           \n        \n        \n    International Journal of Wavelets, Multiresolution and Information Processing\n                          ISSN:0219-6913 , Bimonthly\n    <!--      http://www.worldscinet.com/ijwmip/ijwmip.shtml -->\n\n&lt;/td&gt;\n&lt;!-- &lt;td  width=60px class=mya1 style=&quot;text-align:right;&quot; valign=middle&gt;&lt;center&gt;&lt;b style=&quot;font-size:22px;&quot;&gt;0.463&lt;/b&gt;&lt;/center&gt;&lt;/td&gt; --&gt;\n\n  &lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n\n\n\n\n","categories":["图像处理"],"tags":[]},{"title":"震惊！为何程序员总是会情不自禁的打开这些网站","url":"http://tanqingbo.cn/2017/09/10/程序员竟然总是会情不自禁的打开这些网站/","content":"前言\n程序员每天必不可少的就是与电脑打交道，经常逛的一些网站也相对固定，收藏一些干货较多的网站有时能让自己的效率事半功倍，今天给大家分享一下自己平时经常逛的一些网站，不管是开发，还是了解行业资讯，这些网站必不可少。它们分别是：博客社区类、互联网资讯类、问答社区类、代码托管类、学习平台类、老司机开车类。博客社区类\n博客社区类是平时查看技术帖子的地方，给大家推荐几个程序员经常逛的博客社区。CSDN\n专注为IT专业人士及IT企业提供“集成化信息传播与服务平台”，CSDN拥有全球最大的中文IT技术社区，形成了网站, 杂志、图书、电子商务、企业服务、教育培训等关联专业业务互动的商业模式。\n### [博客园](https://www.cnblogs.com/) ###\n博客园有互动交流的小组，有你问我答的博问，有收藏精彩内容的网摘，有搜索站内内容的找找看，有随时记录思想火花的闪存，有随时了解业内动态的新闻频道，有知识库，有期刊，有……\n### [简书](http://www.jianshu.com/) ###\n简书是一个创作社区，任何人均可以在其上进行创作。用户在简书上面可以方便的创作自己的作品，互相交流。简书成为国内优质原创内容输出平台。互联网资讯类\n互联网资讯类可以帮助你提前了解一些前沿的科技信息。36氦\n36氦是中国规模较大、产业链覆盖完善、理念前卫、综合实力强的科技创新创业生态服务平台。开源中国\n开源中国由开源软件库、代码分享、资讯、协作翻译、码云、众包、招聘等几大模块内容组成，为IT开发者提供了一个发现、使用、并交流开源技术的平台。问答社区类\n问答类是遇到问题用来提问的社区，推荐几个含金量比较高的。知乎\n知乎是一个真实的网络问答社区，社区氛围友好与理性，连接各行各业的精英。用户分享着彼此的专业知识、经验和见解，为中文互联网源源不断地提供高质量的信息。\n\nstackoverflow(国外)\nStack Overflow是一个与程序相关的IT技术问答网站。用户可以在网站免费提交问题，浏览问题，索引相关内容。代码托管类\n代码托管和分享的工具。GitHub\ngitHub是一个面向开源及私有软件项目的托管平台，因为只支持git 作为唯一的版本库格式进行托管，故名gitHub。学习平台类\n大量免费视频教程向你来袭，学习使我快乐！慕课网中国大学极客学院网易云课堂老司机开车类\n不要问我链接和使用方法，我这么纯洁怎么会知道呢？1. 海盗湾2. 汤不热（Tumblr）\n\n","categories":["技术博客"],"tags":[]},{"title":"VTK图像处理 | 体绘制","url":"http://tanqingbo.cn/2017/08/27/体绘制/","content":"前言\n体绘制，有时又称作三维重建，它能够通过设置不透明度值来显示提数据内部不同成分的细节。\n\n本篇讲述了一个标准的VTK体绘制渲染流程。其中最重要的两个内容分别是：vtkVolumeMapper 和 vtkVolume。\n\nvtkVolumeMapper机器子类实现了各种体绘制算法：\n\n光线投影法，如：vtkVolumeRayCastMapper、vtkFixedPointVolumeRayCastMapper、vtkGPUVolumeRayCastMapper；\n基于纹理绘制算法，如：vtkVolumeRayTestureMapper2D、vtkVolumeRayTestureMapper3D;\n\n\nvtkVolume负责组合体绘制管线，处理包含一个Mapper对象外，还需要vtkVolumeProperty对象来体绘制的颜色映射，如不透明度函数、颜色传输函数、梯度不透明函数以及设置阴影效果等。\n\n\n\n\nvtkVolumeMapper\nvtkVolumeMapper是所有体绘制Mapper类的虚基类，提供接口函数，并由其子类实现具体功能。\nvtkVolumeRayCastMapper\n光线投影法是一种基于图像序列的直接体绘制方法，其基本原理是从投影图像平面的每个像素沿着视线方向发射一条穿过体数据的射线，然后在射线上按照一定的步长进行等距采样，对每个采样点采用插值技术计算其体素值，根据颜色传输函数和不透明度传输函数来获取相应的颜色值和不透明度，最后利用光线吸收模型将颜色值进行累加，直至光线穿过体数据，即可得到当前平面像素的渲染颜色，生成最终显示图像。\n\n优点：能够精确的模拟原始数据；\n缺点：计算量大，对计算机硬件要求较高。\n\n\nvtkVolumeRayCastMapper类中有两个中最要的函数：\n\nSetInput(vtkImageData*)：用于设置输入图像数据；\nSetVolumeRayCastFunction(vtkVolumeRayCastFunction*)：设置光线投射函数。\n\n\n光线投射函数vtkVolumeRayCastFunction是一个虚基类，它由3个子类：\n\nvtkVolumeRayCastCompositeFunction：通过Alpha合成技术生成每个像素的颜色值。对每个采样点采用插值技术计算其体素值，根据颜色传输函数和不透明度传输函数来获取相应的颜色值和不透明度，最后对所有采样点用Alpha合成方法计算最终的颜色。\n另外，该方式还可以设置插值优先和分类优先：\n插值优先设置函数：SetCompositeMethodToInterpolateFirst()；\n分类优先设置函数：SetCompositeMethodToClassfyFirst()；\n从显示效果上看，插值优先具有较好的显示效果。\n\n\n\n\nvtkVolumeRayCastMIPFunction：最大密度投影函数，主要用于对体数据中搞灰度值的结构进行可视化。当光线穿过体数据时，在光线上进行等距采样。取采样点中属性最大值为该条光线的输出。\n\nvtkVolumeRayCastIsosurfaceFunction：等值面绘制函数能够渲染数据中的特定等值面，其中：SetValue(double)函数用于设置等值面的值，在进行体绘制时，所有小于该值的像素不透明度都设置为。\n\n从效果上看，光线投射法体绘制效果最好，最大密度投射法缺乏深度信息，二等值面投射法体绘制可以对体数据的某个等值面进行显示和观察，于面绘制效果类似。\n\n光线投射中，投射光线上的采样步长是一个很重的参数，设置函数：SetSampleDistance(float)，步长越小，采样点越多，效果越好。但计算量变大。当数据变化剧烈时，应该减少采样步长以获得更好的效果。\n\n另外，还可以设置图像采样间距，即投射光线的间隔，设置函数：SetImageSampleDistance(float)，使用该函数时，必须先关闭自动调节采样距离功能，SetAutoAdjustSampleDistances(int),设置为0关闭功能。\n\n\n\n\nvtkFixedPointVolumeRayCastMapper\n该类能够实现基于Aplha合成的体绘制方法和最大密度投影体绘制方法，能够支持任意类型的一元或者独立多元数据。该类使用了空间跳跃技术来加速体绘制渲染过程，而且在内部计算时统一使用了float数据类。\nvtkFixedPointVolumeRayCastMapper与vtkVolumeRayCastMapper用法基本相同。\n\nvtkGPUVolumeRayCastMapper\n实现了基于GPU加速的光线投射体绘制算法，与vtkVolumeRayCastMapper用法基本相同。\n\n纹理映射体绘制\n主要原理是将3维体数据作为纹理载入图像硬件缓存中，利用硬件来实现插值以及图像合成操作，以提高绘制效率。\n\n主要利用硬件的三线性过滤插值能力，通过渲染多个与视线垂直的面片来重建整个三维结构。\n\n二维纹理映射：\n\n在光线投射时，选择与当前视线方向垂直的一组纹理图像，在硬件中进行插值和合成运算以实现体绘制。类vtkVolumeTextureMapper2D可用于实现基于二维纹理映射的体绘制方法。\n\n\n三维纹理映射：\n\nvtkVolumeTextureMapper3D类实现3维纹理映射，当数据传递给vtkVolumeTextureMapper3D后，在内部会进行重采样，以确保图像大小能满足当前纹理空间。\n\n\n\n裁剪\nvtkVolumeMapper提供了两种裁剪技术，分别是Cropping和Clipping。\n\nCropping技术只支持vtkImageData数据的裁剪，该方法在每个坐标轴上定义了两个裁剪面，共6个平面(xmin,xmax,ymin,ymax,zmin,zmax)将3维空间分成27个区域。\n\nvtkVolumeMapper中定义了Cropping方法的接口函数：\n\n**SetCropping(1)**：打开Cropping方法；\n**SetCroppingRegionPlanes()**：设置三个坐标轴6个裁剪面的位置；\n**SetCroppingRegionFlags()**：设置显示区域标记。\n还提供了几个常用的显示区域设置函数，见《VTK图形图像开发进阶》7.2.5节。\n\n\nClipping技术可以由任意方向将图像切开，便于观察内部细节，只需要定义一个vtkPlane类型的裁剪平面对象，然后通过vtkVolumeMapper类的AddClippingPlane()函数将该平面添加至Mapper对象即可。\n\n\n法向编码\n在vtkImageData的部分体绘制Mapper对象中，可以使用法向编码减少存储量。\n\nvtkVolume\nvtkVolume类似于集合渲染中的vtkActor,用于表示渲染场景中的对象。内部存储了两个重要的对象，分别是vtkAbstractVolumeMapper对象和vtkVolumeProperty对象。相应函数如下：SetMapper(vtkAbstractVolumeMapper*)和SetProperty(vtkVolumeProperty*)。\n\n不透明传输函数\n不透明传输函数是一个分段线性标量映射函数，利用该函数可将光线投射过程中的采样点灰度值映射为不同的不透明度值，以决定最终的颜色值。\n          SetScalarOpacity(vtkPiecewiseFunction*);\n\nvtkPiecewiseFunction类定义线性分段函数：\n\nAddPoint(double x,double y)：第一个参数x为自变量，这里是指灰度值，y则指映射值，这里指不透明度；\nRemovePoint(double x)：将自变量值为x的断点删除。\nRemoveAllPoint(double x)：删除所有断点。\n\n\n利用不透明函数可以有选择的对图像中的对象进行显示，对于部显示的对象只需将其对应的灰度范围的不透明度映射为0即可。\n\n\n梯度不透明函数\n该函数将梯度模值映射为一个不透明度乘子，从而增强过度区域显示效果，同样是使用vtkPiecewiseFunction类实现。\n      SetGradientOpacity(vtkPiecewiseFunction*);\n\n函数设置类似于不透明传输函数的设置，不过意义不同，详情参见见《VTK图形图像开发进阶》7.3.2节\n\n\n颜色传输函数\n颜色传输函数与不透明传输函数类似，不同之处是颜色传输函数是将一个标量值映射为一个颜色值，VTK中用vtkColorTransferFunction类实现，其函数为：\n      AddRGBPoint(double x,double r,double g,double b);\n      AddHSVPoint(double x,double h,double s,double v);\n\n其中x代表灰度值，r,g,b和h,s,v代表颜色分量。vtkVolumeProperty中设置颜色传输函数的函数原型如下：\n      SetColor(vtkColorTransferFunction*);\n\n\n光照与阴影\n通过vtkVolumeProperty可以设置体绘制的阴影效果，阴影效果主要受环境光系数、散射光系数、反射光系数和高光强度4个参数影响。\n      SetDiffuse()  //设置散射光系数\n      SetAmbient()  //设置环境光系数\n      SetSpecular() //设置反射光系数\n\n一般情况下，着三个系数之和为1.\n\n高光强度系数用于控制体绘制外观平滑程度，使用SetSpecularPower()函数设置。\n\nvtkVolumeProperty中默认是关闭阴影效果，因此需要显示调用ShadeOn()函数来打开阴影效果。\n\n\nvtkLODProp3D\n对一个大数据来讲，体绘制是一个计算量非常庞大、非常耗时的操作，为了提高绘制速度，引入vtkLODProp3D来解决这个问题。\nvtkLODProp3D在渲染过程中，会为每个Mapper估计一个渲染时间，并选择一个最优的实现渲染。用法与vtkVolume类似。\n\n不规则网格数据体绘制\n不规则网格的体绘制渲染流程与规则网格绘制的流程一致，不同的是需要选择应用于不规则网格数据的Mapper对象。所有支持不规则网格体绘制的Mapper类都继承自vtkUnstructuredGridVolumeMapper：\n\nvtkUnstructureGridVolumeRayCastMapper实现了基于软件实现的不规则网格光线投射算法，该Mapper仅支持4面体数据，非4面体数据需要借助Filter转换一下。该方法需要较大的内存，不适合大数据渲染处理。\nvtkUnstructureGridVolumeRayZSweepMapper实现了一种在任何平台下运行的体绘制方法，是不规则网格数据体绘制方法中最慢的一种，内存需求较小，可以用来渲染大数据。\nvtkProjectTetrahedraMapper实现了经典的投影四面体法。\nvtkHAVSVolumeMapper实现了HAVS算法，能够快速渲染大数据，但由于该类中使用了较多显卡的高级技术，因此只有在支持这些技术的显卡中才能运行该方法。\n\n\n对比4种类的渲染效果，其中ZSweep方法渲染速度最慢，而投影四面体方法较其他两种方法快，但ZSweep方法渲染结果最精确。\n\n\n","categories":["图像处理"],"tags":[]},{"title":"VTK图像处理（二）--vtkPolyData数据处理","url":"http://tanqingbo.cn/2017/08/24/vtkPolyData数据处理/","content":"前言\nvtkPolyData数据是一种广泛使用的vtk数据结构，可以用来表示很多常用的数据结构，如点云数据、面片模型等。本文章先分析vtkPolyData数据的基本组成，创建方法和显示管线，结果介绍了一些基本操作，如距离、面积、包围盒、法向量以及符号化等。这些都是高级图像图像处理，此外还着中分析了图形平滑、封闭性检测、连通性分析、多分辨率处理、表面重建、点云配准、纹理映射等内容。掌握这些内容便可以解决许多实际性的工程问题。\n\n详细内容参见《VTK 图形图像开发进阶》第六章。\nvtkPolyData数据生成与显示\nvtkPolyData数据由几何结构数据、拓扑结构数据和属性数据组成。几何结构数据主要是组成模型的点集，拓扑结构数据是点按一定关系组成的单元数据，属性数据与几何结构数据和拓扑结构数据想关联，可以标量、向量、张量，可以用来间接表示图像的颜色。\n\nGetNumberOfPoints()和GetNumberOfCells()可以分别获取图形的点数和单元数目；\nvtkPolyData数据显示时需要定义vtkPolyDataMapper对象，用来接受vtkPolyData数据以实现图形数据到渲染图元的转换。VTK常见的vtkPolyData数据源类vtkPolyData数据的创建\n\n\n需要先定义一个点集和一个单元集合，单元的类型可以是点、三角形、矩形、多边形等基本图形。只有定义了单元数据才能显示该图形数据。\n\n具体创建代码见6.1.2节。\nvtkPolyData属性数据\n图形的颜色与vtkPolyData属性数据息息相关，可为点数据和单元数据分别指定属性数据。\n\n点和单元属性数据分别存储咋vtkPointData和vtkCellData中，可以通过调用GetCellData()函数获取一个vtkCellData类型单元数据指针，在通过SetScalars()函数设置颜色数据。\n\n由于可以同时设置点和单元设置属性，那么怎么用点和单元来控制颜色呢？这就需要使用vtkPolyDataMapper类的方法。\n\n**SetScalarModeToDefault()**，默认设置，该设置下首先使用点的标量数据控制颜色，若点标量数据不可用时，则使用单元数据。\nSetScalarModeToUsePointData(),使用点的标量数据控制颜色，若点标量数据不可用也不会使用其他数据。\nSetScalarModeToUseCellData(),使用单元的标量数据控制颜色，若单元标量数据不可用也不会使用其他数据。\n**SetScalarModeToUsePointFieldData()/SetScalarModeToUseCellFieldData()**，点数据和标量数据都不会用来着色，而是使用属性数据中场数据数组。可以通过名字来指定进行颜色渲染的数据。\n\n\n在某些情况下，需要对点属性数据和单元属性数据进行转换，这需要用到两个类vtkCellDataToPointData和vtkPointDataToCellData。转换原理是：当由带属性向单元属性转换时，每个单元属性数据为组成该单元的点对应的属性的平均值；当单元属性数据向点属性数据转换时，点属性为使用该点的单元的属性平均值。\n\n\n基本图形操作\nVTK提供了多种基本图形操作：\n\nvtkLine提供了点与线、线与线间的距离计算；\nvtkTriangle提供了面积、外接圆、法向量的计算，点与三角形位置关系的判断；\nvtkPolygen提供了法向量、重心、面积的计算、点与多边形位置的判断、点与多边形、多边形与多边形相交判断；\nvtkTetra实现了四面体体积计算、重心计算；\nvtkMassProperties实现三角网格的表面积和体积计算，但要求网格必须时封闭的三角网格；\nvtkTriangleFilter可以实现多边形网格向三角网格转换。\n\n\n测地距离：三维模型上两个点的测地距离是指沿着模型表面两者之间的最短距离，通常采用Dijkstra算法近似求解，VTK中的vtkDijkstraGraphGeodesicPath类可实现测地距离求解。通过**GetGeodesicLenght()**函数可以获取当前计算的两点测地距离的数值。\n\n包围盒是指能够包围模型的最小立方体，常用于模型的碰撞检测中。vtkOutlineFilter提供一个方便的方法来生成包围盒。\n\n\n法向量计算\n三维平面的法向量是指垂直该平面的向量。某点的法向量为垂直该点切平面的法向量。\n在计算网格法向量时，单元法向量可以通过组成每个单元的任意两条边的叉乘向量归并化来表示；二点的法向量则是由使用该点的单元单元法向量的平均值表示。\nVTK中计算法向量的类为vtkPolyDataNormals,可以通过SetComputeCellNormals()和SetComputePointNormals()来设置需要计算的法向量类型，默认计算点法向量。\n计算单元法向量时，要保持单元法向量一致才能得到合理的法向量。SetConsistency()可以自动调整单元点的顺序；SetAutoOrientNormals()可以自动调整法向量方向。\n类vtkPolyDataNormals自动开启对锐边缘处理，如果检测到锐边缘，会将其分裂，使图形更加平滑，可通过SetSplitting()函数关闭该功能。符号化Glyphing\n通过符号化（Glyphing）技术将法向量图形化显示。VTK中使用vtkGlyph3D类实现该功能，并支持图形缩放、着色、设置空间姿态等，需要接受两个输入：几何数据点集合、Glyph图形数据（vtkPolyData数据）。几何数据点集合来自求完法向量的图像，Glyph图形数据用于在点集合处显示法向量。曲率计算\n曲率时曲面弯曲程度的一种度量，是几何体的一种重要局部特征。计算曲面M点曲率，考虑经过M的法线的一个平面与曲面相交，可得到一条二维曲线，经过M的法线的平面可以有很多，与曲面相交时可得到多条曲线，取曲率最大和最小的曲线，若其对应曲率为k1和k2，称为主曲率，而该点的高斯曲率为k1*k2,平均曲率为：(k1+k2)/2。\nVTK中vtkCurvatures类实现了4种网格模型曲率计算方法：\n**SetCurvatureTypeToMaximum()**：计算最大主曲率；\n**SetCurvatureTypeToMinimum()**：计算最小主曲率；\n**SetCurvatureTypeToGaussian()**：计算高斯曲率；\n**SetCurvatureTypeToMean()**：计算平均曲率。\n\n\n\n网格平滑\n拉普拉斯平滑是一种网格平滑算法，将每个点用其邻域点的中心来代替，通过不断迭代，得到较为光滑的网格。\nvtkSmoothPolyDataFilter类，实现了拉普拉斯平滑算法，用SetNumberOfIterations()控制平滑次数，次数越大，平滑越厉害。\nBoundarySmoothing控制是否对边界点平滑；\nFeatureEdgeSmoothing控制是否对特征边上的点平滑，通过调用SetFeatureAngle()函数设置特征角阈值。\n\n\nvtkSmoothPolyDataFilter类通过拉普拉斯不断迭代，模型会不断向网格中心收缩。\nvtkWindowedSincPolyDataFilter类，使用窗口函数Sinc实现网格平滑，能够最下程度避免收缩，使用方法与vtkSmoothPolyDataFilter类相同。\n\n封闭性检测与填补漏洞\n如果一条边只被一个多边形包含，那这条边就是边界边，是否存在边界边是检测网格模型是否封闭的重要特征。\n\nvtkFeatureEdges类能够提取多边形网格模型中4种类型的边：\n\n边界边；\n非流形边；\n特征边；\n流形边；\n\n\n可以通过判断边界边的数目来网格是否封闭。\n\n检测出网格是否封闭之后可以通过类vtkFillHoleFilter将漏洞填补起来。\n\n\n连通区域分析\nvtkAppendPolyData类可以实现vtkPolyData的合并，使用该类可以方便地构造含有多个连通区域的数据。\nvtkPolyDataConnectivityFilter类用于实现连通区域分析：\n**SetExtractionModeToLargestRegion()**：用于提取具有最多点的连通区域；\nSetExtractionModeToAllRegion():用于连通区域标记，配合函数ColorRegionsOn()一起使用；\nSetExtractionModeToSpecifiedRegion():用于提取一个或多个连通区域，需要通过AddSpecifiedRegion()来添加需要提取的边界号；\n\n\n\n多分辨率处理网格抽取\n抽取的作用是减少模型数据中的点数据和单元数据，便于后续处理和交互渲染。\nVTK中有3种网格抽取类：\nvtkDecimatePro：用一种塌陷的方法删除点和单元，处理速度快、可以方便的控制网格抽取幅度，得到不同级别的模型数据；\nvtkQuadricDecimation:最终简化率并非严格等于程序中设置的简化率；\nvtkQuadricClustering:3种模型中抽取速度最快的一种，能够处理大数据模型；\n\n\n\n网格细化\n网格细化是利用一定的细化规则，在给定的初始网格中插入新的点，从而不断细化处新的网格单元，在极限细化情况下，该网格能够收敛于一个光滑的平面。\n\nVTK中有3种网格细化类,如下，它们都继承自类vtkInterpolatingSubdivisionFilter,它内部提供了SetnumberOfSubdivisions()函数来设置细化次数，其中每次细化后模型的三角面片的个数将是细化前的4倍。\n\nvtkLinearSubdivisionFilter：实现了一种线性细分算法；\nvtkLoopSubdivisionFilter：实现了Loop细分算法，能够生成光滑连续曲面；\nvtkButterSubdivisionFilter：实现了蝶形细分算法；\n\n\nvtkLoopSubdivisionFilter与vtkButterSubdivisionFilter结果优于vtkLinearSubdivisionFilter。\n\n\n表面重建\n利用表面重建技术将点云数据重建为面模型。三角剖分\n三角剖分将一些散乱的点云数据剖分为一系列三角网格，最常用的三角剖分技术是Delaunay三角剖分，主要用于二维三角剖分，三维数据通常使用点云重建。\nvtkDelaunay2D类实现了2维三角剖分。\nvtkDelaunay3D类实现了3维三角剖分。得到的结果并非三角网格，而是四面体网格，因此，其输出数据类型为vtkUnstructuredGrid.\n\n等值面提取\n类似与面绘制，通过等值面提取提取技术，仅提取感兴趣的一个或者几个组织轮廓，并生成网格模型以供后续处理和显示。\n\n等值面提取算法多基于Marching Cubes算法实现：\n\nvtkImageMarchingCubes主要处理三维图像数据；\nvtkMarchingCubes主要针对规则体数据生成等值面；\nvtkMarchingSquares针对二维规则网格数据生成等值线。\n\n\n通常需要搭配图形平滑、抽取等操作来对等值面数据进行后处理。\n\n\n点云重建\nvtkSurfaceReconstructionFilter实现了一种隐式曲面重建方法，该方法需要对点云数据进行网格划分，然后估算每个点的切平面方向，并以每个点与最近的切平面距离来近似表面距离。用vtkContourFilter来提取面距离来近似表面距离。\n\n点云配准\n点云配准即是对一组原点云数据应用一个空间变换，使得变换后的数据与目标点云数据能够一一映射，使两组数据之间的平均距离误差最小。\n\nvtkLandmarkTransform类实现了标记点配准算法，使得两个点集在配准后平均距离误差最小。通过SetSourceLandmarks()和SetTargetLandmarks()函数分别设置源标记点集和目标标记点集。\n\nSetModeToRigidBody()：函数用于设置其配准变换的类型为刚体变换；\nSetModeToAffine()：设置其配准变换的类型为放射变换；\nSetModeToSimilarity()：设置相似变换，即平移、旋转和放缩变换。\n\n\nvtkVertexGlyphFilter类显示点集；\n\nvtkTransformPolyDataFilter用来对面源标记点进行变换来显示配准后的点集。\n\n点云数据配准最经典的方法是迭代最近点算法（ICP）：每次迭代中对于源数据点P找到目标点集Q中的最近点，然后基于最小二乘原理求解当前的变换T。通过不断迭代直至收敛，即完成了点集的配准。\n\nvtkIterativeClosesPointTransform类中内部定义了一个vtkLandmarkTransform指针，用于就算ICP迭代中最佳匹配点集，可以通过GetLandmarkTransform()函数获取，并通过vtkLandmarkTransform指针设置相应的变换类型。SetMaximumNumberOfIterations()函数用于设置ICP算法迭代次数，StartByMatchingCentroidsOn()函数则用于设置配准之前先计算两个点集重心，并平移源点集使得两者重心重合。配置完毕可以通过GetMatrix()函数来获取相应的变换矩阵。\n\n\n\n纹理映射\n纹理映射是将纹理空间中的纹理像素映射到屏幕空间中的过程。主要是建立纹理空间与模型空间、模型空间与屏幕空间之间的映射关系。\nVTK中定义了许多个类实现纹理空间到模型空间的映射：\nvtkTextureMapToPlane：通过一个平面建立纹理空间到模型空间的映射关系；\nvtkTextureMapToCylinder：通过圆柱面建立映射关系；\nvtkTextureMapToSphere：通过球面建立映射关系；\nvtkTexture：实现加载纹理；\nvtkTransformTextureCoords：实现纹理坐标的平移和缩放；\n\n\n\n","categories":["图像处理"],"tags":[]},{"title":"VTK数据读写","url":"http://tanqingbo.cn/2017/08/21/VTK数据读写/","content":"VTK数据读写前言\n具体内容参见《VTK图形图像开发进阶》第4章.\n\nReader与Writer\n主要介绍vtkImageData,vtkPloyData,vtkRectilinearGrid等数据类型的Reader/Writer类。\nvtkImageData类型\nvtkImageData类型的数据是按照规则排列在矩形方格中的点和单元集合。\n\nvtkImageData类型的Reader/Writer类如下：\n\n读取RAW格式数据时，该类型图像没有文件信息，因此读取此类图像时，需要指定图像的各个维度大小、字节顺序、存储像素值等信息。\n\n.mha与.mhd：这两个格式差不多，只不过MHA格式图像把图像信息头与实际的像素值等信息写入了同一个文件，而MHD的图像信息头与实际像素值分别存在两个文件（即*.mhd和*.raw/*.zraw,zraw表示有压缩）\n\n*.mhd图像格式信息：\n      ObjectType = Image\n      NDims = 3                            //表示该图像的维数；\n      BinaryData = True\n      BinaryDataByteOrderMSB = False\n      CompressedData = True\n      CompressedDataSize = 1961160\n      TransformMatrix = 1 0 0 0 1 0 0 0 1\n      Offset = 0 0 0\n      CenterOfRotation = 0 0 0\n      AnatomicalOrientation = RAI\n      ElementSpacing = 1 1 1               //像素间的间隔\n      DimSize = 256 256 41                 //图像各维的大小；\n      ElementType = MET_UCHAR              //存储图像像素值所用的类型\n      ElementDataFile = img-41.zraw        //存储像素数据的文件位置\n\n读取单个图像：如果无法确定所读取的图像时什么格式，可以用类vtkImageReader2Factory来读取导入的文件。\n\n有图像显示的例子。\n\n\n读取序列图像文件：Reader类有提供SetFileNames()来设置斗个图像文件名，利用该方法可以实现序列图像的读取。\n\n\nvtkPolyData类型\n详见第6章。\n\n","categories":["图像处理"],"tags":[]},{"title":"VTK图像处理（一）","url":"http://tanqingbo.cn/2017/08/18/VTK图像处理1/","content":"前言\n该篇只简单整理VTK图像处理的函数以及对应的功能，详细内容以及具体源码参见《VTK图形图像开发进阶》第五章。\n1.图像创建\n图像源Source\n\nVTK内置了很多创建图像的Source类，可以创建点、线段、圆、矩形等图像。\nvtkImageCanvasSousce2D:创建画布（空白图像）；\nvtkImageEllipsoidSousce:创建前景为椭圆的二值图像；\nvtkImageGaussianSousce:高斯分布图像；\nvtkImageGridSousce:网格图像；\nvtkImageSinusoidSousce:像素值有正弦函数决定的图像；\n\n\n直接创建图像\n\n手动生成vtkImageData图像数据，再给像素赋值。2.图像显示\n\n\nvtkImageViewer2\n\n该类提供主要的交互操作有图像缩放、窗框窗位的调节、切片选择、切片方向设置。\n可以根据设置不同的切片方向显示不同方向的切面。\n\n\n3维医学图像二视图\n\n在医学图像中，不同方向的切面都有特定的名字；\n矢状面（Sagital Plane）：沿着身体前后径所做的与地面垂直的切面；\n冠状面（Coronal Plane）：沿着身体左右径所做的与地面垂直的切面；\n横断面（Transverse/Axial Plane）：与地面平行的切面。\n\n\nvtkImageActor\n\n是一个3维图像渲染Actor，通过纹理映射将图像映射到一个多边形上进行显示。功能类似于vtkImageViewer2。\n\n\n图像融合\n\n类vtkImageBlend实现图像融合，它可以接收多个图像输入，并输出其融合图像，即把几张图像融合叠在一起显示。\n\n\n\n3.VTK图像基本操作\n图像信息访问与修改\n\n利用vtkImageData的方法：它提供了多个用于信息访问的函数，例如：\n\nGetDimensions()，获取图像维数；\nGetOrigin(),获取图像原点；\nGetSpacing()，获取图像像素间隔；\n还有多个Set函数用于设置图像信息。\n\n\n利用类vtkChangeImageInformation:利用这个类可以修改图像原点，像素间隔以及范围，还可以实现图像平移及缩放等操作。\n\n\n\n\n\n图像像素的访问与修改\n\nvtkImageData中提供了GetScalarPointer()函数数据数组指针，该函数有三种形式：\n\nvirtual void *GetScalarPointer(int coordinates[3]):返回第（x,y,z）个像素的地址；\nvirtual void *GetScalarPointer(int x,int y,int z):返回第（x,y,z）个像素的地址；\nvirtual void *GetScalarPointer():返回图像数据的头指针；\nGetScalarPointer()返回的是void*类型，需要根据图像的具体数据类型强制转换，然后在根据返回的地址修改像素值。\n\n\n用vtkImageIterator类实现迭代器方法访问图像像素，使用时需要提供迭代的图像像素类型以及迭代的区域大小。\n\n\n\n图像类型转换\n\n类vtkImageCast:只需要把该类的函数SetOutputScalarTypeToXXX()设置相应输出类型即可。\n类vtkImageShiftScale:可以指定偏移和比例参数来对输入图像数据进行类型转换操作。\n\n\n图影颜色映射\n\n灰度图像映射 \n类vtkImageLuminance：负责将RGB彩色图像转化为单分组的灰度图像，\n\n\n提取颜色分组\n类vtkImageExtractComponents:提取彩色图像的各个颜色组分，使用该类时只需要设置要提取的组分序号即可。\n\n\n图像彩色映射\n类vtkImageMapToColors:实现图像彩色映射，以vtkLookUpTable类生成颜色查找表。原理时先生成颜色查找表，然后根据图像像素的一个标量值在颜色查找表中查找对应的颜色。\n\n\n颜色合成\n前面提到彩色图像的各个颜色组分，VTK也支持将多个灰度图像合并成一个彩色图像，类vtkImageAppendComponents类可以用来合成彩色图像。其输入需要提供三个灰度图像。合成效果为三个图像中对应的三个像素点的像素值合成一个RGB值，如三个图像中100像素的像素值分别为255，0，0，那么合成图像中该点像素值为（255，0，0），为红色。\n\n\n\n\n区域提取\n\n提取感兴趣的区域\n感兴趣区域（Volume of Interest,VOI）是图像内部的一块子区域，在VTK中vtkExtractVOI类可根据用户指定的区域提取子图像。\n\n\n三维图像切面提取\nVTK中vtkImageReslice类图像切面的提取。\n\n\n\n\n直方图统计\n\n灰度图像直方图\nvtkImageAccumulate类用于实现直方图统计功能，他将每个分组的数值范围离散的间隔，然后统计每个灰度间隔上的像素数目。虽然vtkImageAccumulate输出的类型为vtkImageData，但是不能直接一图像的方式显示。\nvtkBarChartActor类用来显示条形图，可以利用它来显示直方图，但该接受的数据类型为vtkDataObject类型，所以在显示之前需要类型转换。\n\n\n彩色图像直方图\n彩色图像有3个颜色通道，因此需要提取RGB3个通道数据分别计算直方图。每个通道计算直方图的方法与灰度图像直方图的计算方法一致。\n\n\n\n\n图像重采样\n\n图像重采样是指对数字图像按所需的像素位置或像素间距重新采样，以构成几何变换后的新图像。当重采样图像维数小于源图像时，称为降采样，当重采样图像维数大于源图像时，称为升采样。\n类vtkImageShrink3D用于实现图像降采样，图像会更模糊。\n类vtkImageMagnify用于实现图像升采样。\n\n\n图像运算\n\n数学运算：vtkImageMathematics提供了基本的一元二元数学操作。\n逻辑运算：vtkImageLogic接受一个或两个图像进行布尔逻辑运算，该类只要支持与、或、异或、与非、或非、非等操作。\n上述两个操作，两个输入的图像输入图像的类型必须保持一致。\n\n\n图像二值化\n\n图像二值化是一个最简单的图像分割模型，设置一个灰度阈值，将图像中阈值以下的像素设置为背景，阈值以上的设置为前景，即可得到一副二值图像。\nvtkImageThreshold类可实现图像阈值化处理：\nThresholdByUpper()：取大于阈值的灰度范围为有效范围；\nThresholdByLower()：取小于阈值的灰度范围为有效范围；\nThresholdBetween()：取大于UpperThreshold和LowerThreshold之间的部分为有效范围；\n\n\n\n\n\n","categories":["图像处理"],"tags":[]},{"title":"RSS订阅|怎么订阅别人的博客","url":"http://tanqingbo.cn/2017/08/17/RSS订阅什么值得买/","content":"RSS订阅|怎么订阅别人的博客什么是RSS？\nRSS（Really Simple Syndication，简易信息聚合）是一种定制个性化推送信息的服务。它能解决你漫无目的浏览网页的问题。它不会过时，信息越是过剩，它的意义也越加彰显。\n为什么需要RSS？\n网络上充斥着大量的信息垃圾，每天摄入了太多我根本不关心的信息。我希望让我关注的信息主动来找我 ，且这些信息都是我需要的，这就是RSS的意义。\n捣鼓RSS的初衷\n之前浏览人家的博客时，经常能看到一个RSS订阅的按钮，但是点击订阅的按钮之后就跳到了一个源码的页面，一直没搞清楚这个订阅到底有什么用。后来听了一节中科大罗绍峰老师的一节文献查阅课，他在课上一直给我们安利RSS订阅的好处，从那以后我便花时间琢磨了一下怎么利用RSS订阅获取对自己有用的信息。\n\n好玩的东西要一起分享，今天就分享一下如何用RSS订阅“什么值得买”的信息源吧！**订阅之后它会每天综合全网购物平台的商品信息，帮助你控制网购的风险的同时，尽可能的向大家介绍高性价比的网购产品，让大家买着不心疼，花钱等于省钱。简直就是购物神奇啊，先截几张图给大家感受一下吧！**\n\n![](http://i.imgur.com/EHZqvZP.png)\n![](http://i.imgur.com/nvu7e0L.png)\n![](http://i.imgur.com/DBC2qQ1.png)\n\n好了，下面就正式教大家如何进行RSS订阅吧，至于想要订阅技术类或者其他信息的亲们，可以自己按照这个教程操作，下次我会把一些优秀的订阅源分享给大家。\n如何进行RSS订阅\n首先需要一个RSS阅读器，电脑端和移动端都有对应的阅读器，我电脑用的是feedlychrome浏览器插件，手机端用的是press阅读器，要是不翻墙的话，目前国内只能用这两个阅读器。\n\n先从Google play上将feedly插件安装到chrome浏览器当中，如图，”搜索feedly-&gt;添加至CHROME”就可以了。\n\n因为我已经添加完了，所以是评分的按钮，添加完之后在浏览器的右上角会出现feedly插件的，点击打开，然后用账号登陆，**在国内目前好像只支持用Evernote（印象笔记）的账号登陆，**所以用Evernote账号登陆，没有就注册一个，登陆之后会出现如下界面：\n\n左下角有一个**ADD CONTENT**按钮，点击，然后选择Publication&amp;Blogs，在What source do you want to follow?下面的输入框里面输入“什么值得买”的RSS源：http://feed.smzdm.com。然后选择Follow，为这个源构建一个分组“CREATE A COLLECTION”就OK了，接下来你就能看到“什么值得买”的RSS源里面的信息了。\n\n之后只要打开feedly就能看到“什么值得买”每天更新的信息了。最最重要的是，在手机上也能同步看到，在手机上从应用商店下载press阅读器，然后用Evernote（印象笔记）的账号登陆，就能同步电脑上的信息了。\n\n这只是RSS订阅的一小部分应用，它主要的用处还是屏蔽对我没用的信息，让我关注的信息主动来找我，节省自己的阅读成本。所以最主要的还是找到适合自己的订阅，让有用的信息来找你。最后给大家推荐一些比较实用的RSS订阅链接吧：你必读的RSS订阅有哪些？\n\n\n","categories":["技术博客"],"tags":[]},{"title":"Shape-Based Human Detection and Segmentation via Hierarchical Part-TemplateMatching","url":"http://tanqingbo.cn/2017/08/16/基于形状的人体检测和通过分层部分模板进行分段匹配/","content":"Shape-Based Human Detection and Segmentation via Hierarchical Part-TemplateMatching基于形状的人体检测和通过分层部分模板进行分段匹配1.介绍1.1 Previous Work\n形状建模或形状特征提取方案可以大致分为两类。\n\n基于全局和密集的特征提取方法，人被模拟成全局模板。需要大量的训练集。\n基于稀疏局部特征，或者部分视觉集合表示物体形状的方法（基于可变部分模型方法）。处理部分遮挡的物体特别有效。检测器分别针对每个身体部位进行训练，并与二级分类器组合。问题是在非常混乱的图像中，可能产生太多的检测假设，因此需要鲁棒的组合方法来组合这些检测。\n\n\n基于可变部分模型方法法已经成功的运用到很多的视觉处理当中。\n\n基于全局的方法训练数据集单一，分类功能强大，它们比基于可变部分模型的方法简单很多。\n\n在基于可变部分模型方法中，每个部分都需要分开训练，此外还必须训练一个额外的装配分类器。相对于基于全局的方法，它更容易处理部分遮挡的图像，而且也更加灵活。\n\n基于部分模型还可以结合形状外观线索，外观线索结合运动线索，同时检测和分割。\n\n\n\n一些检测方法构建了基于树的数据结构来进行有效的形状匹配，每个窗口基于模板匹配和最邻近搜索来计算得分。\n\n在监控的场景，运动斑点信息为人类检测提供了非常可靠的线索。这些基于斑点的方法在计算上比纯粹的基于形状的方法更高效。但是他俩的共同问题是结果取决于背景减法或者运动分割的情况。\n\n我们的方法提出的动机如下：\n\n分层模板匹配是一种便捷的方法去有效地整合形状的检测和分割，但由于需要收集和匹配大量全局形状模型导致计算量大。\n之前的大多数识别方法主要是在大量的人类中心对齐的二值样本上训练分类器，然而由于图像中人体高度铰接且姿势不一，这就需要大量的对齐了的训练样本，而且还有可能使结果偏向训练样本。也就是说训练之后的分类器泛化能力会受到影响。\n可变形零件模型和多个基于实例的学习方案对本地化对象分割非常有效，但受精度和姿势约束。\n\n\n\n1.2 Overview of Our Approach（方法概述）\n在本文中，我们解决了同时检测和分割多个人类（可能部分被遮挡）的困难。为了实现这一目标，提出了一种结合可视化学习（discriminative learning）的分层部分模型匹配方法来建立一个通用的人类检测器。\n给定输入图像，该检测器返回人类边框作为精准的分割。\n我们的方法优于基于局部和基于全局的方法。人类检测器是通过分解全局模型构建一个更加灵活和有效的部分模板树人体模型，它能更有效的匹配人体姿势。然后估计的姿势通过合成部件自动检测。\n使用分层部分模板匹配方案时，为了更好的区分人和非人类，我们提出一种姿态自适应特征提取方法。它能更好的处理局部形状空间重复的事件。\n我们在人体的正面和反面样本上面分割人体姿势，并在姿势局部邻域进行特征自适应提取。再将所有可能的姿势实例集合映射到规范的姿势上，即任意姿势上的点要与规范姿势一一对应，\n将树的匹配算法用于处理多个封闭的人体，检测假设集由通用的人体检测器产生，然后通过基于形状匹配分数重新评估和精细遮挡分析的迭代过程来改进和优化。\n\n\n我们的主要贡献总结如下：\n介绍部分模板树模型和自动学习算法，并应用于人体检测和姿势分割。将流行的基于局部零件的物体检测器与基于全局形状模板的方案相结合。\n提出快速封层部分模板匹配算法根据局部图像的线索来估计人体的形状和姿势，人的形状和姿势由部分参数模型表示。\n在任意姿势和规范姿势的轮廓点组之间建立一对一的对应关系。\n树匹配算法也被扩展到具有挑战性的监控场景中处理多次闭塞的人类检测和分割，我们通过基于形状匹配分数重新评估和精细遮挡分析的迭代过程以贪婪方式执行优化来估计人体配置。\n\n\n\n\n第2节介绍了我们的分层部分模板匹配方法的细节。\n第3节描述了用于学习泛型的姿态适应特征提取方法人体探测器。\n第4节扩展了到个人类检测和细分的方法。\n第5节简要介绍了框架中运动和几何线索的结合。\n第6节介绍实验和评估。\n\n2 HIERARCHICAL PART-TEMPLATE MATCHING\n引入了一种分层形状匹配方法，以有效地搜索粗糙的人类姿势（形状），并计算每个候选窗口检测的匹配分数，为了实现这一点，我们通过利用基于局部组件和全局形状模板的方法将它们结合在统一的自顶向下和自下而上的搜索方案中， 具体来说，我们通过将全局形状模型分解为零件，并构建一个新的基于部件模板的树，从人物形状的训练数据库中获取部件模型之间的外观联系。2.1 Generating the Part-Template Tree Model（生成部分模板树模型）\n由于真实图像中人体姿态自由度高，直接从真实的图像中构建形状模型需要大量的真实轮廓数据集，这给训练样本对齐带来了很大的困难，所以我们使用简单的姿势生成器通过零件合成生成一组灵活的全局形状模型，然后使用身体部分分解构建零件模板层次结构。平行四边形部分在空间上组合，用于模拟粗糙的人类部分形状。 我们通过在空间上分解全局形状模型来获得部分模板模型，并构建一个部分模板树来捕获人类姿态变化。 之后，我们再通过从一小组真实姿态图像学习来优化合成树模型。2.1.1 Synthesizing Global Shape Models（合成全局形状模型）\n为捕捉人体姿态，用6个区域：头、躯干、两只手和两条腿来表示人体。通过在空间中合成这些区域形成全局形状模型。每个部分区域的形状由水平平行四边形建模，其特征位于其中心位置（2 dofs），大小（2 dofs）和方向参数（1 dof）。 因此，全身的自由度系数是5*6=30.（dofs：自由度）。\n我们生成这些全局模型主要是为了通过空间分解获得自动姿势对齐紧凑的部分模板模型集。给予躯干位置作为参考，其余参数被视为在在线检测/测试阶段估计的隐藏变量。\n全局形状的6个自由度（头、躯干、两只手和两条腿）即6个参数在其范围内的取值为{3; 2; 3; 3; 3; 3}（每个自由度可以对应有几个姿势），也就是说部分实例可以独立组合成32333*3=486种全局模型形状。2.1.2 Generating Parts by Decomposition（通过分解生产零件）\n全局形状模型的数量由每个部分区域（合成之前）的自由度确定，部分模板的数量等于树中的节点数，所以它远小于全局模型。\n![](http://i.imgur.com/tlZB0PJ.png)\n\n先将全局模型分成3各部分（头躯体（ht），大腿（ul）和小腿部（11）），如图所示。2.1.3 Constructing an Initial Tree Model Using Parts(使用零件构建初始树模型)\n给定索引部分的集合，通过将分解的部分区域和边界片段放置在树中来构建部分模板树，如图所示。树边缘（或链接）是根据全局形状模型中部分索引之间的关系自动确定的。\n![](http://i.imgur.com/0C4iEvQ.png)\n\n树中的每个部分模板表示零件的一个实例，也可以被视为参数模型，其中零件位置和尺寸是模型参数。\n树中的部分模板的数量直接由生成的全局形状模型的数量决定。在生成全局形状模型时，通过更精细的离散化和更广泛的参数范围可以获得更大的一部分模板。但是通过参考树中的模板数量，虽然计算需求的线性增加，但匹配成本几乎不变。速度非常快。\n初始树结构和部分模板由上述合成剪影构建，但是通过从实际图像学习来进行细化，这在下面的部分描述。在上图中，任何树路径（从根节点到叶节点）唯一地确定全局形状模型，并且唯一树路径与任何全局形状模型相关联。2.2 Learning the Part-Template Tree（学习部分模板树 ）\n所有全局形状模型的集合通过枚举所有可能的部分参数形成，因此构造的部分模板树不包含来自真实人类剪影的任何先前统计。所以，我们通过将它们与真正的人物剪影相匹配来学习部分模板的出现概率。由于我们将零件模板模型放置在树形配置中，所以先验值被估计为条件概率分布（每个内部树节点处的分支概率）。\n为了通过将树匹配到输入图像来更有效和可靠地估计人的形状和姿势，我们使用真实图像来学习与部分模板树模型的边缘相关联的概率。具体地，通过将​​树匹配到一组人体剪影图像来执行学习。目标是明确地估计分支概率分布，即在每个树层中的树边缘（图2中连接两个连续层之间的节点的箭头）的条件分布，以处理观察到的形状关节的范围。例如，给定层L0处的空节点，我们基于其在训练轮廓集中的发生频率来估计层L1处的六个ht模型的概率分布。\n剪影训练集由404（加镜像）二进制剪影图像（白色前景和黑白背景）组成。那些二进制剪影图像是通过手动分割INRIA个人数据库的正图像块的一个子集获得的。每个训练轮廓图像通过树从根节点到叶节点，用于识别最佳路径（对应于最大匹配分数）。使用贪心搜索算法通过选择每个节点处的局部最优分支来估计最优路径。这可以由更复杂的动态规划算法代替，但是我们发现贪婪搜索工作得很好，速度要快得多。每个节点的匹配分数被计算为当前节点的部分模板与观察到的轮廓之间的覆盖程度（即，与训练剪影一致的假设内的像素的比例）。对于所有训练轮廓重复此过程，并且针对每个轮廓估计最佳路径。然后，基于路径集合，基于发生频率针对每个节点估计分支概率分布（分支边缘的条件分布）。\n给定已知的分支概率，从根到叶的任何树路径可以与三个概率值（分别为三个部分ht，ul和ll）相关联。每个树节点现在携带部分模板的二进制图像，其边界采样点坐标和从树学习步骤获得的分支概率分布。由于路径和全局形状模型之间存在一一对应关系，因此每个全局形状模型现在由软覆盖图表示。我们累积所有路径的软覆盖图，以计算学习树的平均全局形状。图3通过显示学习的平均全局形状与所有训练轮廓的平均值非常相似，验证了我们的树学习方法。\n补充：“我们累积所有路径的软覆盖图，以计算学习树的平均全局形状”，这句话的理解，每条路径都携带自身的概率，树的平均全局形状由所有路径乘以自身概率的和所得。\n\n2.3 Hierarchical Part-Template Matching（分层部分模板匹配）\n给定一个测试图像，我们使用扫描窗口方法来估计每个候选检测窗口的最佳姿势。对于每个窗口，我们将所学习的树与图像观察（边缘或边缘方向）相匹配，以估计路径节点的最佳树路径和相关位置参数。与用于树木学习的模型类似，特定检测的总体匹配得分窗口被简单地建模为沿着该路径的所有节点的匹配分数的总和。但是，与学习不同，测试阶段的匹配是在边缘或梯度取向而不是轮廓上执行的，并且每个节点的得分都被计算为部分模板匹配分数与该节点之前学习的先前可抢占性的乘积培训阶段。我们定性验证，结合分支先验概率给予姿态估计更好的鲁棒性。另一个区别是，在测试阶段，我们允许零件模板位置在本地移动，并且对于每个零件模板估计最佳位置，而不是固定零件模板位置。其中每个部分可以调整到其局部最佳位置。\n我们使用类似于Chamfer匹配的方法匹配单个零件模板并计算零件模板匹配分数[6]。通过边缘方向匹配来测量零件模板轮廓上的采样点的匹配分数。目标是估计与图像观察最一致的最佳人类姿势（对应于路径上的每个部分模板的树路径和位置估计）。\n优化问题可以通过动态规划解决，实现全局最优解。但是，这个算法在计算上太昂贵，不能密集地扫描所有的假想窗口。为了提高效率，我们使用快速的K-fold贪心搜索算法。我们保留层L1中所有节点（k = 1; 2。.K）的分数，而不是估计最佳k，并且对于这些K个节点（或线程）中的每一个单独执行贪婪过程。通过分层部分模板匹配算法估计的姿态模型参数直接用于通过部分合成（区域连接）进行姿态分割。\n\n3 POSE-ADAPTIVE DESCRIPTORS（自适应描述）\n为了将我们的部分模板树模型和分层部分模板匹配算法应用于区分人类检测，引入标准机器学习技术SVM和Boosting，并且介绍姿势自适应特征计算方法来从图像中检测人体。3.2 Low-Level Feature Representation（低级特征表示）\n在行人检测方面，定向梯度直方图（HOG）方法将人与非人分离表现出优异的性能，能忽略空间本身的信息，具有很强的鲁棒性。我们使用相似的方法—边缘方向直方图（梯度幅度加权）作为我们的低级特征描述。\n输入图像，使用差分运算计算梯度G和边缘方向O，每幅图像量化为8*8的无重叠单元格。，用边缘取向直方图表示（每个周围的像素对直方图栏进行梯度变化的投票）。边缘方向被量化为Nb = 9，为了减少混叠和不连续性的影响，我们还使用三线插值法来计算空间和取向尺寸的梯度大小。\n低级特征描述由一组原始直方图和一组归一化图像位置索引快组成。原始直方图携带梯度幅度信息，因此它们用于姿态匹配（匹配直方图对于树中姿势轮廓的边缘方向），而归一化直方图基于估计姿态用于最终描述符。3.3 Pose Inference on the Low-Level Features（低级特征姿势推理）\n通过方向一致性而不是传统倒角匹配中边缘之间的距离来测量得分。 使用基于位置的查找表来测量每个模板点的得分。 加权来自相邻直方图栏的幅度以减少定向偏差并使每个模板点的匹配分数正规化。\n令O（t）轮廓点t处的边缘方向，与其对应的方向索引B(t)=[O(t)/(#/9)],#:圆周率。对于每个点t，我们首先在检测窗口中识别与之最邻近的8*8单元格。令H = （hi）表示t处的直方图，则t处的匹配分数计算为： \n![](http://i.imgur.com/yT8sO0I.png)   （1）\n\n其中b表示领域范围，w(b)表示对称权重分布。如果给定一个模板T（部分模板上的边界采样点的集合），则该模板的匹配分数可以计算为：\n![](http://i.imgur.com/7h0oJnw.png)  （2）\n\n### 3.4 Representation Using Pose-Adaptive Descriptors（使用姿态自适应描述符表示） ###\n为了获得具有不同尺寸姿态模型的图像的统一（恒定尺寸）描述，并且在不同的轮廓点之间建立一对一的对应关系姿势，我们将任何姿态模型的边界点映射到规范姿态模型的边界点。对于人体上部（头部和躯干），边界被均匀地取样为八个左侧和八个右侧位置，并且根据垂直y坐标和侧面（左侧或右侧）信息在姿势之间建立点对应关系。对于下体（腿），边界被均匀地采样到每个y值处具有四个位置的垂直，如何分配采样位置参照下图：\n![](http://i.imgur.com/7FtHqJj.png)\n![](http://i.imgur.com/eR7W6es.png)\n\n注意，只有块的子集与描述符相关，并且块可能会根据位于块内的轮廓点的频率重复多次。4. DETECTING AND SEGMENTING MULTIPLE OCCLUDED HUMANS（检测和分类多个被检测的人）\n上一节讨论的姿态自适应描述符主要是为了从图像中检测完全可视的人的目的而开发的。在这些复杂情况下，我们基于姿态自适应特征的通用检测器可用于提供初始 一组人类假设（通过降低阈值以确保低错失率），然后可以执行更详细的闭塞分析和优化。\n\n4.1 Initial Hypotheses（初始假设）\n使用我们的姿势适应特征训练的通用人体检测器和诸如SVM的辨别分类器可以提供用于从静止图像中检测人类的可靠的初始人类假设集合。 然而，对于拥挤的视频，由于人体的任何部分都可以闭塞，有时只能看到很小的一部分。 因此，在这里，我们介绍了一种替代方法，用于生成监控场景的初始人为假设。\n分层部分模板匹配提供每个检测窗口的姿态模型参数的估计。 我们定义能够评估任何部分或部分组合的图像响应的分数函数Fw，该函数被建模为单个部分匹配分数fj的加权和：\n![](http://i.imgur.com/jSS2avn.png)  （3）\n\n其中权重分布w={wj,j=ht,ul,ll}(三个wj之和等于1)，若Wht = Wul = Wll = 1/3,则对应全是检测器。若Wht = 0，Wul = Wll = 1/2,则对应腿部检测器。对于得分函数Fw通过应用检测阈值，我们得到7个部分或分布组合检测器。如下图所示：\n![](http://i.imgur.com/qIE6lav.png)\n\n使用M部分检测器，对应于M个权重向量基于公式（2）计算单个零件匹配得分fi。\n在实践中，我们从输入图像中构建一个金字塔，并使用我们的基于滑动窗口的通用人类检测器将搜索空间减少到一个小的子集，并通过使用上述部分/部分组合检测器搜索其他假设来提高搜索空间。每个响应图我们使用恒定的全局检测阈值，并自适应选择模式。 也可以在平滑似然图像之后通过局部最大选择来执行该步骤。 最大值的联合形成了人类假设的集合：\n![](http://i.imgur.com/uJ85oFY.png)\n\n我们计算所有假设的全身匹配分数，并用L(ui)，i，2…N表示。更具体点，L(ui)被计算为所有 部分模板轮廓点的平均匹配分数。\n\n4.2 Objective Function(目标函数)\n使用初始检测假设u作为图像观察，我们将多次闭塞人类检测模型作为最大化目标函数%的问题进行建模。\n![](http://i.imgur.com/anayaYM.png)\n\n其中c表示有序的人体配置，n表示配置中的人数。\n由于遮挡，不能直接用L(ui)来模拟%(u|c)，相反，需要基于遮挡图Iocc全局重新估计每个假设ui的匹配分数。如果ui属于c，则仅基于或可见部分计算其匹配分数。我们通过从精确的人类分割生成的遮挡图在像素级处精确地执行遮挡补偿。这种基于遮挡补偿的评分重新评估方案在保留真实检测的同时有效地拒绝大多数假警报。\n如果ui属于c，则存在j，使得ui = cj，并且因此，遮挡补偿匹配分数L(ui|Iocc)被定义为位于cj可见区域内的ui形状模板点的平均匹配分数;如果ui不属于c，则L(ui|Iocc)被设置为常数检测阈值α。基于上述建模，目标函数可以重写为：\n![](http://i.imgur.com/ReVRnDA.png)\n\n现在，给定任何有序的人类假设（配置），可以精确地评估目标函数。\n\n5 COMBINING WITH CALIBRATION AND BACKGROUND SUBTRACTION（结合校准和背景技术）\n我们还可以将基于形状的检测器与统一系统中的背景扣除和校准技术相结合。\n\n问题\n该论文介绍的是二维图像上人体的检测和分割，其中的方法如何应用到3维的医学图像分割上去？\n论文树模型分块部分是先利用姿势生成其来产生人体的部分零件，然后再通过真实姿态图像学习来优化合成树模型，而并非一开始就是真实的人体图像，这一情况如何与医学图像的器官对应上？\n分块程序对每一个脾脏和脑室分割时，每一块都是不规则的，而人体分块是规则的，是不是得寻找其他程序对器官分块，而分块的标准又是什么呢？\n\n","categories":["东搞西搞"],"tags":[]},{"title":"你必读的RSS订阅有哪些？","url":"http://tanqingbo.cn/2017/08/16/你必读的 RSS 订阅源有哪些/","content":"\n什么是RSS？RSS（Really Simple Syndication，简易信息聚合）是一种描述和同步网站内容的格式。你可以认为是一种定制个性化推送信息的服务。它能解决你漫无目的浏览网页的问题。它不会过时，信息越是过剩，它的意义也越加彰显。为什么需要RSS？网络上充斥着大量的信息垃圾，我的体会是：每天摄入了太多我根本不关心的信息。我希望让我关注的信息主动来找我 ，且这些信息都是我需要的，这就是RSS的意义。 \n有什么RSS源推荐给我吗？拓宽知识类知乎每日精选（强烈推荐）：http://www.zhihu.com/rss知乎日报（非常宝贵的源）：http://feeds.feedburner.com/zhihu-dailynhzy资讯（健康生活）：http://www.nhzy.org/?feed=rss2果壳网（科普生活）：http://www.guokr.com/rss/科学松鼠会（科普）：http://songshuhui.net/feed科学公园（分析各种误区）：http://www.scipark.net/feed/泛科学（台湾的科普资讯）：http://pansci.tw/feedMatrix67（数学爱好者）：http://www.matrix67.com/blog/feed.asp战隼的学习探索（效率生活）：http://feed.read.org.cn/新闻资讯类每日鲜果精选：http://xianguo.com/service/dailyshare凤凰网：http://feed43.com/1726484643045386.xml科学网头条：http://fullrss.net/a/http/www.sciencenet.cn/xml/news.aspx?di=0联合早报国际：http://zaobao.feedsportal.com/c/34003/f/616931/index.rss联合早报国内：http://zaobao.feedsportal.com/c/34003/f/616930/index.rss深度阅读类科学网博文精选：http://fullrss.net/a/http/www.sciencenet.cn/xml/blog.aspx?di=20译言精选：http://feed.yeeyan.org/select美文日赏：http://meiwenrishang.com/rss南都周刊：http://www.nbweekly.com/rss/smw/网易新闻·有态度专栏：http://news.163.com/special/00011K6L/rss_newsattitude.xmlIT资讯类http://cnBeta.COM业界资讯：http://feeds2.feedburner.com/cnbeta_full月光博客：http://feed.williamlong.info/Engadget 中国版：http://cn.engadget.com/rss.xml36氪：http://feed.36kr.com/c/33346/f/566026/index.rss微软亚洲研究院：http://blog.sina.com.cn/rss/1286528122.xml善用佳软：http://feed.xbeta.info小众软件：http://feed.appinn.com/异次元软件世界：http://fullrss.net/a/http/feed.iplaysoft.com/小木虫论坛热门资源：http://emuch.net/bbs/rss.php?fid=300\n\n\n艺术、设计方面：爱午茶：http://iwucha.com/feed/理想生活实验室：http://www.toodaylab.com/feedLeica中文摄影杂志：http://feed.feedsky.com/leicaCinephilia迷影：http://cinephilia.net/feed时尚生活杂志：http://www.adaymag.com/feed/Type is Beautiful：http://feed.feedsky.com/typeisbeautiful优设：http://www.uisdc.com/feed软件：掌握Evernote：http://evernote-tw.tumblr.com/rss异次元软件世界：http://feed.iplaysoft.com/善用佳软：http://feed.xbeta.info/小众软件：http://feed.appinn.com/反斗软件：http://www.apprcn.com/feed反斗限免：http://ree.apprcn.com/feed软件小子：http://www.bzdiao.com/rss科技、科学方面Engadget中国版：http://cn.engadget.com/rss.xmlcnBeta:http://cnbeta.com/backend.php月光微博客：http://www.williamlong.info/blog/rss.xml锋客网：http://www.phonekr.com/feed/WPDang:http://www.wpdang.com/feed电脑玩物：http://playpcesor.blogspot.com/feeds/posts/default?alt=rss科学松鼠会：http://songshuhui.net/feed果壳网：http://www.guokr.com/rss/PanSci泛科学：http://pansci.tw/feed极客公园：http://feeds.geekpark.net/谷奥：http://feed.google.org.cn/同步控：http://www.syncoo.com/feed36氪：http://www.36kr.com/feed爱范儿：http://www.ifanr.com/feed互联网分析沙龙：http://www.techxue.com/极客范：http://www.geekfan.net/feed/GFW与XX：http://www.chinagfw.org/feeds/posts/default?alt=rss评论、新闻方面：政见：http://cnpolitics.org/feed/大家：http://hanhanone.sinaapp.com/feed/dajia爱思想：http://www.aisixiang.com/rss.php?type=1南都周刊：http://www.nbweekly.com/rss/smw/Solidot:http://feeds2.feedburner.com/solidot中国数字时代：http://feeds.feedburner.com/chinadigitaltimes/IyPt共识网：http://www.21ccom.net/plus/rss.phpXX观察：http://www.hrw.org/zh-hans/rss海德沙龙：http://headsalon.org/feed自由亚洲电台：http://www.rfa.org/mandarin/RSS墙外楼：http://feeds.feedburner.com/letscorp/aDmw经济学人中文版：http://blog.ecocn.org/feed德国之声：http://rss.dw.de/rdf/rss-chi-all纽约时报：http://cn.nytimes.com/rss.html我在中国：https://cochina.co/feed/壹读博文：http://yidu.im/rssBBC中文网：http://www.bbc.co.uk/zhongwen/simp/index.xml生活、购物方面心理网：http://feed.feedsky.com/xinli001Nhzy健康资讯：http://www.nhzy.org/?feed=rss2什么值得买：http://feed.smzdm.com消费者报道：消费者报道 chinaconsumerreport.org效率、时间管理方面褪墨：http://feed.mifengtd.cn/战隼的学习探索：http://www.read.org.cn/feed读书笔记：http://www.write.org.cn/feed个人博客（包括看上去像的）：捷学的哲学：http://chit-philosophy.blogspot.com/feeds/posts/default?alt=rss编程随想的博客：http://feeds2.feedburner.com/programthink孤岛客：http://www.huangjiwei.com/blog/?feed=rss2土摩托日记：http://www.immusoul.com/feed梁文道文集：http://feed.feedsky.com/commentshk阮一峰的网络日志：http://feeds.feedburner.com/ruanyifeng不许联想：http://feed.feedsky.com/bxlxwxf学而时嘻之：http://www.geekonomics10000.com/feed徐贲的博客：http://blog.sina.com.cn/rss/1286402547.xml阅读、语言学习方面：读写人：http://www.duxieren.com/duxieren.xml译言精选：http://www.adaymag.com/feed/词穷先生美文网：http://www.ciqiong.cn/feed一个：http://onehd.herokuapp.com/上海书评：http://www.dfdaily.com/rss/1170.xml其他：知乎每日精选：http://www.zhihu.com/rss糗事百科：http://feed.feedsky.com/qiushi知乎日报：http://www.zhihudaily.net/rss.xml亚洲善待动物组织：http://blog.china.petaasiapacific.com/feed/煎蛋：http://feeds2.feedburner.com/jandan更新地址：http://maybeiwill.me/?p=126\n\n\n\n\n\n\n再推荐一个功能强劲的RSS源搜索引擎：RSS Search Engine总之，好的RSS源实在是不胜枚举。进阶使用与提高1.其实QQ空间、新浪微博都可以输出成RSS源。你QQ空间的RSS源就是：http://feeds.qzone.qq.com/cgi-bin/cgi_rss_out?uin=你的QQ号码新浪微博RSS输出教程：新浪微博档案2.没有RSS源的网页也可以搞出RSS源。教程：FEED43 – 为没有 Feed 的网页生成 RSS 格式订阅源[教程]3.可以让摘要模式的RSS源变成全文输出模式。教程：fullrss.net RSSReader4.打造你自己的个性化极速通知神器。如果你和我一样喜欢折腾，并且还没有用过IFTTT这款软件，那么请赶紧尝试吧~ifttt是“if this then that”的缩写，事实上是让你的网络行为能够引发连锁反应、让你使用更为方便，其宗旨是“Put the internet to work for you”（让互联网为你服务）。ifttt旨在帮助人们利用各网站的开放API，将Facebook、Twitter等各个网站或应用衔接，完成任务，使“每个人都可以成为整个互联网不用编程的程序员”。目前已经同时支持iOS、Android以及网页版：Put the internet to work for you.有了它可以实现非常多非常好玩有用的功能，爱折腾的同学肯定能自行研究出各种厉害的用法。入门介绍：iFTTT 入门介绍与简单使用设置教程这里只介绍和RSS功能结合起来的基本应用：注册了IFTTT账号、在手机上下载客户端后，就能够在线编辑你想要的各种网络任务了。写在后面如果您和我一样面临信息爆炸带来的困扰，请你尝试一下RSS方式的阅读生活。我自己体验是：每天只需很少的时间，就能非常高效地阅读大量精华的信息，知识摄入和积累的效率确实大大提高了。如果您是自己做网站，请让您的网站支持RSS服务，因为，在这个资讯过剩、信息垃圾横流的时代：支持RSS是一种美德。\n","categories":["资源分享"],"tags":[]},{"title":"Ubuntu安装搜狗输入法","url":"http://tanqingbo.cn/2017/08/15/Ubuntu安装搜狗输入法/","content":"前言\n初次使用Ubuntu系统的新手，肯定会遇到各种各样的问题，输入法的问题肯定没少折磨过大家，因为Ubuntu默认只有英文输入，没有中文输入。别着急，我马上就教大家如何在Ubuntu下安装搜狗输入法。\n准备工作\nLinux搜狗输入法安装包，下载地址：http://pinyin.sogou.com/linux/;\n\n根据自己的系统下载对应位数的安装包；\n\n如果你是首次使用Ubuntu，请先更新一下源，按ctrl+alt+t键打开终端，执行如下语句：\n      sudo apt-get update\n\n\n开始安装\n进入到搜狗输入法安装包的目录，我把安装包放在Download目录下，所以我想进入到Download目录，然后使用dpkg语句安装，执行命令如下：\n  cd Download\n  sudo dpkg -i sogoupinyin_2.1.0.0086_i386.deb\n\n\n\n\n到此输入法算是安装完了，但是现在还使用不了，还需要配置一下。\n点击右上角的小齿轮，选择System Settings，然后单击Language Support。\n初次点击Language Support，会提示执行sudo apt-get install -f，在终端中执行该条语句，跳出来的提示选择Y，等几分钟然语句执行完，然后重新打开Language Support，选择install Language Support，如下图：\n\n\n\nKeyboard input method system选择  fcitx。然后重启系统，重启之后会在右上角看到输入法的符号，但是现在还不能用，还得在配置一下，依次点击 输入法符号-》配置-》加号-》去掉Only Show Current language的红勾。\n\n    \n\n然后滑倒最下面，选择Sogou Pinyin，再点击右下角的OK键就打工告成了。\n\n\n\n之后按Ctrl+空格键切换输入法，就可以正常使用搜狗输入法了。\n\n\n","categories":["技术博客"],"tags":[]},{"title":"PS安装破解教程","url":"http://tanqingbo.cn/2017/08/10/PS安装破解教程/","content":"准备工具\nAdobe Photoshop CC 2017-18.0安装包\n破解工具：amtemu.v0.9.2-painter获取地址\n\n\n以上两个东西可以从下面链接获取\n链接：http://pan.baidu.com/s/1bpwADsV \n密码：0r38##\n\n开始安装\n把安装包解压之后进入Adobe Photoshop CC 2017文件夹，双击Set-up,就可以安装程序了。**注：安装前最后断网，否则会让你注册账户，挺麻烦的。当然，你联网注册也行，因为后续需要登陆。**\n跳出安装界面，点击继续。这个时候开始安装了，默认装在C盘，**路径是C:\\Program Files\\Adobe\\Adobe Photoshop CC 2017，这个很重要，破解的时候需要这个路径。**\n安装完之后需要登录，把之前注册的账号登陆就可以了，我的因为登陆过来，就不需要输入账号登陆了。\n登陆好之后会出现软件说明，不用管他，单击**开始试用。**\n软件会被打开，完全打开之后关闭软件，找到刚刚下载的破解软件，解压，打开amtemu.v0.9.2-painter注册机。\n注册机里面第一个选项卡点击下拉找到Adobe Photoshop CC 2017，选中它。\n再点击右下角的install，然后在安装目录C:\\Program Files\\Adobe\\Adobe Photoshop CC 2017下找到amtlib.dll文件，再点击打开。\n如果注册机内显示OK，并有enable字样，说明破解成功了，接着就可以没有限制的使用软件了。\n\n##\n最后\n看到这里还没有关掉的亲们肯定是已经装好软件了，最后再把PS的视频学习教程也分享给大家吧！视频教程获取地址\n链接：http://pan.baidu.com/s/1jI3NWb0 \n密码：tv4p\n\n","categories":["资源分享"],"tags":[]},{"title":"python学习图书","url":"http://tanqingbo.cn/2017/08/08/Python学习图书/","content":"前言\n如果你想学好Python，这几本书说不定可以帮助到你哦。\n\nPython核心编程(第二版)\n本书是经典的Python[1]  指导书，在第一版的基础上进行了全面升级。全书分为两个部分：第1部分占据了大约三分之二的篇幅，阐释这门语言的“核心”内容，包括基本的概念和语句、语法和风格、Python对象、数字类型、序列类型、映射和集合类型、条件和循环、文件和输入/输出、错误和异常、函数和函数式编程、模块、面向对象编程、执行环境等内容：第2部分则提供了各种高级主题来展示可以使用Python做些什么，包括正则表达式、网络编程、网络客户端编程、多线程编程、图形用户界面编程、Web编程、数据库编程、扩展Python 和一些其他材料。下载地址\n链接：http://pan.baidu.com/s/1miFVbwW \n密码：3kdkPython高级编程\n《Python高级编程》针对具备一定Python基础并希望通过在项目中应用最佳实践和新的开发技术来提升自己的Python开发人员。下载地址\n链接：http://pan.baidu.com/s/1qYa5t6k \n密码：3a76\n\nPython数据结构与算法\n主要是介绍了如何使用Python实现常用的一些数据结构,例如堆栈、队列、二叉树等等。下载地址\n链接：http://pan.baidu.com/s/1i5CDtbf \n密码：xpyv\n\n利用Python进行数据分析\n从pandas库的数据分析工具开始利用高性能工具对数据进行加载、清理、转换、合并以及重塑；利用matpIotlib创建散点图以及静态或交互式的可视化结果；利用pandas的groupby功能对数据集进行切片、切块和汇总操作；处理各种各样的时间序列数据。下载地址\n链接：http://pan.baidu.com/s/1i5gPm1R \n密码：kxwc\n\n","categories":["资源分享"],"tags":[]},{"title":"据说想要学好C++，这几本书一定要看","url":"http://tanqingbo.cn/2017/08/08/据说想要学好C++，这几本书一定要看/","content":"前言\n我之前问过ACM大神，如何学好C++？他说最好的办法就是读书，读大量的书，就可以解决。要把C++作为日常语言，而不是一种程序语言，这样就好办了。The Design and Evolution of C+\n首先肯定要读一读Bjarne Stroustrup的The Design and Evolution of C++，了解一下这个语言的历史。接下来就可以看别的书了，但要不停地回头看这本书，看到你不断地学到的新技术是怎么样一点点地被接纳到这个语言中去的。\n这本书我也没有资源，大家可以到网上找找。\n\nC++ Primer\n第一本书因人而异，基础好一些的，可以看Stanley B. Lippman的C++ Primer，这本书非常地巨大，你打星号的部分可以不要看。基础不太好的，可以看Stanley B.Lippman的Essential C++，这本书份量要轻得多，不过四个C++的范型都讲了，而且讲得非常清楚。下载地址\n链接：http://pan.baidu.com/s/1i5ilfPN \n密码：64yv\n\nThinking in C++\n第二本书，就应该是Bruce Eckel写的、候捷译的Thinking in C++，这本书技术运用的非常高的境界，但是语言非常平实，只要认真地读，即使基础不行，也一定可以懂。下载地址\n链接：http://pan.baidu.com/s/1sl0RDaX \n密码：j21o\n\nEffective C++和More Effective C++\n\n第三本应该静下心来看看Scott Meyers的Effective C++和More Effective C++，好好地整理一下，在程序设计中应该有哪些注意的事项。可以指导项目运作了，可以编写一切你想做的程序了，可以指出别人看起来不错的代码的大小问题了下载地址\n\n\n链接：http://pan.baidu.com/s/1i57nCpB \n密码：80wx\n\n","categories":["资源分享"],"tags":[]},{"title":"如果你想做java研发的话，这几样工具你肯定用得到","url":"http://tanqingbo.cn/2017/08/04/如果你想做java研发的话，这几样工具你肯定用得到/","content":"Eclipse IDE for Java EE Developers\n该版本集成了Java ee开发常用插件，方便动态web网站开发。适合Java web开发者使用。集成了XML编辑器、数据库查看工具，提供jsp可视化编辑器。获取地址\n链接：http://pan.baidu.com/s/1hsBZi2g \n密码：y05m\n\njdk（包含1.7和1.8两个版本）\nJDK是 Java 语言的软件开发工具包，主要用于移动设备、嵌入式设备上的java应用程序。JDK是整个java开发的核心，它包含了JAVA的运行环境（JVM+Java系统类库）和JAVA工具。获取地址\n链接：http://pan.baidu.com/s/1nu96J3N \n密码：4wfv\n\ntomcat（包含7.0和8.0两个版本）\nTomcat 服务器是一个免费的开放源代码的Web 应用服务器，属于轻量级应用服务器，在中小型系统和并发访问用户不是很多的场合下被普遍使用，是开发和调试JSP 程序的首选。对于一个初学者来说，可以这样认为，当在一台机器上配置好Apache 服务器，可利用它响应HTML（标准通用标记语言下的一个应用）页面的访问请求。获取地址\n链接：http://pan.baidu.com/s/1miRzXXI \n密码：hg24\n\nmysql数据库\nMySQL是一个关系型数据库管理系统，由瑞典MySQL AB 公司开发，目前属于 Oracle 旗下产品。MySQL 是最流行的关系型数据库管理系统之一，在 WEB 应用方面，MySQL是最好的 RDBMS (Relational Database Management System，关系数据库管理系统) 应用软件。获取地址\n链接：http://pan.baidu.com/s/1gfJ2Jar \n密码：sucw\n\nnavicat for mySQL破解版\nNavicat是一套快速、可靠并价格相当便宜的数据库管理工具，专为简化数据库的管理及降低系统管理成本而设。获取地址\n链接：http://pan.baidu.com/s/1nvoOu97 \n密码：8swq\n\n","categories":["资源分享"],"tags":[]},{"title":"VMware Workstation 12 Pro 正版许可证密钥","url":"http://tanqingbo.cn/2017/08/02/VMware Workstation 12 正版密钥一枚/","content":"VMware Workstation 12 Pro 正版许可证密钥\n前几天刚安装最新的 VMware Workstation 12 Pro 时，去网上找序列号，官方叫法是“许可证密钥”，结果好像很少唉，可能会跟 12 版本刚出来也有关系吧！好不容易找到一枚，上面居然写了：VMware 12 Pro 试用序列号128天。哇靠！居然是“试用”的？咱们是有骨气的孩纸，坚决不要！\n几经周折，终于搞到一枚正版密钥，其实我也搞不懂这种算不算“正版”，总之完美永久激活！站长亲测！不敢独享，特意放到小站上来，请低调下载与分享。\n\n\n\nVMware Workstation 12 Pro下载地址：\n\n链接：http://pan.baidu.com/s/1dEHo83R 密码：lkpi\n\n\n永久密钥：\n\n5A02H-AU243-TZJ49-GTC7K-3C61N\n\n\n\n","categories":["技术博客"],"tags":[]},{"title":"青春兵荒马乱，我们潦草地离散","url":"http://tanqingbo.cn/2017/08/02/青春兵荒马乱，我们潦草地离散/","content":"青春兵荒马乱，我们潦草地离散就在前几天，学校在我的学生证上盖了一个大戳，上面写着四个醒目的大字：毕业留念。不管有多么的不愿意，我们还是不得不承认，这场长达4年的旅程终于要画上句号了，从此以后我不再是一个拥有学生证的同学了，我毕业了。\n\n按照惯例，作为即将要离开的师兄，我应该要给师弟师妹们一些忠告：学校的月考就像电视台里插播的广告，不是你换台就能逃避得了的；别太依赖老师考前画的重点，因为他可能会告诉你讲过的都是重点；老食堂的饭菜真的要比新食堂的要好吃很多；拼了老命也要在四年的时间里过完四六级啊；学妹们千万不要相信任何以学习的名义来加你微信的师兄，因为在我身边就有这样一群非常饥渴的师兄在加完你微信后就开始探讨哲学问题，“防火防盗防师兄”这句话还是有一定道理的。\n\n其实关于毕业，每个人都有不同的感受，有的人很难过，我最难过的时候，是当我走在那条上课必经的路上，突然想到以后我可能再也不会在这条路上跑着去上课的那个瞬间。不是因为我多么的好学，而是在大学期间我特别积极的跑着去上课的次数真的没有几次好吗？其实毕业了也挺好，至少我们再也不用费尽心机千方百计地想要逃课了，因为我们可能再也没有课可以上了。下一个秋天的时候，那间总是想逃开的教室依然还是会坐满人，只是再也不可能是我们了。\n\n拍毕业照的那天，全班的男生和女生都盛装打扮，男生穿着正装，女生露在大腿，从主楼开始拍，一路经过丹青楼、科学会堂、小红房，最后到南校区校碑结束。我们拼命的记录校园的每一个角落，就好像下一个镜头就是我和母校最后一次的合影一样。那天我们全班又重新来到上课的教室，特别认真的坐在座位上，感受了一下上课的氛围，没要人逃课，也没有人讲话，我们就这样静静的坐了一会，视线逐渐变得模糊。人总是这样，只有在快要结束的时候才想着要好好开始。离开了学校，我们就再也没有一个地方能像学校这样把男生和女生这么紧密的联系在一起，却又无关风月，只为真心。\n\n吃最后一次班饭的那天，我醉的像个傻逼一样，大家都说毕业之后一定要再聚，只要来到我的地盘，随时找我。就好像又回到了第一次班会一样，大家轮流站在台上自我介绍：大家好，我叫谭庆波，请大家以后多多关照。可是，为什么我们这么快就要毕业了呢？我们还没来得及多多关照呢！我爱的人都还没来得及出现呢！然后你就告诉我：你毕业了，快收拾东西滚蛋吧！时间这个心机婊总是这样，趁着你不注意的时候给你一记响亮的耳光。我们总以为只有长大了才能永远在一起，所以我们不惜一切代价，拼命的成长，但是当我们真的成长到足以和这个世界单打独斗的时候，才发现，被骗了，原来成长只能让我们分离。当我们挥手和青春告别的时候，同时也是宣告着我们孤身一人闯荡这个善恶未知的江湖的开始，你的剑配好了吗？\n\n早上出门的时候，住在同一层的同学拖着行李箱从我身边经过，他像往常一样和我打招呼，只不过这一次他说的却是—再见。在那个瞬间，我才真真切切的感受到真的要分离了。从明天开始，我们就要全神贯注的和这个世界单打独斗了，你准备好了？\n\n2013年9月，我一个人拖着行李箱来到东北林业大学，4年的大学生活，有过收获，也有过遗憾，经历过保上研究生的喜悦，也体验过深夜痛哭的滋味，所有的酸甜苦辣都已经化成我身上的烙印，我感谢学校4年来所赐予我的一切。现在是2017年6月，再过几天，我也要收拾行李离开这里了，离开之前总免不了要洒一点鸡汤：让我们一起捍卫自己的梦想，下一次，世界精彩处见。\n我叫谭庆波，出生于1995年11月28日，来自湖南省衡南县的某个小农村，我毕业于东北林业大学计算机科学与技术专业，我毕业了。\n","categories":["漂来漂去"],"tags":[]},{"title":"他们在大理","url":"http://tanqingbo.cn/2017/07/30/他们在大理/","content":"他们在大理　　这几天广东的太阳真的很大，晒得我都不敢出门，整天待在家里不知如何是好。心想，不如趁着最后几天空闲时间写点什么吧！\n　　我曾经说过，旅行有时不仅仅是为了风景和美食，也是为了在路上能够遇见有趣的人。每次出去玩的时候几乎都不例外，总能遇到几个精彩而又有趣的人儿。这次去大理也不例外，在那里，我遇到了他们。\nA“我要搭车去西藏。”\n　　A是北大即将毕业的硕士，身材魁梧，一身腱子肉，有点像山东的彪形大汉。初次见面的时候，A刚到达客栈，背着一个60L的大旅行包站在门口正询问客栈老板从大理搭车进藏的攻略。不知道他是攒了多久的假期，只知道他只有一个月的时间，想要徒步或者搭车进入西藏。现在，A仍然在进藏的路上，时不时的会在群里给我们分享几张路上的风景。\n　　A是和我同一天到达大理的。西南的天亮的要比东边晚很多，那天早上6点多到达客栈的时候，天还没大亮，加上前一天晚上的舟车劳顿，身体实在是吃不消，进客栈就赶紧找床位睡下了，9点多醒来后就开始找人陪我去逛大理古城，忽然看到一个大汉在跟老板闲聊，便上去询问要不要一起去逛大理古城。虽然A也是下车刚到，却一点疲惫感都没有，放下行李就准备要和我一起去。后来经老板提醒，白天的古城很冷清。我们就和店里的其他几个小伙伴一起组队去爬了苍山，还在寂照庵里面吃了一顿很便宜的斋饭。第二天我们又一起骑车环洱海。\n　　路上交谈得知，A的经历其实很丰富，在新加坡做过交换生，还去过日本，如今又一个人走在滇藏线的路上。\n　　或许每个喜欢折腾的人都喜欢在路上的感觉，就算很辛苦，就算是一个人也会感到很满足。生活就像一本书，至少我这一本比别人多了几页。\nB“我辞职了。”\n　　B是来自成都的一个小姑娘，出来之前是成都某家医院的小护士，后来辞职出来旅行了。不知道是我的运气好，还是当护士的小姐姐们都有一颗浪迹天涯的心。这已经是我第二次遇到职业是护士的姑娘辞职出来旅行了。\n　　B今年3月份来过一次大理，和我相遇的时候已经是第二次来大理了，而且在我来之前她已经在大理待了一周多时间，在此之前，在客栈做过义工，也在古城里摆过地摊。后来因为闲义工时间太不自由了，于是辞掉了义工，搬到我住的那家青旅，这才相遇。当然这些都不是重点，重点是她只有18岁，其实我第一次听说的时候，死活都不愿意相信的，但是在她特别认真的强调很么多次之后，我姑且相信吧，哈哈！\n　　可能是因为B的姐姐在医科大学上学的原因，B的父亲就托关系给她找了一个护士的工作，想着可能以后和姐姐能有个照应。但是整天面对各种病人，随时准备应对各种突发情况，这种工作环境不是每个人都能接受的，索性B就辞职出来旅行了。她说：“我是出来渡劫的，等我回去就要重新开始了。”\n　　后来，B回家开始寻找新的工作，朋友圈依旧正能量满满，也的确是果断的开始了自己新的生活。\n　　曾经有朋友跟我说：“所谓在路上‘寻找自己’都是狗屁，我们都知道，所有要面对的事情回去还是要面对。”是的，我们都知道，最终能找回自己的终究只有自己。\nC“我骑摩托车来的。”\n　　C呢，算是另外一种人了，地道的广东人，热爱旅游，之前在广东摆摊卖过肠粉，后来爱上旅行，抽空就会出来玩。\n　　那天我们组织去寂照庵吃斋饭，C是最后一个加入的，之后我们便一直组团出去浪。聊天得知，C本来是骑着摩托车从广东出发的，打算骑车环游中国，为了这次旅行他准备了很久，出发之前买了新摩托车、骑行护具、雨披。然后就满怀期待的出发了，谁知在骑到广西南宁的时候，因为无证驾驶，摩托车便被交警扣下了，算是出师不捷吧！挣扎了一会无果之后便豁达的接受了这个事实，临走之前还把所有的骑行装备送给了路边的一个大妈，然后便又一个人潇洒的前往下一个目的地了。\n　　C不仅会做肠粉，厨艺也很不错，我们住的青旅提供厨房，我们可以买菜回来自己动手做饭吃。在青旅住的期间，C给我们煲过一次排骨粥，还给我们做过一次广东菜，味道真的很好。\n　　后来，我在大理待了4天之后回到了广东，他又接着开始了他之后的旅程，在我离开的时候，他说：“下次再来广东的时候找我，我好好招待你。”\n　　我想像这样一个热爱生活、热衷于探索的人，无论最终以怎样的形式生活，必然都能体味到独属于他的乐趣吧！\nD“下回，我要和哥哥一起来。”\n　　D是来自浙江嘉兴的妹子，新加坡毕业归来。可能是有海外留学的经历，性格比国内的妹子要稍微开放一点，我们坐在一起聊天的时候，一言不合就开车，经常把小护士说的一愣一愣的。\n　　其实D这一趟旅程也挺任性的，刚从西藏拉萨下来没多久便又来到了云南，在我来到大理之前，她已经在大理待了有一个多星期了，之前和小护士在同一家客栈做过义工，在古城摆过地摊。我来的时候还一直邀请我一起去摆地摊，可是那几天古城一直下雨，地摊没摆成，走之前把所有的东西都留在了客栈。\n　　环洱海的那天，我和D骑同一辆小电驴。路上我和她提起我即将在哈工大读博士的事情，她听说后一直鼓励我说博士期间一定要出国看看，还说了很多留学生在国外的心酸历程，虽然很辛苦，但是收获却很多。她称的她男朋友为哥哥，她说：“下回等双廊正式开通的时候，一定要带哥哥一起来大理。”\n　　与D交流很是舒服，同她聊天时她会鼓励我去追求梦想、直面内心。我想，大概每一个真善的人都会希望另一个同行的人能生活得更好吧。\n\n　　很多人向往大理，也有很多人来到了大理。碰见他们时，听到的也是他们一路前行的故事，大抵是风景很优美、经过了很多地方。当然，这是旅行的一种形式，同时也是人生中不可多得的另一份乐趣。\n\n　　韩寒在《后会无期》中写到：“你连世界都没观过，哪来的世界观？”或许，那些学富五车的人同样有着对人生、对世界的清晰认知，但对于绝大多数人而言，我们世界观的形成还没达到拼知识的高度。所以，于我们而言，走出去总归是件好事。\n\n　　蔡澜说：“多看天下，多观察别人是怎么过这一生的。回来后，你会对别人更好，你会对自己更好。”那就走出去吧，当然也愿你出走半生，归来仍是少年。\n\n","categories":["漂来漂去"],"tags":[]},{"title":"这些超实用的电脑快捷键，你都get到了吗？","url":"http://tanqingbo.cn/2017/07/30/这些超实用的电脑快捷键/","content":"这些超实用的电脑快捷键，你都get到了吗？不知道小伙伴们经常是不是看到一些电脑操作大神，在键盘上“啪啪啪”敲两下就能解决很多事情，既高效又帅气。来来来，当你get到这几个快捷键之后，一样可以既高效又帅气的用你电脑干活。\n锁屏\n有些时候，需要暂时离开座位去处理其他事，可是电脑还有数据再跑。\n\n关掉的话，数据就白跑了，不关的话，又不想让别人看到我电脑的资料。\n\n\n\n那么就按住windows键后，再按L键。\n\n这样电脑就直接锁屏了，不用担心电脑的资料外泄。\n快速显示桌面\n在实验室里，正高兴的开黑玩游戏的时候，老师突然闯进来了。\n\n这时让他看到自己在玩游戏肯定不好，游戏界面又没法一下子最小化，怎么办？\n\n别紧张，直接按下Windows键和D键，桌面出现了。\n\n\n\n屏幕放大\n有时出门忘记带眼镜了，电脑上的字太小，看不清怎么办？\n\n别着急，教你使用窗口放大镜，立刻解决这一问题。\n\n按住windows键，然后使劲连续按加号键\n\n屏幕就会变得很大，直到你满意为止。\n\n然后按住windows键，连续按减号键，屏幕又可以回到原来的样子。\n\n\n新建文件夹\n通常新建文件夹都需要3个步骤，“右键-&gt;新建-&gt;文件夹”,费时费力，效率太低了，那么怎么办呢？\n\n按住“Ctrl+Shift+N”键，立刻新建文件夹。\n步骤记录器\n实验室来学弟了，老师让你带带，你把一些软件演示了好几次，他还是没学会，而你又没更多的时间再去手动演示。\n\n这个时候，步骤计步器就体现它的作用了。\n\n按下windows键+R，输入psr.exe回车，然后点击“开始记录”就可以了。\n\n它会记录下你做的所有操作，然后生成一个图文并茂的详细文档,单击停止记录后，会将详细记录文档保存到一个压缩文件中。\n\n\n屏幕虚拟键盘\n有时突然急需要一台电脑操作文件，但发现它们的键盘居然是坏的。稳住，别慌~\n\n这时候，用鼠标打开运行栏，输入osk，电脑自动会出现炫酷虚拟键盘！\n关闭浏览器当前页面和当前文档\n浏览器打开了很多页面，用鼠标挨个去关太费劲，没关系，按Ctrl+W键，快速帮你搞定。\n\n打开的文档太多，找不到你想要的文档，拖慢电脑速度，买关系，按Ctrl+W键，帮你关掉它。\n\n\n一次性快速设置\n如果有很多设置需要重新操作，比如调整显示器亮度、音量大小，打开无线网，还要看本本电池电量。\n\n只需要按下Windows键+X，一次性满足所有要求。\n清缓存刷新\n很多Java程序员在写网页的时候，明明源码已经改过来了，可是浏览器上显示的页面还是不多，这个时候你就得考虑是不是缓存的问题了。\n\n按住“Ctrl+F5”键，清缓存刷新，帮你解决因为缓存而带来的问题。\n\n\n文档打印\n去打印店打印东西，打印店的小哥太忙没时间招呼你。\n\n别急着，没有他，自己也能打印。\n\n按住“Ctrl+P”键，帮你打印文档。\n\n\n","categories":["技术博客"],"tags":[]},{"title":"C/C++、Java和Python开发工具一网打尽","url":"http://tanqingbo.cn/2017/07/25/C语言与Java开发工具汇总/","content":"前言在我们埋头于代码死磕的时候，会发现一个好的开发工具往往会起到事半功倍的效果，本帖子总结了C语言与Java几个比较流行的开发工具，希望能对大家有用。另外，本文将持续汇总各种开发语言中使用的优质工具，欢迎小伙伴推荐，互利互助，发我邮件：&#x31;&#x37;&#x42;&#x39;&#48;&#x33;&#48;&#50;&#55;&#x40;&#115;&#116;&#x75;&#x2e;&#104;&#x69;&#x74;&#x2e;&#101;&#100;&#x75;&#x2e;&#x63;&#x6e;格式要求：工具名，工具介绍，网盘地址\nJava开发工具IntelliJ IDEA\nIDEA 全称 IntelliJ IDEA，是java语言开发的集成环境，IntelliJ在业界被公认为最好的java开发工具之一，尤其在智能代码助手、代码自动提示、重构、J2EE支持、各类版本工具(git、svn、github等)、JUnit、CVS整合、代码分析、 创新的GUI设计等方面的功能可以说是超常的。IDEA是JetBrains公司的产品，这家公司总部位于捷克共和国的首都布拉格，开发人员以严谨著称的东欧程序员为主。它的旗舰版本还支持HTML，CSS，PHP，MySQL，Python等。免费版只支持Java等少数语言。获取地址\n链接：http://pan.baidu.com/s/1pKPbhMz\n密码：e8la\n\nmyeclipse\nMyEclipse 是一个十分优秀的用于开发Java, J2EE的 Eclipse 插件集合，MyEclipse的功能非常强大，支持也十分广泛，尤其是对各种开源产品的支持十分不错。MyEclipse可以支持Java Servlet，AJAX，JSP，JSF，Struts，Spring，Hibernate，EJB3，JDBC数据库链接工具等多项功能。可以说MyEclipse是几乎囊括了目前所有主流开源产品的专属eclipse开发工具。获取地址\n链接：http://pan.baidu.com/s/1eRC2pUy \n密码：bgr0\n\neclipse\nEclipse 是一个开放源代码的、基于Java的可扩展开发平台。就其本身而言，它只是一个框架和一组服务，用于通过插件组件构建开发环境。幸运的是，Eclipse 附带了一个标准的插件集，包括Java开发工具（Java Development Kit，JDK）。获取地址\n链接：http://pan.baidu.com/s/1bp8KSs3 \n密码：tyut\n\nC/C++开发工具Visual Studio 2017\nVisual Studio 2017是微软于2017年3月8日正式推出的新版本，是迄今为止 最具生产力 的 Visual Studio 版本。其内建工具整合了 .NET Core、Azure 应用程序、微服务（microservices）、Docker 容器等所有内容。获取地址\n链接：http://pan.baidu.com/s/1nuHDGXN \n密码：fm84\n\nCode::Blocks\nCode::Blocks 是一个开放源码的全功能的跨平台C/C++集成开发环境。 Code::Blocks是开放源码软件。Code::Blocks由纯粹的C++语言开发完成，它使用了著名的图形界面库wxWidgets(2.6.2 unicode)版。对于追求完美的C++程序员，不必忍受Visual Studio的庞大和高昂的价格。获取地址\n链接：http://pan.baidu.com/s/1qY6Yzgg \n密码：tbah\n\npython开发工具Pycharm\nPyCharm是一种Python IDE，带有一整套可以帮助用户在使用Python语言开发时提高其效率的工具，比如调试、语法高亮、Project管理、代码跳转、智能提示、自动完成、单元测试、版本控制。此外，该IDE提供了一些高级功能，以用于支持Django框架下的专业Web开发。获取地址\n链接：http://pan.baidu.com/s/1dFb6KU1 \n密码：x9vm\n\n","categories":["资源分享"],"tags":[]},{"title":"Java学习视频教程一网打尽","url":"http://tanqingbo.cn/2017/07/25/Java学习视频教程一网打尽/","content":"前言对于自学Java的初学者来说，一定会非常希望有个大神带你一步一步由浅入深系统的学习Java知识，绕过所有的坑，那么跟着视频教程学肯定是最好的途径了。本文汇总java开发中使用的优质视频教程，希望对你在学习Java的道路上有所帮助。\nJava基础视频教程\n本套视频可谓目前同类视频中代码量最大、案例最多、实战性最强的Java基础视频。本教程注重技术原理剖析，同时全程贯穿代码实战，用实践驱动理论，所有知识点的讲解都围绕实际案例展开，并配有相应的代码练习。获取地址\n链接：http://pan.baidu.com/s/1dFCK7uD \n密码：nsjx\n\njQuery视频教程\njQuery是一个快速、简洁的JavaScript框架，是继Prototype之后又一个优秀的JavaScript代码库（或JavaScript框架）。jQuery设计的宗旨是“write Less，Do More”，即倡导写更少的代码，做更多的事情。它封装JavaScript常用的功能代码，提供一种简便的JavaScript设计模式，优化HTML文档操作、事件处理、动画设计和Ajax交互。获取地址\n链接：http://pan.baidu.com/s/1b6mYn0    \n密码：hazq\n\nbootstrap视频教程\nBootstrap是目前很受欢迎的前端框架。Bootstrap 是基于 HTML、CSS、JavaScript 的，它简洁灵活，使得 Web 开发更加快捷。获取地址\n链接：https://pan.baidu.com/s/1bwFYYAt3IO25U3UFV5t_0A \n密码：igcz\n\nStruts2视频教程\nStruts2是一个基于MVC设计模式的Web应用框架，它本质上相当于一个servlet，在MVC设计模式中，Struts2作为控制器(Controller)来建立模型与视图的数据交互。获取地址\n链接：http://pan.baidu.com/s/1o8Txkts \n密码：ju0x\n\nhibernate视频教程\nHibernate是一个开放源代码的对象关系映射框架，它对JDBC进行了非常轻量级的对象封装，它将POJO与数据库表建立映射关系，是一个全自动的orm框架，hibernate可以自动生成SQL语句，自动执行，使得Java程序员可以随心所欲的使用对象编程思维来操纵数据库。本教程主要包括：Hibernate框架概述&amp;安装、 hibernatetools 插件、hibernate.cfg.xml 、hibernate 映射文件、详解 hibernate 映射文件等。获取地址\n链接：http://pan.baidu.com/s/1miPx7F6 \n密码：8dgv\n\nmybatis视频教程\nmybatis同hibernate一样，也是持久层框架，hibernate可以自动生成SQL语句，从操作上来说，hibernate使用起来更顺手，但是效率相对来说比mybatis要低。获取地址\n链接：http://pan.baidu.com/s/1pL5E8EB \n密码：aeyb\n\nspring视频教程\nSpring 是一个开源框架，是为了解决企业应用程序开发复杂性而创建的。框架的主要优势之一就是其分层架构，分层架构允许您选择使用哪一个组件，同时为 J2EE 应用程序开发提供集成的框架。获取地址\n链接：http://pan.baidu.com/s/1b7QJbo \n密码：ubm1\n\n\n后续还会陆续更新学习Java基础和各大框架的笔记，欢迎大家在讨论区留言。\n此外，本文还将继续汇总各种视频教程，大家期待后续更新，如果小伙伴们有什么好的资源，欢迎给我推荐，大家互惠互利。资源可以发我邮箱：&#49;&#55;&#x42;&#57;&#48;&#x33;&#48;&#x32;&#x37;&#64;&#x73;&#x74;&#117;&#x2e;&#104;&#x69;&#116;&#x2e;&#101;&#100;&#117;&#46;&#x63;&#110;\n\n","categories":["资源分享"],"tags":[]},{"title":"Java必看图书籍一网打","url":"http://tanqingbo.cn/2017/07/25/Java必看图书籍一网打尽/","content":"前言对于程序员来说，个人感觉最佳学习方式是看书，视频花费时间太长，而博客则不够系统。初学相关领域最好的方式就是找到一本经典的好书，然后啃完它。本贴子收集了几本Java学习的经典书籍，从入门到深入，每一个阶段都有对应的学习书籍，希望能帮到你。\nJava基础Java编程思想(第4版)\n本书赢得了全球程序员的广泛赞誉，即使是最晦涩的概念，在Bruce Eckel的文字亲和力和小而直接的编程示例面前也会化解于无形。从Java的基础语法到最高级特性（深入的面向对象概念、多线程、自动项目构建、单元测试和调试等），本书都能逐步指导你轻松掌握.获取地址\n链接：http://pan.baidu.com/s/1boYndmv \n密码：vvod\n\nJava核心技术 卷Ⅰ 基础知识(第8版)\n这本书在Java领域是和Java编程思想齐名的一本书，很多知识点都讲的特别细，我初次看的时候发现课上好多没讲的基础知识这本书上都提到了，非常有助于你练好扎实的基础知识。获取地址\n链接：http://pan.baidu.com/s/1eSb4H7k \n密码：7rt9\n\nJava中级大话设计模式\n设计模式体现的是一种思想，思想是指导行为的一切。理解和掌握设计模式，记住23种或者更多的设计场景和解决策略是不够的，更要接受一种思想的熏陶和洗礼。\n本书通过故事讲述程序如何设计。希望能给渴望了解面向对象程序设计的初学者及困惑、无法复用的代码编程体验者一些好的建议和提示。获取地址\n链接：http://pan.baidu.com/s/1c13cVuw \n密码：ur4q分布式Java应用基础与实践\n本书介绍分布式Java应用涉及的知识点，分为基于Java实现网络通信、RPC；基于SOA实现大型分布式Java应用；编写高性能Java应用；构建高可用、可伸缩的系统四个部分，共七章内容。获取地址\n链接：http://pan.baidu.com/s/1miFod5m \n密码：bmk0 \n\nJava并发编程实践\n《JAVA并发编程实践》随着多核处理器的普及，使用并发成为构建高性能应用程序的关键。Java 5以及6在开发并发程序中取得了显著的进步，提高了Java虚拟机的性能以及并发类的可伸缩性，并加入了丰富的新并发构建块。在《JAVA并发编程实践》中，这些便利工具的创造者不仅解释了它们究竟如何工作、如何使用，还阐释了创造它们的原因，及其背后的设计模式。获取地址\n链接：http://pan.baidu.com/s/1kVwtukv \n密码：1oom\n\nJava高级大型网站技术架构：核心原理与案例分析\n该书通过梳理大型网站技术发展历程，剖析大型网站技术架构模式，深入讲述大型互联网架构设计的核心原理。获取地址\n链接：http://pan.baidu.com/s/1i5N1LxN \n密码：s5j5\n\n代码整洁之道\n这本书重在对细节的关注。书的编排极其合理，从最小的点开始一点点往大处讲。感觉对刚开始工作的小朋友们，代码看得、写得还不够多，读设计模式之类的书可能还没什么体会。但这本代码细节的书，却是能立竿见影，直接用到工作中去的。获取地址\n链接：http://pan.baidu.com/s/1geNp5jd \n密码：9qpo\n\n","categories":["资源分享"],"tags":[]},{"title":"科学上网 | Ubuntu使用shadowsocks翻墙","url":"http://tanqingbo.cn/2017/07/19/Ubuntu使用shadowsocks翻墙/","content":"前言之前用的图床倒闭了，所以这篇博客上有部分图片显示不出来，如果看不懂的话可以看这篇科学上网（翻墙）之—Shadowsocks篇,图片可以正常显示，很多人都是看了这篇成功科学上网的。\n换一个新地方干活的时候，比较烦人的是，机器工作的环境又得重新配一遍。这边的活都得在Linux下才能完成，实在受不了国内的百度搜索引擎，所以又在Ubuntu下重新配了一次shadowsocks翻墙，耽误了不小时间，干脆自己动手总结一下。\n工具\n需要chrome浏览器，Ubuntu下安装chrome浏览器教程链接：http://jingyan.baidu.com/article/335530da98061b19cb41c31d.html\n\n初步安装\n更新软件源\n  sudo apt-get update\n\n安装pip （一个安装和管理 Python 包的工具）\n  sudo apt-get install python-pip\n  sudo apt-get install python-m2crypto\n\n通过pip安装shadowsocks\n  sudo pip install shadowsocks\n\n若在执行过程中出现黄色警告，改用如下命令：\n  sudo -H pip install shadowsocks\n配置shadowsocks\n在/home路径下建一个shadowsocks.conf文本文件\n   sudo gedit shadowsocks.conf\n\n在文件中添加如下信息：\n      &#123;\n          &quot;server&quot;:&quot;jp01.v2ss.xyz&quot;,\n          &quot;server_port&quot;:1018,\n          &quot;local_address&quot;:&quot;127.0.0.1&quot;,\n          &quot;local_port&quot;:1080,\n          &quot;password&quot;:&quot;*******&quot;,\n          &quot;timeout&quot;:300,\n          &quot;method&quot;:&quot;RC4-MD5&quot;\n      &#125;\n\n上述变量信息填写你自己的代理服务器信息，具体含义如下：\n      &quot;server&quot;:  服务器 IP (IPv4/IPv6)，注意这也将是服务端监听的 IP 地址\n      &quot;server_port&quot;:  服务端监听端口\n      &quot;local_address&quot;:&quot;  本地ip\n      &quot;local_port&quot;: 本地服务监听的端口\n      &quot;password&quot;:&quot;*******&quot;,  加密的密码\n      &quot;timeout&quot;:300, 超时时间间隔（秒）\n      &quot;method&quot;:&quot;RC4-MD5&quot; 加密方法 需要和服务器端一样\n\n配置完成之后运行如下命令，start表示开启服务，stop便是关闭服务。\n  sudo sslocal -c /home/shadowsocks.conf -d start\n遇到的问题\n使用 sslocal 显示“ERROR methond rc4-md5 not supported ” 问题 ～～～\n解决办法\n在执行  sslocal 命令时候 会显示 shadowsocks 2.1.0，说明我们使用的shadowsocks版本太低。Ubuntu 默认的是2.1.0，目前最新版本是 2.8.2。安装最新的版本就可以啦。\n  sudo pip install shadowsocks --upgrade\n\n然后stop之后，重新运行上述sslocal 命令就可以啦。\n\n到此还不能实现翻墙，还需配置chrome浏览器。\n\n\n配置chrome浏览器\n第一步：我们需要下载一个chrome 浏览器的插件 Proxy SwitchyOmega，但是没有代理之前是不能从 Google 商店安装这个插件的，但是我们可以从 Github 上直接下载最新版：https://github.com/FelisCatus/SwitchyOmega/releases/.\n然后浏览器地址打开chrome://extensions/，将下载的插件托进去安装。\n第二步：安装完成之后，我们会在浏览器的菜单栏看到一个蓝色环形小图标，点击选项按钮：\n第三步：在情景模式中选择 proxy ，在代理服务器中的代理协议选择 socks5，本地代理服务器 127.0.0.1，代理窗口1080。完成之后，一定一定要点击下面的应用选项，进行保存！！\n第四步：测试。打开 www.google.com，你会发现好像打不开。\n\n\n\n这时候你会发现有一个资源未加载，我们点击它,再选择 proxy 代理，点击添加条件，完成刷新页面，如下图所示：\n\n\n\n再次打开www.google.com就好使了。\n\n\n\n之后，每次需要翻墙之前运行如下命令，就可以畅通无阻的上外网了。\n      sudo sslocal -c /home/shadowsocks.conf -d start\n\n哈哈，帅气~~\n\n\n","categories":["Linux"],"tags":[]},{"title":"ITK与VTK混合编程之ItkVtkGlue","url":"http://tanqingbo.cn/2017/05/03/ITK与VTK混合编程之ItkVtkGlue/","content":"ITK与VTK混合编程之ItkVtkGlue前言做医学图像处理的时候，通常都是利用ITK做图像处理，VTK做可视化，所以在图像处理的过程中有时需要ITK与VTK混合编程。该文档是基于Linux系统的，VTK在Linux下安装与ITK的安装很相似，ccmake的时候默认配置就好，具体参见Linux 下配置ITK.在ITK与VTK混合编程的时候需要安装另外一个工具ItkVtkGlue。下面就开始介绍如何安装ItkVtkGlue。\nItkVtkGlue\n首先需要下载ItkVtkGlue的源码包，下载地址： download ItkVtkGlue\n\n将ItkVtkGlue的源码包解压到ITK目录下，并在ITK目录下新建ItkVtkGlue-bin目录用来存放ItkVtkGlue的源码包的编译文件。\n      ~/ITK/itkvtkglue-bin$ ccmake ../ItkVtkGlue\n      ~/ITK/itkvtkglue-bin$ make\n\n配置与编译ItkVtkGlue的源码的方式和配置编译ITK程序的方式一样。\nCMakeLists.txt\n每一个ITK或者VTK程序都需要一个CMakeLists.txt文件，并放在同一个目录下，该文件包含了cmake的版本信息、程序执行的环境信息以及整个工程的信息，所以在执行ITK和VTK程序是必须要有CMakeLists.txt文件。\n\nITK与VTK混合编程时，CMakeLists.txt文件的信息如下：\n  cmake_minimum_required(VERSION 2.8)\n\n  project(SubtractImageFilter)\n\n  find_package(ITK REQUIRED)\n  include($&#123;ITK_USE_FILE&#125;)\n  if (ITKVtkGlue_LOADED)\n    find_package(VTK REQUIRED)\n    include($&#123;VTK_USE_FILE&#125;)\n  else()\n    find_package(ItkVtkGlue REQUIRED)\n    include($&#123;ItkVtkGlue_USE_FILE&#125;)\n    set(Glue ItkVtkGlue)\n  endif()\n\n  add_executable(SubtractImageFilter MACOSX_BUNDLE SubtractImageFilter.cxx)\n  target_link_libraries(SubtractImageFilter\n    $&#123;Glue&#125;  $&#123;VTK_LIBRARIES&#125; $&#123;ITK_LIBRARIES&#125;)\n\n在ccmake配置的时候会提示输入ItkVtkGlue的目录，类似输入ITK编译后的目录一样，在提示itkvtkglue目录路径的地方输入itkvtkglue-bin文件所在的目录就好了，然后程序就能正常编译了。\n找不到“itkImageToVTKImageFilter.h”的问题\n在程序的头文件中如果引入’itkImageToVTKImageFilter.h’头文件，会提示找不到该文件，这时需要下载一个工具包：InsightApplications.zip，下载地址：download InsightApplications。\n\n解压InsightApplications.zip文件，将itkImageToVTKImageFilter.h，itkImageToVTKImageFilter.txx从\\InsightApplications\\Auxiliary\\vtk文件夹找出添加到正在执行的工程文件，然后再编译就不会有错了。\n\n\n","categories":["Linux"],"tags":[]},{"title":"科学上网（翻墙）之---Shadowsocks篇","url":"http://tanqingbo.cn/2017/03/30/科学上网之VPN篇/","content":"科学上网（翻墙）之—Shadowsocks篇前言　　科学上网，又叫翻墙。说到这，问题就来了，既然要翻墙，那么什么是墙呢？great firewall, 中国特有的。就是国家对网络的封锁。想要看看外面的世界，就得翻墙。　　之前我有提到过用hosts翻墙，但是不太稳定，经常得更换源，还上不了youtubu，所以干脆就放弃了。我比较提倡用钱能解决的问题，尽量还是花些钱吧。方便、稳定、一劳永逸。所以今天给大家介绍花钱的翻墙办法。\n一枝红杏\n先摆一下一枝红杏的介绍：一支红杏网络加速器是銘佑科技（香港）有限公司，（也是老薛主机，不会跑路型）推出的网络加速器服务，基于Shadowsocks的科学上网方式，Shadowsocks是一款高性能的基于python开发的socks5代理，连接速度快，它会帮助你在互联网上冲浪时保护你的隐私和安全。支持 Windows、MAC OS X、cross platform、Android、IOS、openwrt等系统，是非常实用的网络代理软件。\n我买的就是一枝红杏的VPN，亲测真的很好用，网速很快，Google、youtubu、Facebook啥的都能上。下面就教大家怎么用起来。\n打开一枝红杏官网。翻到下面会有3中VPN的购买方式，如果是个人用的话，选择入门版就可以了，一个月50G足够用了。\n跳转到订购页面后可以先在右上角点击注册，注册一个新账号，然后在根据提示购买你的产品。另外偷偷提一嘴，在让你输入优惠码的时候输入：qj80。可以打8折。\n购买之后依次点击账号统计-&gt;查看详情，就能看到你购买的节点信息。好了，别着急。接下来需要下载一个软件Shadowsocks来辅助不科学上网。\n\nShadowsocks\n先放一个下载链接: https://download.csdn.net/download/tanqingbo/10320125\n下载好之后打开会在电脑右下角出现一个小飞机，如图：\n接下来到你购买账号的查看详情页面，每一个节点后面都会有一个对应的二维码，让二维码在屏幕上显示，右键右下角的小飞机-&gt;服务器-&gt;扫描屏幕上的二维码，扫描成功后单击确定之后节点就添加成功了，然后再一次将剩下9个节点的信息添加进来，你就可以开启你的外网之旅啦。\n然后右键右下角的小飞机-&gt;服务器。就能看到你配置的节点信息，随便选择一个节点就能上外网了。\n之后再右键右下角的小飞机-&gt;系统代理模式-&gt;PAC模式。之后再右键右下角的小飞机-&gt;启用系统代理。设置完之后，当你在上国内网站而不是上外网的时候，系统就不会跑一枝红杏的流量。互不干扰。\n最后再放一个一枝红杏的官网:https://order.yizhihongxing.cc/aff.php?aff=4818。\n\n我觉得还是蛮好用的\n","categories":["技术博客"],"tags":[]},{"title":"win8换win7教程","url":"http://tanqingbo.cn/2017/03/29/win8换win7教程/","content":"win8换win7教程前言重做系统相信很多小伙伴都get到了这个技能，U启动、大白菜、Ghost安装器…blablabla…一大堆。很多方法都可以帮助你重新换一个系统，但是在预装win8换win7的时候，小伙伴们可能会遇到这样一个问题：按照往常的方法装完系统重启电脑之后找不到系统了，硬盘启动项也找不到了，黑屏了。别慌，下面就教你怎么解决这个问题。\n转换硬盘格式\n由于预装win8的电脑硬盘是GPT格式，而win7系统貌似不支持这种格式，所以在换win7之前需要改一下硬盘的格式，这里主要介绍两种硬盘格式转换方式：\n第一种比较简单\n借助Diskgenius工具来实现格式转换，在转换之前需要将硬盘的主分区缩减至小于等于4个分区，然后打开Diskgenius工具，点击左上角“硬盘”选项，选中“转换成mbr格式”，然后稍等一会，点击“保存”就大功告成了，之后就可以按照之前你重做系统的方式重做系统了，怎么玩都行。这种方式不会清空硬盘里的文件，比较安全，但是并不适应所有的电脑。\n第二种方式比较通用\n通过doc指令实现硬盘格式转换，但是这种方式会清空硬盘所有数据、会清空硬盘所有数据、会清空硬盘所有数据（重要的事情说三遍），所以在转换之前需要备份硬盘里所有的数据。\n\n先进入U盘中的winPE系统，Win+R、cmd进入命令提示符：\n     1. 输入diskpart 回车--对分区操作\n\n  　　2. 输入select disk 0 回车--选择要操作的磁盘\n\n  　　3. 输入clean 回车--深度格式化磁盘\n\n  　　4. 输入 convert MBR 回车 -- 将磁盘转换为MBR分区形式。\n\n  　　5. 退出DOS并刷新\n\n如图所示;\n\n\n\n\n好了，大功告成，打完收工。之后再换成win7，或者换成其他系统对你就没有难度了。\n\n","categories":["技术博客"],"tags":[]},{"title":"Matlab实现Graph cut","url":"http://tanqingbo.cn/2017/03/20/Matlab实现Graph cut/","content":"Matlab实现Graph cut最大流最小割\n最大流最小割最开始从图论的概念中引来，讲述一个带有起点与终点并且具有边权值的网络图中，如何进行边的切割，把这个网络图分成独立的两个部分（或者多个部分），使得这个切割中被切割的边的权值之和最小。比如现在有一个网络图如下：\n\n那么要把这个图分割成两部分，如上虚线就是一种切割方式，消耗的权值3+4=7，当然，切割的方式有很多种，不同的切割对应不同的切割边权值，而最大流最小割就是找到一种切割方式使得切割的边的权值之和最小。\n最大流最小割应用到图像分割\n图像简单来说就是矩阵，对于灰度图像，那么就是一般的二维矩阵，矩阵中值得大小就是改点的灰度值，那么图像分割问题就是寻找到图像的边界，而边界肯定在两个像素值差别很大的邻域间，如果把两个邻域间的像素值的差定义为该领域的边权值，那么分割问题就转化为如何切割这些边的问题了，这样的模型就和上述的最大流最小割对应上了。有点、有边、有边权值，那么就可以运用上述理论分割图像了。\n图割理论\n理论化介绍都是直观上的对图像的操作，而实际变成现实的时候是要事先转化到一维或者直接调用相应的函数才能对二维图像进行操作。先介绍一维图割操作，在介绍二维如何转为一维。\n\n源点s与汇点t\n\n如下图所示的由五个点site组成的一维情况，假设最终我们要分成两类，那么就把这两类认为是源点s与汇点t好了，那么一次类推，如果要分成多个类的话，就可以加相应的节点s或者t表示他们的类就可以了。\n\n\n点与点之间的权值Smoothcost\n\n从下图上也可以看出在这个一维点与点之间相连接的权值就是Smoothcost项，图中为了简化只是画出了相邻的两个点之间有一条线连接，也就是他们之间存在着权值（这里图为一个无向图，也就是权值是没有方向之分的），正常情况下，可能每两个点之间都可能存在着联系，比如如果点1与点3之间，你也可以看成他们是连接的，只不过他们之间的权值为0而已。这也是matlab里面表示这一项点与点权值的时候用一个n*n维矩阵的原因（n为点数），像这里，如果权值的大小如上图所示定义的话，那么这个图的Smoothcost项的权值矩阵可以表示:\n 0 5 0 0 0\n 5 0 4 0 0\n 0 4 0 3 0\n 0 0 3 0 2\n 0 0 0 2 0\n\n\n\n点与源汇点（类点）之间的权值Datacost\n\n除了上述的Smoothcost项之外，图割理论中还有一种项就是Datacost，表示的是各个点到源汇点（类点）之间的权值大小，这一项的权值同样对于分割至关重要。比如我们知道点1与点2属于s，其他点属于t的话，那么最终优化的结果就是1-s,2-s之间的权值可能很大，3-s,4-s,5-s之间的权值都很小，这对分割最后的形式很重要。Datacost也可以用矩阵表示，用c表示类的话（这里只有s与t那么c为2），n表示点的个数的话，那么Datacost可以表示为一个c*n的矩阵了：\n 1 2 3 4 5\n 5 4 3 2 1\n最大流最小割的实现过程\n\n\n关于具体怎么解最大流最小割的方法有很多种，假设在上述Smoothcost和Datacost都定死的情况下，具体有以下几种方法实现：\n\nFord-Fulkerson方法（增大路径最大流算法）\nEdmonds-Karp（EK）算法实现\nDinic算法\nSAP算法(最短路径增广算法)\nPreflow push method(预流-推进最大流方法）\n\n\n详细参考如右：\n\n里面有详细的c语言代码，可供详细研究实现这个的过程。\ngraph cut之图割工具箱GCO3.0\n有了前面的介绍，我们大致了解了分割的过程，下面下载GCO3.0的源码，下载地址：http://vision.csd.uwo.ca/code/,在这里找到对应的内容即可。\n\n解压源码包之后里面会有一些c编写的代码以及另一个matlab版文件夹，如图：\n\nmatlab文件夹中有很多.m文件和一个C文件\n\n注意在使用这些代码时，matlab文件夹和外面的c编写的代码文件相对位置不要发生改变，因为在程序的执行过程中.m文件会调用.cpp文件。\n\n我们主要用到的是matlab文件中提供的函数对图像进行分割，在正式分割之前我们需要先自己编写几个辅助函数：\n\nDatacost1函数：用来计算点与类的权值datacost，代码如下:\n        function datacost = Datacost1(img,ctrs)\n          [m,n] = size(img);\n          num_lables = size(ctrs,1);\n          totalsizes = m*n;\n          datacost = zeros(totalsizes,num_lables);\n          for i = 1:totalsizes\n              Ip = double(img(i));\n              for j = 1:num_lables\n                   datacost(i,j) = (Ip - ctrs(j)).^2;  %计算datacost项\n              end\n          end\n\nneighbours1函数：计算点与点之间的权值neighbours，代码如下：\n          %%-------------------\n          %  每个点的灰度作为特征\n          %%-------------------\n          function Neighbours = neighbours1(img)\n          [m,n] = size(img);\n          totalsizes = m*n;\n          var_img = var(img(:)); %图像方差\n          %% 选择neigh=4四连通计算权值，neigh=8八连通计算权值\n          neigh = 4;\n          %%\n          if neigh == 4\n              %构建索引向量--生成距离的稀疏矩阵\n              i1 = (1:totalsizes-m)&#39;;\n              j1 = i1+m;\n              for i = 1:n\n                  i2_tem(:,i) = (i-1)*m + (1:m-1)&#39;;\n              end\n              i2 = i2_tem(:);\n              j2 = i2+1;\n              %对应边的值\n              ans1 = exp(-(img(i1(:))-img(j1(:))).^2/(2*var_img));\n              ans2 = exp(-(img(i2(:))-img(j2(:))).^2/(2*var_img));\n              %组合相应的向量：x位置，y位置，权值（注意必须都是列向量）\n              all = [[i1;i2],[j1;j2],[ans1;ans2]];\n          else\n              %构建索引向量--生成距离的稀疏矩阵\n              i1 = (1:totalsizes-m)&#39;;  %正右权值\n              j1 = i1+m;\n              for i = 1:n  %正下权值\n                  i2_tem(:,i) = (i-1)*m + (1:m-1)&#39;;\n              end\n              i2 = i2_tem(:);\n              j2 = i2+1;\n              for i = 1:n-1  %斜下权值\n                  i3_tem(:,i) = (i-1)*m + (1:m-1)&#39;;\n              end\n              i3 = i3_tem(:);\n              j3 = i3+n+1;\n              i4 = i3+1; %斜上权值\n              j4 = i3+m;\n              %对应边的值\n              ans1 = exp(-(img(i1(:))-img(j1(:))).^2/(2*var_img));\n              ans2 = exp(-(img(i2(:))-img(j2(:))).^2/(2*var_img));\n              ans3 = exp(-(img(i3(:))-img(j3(:))).^2/(2*var_img));\n              ans4 = exp(-(img(i4(:))-img(j4(:))).^2/(2*var_img));    \n              %组合相应的向量：x位置，y位置，权值（注意必须都是列向量）\n              all = [[i1;i2;i3;i4],[j1;j2;j3;j4],[ans1;ans2;ans3;ans4]];\n          end \n          %matlab函数生成稀疏矩阵（这么做的速度最快） %----------------\n          neighb = spconvert(all);\n          neighb(totalsizes,totalsizes) = 0; \n          Neighbours = neighb;\n          end\n\n\n\n有了上述的工具函数之后，我们就可以编程调用这些函数实现图像分割了，    下面给出综合起来的主程序：\n          clc;\n          clear;\n          img = imread(&#39;b_04_95.jpg&#39;);\n          img = double(img);\n          % 定义分类数Numlables\n          Numlables = 2;\n          % 定义Potts模型参数K\n          Potts_K = 1500;\n          [m,n] = size(img);\n          totalsizes  =n*m;\n          %k-means预分类找到中心与分类\n          %init_lable预分类，列向量； ctrs-类中心灰度值值\n          [init_lable,ctrs] = kmeans(img(:),Numlables);  %img通过索引转化为列向量可用\n          ctrs_new = zeros(Numlables,1);\n          % 生成目标体\n          h = GCO_Create(totalsizes,Numlables);\n          %设置初始标签\n          GCO_SetLabeling(h,init_lable);\n          %设置datacost项\n          datacost = Datacost1(img,ctrs);\n          datacost = datacost&#39;;\n          GCO_SetDataCost(h,datacost);\n          %设置smoothcost\n          %不设置的时候默认使用potts模型\n          SmoothCost = eye(Numlables);\n          SmoothCost = 1 - SmoothCost;\n          GCO_SetSmoothCost(h,SmoothCost);\n          %设置neighbors项\n          Neighbours = Potts_K*neighbours1(img);\n          GCO_SetNeighbors(h,Neighbours);\n          %显示输出结果\n          GCO_SetVerbosity(h,2);\n          %类标签运算顺序\n          GCO_SetLabelOrder(h,randperm(Numlables));\n          %膨胀算法\n          GCO_Expansion(h);\n          %获得该标签lables\n          Labeling = GCO_GetLabeling(h);  %列向量\n          % 释放内存\n          GCO_Delete(h);\n          %显示graph cut分类\n          for i = 1:length(Labeling)\n          img1(i) = ctrs(Labeling(i));\n          end\n          img1 = reshape(img1,m,n);\n          %绘制分割图\n          figure;\n          %原图像\n          subplot(1,2,1);imshow(img,[]);\n          title(&#39;原始图像&#39;);\n          %显示graph cut分类\n          subplot(1,2,2);imshow(img1,[]);\n          title([&#39;Potts模型参数:&#39;,num2str(Potts_K)]); \n\n因为涉及到matlab和C语言的混合编程，因此在执行上述代码之前需要先安装好C语言编译器，通常安装了VS软件就没什么问题了，然后在执行时可能会出现一个如下的错误：\n      Error using mex (line 206) \n      Unable to complete successfully.\n\n此时我们安装mex编译器，在matlab的命令行输入：\n          mex -setup\n\n根据提示选择y    和需要的编译器就可以了，程序再执行就会出现结果了。如题所示：\n\n另外可以通过调节Potts_K参数的值，以实现不同的效果。    \n\n参考博客：\n\nmatlab实现Max-flow/min-cut的方法\n 图像分割之图割工具箱GCO3.0的使用（二）\nGCO3.0的图割分割算法应用(三)        \n\n\n\n","categories":["技术博客"],"tags":[]},{"title":"Git教程","url":"http://tanqingbo.cn/2017/03/17/Git教程/","content":"版本控制为什么要进行版本控制？  最简单的例子，当我们用文字处理软件工作时（如Word）时需要进行修改，而有时候又不确定修改的内容是不是需要的，因此会产生许多个文件，如图：  \n \n每一个文件都是在之前的文件基础上进行微小的修改，久而久之，不但文件冗杂，而且还不清楚修改的内容是什么，是一种很杂乱的方式。\n而版本控制就是解决这一问题——通过记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。\n采取版本控制后，你可以将文件还原到之前的状态，比较各状态之间的细节从而查出是修改了哪个地方，找出哪里出了问题。甚至你可以随意删改项目中的文件，照样可以恢复到之前的样子，因而增加了容错率，提供了更多可能性。\n版本控制有三种，第一种是本地式版本控制，也就是在本地的硬盘上用数据库记录历代文件；第二种是集中式版本控制，通过一个服务器，多个用户连接到服务器进行文件的记录。而第三种是我们着重介绍的分布式版本控制，它将前两种结合起来，在本地和服务器都建立数据库，每次工作时从服务器克隆（clone）下来，同时又与服务器交互，从而兼顾协同性和安全性。\n我们所说的git就是一个分布式版本控制软件，GitHub就是一个git的托管服务。\n#git本地操作  \ngit设计简单，是完全分布式，允许成千上万个并行开发的分支(Branch)，有能力管理超大规模的项目，是目前首选的版本控制软件。\n##一、工作流程git的三个工作区域，对应着三种状态：git 工作流程如下：    \n\n在工作目录中修改文件。（modified）  \n\n暂存文件，将文件的快照放入暂存区域。（staged）  \n\n提交更新，找到暂存区域的文件，将快照永久性存储到 git 仓库目录。（committed）\n\n\n这是最基本的流程，需要时刻记住。  \n##二、安装gitgit官方网站下载对应自己电脑的版本，按照指引进行安装。\n##三、git使用知识  \n首先我们需要在本地创建一个仓库，用于存放历代版本。\n1.命令行中运用cd指令进入项目的目录，输入  \n    $ git init  \n这将创建一个名为.git的隐藏子目录。    \n2.git status:查看哪些文件处于什么状态  \n    $ git status\n    On branch master\n    nothing to commit, working directory clean\n   （创建git仓库后目录下没有文件时的情况）  \n   创建一个文件（test）后再使用git status命令，将会看到一个新的提示  \n    $ git status\n    On branch master\n    Your branch is up-to-date with &#39;origin/master&#39;.\n    Untracked files:\n    (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed)\n\n        test\n\n    nothing added to commit but untracked files present (use &quot;git add&quot; to track)\n\n    （新建的“test”文件出现在Untracked files下）\n3.git add：跟踪文件运行     \n    $ git add test\n此时再运行git status，会看到test文件已被跟踪，处于暂存状态(staged)，显示Changes to be committed    \n    $ git status\n    On branch master\n    Your branch is up-to-date with &#39;origin/master&#39;.\n    Changes to be committed:\n    (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage)\n\n        test\n4.git commit：提交更新至仓库  \n先用git status命令确定暂存区域准备妥当，再运行$git commit -m ”提交信息”（提交信息指本次提交的说明，类似于注释）    \n$ git commit -m &quot;first&quot;\n[master 5e43df6] first\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 test \n此时会显示提交成功的信息。  \n5.git diff：显示尚未暂存的改动（并不是所有改动）\n6.git rm test：删除暂存区域中的文件test\n7.git log:查看提交历史  \n$ git log\ncommit 5e43df6b6d003ea70444ee3125456fd75b066803\nAuthor: *** &lt;****@gmail.com&gt;\nDate:   Thu Mar 16 19:37:52 2017 +0800\n\nfirst\n\ncommit 1c83e2a07f0279ea510e2a323fada53166c3c657\nAuthor: *** &lt;****@gmail.com&gt;\nDate:   Thu Mar 16 19:16:26 2017 +0800\n\ntest  \n8.版本回退  \n  在git log命令中我们可以看到类似5e43……6803的一大串字符，那就是版本号（commit id）我们可以用 git reset命令回退到之前任何一个版本:    \n $ git reset --hard 1c83e2a0\n   HEAD is now at 1c83e2a test\n（版本号不必补全，Git会自动去查找）\n以上就是git的本地基本操作，包括创建一个仓库，更改、暂存和提交，查看仓库的提交历史，版本回退。  \n#分支分支是把工作从主线上分离开来，以免影响开发主线。在不同的分支上你可以尝试各种各样的增删改，实现不同的设想。而git的分支模型是它最突出的特点，也是git脱颖而出的原因。\n##一、分支概念在版本回退里，你可以回溯到之前的任意版本，而这些版本都是处于一条时间线上，这条时间线就是一个分支。默认的分支为master分支，本身可以看做一个指针，HEAD指针则指向master指针，如图：    \n    \n每次提交都会多出一个节点，指针也随之移动。当我们创建新的分支时，也就创建了一个新的指针，我们通过命令将HEAD指针移到新指针上：  \n新提交一次后，新指针向前移动，master指针不变，这就产生了分支：我们可以将两条分支合并，之后可以删掉新分支。  \n这样就完成了分支的合并。\n##二、分支使用1.git branch：查看当前所有分支      \n$ git branch\n* master\n（*标示当前分支，默认处于master分支）  \n2.git branch testing : 创建testing分支      \n$ git branch testing\n此时创建了testing分支，运行git branch命令验证       \n$git branch    \n* master\ntesting\n3.git checkout testing： 切换到testing分支      \n$ git checkout testing\nSwitched to branch &#39;testing&#39;\n此时主分支位于testing，运行git branch命令验证   \n$ git branch\n  master\n* testing\n4.git merge testing：将master分支和testing分支合并（假设处于master分支）  \n$ git merge testing\nAlready up-to-date.\n如果在两个不同的分支中，对同一个文件的同一个部分进行了不同的修改，则会产生冲突从而无法合并，只能手动解决后再合并。    \n5.git branch -d删除分支  \n$ git branch -d testing\nDeleted branch testing (was 1c83e2a).  \n#使用GitHubGitHub 是最大的 Git 版本库托管商，尽管这不是 Git 开源项目的直接部分，但如果想要专业地使用 Git，你将不可避免地与 GitHub 打交道。  \n###创建帐户及配置1.访问https://github.com进行注册  \n2.SSH访问：    \n$ cd ~/.ssh\n$ ls\n id_rsa        id_rsa.pub    known_hosts  \n 寻找到id_rsa命名的文件，.pub文件是公钥，另一个是私钥。    \n 如果找不到，可以运行如下命令创建它们    \n $ ssh-keygen  \n 进入github的帐户设置，点击左侧的SSH and GPG keys，将~/.ssh/id_rsa.pub公钥文件的内容粘贴到文本区，然后点击”Add key”    \n SSH访问配置成功###创建、维护和管理你自己的项目。1.点击页面右上角的＋号，点击New repository按钮   \nRespository name是必填项目，而其余都是选填项，可以默认。点击Create respository按钮  ，即创建了一个新的仓库这时候可以将项目分享给其他人，通过HTTP和SSH的形式。  \n 2.对仓库进行操作，使本地和github同步  \n     $ git remote add origin     **********（仓库地址）   \n    （添加远程仓库至本地）\n\n     $ git pull --rebase origin master    \n    （更新远程更新到本地）\n\n     $ git push -u origin master  \n    （将本地仓库和远程仓库合并）\n 在今后的项目工作中就是用以上命令同步本地和Github，需要记住。  \n 3.克隆仓库 我们可以将远程仓库的内容克隆到本地\n $ git clone git@github.com:Liuwt1997/github-photo.git\nCloning into &#39;github-photo&#39;...\nremote: Counting objects: 3, done.\nremote: Compressing objects: 100% (3/3), done.\nremote: Total 3 (delta 0), reused 3 (delta 0), pack-reused 0\nReceiving objects: 100% (3/3), 196.28 KiB | 67.00 KiB/s, done.\nChecking connectivity... done.\n   此时远程仓库的文件全部克隆至本地。\n 4.添加合作者点击边栏的 “Settings” 链接，然后从左侧菜单中选择 “Collaborators” 。 然后，在输入框中填写用户名，点击 “Add collaborator.” 此时可以给予他们提交的权限。  \n    \n5.Fork按钮可以将他人项目派生下来，在你的空间中创建一个完全属于你的项目副本。  \n   \n如何对项目做出贡献呢？    \n\n将派生出的副本克隆到本地\n\n创建出名称有意义的分支\n\n修改代码\n\n检查改动\n\n将改动提交到分支中\n\n将新分支推送到 GitHub 的副本中    \n\n\n现在到 GitHub 上查看之前的项目副本，可以看到 GitHub 提示我们有新的分支，并且显示了一个大大的绿色按钮让我们可以检查我们的改动，并给源项目创建合并请求。    \n如果你点击了那个绿色按钮，就会看到一个新页面，在这里我们可以对改动填写标题和描述，让项目的拥有者考虑一下我们的改动。通常花点时间来编写个清晰有用的描述是个不错的主意，这能让作者明白为什么这个改动可以给他的项目带来好处，并且让他接受合并请求。  \n以上就是简单的Github的使用方法。    \n参考资料：        \n\nhttps://git-scm.com/book/zh/v2\n廖雪峰git教程\n\n","categories":["技术博客"],"tags":[]},{"title":"Young Forever","url":"http://tanqingbo.cn/2017/03/17/Young Forever/","content":" Young Forever　  　　这两天太阳很暖，和儿时的小伙伴坐在院子里聊天，不经意间发现不知道从什么时候开始，我们已经是大人了，时间就是会有这样的魔力，让你在某个午后突然意识到它已经流逝。\n 　　 电视机中静电的声音和秒钟转动的声音一直在耳边响，现在是大年初一的凌晨一点多钟，2016年算是彻彻底底的过去了，总觉得应该写点什么来东西记念一下。\n 　　 考试、为保研做准备这应该是2016年上半年的主要节奏，从实验室到宿舍需要20分钟的路程，每天晚上和阿勇在回寝的路上都会再讨论一会， hashmap的内部实现、线程安全、网络窗口阻塞机制…… 很多类似的问题都有幸成为了我们回寝路上的佐料。后来，春招来临，实验室里凡是找工作的同学都签了很好的公司去实习，而保研同学的情况却仍处在冬季，一点动静都没有，本来信念就不是很坚定的我，看着身边的同学一个个都有了着落，羡慕、着急、后悔，心里各种滋味都有，既担心自己没人要，同时也一刻都不能放松。生活就是这样，越是痛苦的日子，越是记忆深刻，汗水流过额头，有过痛苦，也有过开心，庆幸的是我最终也找到了属于自己的梦想归属地。\n  　　暑假最让我开心的事情是去了趟泰山，大学期间有过很多次说走就走的旅行，对于一个混迹青旅的老司机来说，美景、美食、啤酒、民谣、艳遇，这些都不那么重要。重要的是能在路上结识很多很潇洒的人，不管是朝九晚五还是浪迹天涯都很潇洒，这样的朋友结识多了之后，当自己在四处碰壁的时候心中就会有足够的信念支撑自己走下去，因为你清楚的知道并不是行不通，而是自己还不是足够的优秀，于是又有了前进的动力。外面的世界对我的吸引力很大，有个朋友曾经跟我说过，浪迹天涯，至死方休。我没有他那么大的勇气，我只想尽自己的能力，去外面的世界多看一眼，再多看一眼。\n  　　一般没有什么特别的事情，日子会过得很快，并且慢慢消退。毕业设计开题后不久我们宿舍就经常找机会出去撸串，啤酒、烤串，室友聚会永恒不变的主题。啤酒一杯一杯的下肚，宿舍内特有的“文化氛围”慢慢显现出来，各种打闹和wuli段子满天飞，这样的酒喝一次少一次。以后可能还会遇到很好室友，但是像这么合拍的室友很难遇到了。随着毕业的临近，面临的告别越来越多，向朋友告别，向课桌和椅子告别，最重要的是向母校告别，是她给了我探索这个世界的勇气，来时空空行囊，归去却，豪情万丈。\n  　　最喜欢哈尔滨的冬天，冰和雪的世界，很是漂亮。在这里有过痛苦的经历，也有浪漫的回忆，雪花飘落，掩埋了痛苦的经历，而那些浪漫的回忆会带着闪耀在心中生根发芽。\n  　　村上春树在他的书中说：“到死都是18岁”。我只想趁着年少无知，朝着心中的盖世英雄梦一步步迈进。\n  　　昨天的雾很大，看不清楚路，但随着太阳的升起，很多东西都清晰了许多。\n  　　天亮了。农历2017年的第一天。会是个大晴天吧？  \n \n![](https://github.com/tqb4342/BlogPhoto/blob/master/2017-01-28%2004.55.36%201.jpg?raw=true) \n![](https://github.com/tqb4342/BlogPhoto/blob/master/2017-02-25%2011.30.20%201.jpg?raw=true) \n![](https://github.com/tqb4342/BlogPhoto/blob/master/2017-03-13%2003.04.07%201.jpg?raw=true)   \n","categories":["漂来漂去"],"tags":[]},{"title":"分块程序执行","url":"http://tanqingbo.cn/2017/03/01/分块程序执行/","content":"前言分块程序依然是基于ITK的，但是借助的辅助工具比较多，有一些还需要自己编译过后才能用，但是都可以在网上下载得到，先介绍一下工具MEPP、SPHARM-PDM-master和ParaView这3个工具的获得，在介绍程序执行的具体步骤。\nMEPP和SPHARM-PDM-master\n这两个工具的编译过程在关于环境配置的一些事中有介绍。\nMEPP/build中的mepp和SPHARM-PDM-master/build/SPHARM-PDM-build中的GenParaMeshCLP、ParaToSPHARMMeshCLP、SegPostProcessCLP的文件是我们最后需要的，用的时候拷贝到需要的地方就可以了。ParaView\n这是个3维图像软件，从官网下载即可，如果是Linux版本的话，打开bin文件夹下的paraView即可，主要用来做3维文件的格式装换。分块程序执行步骤\n\n\n先将nrrd格式的二值图像文件转化为nii格式的，转化的代码在此处获得：nrrd2nii。\n\n将GenParaMeshCLP、ParaToSPHARMMeshCLP、SegPostProcessCLP和nii文件放到同一文件夹下，在此文件夹下运行GeneralMesh脚本，脚本内容如下：\n     #!/bin/bash\n\n     mkdir brain-segout\n     for ((a=0; a &lt;= 19; a++))\n     do\n         ./SegPostProcessCLP brain-$a.nii brain-segout/brain-$a-segout.vtk --space 1.5,1.5,1.5\n     done\n     mkdir brain-meshout\n     for ((a=0; a &lt;= 19; a++))\n     do\n         ./GenParaMeshCLP brain-segout/brain-$a-segout.vtk brain-meshout/brain-$a-para.vtk brain-meshout/brain-$a-surf.vtk --label 1\n     done\n\n\n        mkdir brain-align\n\n        for ((a=0; a &lt;= 19; a++))\n        do\n            ./ParaToSPHARMMeshCLP brain-meshout/brain-$a-para.vtk brain-meshout/brain-$a-surf.vtk brain-align/brain-$a \n        done\n\n数据名字与数据个数随自己的数据情况修改。\n\n执行这个脚本需要很长时间，待执行完之后，在brain-align文件加下会出现brain-$aSPHARM_ellalign.vtk形式的文件，先用ParaView软件将该类型的文件挨个转化为.ply格式，然后用mepp软件将.ply文件转化为.off文件，在保存的时候会跳出两个提示框：Do you want to save colors?、Do you want to save normals?，都选择NO就行，得到的.off 文件需要去掉第二行（mepp的注释）。\n\n进入meshSegmetation,该文件夹里有meshSeg.cpp等程序及CmakeList.txt,新建build文件夹,在build下面新建data和training两个文件夹，data里面放测试数据，training里面放训练数据，都是.off文件。\n\n用average.cpp求data里面数据的平均值，根据数据的情况修改average.cpp文件，会得到meanShape_liver.off，将meanShape_liver.off保存到meshSegmetation/build中。\n\n在meshSegmetation/build中ccmake、make、./main后得到shapeVariation_Face.csv和shapeVariation_Vertex.csv，将这两个文件放到MEPP/build中，打开mepp软件，用该软件打开meshSegmetation/build中的meanShape_liver.off文件，点击components——segmentation——VSA——Variation Segmentation，修改Region Number为要分的块数，数字不要太大，否则会崩掉，再点击components——segmentation——VSA——Face Label to Map，会得到’seg.csv’。\n\n将得到的seg.csv放入到meshSegmetation/build文件夹中，并在该文件夹中建labels 、segs 和 segsF三个文件夹，注释掉meshSeg.cpp中的前3行有用代码，重新编译，运行main\n         ./main\n\n最终结果会出现在segsF文件中，用mepp软件打开便可以看到分块的情况。\n\n\n","categories":["东搞西搞"],"tags":[]},{"title":"关于环境配置的一些事","url":"http://tanqingbo.cn/2017/02/28/关于环境配置的一些事/","content":"前言  最近干的活有很多涉及环境配置的工作，有很多细节需要注意，稍有疏漏就有可能让你捣鼓一天，因此把这些环境配置的细节和步骤整理下来以便往后查看。主要分为两个部分，分块程序环境配置和图谱程序环境配置，具体如下：\n分块程序环境配置\n首先接受介绍一款Linux系统下软件包下载神器：新立得（Synaptic），它是Linux操作系统的包管理工具apt的图形化前端。它可以以图形界面代替apt-get install命令来对软件包进行下载，因此我们在配置环境之前先安装新立得（Synaptic），指令如下：\n    sudo apt-get install synaptic\n\n分块代码主要需要配置MEPP和SPHARM-PDM-master这两部分代码的运行环境，我之前用Ubuntu 16.04版本的系统试验的时候，多次失败，后来改为14.04后一次成功，所以在陪环境的时候不要用高版本的Ubuntu系统。默认已经装好了g++，以及make，如不知道怎么装，移步Linux 下配置ITK\nMEPP\n\n\n建一个build文件夹存放make编译后的文件，在ccmake配置过程中，依次需要安装CGAL，用新立得（Synaptic）搜索CGAL，安装libcgal-dev.\n\n\n安装软件包qt4，用Synaptic搜索qt4，一直往下翻，安装libavahi-qt4-dev这个软件包。\n\n安装QGLViewer，用Synaptic搜索QGLViewer，安装libqglviewer-dev这个软件包。\n\n下载xerces源码包，源码包下载链接http://xerces.apache.org/xerces-c/download.cgi,先将xerces源码包解压到/usr/include文件加下（需要root权限），进入xerces文件家中执行如下语句(#号代表在root权限下)：\n      # chmod +x configure\n      # ./configure --prefix=/usr \n      # make\n      # make install\n\n之后在ccmake这一块应该就不会有什么关卡了，接下来就是make编译，大概需要等10多分钟，结束之后会出现一个mepp文件，要是能正常执行就说明大功告成了。\nSPHARM-PDM-master\n\n\n这个ccmake配置这一块很简单，也要建一个build文件夹存放make编译后的文件，然后安装一个git-svn和libsvn-dev,用Synaptic搜索SVN，安装git-svn和libsvn-dev软件包就可以了。\n之后用make编译，编译过程需要联网，时间会很长，大概要1-2个小时，中途没有报错，顺利完成就没有问题了。\n\n图谱程序环境配置\n要运行图谱的程序，需要先安装ITK，这是大前提，具体步骤在这：Linux 下配置ITK。\n接着需要安装eigen源码包，同上一样，用Synaptic搜索eigen，然后下载安装，文件保存在/usr/inlcude/目录下，进入到eigen文件中，把其中的Eigen文件夹拷贝到上一级目录中，这样才能起效。\n下载elastix，同样是在Synaptic中搜索，完事之后会在/usr/bin/文件夹中出现elastix和transfoxmix两个文件，然后拷贝到需要的地方去就行了。\n训练和分割是需要下载libblas-dev和liblapack-dev这两个源码包，方法如上，搜索libblas和liblapack。\n计算精度的代码需要下载libann-dev源码包，用Synaptic搜索libann。\n\n","categories":["东搞西搞"],"tags":[]},{"title":"分割ROI篇","url":"http://tanqingbo.cn/2016/11/14/分割ROI篇/","content":"###　获取灰度图像的ROI\n\n获取ROI之前需要需要数据对应的坐标，并存放到roi.txt文件夹中，并将roi.txt与getROI的代码可执行文件放到同意路径下，再执行程序便可以得到灰度图像的ｒｏｉ，原始灰度图像和和ROI图像对比如下：\n\n原始灰度图像:  \n\nROI图像:   \n\n将处理好的ＲＯＩ图像放到分割代码的training文件夹中，注意命名方式，序号从０开始。\n图谱处理以及分割\n使用3dseg软件对图谱进行处理，将目标器官分割出来。\n\n注意：用软件对灰度图谱和二值图谱进行分割是，二者的尺寸和坐标要完全一致。\n\n分割完之后也放入training文件夹中，命名方式：灰度－avg.nrrd;二值－avg_mask.nrrd.\n\n接着开始分割，不过需要注意的是，分割数据和图谱都是ROI，并且需要每组分割数据的坐标存放在roi.txt文件中,roi.txt文件放到ｂｕｉｌｄ中。分割代码的执行方式和之前一样，所不同的是会产生两个分割结果：ＲＯＩ结果FINALLL.nrrd，通过坐标处理后的正常大小分割结果FINALLLL.nrrd(比前面多了一个L)。\n\n分割时需要修改如下３个参数：\n  bool TUMOR_CASE_USE_PA_EQUAL_ONE = true;   //true/false\n  bool Use_Process_Ori_mask_9par = false;   //true/false\n  double PAThreshold = 0.2;　　//  0.2/0.9\n\n\n排列组合有８中可能，所以需要分割８次，保存每次的分割结果，注意最终结果的命名，以便区分。\n计算精度\n运行计算精度的代码时需要另外再下载 libann-dev,下载方式如下：\n  sudo apt-get install libann-dev\n\n或者用synatic直接搜索下载。\n\n然后配置和编译好的计算精度的代码，执行时需要两个参数，批量执行的脚本如下：\n  for((a=0;a&lt;=20;a++))\n  do\n   ./EvaluateSegmentationResult seg-spleen/FINALLL-$a-0.2-ff.nrrd refer-spleen/label-roi-$a.nrrd\n  done\n\n执行完之后会产生一个evaluation.txt文件，对比精度信息全部存在里面，如下图：\n\nJI表示程序分割与手动分割的数据重合率，值越大，说明效果越好，最大是１００．\n\nASD表示程序分割与手动分割的数据的边缘距离，值越小，说明效果越好，结果最好是，值为０．\n\n\n","categories":["东搞西搞"],"tags":[]},{"title":"图谱程序字典","url":"http://tanqingbo.cn/2016/11/14/图谱程序字典/","content":"掩码\n对掩码程序进行make编译后会生成一个main的可执行文件，执行该文件是需要传递3个参数，传递方式如下：\n      ./main 原始灰度图像.nrrd 对应的二至图像.nrrd 掩码后文件名.nrrd\n\n如果需要掩码的图像数量较多，可以写一个脚本批量处理，执行脚本前需要主要脚本的执行权限。\n\n\n图像对齐建立图谱\n该部分是进行图像分割的核心代码，代码量比较多，需要有很多细节需要注意。\n\n程序通过调用Traditional_Regi_Elastix函数建立图谱，共有4个参数，参数列表如下：\n      iterIndex   //当前的迭代次数，迭代次数在main函数中设置\n      numSamples  //数据集的个数\n      USE_HEALTHY_ATLAS_AS_REF  //USE_HEALTHY_ATLAS_AS_REF=false\n      ofstream &amp;ofs  //记录程序执行时间等信息\n\n为了方便程序的阅读，有些参数的默认值需要记住：\n      int Index_Atlas = 0;\n      bool use_Index_Atlas = true;\n      numTrainData = numSamples  //数据集的个数\n      FixedAsMoving = false;\n      FirstIterationAffine = false;\n      NON_GREEDY = true;\n      char * movingIm_Affine //存放将要对齐的图像集名\n      fixedIm  //存放平均模板名\n      char *EXE_REGISTER = &quot;./elastix&quot;; //elastix是一个可执行文件，程序中通过system调用，对齐的作用。\n\n\n程序运行说明\n将所有掩码后的数据集放到training文件夹中，命名格式为liver-mask_#.nrrd,#从0开始，且liver-mask_0.nrrd是初始的平均图像模板。初始模板的选择是通过手动挑选最接近平均目标分割图像的数据集。\n\n创建REG_UAB文件夹，用于存放每次Ii对齐到平均图像模板之后所产生的变换矩阵T和刚性与非刚性变换后的图片数据以及平均模板。\n\n每次迭代后产生的平均图形模板命名为：Average_UAB_iter#-0.nrrd\n\nNON_GREEDY用来控制要对齐的数据源，NON_GREEDY=true时，每一次迭代都是将原始的掩码图像（liver-mask_#.nrrd）对齐到平均图像模板上；NON_GREEDY=false时，第一次迭代是将原始的掩码图像（liver-mask_#.nrrd）对齐到初始的平均图像模板（liver-mask_0.nrrd）上，之后得迭代过程是将非刚性变换的数据集（Iter%d_%d_Warped.nrrd）对齐到平均图像模板上；本程序中是第二种情况：NON_GREEDY=true。\n\n刚性变换得到的数据集：Affine_Iter%d_%d_Warped.nrrd;非刚性变换得到的数据集：Iter%d_%d_Warped.nrrd;刚性变换得到的T：Affine_Iter%d_%d.txt;非刚性变换得到的T：BSpline_Iter%d_%d.txt。第一个%d是迭代的次数，第二个%d是第几个数据集。程序先求刚性再求非刚性。\n\n关于第0组数据，需要注意的：\n  Average_UAB_iter0-0.nrrd = liver-mask_0.nrrd\n  Average_UAB_iter0-0.nrrd = Affine_Iter0_0_Warped.nrrd\n  Average_UAB_iter0-0.nrrd = Iter0_0_Warped.nrrd\n\nAverage_UAB_iter#-0.nrrd由每一组数据非刚性对齐后的数据集（Iter%d_%d_Warped.nrrd）叠加求和再求平均得到的。\n\n\n新的肝脏初始化方法\n![概率图谱方法分割](http://chuantu.biz/t5/40/1477986372x3396789373.png)\n\n+ 上图的执行流程如下：\n    + 先将灰度图谱对齐到测试灰度图像上，得到一个刚性变换矩阵和一个非刚性变换矩阵；\n    + 将变换矩阵作用到二值图谱中得到变换后的二值图像；\n    + 将测试的灰度图像做似然运算，得到最大似然图像；\n    + 似然图像与变换后的二值图像做与运算，得到最终的分割结果。\n\n分割参数调节\n在做图像分割是，需要调节MAS_Elastix.cpp文件中如下三个参数：\n      bool TUMOR_CASE_USE_PA_EQUAL_ONE = false;   //true/false\n      bool Use_Process_Ori_mask_9par = false;     //true/false\n      double PAThreshold = 0.2;   //PAThreshold = 0.2/0.9\n\n每个参数都有两个取值，排列组合共有八中可能，所以最后分割数据需要测试八次，取其中结果最好的一次。\n\n\n训练图谱\n需要将灰度图像和二值图像作掩码之后才能开始训练图谱；\n\n掩码的结果又4种可能，因此对应的图谱也有4中结果，情况如下：\n      1.灰度图像与二值图像都不插值作掩码，训练得到图谱；\n      2.灰度图像插值、二值图像不插值，再作掩码，训练得到图谱；\n      3.灰度图像不插值、二值图像插值，再作掩码，训练得到图谱；\n      4.灰度图像与二值图像都插值，再作掩码，训练得到图谱。\n\n分别测试上述4种图谱，对比分割结果，取其中分割结果最好的图谱。\n\n\n","categories":["东搞西搞"],"tags":[]},{"title":"图谱训练与分割","url":"http://tanqingbo.cn/2016/10/29/图谱训练与分割/","content":"代码运行脑图\n![代码运行脑图](http://chuantu.biz/t5/39/1477716982x2728309575.png)\n## 每一步的运行过程说明\n### 对灰度和二值图像做插值（该步可以跳过）\n+ 插值是为了防止在训练的过程出现错误，所以相对灰度和二值图像做插值运算，插值代码在`UpsampleVolume_char-label`和`UpsampleVolume_short-img`文件夹中。\n+ `-label`作用二值图像，`-img`作用于灰度图像，使用前需要先`ccmake`和`make`一下进行配置和编译，然后将生成的`main`可执行文件拷贝到需要插值的文件夹中，执行`upsample`脚本文件就可以进行插值运算来，如果脚本文件不能执行需要先给执行权限，`upsample`脚本文件内容如下：\n\n            #!/bin/bash\n            mkdir upsample_label\n            for ((a=1; a &lt;= 40; a++))\n            do\n                ./main label-$a-flip-spleen-roi.nrrd upsample_label/label-$a-flip-spleen-roi-2.nrrd 1 1 2\n            done\n\n该脚本是作用于二值图像的例子，灰度图像也要重复上述过程。###　掩码运算\n\n掩码的代码在MASKImage文件夹中，同样使用前需要先ccmake和make一下进行配置和编译，然后执行mask-spleen脚本文件，注意脚本中文件的路径，mask-spleen脚本文件内容如下：\n      #!/bin/bash\n      for ((a=1; a &lt;= 40; a++))\n      do\n          ./main spleen-roi/upsample_img/img-$a-flip-spleen-roi-2.nrrd \n          spleen-label-roi/upsample_label/label-$a-flip-spleen-roi-2.nrrd mask_result-2/img-$a-flip-spleen-masked.nrrd\n      done\n\n如图：\n\n\n\n开始训练\n训练的代码在atlas_*_UAB文件夹中，先在此文件夹中建build文件夹，并在build中进行配置和编译。\n\n执行mkdir_file脚本，在build中生成必要的文件夹，将elastix、parameters_BSpline.txt、parameters_Affine.txt、transformix这4个文件拷贝到build中，这个很重要！！！\n\n将掩码后的nrrd文件拷贝到training文件夹中，规范命名，将手动挑选的初始模板与第0组交换。\n\n执行编译后生成的asm的文件，如图：\n\n如果运行出错，需要重新下载elastix和transformix文件，下载方式如下：\n      sudo apt-get install elastix\n\n然后将/etc/bin中的elastix和transformix文件替换掉原来的elastix和transformix文件，重新执行asm文件。\n\n如果数据很多的话，训练过程需要很久，一、两天也有可能，慢慢等吧。\n\n\n计算图谱\n在计算图谱之前需要将最后一次迭代矩阵作用于最初的灰度和二值图像，建两个文件夹‘img_txt’、label_txt分别处理灰度和二值图像。\n将最后一次训练迭代的矩阵，即最后一次迭代产生的txt文件拷贝到‘img_txt’、label_txt文件中。\n执行mkdir_file脚本，生成必要的文件夹，用g++编译.cpp文件，interpolate0to3.cpp作用于img_txt中的txt,avgTranform.cpp作用于label_txt中的txt.如图：\n将最初的灰度和二值图像（nrrd）分别拷贝到‘img_txt’、label_txt文件中，注意命名方式和将手动挑选的初始模板与第0组交换。\n执行update脚本，将txt作用到nrrd上,结果保存在exampleoutput中，如图：\n将处理后的nrrd求平均，得到最终的图谱：avg.nrrd。需要先ccmake和make一下进行配置和编译求平均的代码，得到一个可执行文件main.\n执行main，传的参数为数据集的个数，如图：\n\n通过图谱对原始灰度图像进行分割\n训练的代码在MAS_*_UAB_FFD文件夹中，先在此文件夹中建build文件夹，并在build中进行配置和编译。\n执行mkdir_file脚本，在build中生成必要的文件夹，将elastix、parameters_BSpline.txt、parameters_Affine.txt、transformix这4个文件拷贝到build中，这个很重要！！！\n将图谱和要分割的原始灰度图像拷贝到training文件夹，灰度图谱命名：avg.nrrd,二值图谱命名：avg_mask.nrrd,原始灰度图像命名：liver-0.nrrd.\n在MAS文件夹中建一个文件夹用来保存分割后的结果，命名为：0.注：有多少组原始灰度图像，就需要有多少个保存结果的文件，命名方式依次递增。\n执行asm文件进行分割，如图：\n最后分割结果保存在0文件夹中，如图：\n\n","categories":["东搞西搞"],"tags":[]},{"title":"Linux 下配置ITK","url":"http://tanqingbo.cn/2016/10/23/Linux下配置ITK/","content":"前言对于一个程序员来说，linux系统相对与window来说有很多不可描述的优势，很多在window下不能跑的程序都能在Linux下跑，所以就有了这篇在Linux下配置ITK的博文，一方面是为来记录下来这次安装过程，方便以后自己查阅，同时也是希望当大家在Linux下配置时能提供一点帮助。\n准备工作\n安装cmake:用来编译ITK用的\n\n下载ITK源码包：http://www.itk.org/ITK/resources/software.html,下载最新版本的.tar.gz格式源码包就行。如：InsightToolkit-4.10.1.tar.gz\n安装cmake和ccmake\n第一次使用Linux时需要更新安装源，更新过可以忽略这个条，更新指令如下：\n      sudo apt-get update\n\n可以手动安装，也可以直接使用apt-get 安装，此处我使用后者,即：\n     sudo apt-get install cmake\n     sudo apt-get install cmake-curses-gui\n\n接着：\n      sudo apt-get install build-essential\n配置ITK1.1 为ITK创建目录，我建在/home目录下，命令如下     #cd /home\n\n     #mkdir ITK               //存放ITK源码                                     \n\n     #mkdir ITK/ITK-bin       //做为 ITK 编译目录\n1.2 解压　InsightToolkit-3.14.0.tar.gz 到目录 ITK\n可以在图形界面直接右键解压，然后拷贝到ITK目录\n\n也可以使用命令加压：\n   # tar -xf InsightToolkit-4.10.1.tar.gz  /home/ITK\n1.3 设置编译器环境变量\n在命令框中输入如下指令：\n  export CC=/usr/bin/gcc;  export CXX=/usr/bin/g++\n1.4 使用 CMake 配置 ITK\n进入到ITK编译目录\n      cd /home/ITK/ITK-bin\n\n编译ITK源码：\n   #ccmake ../InsightToolkit-4.10.1\n\n然后根据 CMake 下面的提示, 按 c 键, 进行 配置，接着出现类似 windows 下的选择界面，按照默认的设置就行，然后再按键 c 配置, 成功后按键 g 生成 ITK 编译文件。\n\n最后输入make命令编译ITK,这个过程大概需要20分钟。\n              #make\n\n到此Linux下配置ITK基本完成。\n\n\n测试是否配置成功\n在ITK目录下创建test测试目录\n        cd /home/ITK\n\n        mkdir test               //用于编译 ITK 代码, 为了目录结构清晰\n\n        mkdir test/src         //存放源代码\n\n        mkdir test/bin         //示例编译目标\n\n        mkdir test/src/HelloWorld\n\n        mkdri test/bin/HelloWorld\n\n到 /home/ITK/InsightToolkit-4.10.1/Examples/Installation/中将HelloWorld.CXX 以及 CMakelists.txt拷贝到 test/src/HelloWorld 中\n\n进入到test/bin/HelloWorld目录中编译源码:\n       cd test/bin/HelloWorld\n\n      ccmake   ../../src/HelloWorld\n\n如图所示：这时,可能提示找不到 ITK_DIR, ITK_DIR_NOTFOUND,使用箭头选择此项,然后按 enter 编辑,输入 ITK-bin 路径, 我的为 /home/ITK/ITK-bin,然后按 c 键进行配置, 按 g 键生成编译文件\n\n最后 #make    生成 HelloWorld 可执行文件\n\n生成的可执行文件如下图：\n\n执行该文件：\n      ./HelloWrold\n\n如图：\n\n\n\n\n显示ITK Hello World ! 证明ITK配置成功了。\n\n","categories":["Linux"],"tags":[]},{"title":"ITK在vs2010下安装与搭建","url":"http://tanqingbo.cn/2016/10/22/ITK在vs2010下安装与搭建/","content":"ITK在vs2010下安装与搭建前言ITK（ Insight Segmentation and Registration Toolkit）是一款医学图像处理软件包，是一个开源的、跨平台的影像分析扩展软件工具。对于从事医学图像处理的工作的人来说，ITK是一款必不可缺的工具。本文介绍了如何在win7 64位的环境下利用vs2010安装ITK。\n工具下载链接以及说明\n下载CMake:http://www.cmake.org/cmake/resources/software.html选择与电脑对应的版本，然后默认安装。\n\n下载ITK压缩包：http://www.itk.org/ITK/resources/software.html,   InsightToolkit-4.10.1.zip\n\n在 D 盘新建文件夹: D:/I_VTK/ITK , 之所以要多建立一个 ITK 文件夹, 是为了以后 ITK, VTK 混合编程,这里暂时只编译 ITK.\n\n解压InsightToolkit-4.10.1.zip到  D:/I_VTK/ITK\n\n再建立一文件夹 ITK_bin, 作为 ITK 编译目标. D:\\I_VTK\\ITK\\ITK_bin\n编译过程\n打开之前安装好的 CMAKE 进行配置. 假设你已经安装好 VS2010：\n   Where is the source code: 点击 Browse, 选择刚才 ITK 源码目录: D:\\I_VTK\\ITK\\InsightToolkit-4.10.1\n   Where to build the binaries: 点击 Browse, 选择 ITK 编译目标: D:\\I_VTK\\ITK\\ITK_bin\n\n点击Configure，选择“Visual Studio 10”编译器（如图2），点击Finish,之后出现如下界面\n\n\n\n\n勾选Advanced之后更改CMAKE_INSTALL_PREFIX（表示编译ITK后生成的 lib 及头文件等安装路径）目录可以设置为 D:/I_VTK/ITK\n\n\n\n再次点击 Configure, 直至所有条目都变成灰色,表示配置成功, 点击 Generate确认,如图：\n\n\n\n在ITK_bin文件下找到ITK.sln,右击选择VS2010打开，点击生成-&gt;生成解决方案，这个过程大概需要1个多小时。如果没有错误的话找到“INSTALL”文件右击，选择“仅生成项目”-&gt;“仅生成INSTALL”。如果没有错误就会在ITK文件夹下出现如下图所示的文件夹：\n然后设置ITK的环境变量：如：D:\\ITK\\ITK_bin,把bin下面的dll文件复制到c:\\windows\\system32 中。\n\n测试是否安装成功\n从ITK\\InsightToolkit-4.5.0\\Examples\\Installation目录下直接复制HelloWorld文件和所需的CMakeLists.txt文件。如在ITK文件下创建test文件夹，然后再test文件夹下创建Hello和Hello_bin文件夹，然后把前面复制的两个文件放入Hello文件夹中，启动cmake,按第二步的生成方法，把HelloWorld.cxx放入第一栏，把CMakeLists.txt放入第二栏，点击“Configure”，没错误直接点击“Generate”，然后用到Hello_bin中用VS2010打开HelloWorld,sln文件，右击HelloWorld，选择”设为启动项目“，然后点击运行即可。至此，ITK安装成功。\n\n","categories":["C语言"],"tags":[]},{"title":"基于稀疏表示变形模型的肝脏分割方法","url":"http://tanqingbo.cn/2016/10/20/基于稀疏表示变形模型/","content":"基于稀疏表示变形模型的肝脏分割方法前言肝脏图谱包括灰度图像和对应的标签图像，基于图谱的方法主要是利用肝脏图谱灰度图像到目标图像的非刚性配准来达到分割的目的，现有图谱方法存在如下缺点：\n    1. 图谱易偏向所选择的初始模板图像特定解剖结构\n    2. 灰度图像对其到目标图像是易产生较大配准误差\n 为了解决上述问题，提出了基于稀疏表示变形模型。\n肝脏分割方法\n新提出的肝脏分割方法主要包括训练和测试连个阶段：\n在训练阶段构建得到图谱和基于稀疏表示变形模型（SRDM）。在测试阶段，当输入一副带分割的CT图像时，首先寻找将肝脏图谱的灰度图像对齐到目标图像法的非刚性变换，并依据训练得到的变形模型对这一变换进行正则化，然后利用正则化后的非刚性变换将肝脏图谱的标签图像传播到目标图像，就得到了初始的分割结果，最后再利用可变形Simplex网格方法对获取的初始结果进行进一步细分。\n\n构建肝脏图谱\n采用迭代方法构建图谱，并采用最小变形目标（MDT）方法获取初始的平均模板。具体步骤如下：\n\n准备一组预处理的训练图像{Ii|i=1..k}和对应的二值图像{Li|i=1…k}，从中选择一幅最接近平均肝脏形状的图片作为初始模板图像（比如I1）\n\n计算出模板图像I1对齐到其它所有训练图像的平均非刚性变换`T1\n `T1 = 1/(k-1)*(T1j)  j=2...k\n T1j是将I1对齐到训练图像Ij的非刚性变换\n这样模板图像I1的最小变形目标目标MDT1 = `T1（I1），即将得到的平均非刚性变换。\n\n由于非刚性配准算法具有保持拓扑结构的性质，MDT1会偏向于初始模板I1的特定形状，因此本文将MDT1定义为初始的平均模板，采用迭代的方法构建最终的肝脏图谱，迭代过程见算法（3-1）。\n\n所有非刚性图像配准均采用基于B样条的自由变形模型（FFD），通过上述过程可以得到一组K幅对齐了的训练样本&#123;Ii|i=1..k&#125;和对应的二值图像&#123;Li|i=1...k&#125;,最终的图谱就是它们的平均值;\n （`I,`L）\n\n\n\n\n\n构建基于稀疏表示变形模型\n通过图谱灰度图像`I非刚性地配准到这些处理后的训练图像用于构建变形模型的非刚性变换，这一过程得到了一组K个用于训练的非刚性变换{Ti|i=1,2…k}.\n\n","categories":["东搞西搞"],"tags":[]},{"title":"基于分层区域稀疏成分的肝脏分割","url":"http://tanqingbo.cn/2016/10/19/基于分层区域稀疏成分的肝脏分割/","content":"前言本文是我阅读医学图像分析论文《A hierarchical local region-based sparse shape composition for liversegmentation in CT scans》所做的一些笔记。翻译的中文名为：基于分层区域稀疏成分的肝脏分割。\n基于分层区域稀疏成分的肝脏分割\n本文的主要贡献可以概括如下:\n\n(1)提出了MLR-SSC增加形状先验模型的灵活性和获取详细的局部形状信息更忠实的小训练集(3.1节);\n(2)一个有效和可伸缩的优化算法(即。,LARS-Homotopy方法[34])求解稀疏优化问题在MLR-SSC(3.1.2节);\n(3)提出一种血液vessel-based肝脏形状初始化方法获得一个更特定的初始形状(3.2.1节);\n(4)分级优化策略开发的细分框架更有效率和更健壮的局部最小值(3.2.2节),并成功地应用于部分肝组织从CT图像(5节)。背景和相关工作\n\n\n提出一个新颖的多级当地提出SSC(MLR-SSC)提高精度和降低计算成本。具体来说,我们将肝脏形状分解成多个区域多层次的方式,这样,每个地区都有均匀的形状变化。然后我们建立一个当地的形状库中为每个地区和完善地区的方式输入形状。\n\nZhang et al。[35]他们使用的内点方法解决稀疏优化问题,当我们使用一个更加高效和可伸缩的优化算法(即。LARS-Homotopy方法[34]);\n\n他们应用来自每个次区域的稀疏系数xj来完善整个输入形状,而我们使用一个地区细化策略,更准确和高效。\n\n在他们的层次分割框架,single-resolution技术(即。,只有使用原始输入图像)实现,我们开发一个多分辨率优化策略(即。,使用原始输入图像的高斯金字塔),已被证明对于局部最小值是更有效更健壮的[39]。\n方法（Method）\n在本节中,我们描述我们提出ASM-based分层肝脏分割框架。主要工作流程分割框架见图2,包括离线训练和运行时测试阶段。\n多级形状分割过程：\n输入：\n\nM¯：主要的肝脏形状\n{δi }：对于每一个三角形Ti的形状变化标准差\nnl：多级形状分割L水平划分的区域个数\n\n\nstep1：初始化：\n\n为每一个区域Ri创建一个随机的种子三角形Ti.\n为每一个区域标记代理Pi：Pi=(mi)←δi.\n\n\nstep2：区域划分：\n\nRi←∅;将Ti添加到对应的区域Ri中，Ri←Ri∪Ti.\n\n初始化一个全局优先队列Q： Q←∅.\n\n将每一个与种子三角形Ti相邻的三角形Tj的近似误差L(Tj, Pi)和标签TagTj插入Q，L(Tj,Pi)=|δj−mi|。\n while Q≠∅ do\n  Tj← Pop 三角形最小的近似误差\n   if 没有标签Tj then\n     添加Tj地区表示其标签TagTj:RTagTj←RTagTj∪Tj。\n     将TagTj重新插入Q\n   end if\n end while\n\n\n\nstep3:代理配件\n\n根据邻近区域Ri的平均形状变化更新每一个代理Pi=(mi)， mi←1/|Ri|∑Tj∈Ri δj.\n为每一个新区域Ri更新种子三角形Ti，使Ri的近似误差最小。Ti←argminTj∈Ri L(Tj,Pi).\n\n\nstep4:重复step3和step3.\n\n输出在l区域水平主要肝脏形状的分割结果。R={R1,…,Rnl}.\n\n\nMLR-SSC模型能够非常健壮的处理大型的稀疏错误和小密度的高斯噪音，能够恢复复杂的形状变形和详细地局部信息.\n分层肝脏分割框架\n我们的细分框架包含两个主要组件:肝脏形状初始化和分层优化算法。\n\n肝脏形状初始化\n\n中值滤波应用于输入的CT图像减少噪音\nFrangi׳s vesselness方法来增强肝脏血管\n移动立方体算法将提取的肝血管转换成三角网格\n使用Quickhull算法计算血管的凸包来提取肝脏的核心区域\nASM本地搜索策略可能会导致最终结果过度或欠分割\n\n\n使用我们提出的MLR-SSC策略能够更准确的分割肝脏形状\n\n设level l = 0，nl= 1（设0层只有一个区域）\n用全局SSC定义核心区域\n所推断出来的初始形状更准确，与真值更一致，尤其是在白色矩形所表示的区域分级优化策略\n\n\n分级优化策略的形状模型是由粗到精的方式，是一个支持多分辨率的策略\n\n首先构造多分辨率高斯金字塔的所有训练体积，这样MLR-SSC在不同的级别对应不同的决议。\n输入一个CT进行分割，我们同样为其建立一个多分辨率高斯金字塔，然后开始ASM搜索，设level l = 0，nl= 1，然后再level l 上逐渐增加跟多的区域，这样更详细的局部信息可以重建。\nASM搜索从输入的体积最低分辨率开始，外观模型对应这一级别。\n在收敛或迭代预定义的次数之后移动到更高的分辨出。\n每一级的分割结果直接用来初始化下一级。\n重复这个过程直到收敛达到原始输入量的金字塔。\n\n\n上述算法描述：\n\n输入：\n\nV:腹部门静脉体积\nLmax:分辨率级别数量\nNmax:每级分辨率的迭代次数。\n\n\n输出：\n\nM(Lmax−1)：分割结果\n\nM0:肝脏血管初始化形状\n\n{ V0,V1,…,V(Lmax−1)= V }：为V构建的多分辨率高斯金字塔  \n for l=0 to (Lmax−1) do\n  for i=0 to (Nmax−1) do\n   for 所有的点vj∈Ml do\n     qj = ASM搜索算法在Vj中找到的目标点；\n     vj = qj；\n   end for\n   Ml = 使用MLR-SSC完善的中间变形形状\n   i = i+1;\n  end for \n  l = l+1;\n end for\n return M(Lmax−1);\n实验\n\n\n\n\n数据集：在这项研究中所有数据集的详细信息由表1给出\n\n注意,当比较我们的方法和先进的方法基于3 dircadb1(部分5.4.1之前)和SLIVER07-Test(5.4.2节)数据库中,我们仅仅使用SLIVER07-Train数据库作为训练数据。\n\n\n评价指标和统计分析\n\n为了定量评估我们的方法和性能，提供五个体积和表面的基础指标:体积重叠误差(VOE),标记相对体积差异(SRVD),平均对称表面距离(ASD),均方根对称表面距离(RMSD)和最大对称面的距离(MSD)。\n这些评价指标,值越小,分割的结果更好。\n在所有的指标中，VOE和ASD通常用来评价分割准确性。\n\n\n实现细节\n\n分层肝脏分割框架的参数集确定离线使用SLIVER07-Train数据库来获得最优性能\n在我们的实现中，对所有的测试数据设置都是相同的\n所有的参数设置部署都在表2中列出了\n在Eq中选择稀疏参数 λ 的值\n形状划分的层次数量L和分辨率水平Lmax 将在5.1.3和5.1.4详细讨论 \n\n\n\ntable 2\n参数值详细信息\nnp2562有意义的点的数量\nL5形状分割层数\nλ100Eq中稀疏参数\nLmax5分辨率级别数量\nNmax10每级分辨率的迭代次数\nk9标准剖面两侧采样点的数量\nne6在每一次迭代时，评估两边点的新位置数量\n\n+ 在这项研究中,我们还将提出MLR-SSC模型与两个紧密相关的方法进行比较：\n    1.  SSM,统计形状模型使用主成分分析(PCA)学习形状先验模型\n    2.  SSC,稀疏的形状组成使用形状库D中提炼的一个输入形状作为全局训练形状（这是我们提出的方法中的一个特例，levels L=1.）\n+ **用到的工具：C++实现，Ubuntu平台，SPAMS库（开源稀疏优化工具）**\n### 结果 ###\n+ MLR-SSC模型评估：在不同情况下，评价其泛化能力，在所有试验中令  level l=2 with nl=4 regions.\n+ 泛化能力、专一性和密实度是量化一个形状模型质量的三个最常用的措施。在本论文中采用泛化能力评价模型质量\n+ 泛化能力值越小,形状建模方法就越好。\n+ 泛化能力和效率完胜其他两个方法\n\n+ 训练数据的大小对泛化能力的影响\n    + 我们的方法能够克服有限的训练数据的影响（一般训练数据越小，泛化值越大）\n+ 稀疏参数对泛化能力的影响\n    + 由图12，稀疏参数λ的选择对我们的成功至关重要\n    + 我们的方法在λ的值很大范围内都不敏感，一般选择固定值λ= 100\n+ 层次和区域个数对MLR-SSC肝脏形状重建的影响\n    +  MLR-SSC模型的特征是能够保存详细的局部形状信息，即使训练的数据上没有显著的统计\n    + 每一层的区域个数选择对MLR-SSC模型至关重要，区域个数小，不能更好的重建局部细节；个数多，在细分的交叉区域会发生矛盾，从而导致肝脏表面非常粗糙。\n    +  图13显示了泛化能力和区域个数的关系，随着地区的数量增加,泛化能力的价值下降,但20个区后,它开始上涨,使我们的方法达到最好的结果，区域个数在12-20。\n    +  最大数量的水平 level L = 6\n    +  我们选择 level L = 5，2的4次方 = 16，因此区域数16个，满足最佳重建结果。\n\n肝脏CT图像分割","categories":["东搞西搞"],"tags":[]},{"title":"不读书，不学诗","url":"http://tanqingbo.cn/2016/08/12/不读书，不学诗/","content":"\n言语无味，胸无点墨，时间长了不读书，自然而然面目可憎。\n每个月唯一的读物除了朋友圈分享的心灵鸡汤，就是市面上最流行的时尚杂志。\n慢慢失去理解汉语的能力。\n对世界丧失了敏感的感知。\n体会不到“衣上征尘杂酒痕，远游无处不销魂”的美。\n读不出“红楼隔雨相望冷，珠箔飘灯独自归”的伤。\n不能在下雨天思念一个人的时候背诵：\n青青子衿，悠悠我心，纵我不往，子宁不嗣音？\n青青子佩，悠悠我思，纵我不往，子宁不来？\n挑兮达兮，在城阙兮，一日不见，如三月兮。\n一日不读书，胸臆无佳想。一月不读书，耳目失精爽。\n相思时不会用“忆君心似西江水，日夜东流无歇时”。\n失恋的时候只能听情歌，分手时说不出“一别两宽，各生欢喜”。\n不学诗，无以言。\n言谈举止不优雅，不得体，不妥帖，欠缺人格魅力。腹无诗书胸有波也没用，没文化有钱了也是土豪。\n不学礼，无以立。\n遇到事情的时候，没有人生经验，只能硬着头皮乱闯，殊不知很多事情都是历史的重复。\n看花犹是去年人，读史早知今日事。\n失去了“一生好入名山游”的心境，也没时间“细雨骑驴入剑门”。\n\n","categories":["漂来漂去"],"tags":[]},{"title":"C++ string函数的用法","url":"http://tanqingbo.cn/2016/08/11/C++ string函数的用法/","content":"C++ string函数的用法\nstd::string 相当于string\nstring::npos  取值由实现决定，一般是-1find_first_of()和 find_last_of()\n函数find_first_of()和 find_last_of() 执行简单的模式匹配，如在字符串中查找单个字符c。函数find_first_of() 查找在字符串中第1个出现的字符c，而函数find_last_of()查找最后一个出现的c。匹配的位置是返回值。如果没有匹配发生，则函数返回-1.substr(off,count)\n第一个参数off表示下标，count是子串的长度。如果没有越界异常，返回一个[off，off+count)的字符串。　　erase函数的原型如下：\nstring&amp; erase ( size_t pos = 0, size_t n = npos );\niterator erase ( iterator position );\niterator erase ( iterator first, iterator last );也就是说有三种用法：\nerase(pos,n); 删除从pos开始的n个字符，比如erase(0,1)就是删除第一个字符\nerase(position);删除position处的一个字符(position是个string类型的迭代器)\nerase(first,last);删除从first到last之间的字符（first和last都是迭代器）\n\n\n\n示例代码：\n        #include &lt;string&gt;\n        #include &lt;iostream&gt;\n        using namespace std;\n\n        int main ()\n        &#123;\n            string str (&quot;This is an example phrase.&quot;);\n            string::iterator it;\n            //第（1）种方法\n            str.erase (10,8);\n            cout &lt;&lt; str &lt;&lt; endl;        // &quot;This is an phrase.&quot;\n            //第（2）种方法\n            it=str.begin()+9;\n            str.erase (it);\n            cout &lt;&lt; str &lt;&lt; endl;        // &quot;This is a phrase.&quot;\n            //第（3）种方法\n            str.erase (str.begin()+5, str.end()-7);\n            cout &lt;&lt; str &lt;&lt; endl;        // &quot;This phrase.&quot;\n            return 0;\n        &#125;\n\nC++编程里面每种容器都定义了一对命名为begin和end的函数，用于返回迭代器，如果容器中有元素的话，由begin返回的迭代器指向第一个元素,由end操作返回的迭代器指向容器的“末端元素的下一个”。\nc_str()\nc_str()函数返回一个指向正规c字符串的指针,内容和string类的本身对象是一样的,通过string类的c_str()函数能够把string对象转换成c中的字符串的样式\n\n操作c_str()函数的返回值时,只能使用c字符串的操作函数,如:strcpy()等函数.因为,string对象可能在使用后被析构函数释放掉,那么你所指向的内容就具有不确定性.\n  eg:\n  char * name[20];\n  string ptr = &quot;tongnono&quot;;\n  strcpy(name,ptr.c_str());//c_str()返回的是一个临时的指针变量,不能对其操作.\n\n\nC语言提供了几个标准库函数，可以将任意类型(整型、长整型、浮点型等)的数字转换为字符串。    ● itoa()：将整型值转换为字符串。\n    ● ltoa()：将长整型值转换为字符串。\n    ● ultoa()：将无符号长整型值转换为字符串。\n    ● gcvt()：将浮点型数转换为字符串，取四舍五入。\n    ● ecvt()：将双精度浮点型值转换为字符串，转换结果中不包含十进制小数点。\n    ● fcvt()：指定位数为转换精度，其余同ecvt()。\n\n除此外，还可以使用sprintf系列函数把数字转换成字符串，其比itoa()系列函数运行速度慢\n\nC/C++语言提供了几个标准库函数，可以将字符串转换为任意类型(整型、长整型、浮点型等)。    ● atof()：将字符串转换为双精度浮点型值。\n    ● atoi()：将字符串转换为整型值。\n    ● atol()：将字符串转换为长整型值。\n    ● strtod()：将字符串转换为双精度浮点型值，并报告不能被转换的所有剩余数字。\n    ● strtol()：将字符串转换为长整值，并报告不能被转换的所有剩余数字。\n    ● strtoul()：将字符串转换为无符号长整型值，并报告不能被转换的所有剩余数字。\nfind()\nstring类的查找函数： \n  int find(char c, int pos = 0) const;//从pos开始查找字符c在当前字符串的位置\n  int find(const char *s, int pos = 0) const;//从pos开始查找字符串s在当前串中的位置\n  int find(const char *s, int pos, int n) const;//从pos开始查找字符串s中前n个字符在当前串中的位置\n  int find(const string &amp;s, int pos = 0) const;//从pos开始查找字符串s在当前串中的位置\n  //查找成功时返回所在位置，失败返回string::npos的值 \n\n\n","categories":["C语言"],"tags":[]},{"title":"如何在github上预览网页效果","url":"http://tanqingbo.cn/2016/06/19/如何在github上预览网页效果/","content":"如何在github上预览网页效果\n在github上托管的项目，经常会存放一些demo的HTML文件在里面，比如像下面这样：\n\n我们直接点击的话只能看到html源代码, 那么有没有什么办法直接看html网页效果而不用下载呢?\n\n答案是有的. 它就是: http://htmlpreview.github.com/. 直接把github上html文件的链接复制过去即可.\n\n比如, Github上有这么一个文件 https://github.com/aisinvon/VerticalMiddleForUnknownHeightDiv/blob/master/Set-Unknown-Height-Div-to-Vertical-Middle.html, 如果直接访问是这样的:\n\n只有这样访问才能直接在网页预览到效果: http://htmlpreview.github.com/?https://github.com/aisinvon/VerticalMiddleForUnknownHeightDiv/blob/master/Set-Unknown-Height-Div-to-Vertical-Middle.html\n\n如下图所示：\n\n\n","categories":["技术博客"],"tags":[]},{"title":"JavaWeb中文编码问题","url":"http://tanqingbo.cn/2016/06/10/JavaWeb中文编码问题/","content":"JavaWeb中文编码问题需要编码的原因\n计算机中存储的最小单元是一个字节，即8bit，所以能表示的字符范围是0~255个。\n人类要表示的符号太多，无法用一个字节来完全表示。\n要解决这个矛盾必须要有一个新的数据结构char，从char到byte必须编码。编码格式\n\n\nASCII\n\nASCII码共有128个，用一个字节的低7位表示，031是控制字符，如换行、回车、删除等；32126是打印字符，可以通过键盘输入并能够显示出来。\n\n\nISO-8859-1\n\n128个字符显然是不够用的，ISO组织在ASCII码的基础上又制定了一系列标准用来扩展ASCII编码，他们是ISO-8859-1~ISO-8859-15，其中ISO-8859-1涵盖了大多数西欧语言字符，所以应用最广泛。ISO-8859-1任然是单字节编码，它总共能表示256个字符。\n\n\nGB2312\n\n它的全称是《信息交换用汉字编码字符集基本集》，它是双字节编码，总的编码范围是A1F7，其中从A1A9是符号区，总共包含682个字符。从B0~F7是汉字区，包含6763个汉字。\n\n\nGBK\n\n全称《汉字内码扩展规范》，为了扩展GB2312加入了更多的汉字，它的编码是和GB2312是兼容的，也就是说GB2312编码的汉字可以用GBK来解码，并且不会有乱码。\n\n\nGB18030\n\n是我国强制标准，它可能是单字节、双字节、或者四字节编码，与GB2312兼容，应用并不广泛。\n\n\nUTF-16\n\n用两个字节来表示Unicode转化格式，它是定长的表示方法，不论什么字符都可以用两个字节表示，两个字节是16bit，所以叫UTF-16。每两个字节表示一个字符，这就大大简化了字符串的操作，这也是java以UTF-16作为内存字符存储格式的一个很重要的原因。\n\n\nUTF-8\n\nUTF-16同意采用两个字符表示一个字节，但是很大一部分字符用一个字节就可以表示现在却要用两个字符表示，存储空间放大了一倍，而现在网络带宽还非常有限，这样会增大网络传输的流量，而且也没必要。而UTF-8采用了一种变长的技术，每个编码区域有不同的字码长度。不同类型的字符可以由1~6个字节组成。\n\n\n\njava中需要编码的场景I/O操作中存在的编码\n涉及编码的地方一般在字符到字节或者字节带字符的转换上，二需要这种转换的场景主要是I/O。\nReader类是java的i/o中读字符的父类，而inputstream类是读字节的父类，inputstreamreader类就是关联字节到字符的桥梁，它负责在I/O过程中处理读取字节到字符的转换，而具体字节到字符的解码又委托streamdecoder去做，在streamdecoder解码过程中必须有用户指定charset编码格式，如果没有指定charset，将使用本地环境中的默认字符集。\n写的情况也类似，字符的父类是writer，字节的父类是outputstream，通过outputstreamwriter转换字符到字节。StreamEncoder类负责将字符编码成字节，编码格式和默认编码规则与解码是一致的。\n强烈建议不要使用操作系统的默认编码，因为这样你的应用程序的编码格式就和运行环境绑定起来了，在跨环境是很可能出现乱码。\n\n内存操作中的乱码\n内存中进行字符到字节的转换也很常见。\n      String s = &quot;这是一段中文字符&quot;;\n      byte[] b = s.getBytes(&quot;utf-8&quot;);\n      String n = new String(b,&quot;utf-8&quot;);\n\n      Charset charset = Charset.forName(&quot;utf-8&quot;);\n      ByteBuffer byteBuffer = charset.encode(string);\n      CharBuffer charBuffer = charset.decode(byteBuffer);\n\n\nJava中如何编解码\n以字符串“I am 君山”为例。\n\n按照ISO-8859-1编码\n\nISO-8859-1是单字节编码，中文“君山”被转化成值是3f的byte，3f也就是“?”字符。所以经常会出现中文变成“?”，很可能就是错误地使用了ISO-8859-1编码导致的。\n\n\n按照GB2312编码\n\nGB2312字符集有一个char到byte的码表，不同的字符编码就查这个码表找到与每个字符的对应字节，然后拼装成byte数组。\n\n\n按照GBK编码\n\nGBK与GB2312编码结果是一样的；\n由此可以看出来GBK编码是兼容GB2312编码的，他们的编码算法是一样的。\n不同的是它们的码表长度不一样，GBK包含的汉字字符更多，所以只要是经过GB2312编码的汉字都可以用GBK进行解码，反之则不然。\n\n\n按照utf-16编码\n\n用utf-16编码将char数组放大了一倍，单字节范围内的字符在高位补0变成两个字节，中文字符也变两个字节。\n编码效率非常高，规则很简单。\n\n\n按照utf-8编码\n\nUTF-16采用顺序编码，不能对单个字符的编码值进行校验，如果中间的一个字符码值损坏，后面所有的码值都将受到影响。\n而UTF-8不存在这些问题，UTF-8对单字节范围内字符任然用一个字节表示，对汉字采用三个字节表示。\nUTF-8编码与GBK和GB2312不同，不用查码表，所以在编码效率上UTF-8的效率会更好，所以在存储中文字符时UTF-8编码比较理想。\n\n\n几种编码格式的比较\n\nGB2312与GBK的编码规则类似，但是GBK范围更大，所以GB2312与GBK比较，应该选择GBK；\nutf-16与utf-8都是处理Unicode编码，编码规则不太相同，相对来说utf-16编码效率最高，字符到字节相互转换更简单，进行字符操作也更好，它适合本地磁盘和内存之间使用，可以进行字符和字节中间的快速切换，java内存编码就采用utf-16编码；\n但是UTF-16不适合网络之间的传输，因为网络传输容易损坏字节流，一旦字节流损坏就很难恢复，相比较而言，utf-8更适合网络传输，单个字符的损坏不会影响后面其他字符，编码效率介于GBK和UTF-16之间；\nUTF-8在编码效率上和安全性上做了平衡，是理想的中文编码方式。\n\n\n\nJava Web中涉及的编解码\nURL的编解码\n\n浏览器编码URL将非ASCII字符按照某种编码格式编码成16进制数字后在每个16进制表示的字节前加上“%”，所以就出现了如下情况：\n  http://tanqingbo.com/2016/05/11/%E5%A4%8F%E4%BB%A4%E8%90%A5%E6%B1%87%E6%80%BB/\n\n\n\nhttp Header的编码\n\nheader中传递参数，如：Cookie、redirectPath等，这些用户设置的值可能存在编码问题。\n对header进行解码实在调用request.getHeader时进行的，这个方法将byte到char的转化使用的是ISO-8859-1，不能手动设置Header的其他解码格式，如果有非ASCII字符肯定会有乱码；\n不要在header中传递非ASCII字符，如果一定要出传递，可以先将这些字符用org.apache.catalina.util.URLEncoder编码，然后再添加到header中。\n\n\n访问数据库都是通过客户端JDBC驱动来完成的，用JDBC来存取数据要和数据的内置编码保持一致，可以通过设置JDBC URL来指定，如：MySQL：\n      jdbcUrl=&quot;jdbc:mysql://localhost:3306/boke?characterEncoding=utf-8&quot;\nJS中的编码问题\n外部引入JS文件\n\n如果script没有设置charset，浏览器就会以当前这个页面的默认字符集解析这个JS文件，如果外部的JS文件的编码格式与当前页面的编码格式一致，那么可以不设置这个charset，但是如果script.js文件的编码格式与当前页面不一致，上面的那段中文输入就会变成乱码。\n\n\nJS的URL编码\n\n实际上JS中处理URL编码有三个函数，只要掌握了这三个函数，基本上就能正确处理JS的URL乱码问题了；\n\n\nescape()\n这个函数是将非ascii字符转化成Unicode编码值，并且在编码值前加上“%u”；\n\n\n解码通过unescape()函数；\n通过将特殊字符换成Unicode编码值可以避免因为编码的字符集的不兼容而出现的信息丢失问题，在服务端通过解码参数就可以避免乱码的问题。\n\n\n\n\nencodeURL()\n\n与escape()相比，encodeURL()是真正的JS用来对URL编码的函数，它可以将整个URL中的字符(除了一些特殊字符，如：符号、数字、字母)进行UTF-8编码，在每个值之前加上“%”；\n解码通过encodeURL函数。\n\n\nencodeURLComponent()\n\nencodeURLComponent()这个函数比encodeURL()编码还要彻底；\n通常用于将一个URL当做参数放在另一个URL中；\n\n\n其他需要编码的地方\n\nXML文件可以通过设置投来制定编码格式：\n  &lt;?xml version&quot;1.0&quot; encoding=&quot;UTF-8&quot;&gt;\n\nVelocity(基于Java的模板引擎)设置编码格式：\n  services.VelocityService.input.encoding=uft-8\n\nJsp设置编码格式：\n  &lt;%@page contentType=&quot;text/html; charset=utf-8&quot;&gt;\n常见问题分析\n\n\n\n\n中文变成了看不懂的字符\n\n一个汉字变成一个问号\n\n一个汉字变成两个问号\n\n一种不正常的正确编码\n\n我们通过request.getParameter获取参数值时，直接调用：\n  String value = request.getParameter(name);\n\n会出现乱码，但是用如下方式：\n  String value = new String(request.getParameter(name).getBytes(&quot;ISO-8859-1&quot;),&quot;GBK&quot;);\n\n解析时取得的value会是正确的汉字字符。\n\n\n\n\n","categories":["Java"],"tags":[]},{"title":"外观模式","url":"http://tanqingbo.cn/2016/05/29/外观模式/","content":"外观模式定义\n外观模式(Facade Pattern)：外部与一个子系统的通信必须通过一个统一的外观对象进行，为子系统中的一组接口提供一个一致的界面，外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。外观模式又称为门面模式，它是一种对象结构型模式。\n外观模式结构图\n![外观模式结构图](http://i.imgur.com/8cKi57u.png)\n\n### 代码实现 ###\n\n      public class SubSystemOne &#123;\n          public void MethodOne()&#123;\n              System.out.println(&quot;子系统方法一&quot;);\n          &#125;\n      &#125;\n      public class SubSystemTwo &#123;\n          public void MethodTwo()&#123;\n              System.out.println(&quot;子系统方法二&quot;);\n          &#125;\n      &#125;\n      public class SubSystemThree &#123;\n          public void MethodThree()&#123;\n              System.out.println(&quot;子系统方法三&quot;);\n          &#125;\n      &#125;\n      public class Facade &#123;\n          SubSystemOne one;\n          SubSystemTwo two;\n          SubSystemThree three;\n          public Facade() &#123;\n              one = new SubSystemOne();\n              two = new SubSystemTwo();\n              three = new SubSystemThree();\n          &#125;\n          public void MethodA()&#123;\n              System.out.println(&quot;方法组A（）&quot;);\n              one.MethodOne();\n              two.MethodTwo();\n          &#125;\n          public void MethodB()&#123;\n              System.out.println(&quot;方法组B（）&quot;);\n              two.MethodTwo();\n              three.MethodThree();\n          &#125;\n      &#125;\n      public class Client &#123;\n          public static void main(String[] args) &#123;\n              Facade facade = new Facade();\n              facade.MethodA();\n              facade.MethodB();\n          &#125;\n      &#125;\n\n\n外观模式优点\n对客户屏蔽子系统组件，减少了客户处理的对象数目并使得子系统使用起来更加容易。通过引入外观模式，客户代码将变得很简单，与之关联的对象也很少。\n实现了子系统与客户之间的松耦合关系，这使得子系统的组件变化不会影响到调用它的客户类，只需要调整外观类即可。\n降低了大型软件系统中的编译依赖性，并简化了系统在不同平台之间的移植过程，因为编译一个子系统一般不需要编译所有其他的子系统。一个子系统的修改对其他子系统没有任何影响，而且子系统内部变化也不会影响到外观对象。\n只是提供了一个访问子系统的统一入口，并不影响用户直接使用子系统类。\n\n外观模式缺点\n不能很好地限制客户使用子系统类，如果对客户访问子系统类做太多的限制则减少了可变性和灵活性。\n在不引入抽象外观类的情况下，增加新的子系统可能需要修改外观类或客户端的源代码，违背了“开闭原则”。何时使用外观模式\n\n\n在设计初期阶段，应该有意识的将不同的两个层分离；\n在开发阶段，子系统往往因为不断的重构演化而变得越来越复杂，增加Facade可以提供一个简单的接口，减少他们之间的依赖。\n在维护一个遗留的大型系统时，可能这个系统已经非常难以维护和扩展了，为新系统开发一个外观Facade类，来提供设计粗糙或高度复杂的遗留代码的比较清晰简单接口，让新系统与Facade对象交互，Facade与遗留代码交互所有复杂工作。\n\n","categories":["大话设计模式"],"tags":[]},{"title":"原型模型","url":"http://tanqingbo.cn/2016/05/23/原型模式/","content":"原型模型\n原型模式其实就是从一个对象基础上再创建另外一个可定制的对象，而且不需要知道任何创建的细节。\n\n原型模型可以大大提高效率。一般在初始化的信息不发生变化的情况下，克隆是最好的办法，即隐藏了创建对象的细节，又对性能有大大的提升。\n\n看代码就知道怎么回事了。以书写简历为例：\n  public class Resume implements Cloneable&#123;\n      String name;\n      String sex;\n      String age;\n      String timearea;\n      String company;\n      public Resume(String name) &#123;\n          super();\n          this.name = name;\n      &#125;\n      public Resume() &#123;\n          super();\n      &#125;\n      //设置个人信息\n      public void setPersonInfo(String sex,String age)&#123;\n          this.sex = sex;\n          this.age = age;\n      &#125;\n      //设置个人信息\n      public void setWorkExperience(String timearea,String company)&#123;\n          this.timearea = timearea;\n          this.company = company;\n      &#125;\n      @Override\n      public String toString() &#123;\n          return  name + &quot;  &quot; + sex + &quot;  &quot; + age + &quot;\\n工作经历：&quot; + timearea + &quot;   &quot;\n                  + company;\n      &#125;\n      public Object Clone() throws Exception&#123;\n          return this.clone();\n      &#125;\n  &#125;\n  public class Test &#123;\n      public static void main(String[] args) throws Exception &#123;\n          Resume a = new Resume(&quot;大鸟&quot;);\n          a.setPersonInfo(&quot;男&quot;, &quot;20岁&quot;);\n          a.setWorkExperience(&quot;2013-2017&quot;, &quot;东北林业大学&quot;);\n          Resume b = (Resume)a.Clone();\n          b.setWorkExperience(&quot;2017-2022&quot;, &quot;哈尔滨工业大学&quot;);\n          Resume c = (Resume)a.Clone();\n          c.setWorkExperience(&quot;2022-2030&quot;, &quot;google&quot;);\n          System.out.println(a);\n          System.out.println(b);\n          System.out.println(c);\n      &#125;\n  &#125;\n\n输出结果：\n  大鸟  男  20岁\n  工作经历：2013-2017   东北林业大学\n  大鸟  男  20岁\n  工作经历：2017-2020   哈尔滨工业大学\n  大鸟  男  20岁\n  工作经历：2020-2022   google\n\n注：上述代码是原型模型的浅复制，只能复制值类型的数据，对于引用类型的对象不能复制。\n\n如果将工作经历也单独做一个类，然后在resume类中应用工作经历，就会输出3条一模一样的结果。\n\n浅复制被复制对象的所有变量都含有与原来的对象相同的值，而所有的对其他对象的引用都任指向原来的对象。\n\n将工作经历也单独做一个类的代码：\n  public class WorkExperience &#123;\n      String timearea;\n      String company;\n      public String getTimearea() &#123;\n          return timearea;\n      &#125;\n      public void setTimearea(String timearea) &#123;\n          this.timearea = timearea;\n      &#125;\n      public String getCompany() &#123;\n          return company;\n      &#125;\n      public void setCompany(String company) &#123;\n          this.company = company;\n      &#125;\n      @Override\n      public String toString() &#123;\n          return &quot;\\n工作经历&quot; + timearea + &quot;  &quot; + company;\n      &#125;\n  &#125;\n  public class Resume implements Cloneable&#123;\n      String name;\n      String sex;\n      String age;\n      WorkExperience work;\n      public Resume(String name) &#123;\n          super();\n          this.name = name;\n          work = new WorkExperience();\n      &#125;\n      public Resume() &#123;\n          super();\n      &#125;\n      //设置个人信息\n      public void setPersonInfo(String sex,String age)&#123;\n          this.sex = sex;\n          this.age = age;\n      &#125;\n      public void setWorkExperience(String timearea,String company)&#123;\n          work.timearea  = timearea;\n          work.company = company;\n      &#125;\n      @Override\n      public String toString() &#123;\n          return name + &quot;  &quot; + sex + &quot;  &quot; + age + work ;\n      &#125;\n      public Object Clone() throws Exception&#123;\n          return this.clone();\n      &#125;\n\n  &#125;\n\n输出结果\n  大鸟  男  20岁\n  工作经历：2020-2022   google\n  大鸟  男  20岁\n  工作经历：2020-2022   google\n  大鸟  男  20岁\n  工作经历：2020-2022   google\n\n深复制：把引用对象的变量指向复制过的新对象，而不是原有的被引用的对象。\n\n二层深复制的代码：\n  public class WorkExperience implements Cloneable&#123;\n      String timearea;\n      String company;\n      public String getTimearea() &#123;\n          return timearea;\n      &#125;\n      public void setTimearea(String timearea) &#123;\n          this.timearea = timearea;\n      &#125;\n      public String getCompany() &#123;\n          return company;\n      &#125;\n      public void setCompany(String company) &#123;\n          this.company = company;\n      &#125;\n      @Override\n      public String toString() &#123;\n          return &quot;\\n工作经历&quot; + timearea + &quot;  &quot; + company;\n      &#125;\n      public Object Clone() throws Exception&#123;\n          return this.clone();\n      &#125;\n  &#125;\n  public class Resume implements Cloneable&#123;\n      String name;\n      String sex;\n      String age;\n      WorkExperience work;\n      public Resume(String name) &#123;\n          super();\n          this.name = name;\n          work = new WorkExperience();\n      &#125;\n      public Resume() &#123;\n          super();\n      &#125;\n      private Resume(WorkExperience work) throws Exception &#123;\n          super();\n          this.work = (WorkExperience)work.Clone();\n      &#125;\n      //设置个人信息\n      public void setPersonInfo(String sex,String age)&#123;\n          this.sex = sex;\n          this.age = age;\n      &#125;\n      public void setWorkExperience(String timearea,String company)&#123;\n          work.timearea  = timearea;\n          work.company = company;\n      &#125;\n      @Override\n      public String toString() &#123;\n          return name + &quot;  &quot; + sex + &quot;  &quot; + age + work ;\n      &#125;\n      public Object Clone() throws Exception&#123;\n          Resume obj = new Resume(this.work);\n          obj.name = this.name;\n          obj.age = this.age;\n          obj.sex = this.sex;\n          return obj;\n      &#125;\n  &#125;\n\n输出结果：\n      大鸟  男  29岁\n      工作经历2013-2017  东北林业大学\n      大鸟  男  29岁\n      工作经历2017-2020  腾讯\n      大鸟  男  29岁\n      工作经历2020-2022  google\n\n代码改动的地方：\n\n让WorkExperience类也实现了Cloneable的接口，并增加了clone()方法。\n在resume类中新增了一个私有的构造方法。\n修改了resume的clone()的方法。\n\n\n\n","categories":["大话设计模式"],"tags":[]},{"title":"代理模式","url":"http://tanqingbo.cn/2016/05/21/代理模式/","content":"代理模式\n代理模式：为其他对象提供一种代理，以控制对这个对象的访问。\n\n代理应用的场合：\n\n远程代理：也就是为一个对象在不同的地址空间提供局部代理，这样可以隐藏一个对象存在于不同地址空间的事实。\n虚拟代理：是根据需要创建很大的对象，通过它来代理来存放实例化需要很长时间的真实对象，例如：网页加载图片。\n安全代理：用来控制真实对象访问时的权限，一般用于对象应有不同的访问权限的时候。\n智能指引：是指当调用真实对象时，代理处理另外一些事情。\n\n\n代码：（通过代理去追妹子的例子）\n      public interface IGiveGift &#123;\n          void GiveDolls();\n          void GiveFlowers();\n          void GiveChocolate();\n      &#125;\n      //此类中的@Data用到了lombok的注解，可以自动提供get  set方法，节省代码量\n      //请参考“eclipse使用lombok”博客。\n      import lombok.Data;\n      public @Data class SchoolGirl &#123;\n          String name;\n      &#125;\n      public class Pursuit implements IGiveGift &#123;\n          SchoolGirl mm;\n          public Pursuit(SchoolGirl mm) &#123;\n              super();\n              this.mm = mm;\n          &#125;\n          public Pursuit() &#123;\n              super();\n          &#125;\n          @Override\n          public void GiveDolls() &#123;\n              // TODO Auto-generated method stub\n              System.out.println(mm.getName()+&quot;送你洋娃娃。&quot;);\n          &#125;\n          @Override\n          public void GiveFlowers() &#123;\n              // TODO Auto-generated method stub\n              System.out.println(mm.getName()+&quot;送你鲜花。&quot;);\n          &#125;\n          @Override\n          public void GiveChocolate() &#123;\n              // TODO Auto-generated method stub\n              System.out.println(mm.getName()+&quot;送你巧克力。&quot;);\n          &#125;\n      &#125;\n      public class Proxy implements IGiveGift &#123;\n          Pursuit gg;\n          public Proxy() &#123;\n              super();\n          &#125;\n          public Proxy(SchoolGirl mm) &#123;\n              super();\n              this.gg = new Pursuit(mm);\n          &#125;\n          @Override\n          public void GiveDolls() &#123;\n              // TODO Auto-generated method stub\n              gg.GiveDolls();\n          &#125;\n          @Override\n          public void GiveFlowers() &#123;\n              // TODO Auto-generated method stub\n              gg.GiveFlowers();\n          &#125;\n          @Override\n          public void GiveChocolate() &#123;\n              // TODO Auto-generated method stub\n              gg.GiveChocolate();\n          &#125;\n      &#125;\n      public class Test &#123;\n          public static void main(String[] args) &#123;\n              SchoolGirl mm = new SchoolGirl();\n              mm.setName(&quot;小美&quot;);\n              Proxy daili = new Proxy(mm);\n              daili.GiveDolls();\n              daili.GiveFlowers();\n              daili.GiveChocolate();\n          &#125;\n      &#125;\n\n\n代理模式结构图\n![代理模式结构图](http://i.imgur.com/EHPSse2.png)\n\n\n\nSubject接口，定义了RealSubject和Proxy的共用接口，这样就在任何使用RealSubject的地方都可以使用Proxy。\n  public interface Subject&#123;\n      public void request();\n  &#125;\n\nRealSubject定义Proxy所代表的真实实体，实现了Subject接口。\n  public RealSubject implement Subject&#123;\n      public void request()&#123;\n          //真实请求\n      &#125;\n  &#125;    \n\nProxy类，保存一个实体的引用使得代理可以访问实体，并实现Subject的接口，这样就可以用来代替实体。\n  public class Proxy implement Subject&#123;\n      RealSubject realSubject;\n      public Proxy()&#123;\n          realSubject = new RealSubject();\n      &#125;\n      public void request()&#123;\n          realSubject.request();        \n      &#125;\n  &#125;\n\n客户端代码：\n  public static void main(String[] args) &#123;\n      Proxy proxy = new Proxy();\n      proxy.request();\n  &#125;\n\n\n","categories":["大话设计模式"],"tags":[]},{"title":"装饰模式","url":"http://tanqingbo.cn/2016/05/21/装饰模式/","content":"装饰模式装饰模式之前的面向对象原则介绍\n单一职责原则：就一个类而言，应该仅有一个引起它变化的原因。也就是说功能要单一。\n优点： 灵活性，可复用性。\n如果一个类承担的职责太多，就等于把这些职责耦合在一起，一个职责的变化可能会削弱或者阻碍其他职责能力，这种耦合会导致脆弱的设计，当变化发生时，设计会发生意想不到的变化。\n\n\n开放封闭原则：软件应该可以扩展，但不可以修改。对于扩展是开放的，对于更改是封闭的。\n面对需求，对程序的改动是通过增加新代码进行的，而不是更改现有代码，这就是开放封闭原则的精神所在。\n优点：可扩展  可复用  灵活性好\n\n\n依赖倒转原则：抽象不应该依赖细节，细节不应该依赖抽象。针对对接口编程，不要对实现编程。即高层模块不依赖底层模块，底层模块不依赖高层模块。\n其实就是谁也不依赖谁，除了约定的接口，大家都可以灵活自如。\n\n\n里氏代换原则：子类型必须能够替换掉他们的父类型，只有当子类可以替换掉父类，软件单位功能不受影响时，父类才能真正倍复用。\n\n装饰模式\n装饰模式：动态地给一个对象添加一些额外的职责，就增加功能来说，装饰模式比生成子类更为灵活。\n\n装饰模式是为已有功能动态的添加更多功能的一种方式。\n\n代码实现：\n      //需要被装饰的对象\n      public class Person &#123;\n          private String name;\n          public Person(String name) &#123;\n              super();\n              this.name = name;\n          &#125;\n          public Person() &#123;\n              super();\n          &#125;\n          public void show()&#123;\n              System.out.println(&quot;装扮的&quot;+name);\n          &#125;\n      &#125;\n      //功能的抽象类\n      public class Finery extends Person&#123;\n          protected Person component;\n          //打扮\n          public void Decorate(Person component)&#123;\n              this.component = component;\n          &#125;\n          @Override\n          public void show()&#123;\n              if(component != null)&#123;\n                  component.show();\n              &#125;\n          &#125;\n      &#125;\n      //继承功能类\n      public class BigTrouser extends Finery &#123;\n          @Override\n          public void show()&#123;\n              System.out.println(&quot;垮裤&quot;);\n              super.show();\n          &#125;\n      &#125;\n      //继承功能类\n      public class TShirts extends Finery &#123;\n          @Override\n          public void show()&#123;\n              System.out.println(&quot;大T恤&quot;);\n              super.show();\n          &#125;\n      &#125;\n      //继承功能类\n      public class WearSneakers extends Finery &#123;\n          @Override\n          public void show()&#123;\n              System.out.println(&quot;破球鞋&quot;);\n              super.show();\n          &#125;\n      &#125;\n      //继承功能类\n      public class WearSuit extends Finery&#123;\n          @Override\n          public void show()&#123;\n              System.out.println(&quot;西装&quot;);\n              super.show();\n          &#125;\n      &#125;\n      //动态给对象添加功能\n      public class Test &#123;\n          public static void main(String[] args) &#123;\n              Person xc = new Person(&quot;小菜&quot;);\n              System.out.println(&quot;第一种装扮：&quot;);\n              WearSneakers w = new WearSneakers();\n              WearSuit ws = new WearSuit();\n              BigTrouser bt = new BigTrouser();\n              /*\n               * 首先实例化person对象\n               * 再用WearSneakers类包装person\n               * 再用WearSuit类来包装WearSneakers对象\n               * 再用BigTrouser类包装WearSuit对象\n               * 最终执行BigTrouser的show方法。\n               * \n               */\n              w.Decorate(xc);   \n              ws.Decorate(w);\n              bt.Decorate(ws);\n              bt.show();\n          &#125;\n      &#125;\n\n输出结果：\n      第一种装扮：\n      垮裤\n      西装\n      破球鞋\n      装扮的小菜\n\n什么时候使用装饰模式：\n\n当系统需要新功能时，是向旧的类中添加新的代码，这些新代码通常装饰了原有的核心职责或主要行为。\n\n\n把每个要装饰的功能放在单独的类中，并让这个类包装它所有装饰的对象。\n\n优点：\n\n把类的核心职责和装饰功能区分开来，去除相关类中重复的装饰逻辑。\n简化原有类。\n\n\n\n","categories":["大话设计模式"],"tags":[]},{"title":"eclipse使用lombok","url":"http://tanqingbo.cn/2016/05/21/eclipse使用lombok/","content":"eclipse使用lombok安装lombok\n下载lombok http://projectlombok.org/download.html,下载下来的是一个lombok.jar包。放到eclipse的文件夹下。\n\n\n双击lombok.jar进行安装。\n\n如果程序还在报错，那么点击在eclipse的Project选项的clean.\nlombok使用\nLombok的特色是根据annotation创建一些代码，以减少重复代码的数量，它提供了以下几个annotation：\n     @Getter和@Setter：为属性创建getter和setter\n     @EqualsAndHashCode：实现equals()方法和hashCode()方法\n     @ToString：实现toString()方法\n     @Data：上述3个annotation的和，会创建getter setter equals hashCode和toString （最实用）\n     @Cleanup：关闭流\n     @Synchronized：对象同步\n     @SneakyThrows：抛出异常\n     @Log4j: log4j日志声明\n\n\n实例        import lombok.Data;\n        import lombok.ToString;\n\n        @ToString(exclude=&quot;color&quot;) \n        public @Data class Person &#123; \n            private String name; \n            private int size; \n            private String color; \n            private String style; \n            private boolean flag;\n\n            public static void main(String[] args) &#123;\n                Person p = new Person();\n                p.setName(&quot;aa&quot;);\n                System.out.println(p.getName());\n            &#125;\n\n        &#125;\n\n@Data是实现所有的成员的Get和Set方法\n\n@ToString(exclude=”color”) 是ToString时候排除color成员变量\n\n注意调用flag成员变量时候，是isFlag方法\n\n注解加载类上，对所有的属性都有效，加在单一属性上只对该属性有效。\n\n\n","categories":["Java"],"tags":["lombok"]},{"title":"简单工厂模式与策略模式","url":"http://tanqingbo.cn/2016/05/20/简单工厂模式与策略模式/","content":"简单工厂模式与策略模式前言\n设计模式（Design Pattern）是一套被反复使用、多数人知晓的、经过分类的、代码设计经验的总结。\n\n使用设计模式的目的：为了代码可重用性、让代码更容易被他人理解、保证代码可靠性。 设计模式使代码编写真正工程化；设计模式是软件工程的基石脉络，如同大厦的结构一样。\n\n在介绍设计模式之前需要先介绍一下面向对象的特性和UML类图。\n面向对象的特点\n封装、继承、多态。\nUML类图\n在UML类图中，常见的有以下几种关系: 泛化（Generalization）,  实现（Realization），关联（Association)，聚合（Aggregation），组合(Composition)，依赖(Dependency)\n\n在UML类图中矩形框表示一个类，类分三层，第一层是；类的名称，如果是抽象类，则用斜体显示，第二层表示特性，是字段和属性，第三层表示操作，通常是方法和行为。\n\n注意前面符号，“+”表示public，“-”表示private，“#”表示protected。\n\n【泛化关系】：是一种继承关系，表示一般与特殊的关系，它指定了子类如何具体化父类的所有特征和行为。例如：老虎是动物的一种，即有老虎的特性也有动物的共性。\n【箭头指向】：带三角箭头的实线，箭头指向父类\n\n![](http://static.open-open.com/lib/uploadImg/20120201/20120201092740_578.gif)\n\n【实现关系】：是一种类与接口的关系，表示类是接口所有特征和行为的实现.\n【箭头指向】：带三角箭头的虚线，箭头指向接口\n\n![](http://static.open-open.com/lib/uploadImg/20120201/20120201092741_47.gif)\n\n【关联关系】：是一种拥有的关系，它使一个类知道另一个类的属性和方法；如：老师与学生，丈夫与妻子关联可以是双向的，也可以是单向的。双向的关联可以有两个箭头或者没有箭头，单向的关联有一个箭头。【代码体现】：成员变量【箭头及指向】：带普通箭头的实心线，指向被拥有者\n\n![](http://static.open-open.com/lib/uploadImg/20120201/20120201092741_41.gif)\n\n【聚合关系】：是整体与部分的关系，且部分可以离开整体而单独存在。如车和轮胎是整体和部分的关系，轮胎离开车仍然可以存在。聚合关系是关联关系的一种，是强的关联关系；关联和聚合在语法上无法区分，必须考察具体的逻辑关系。【代码体现】：成员变量【箭头及指向】：带空心菱形的实心线，菱形指向整体\n\n![](http://static.open-open.com/lib/uploadImg/20120201/20120201092741_681.gif)\n\n【组合关系】：是整体与部分的关系，但部分不能离开整体而单独存在。如公司和部门是整体和部分的关系，没有公司就不存在部门。组合关系是关联关系的一种，是比聚合关系还要强的关系，它要求普通的聚合关系中代表整体的对象负责代表部分的对象的生命周期。\n\n\n【代码体现】：成员变量\n【箭头及指向】：带实心菱形的实线，菱形指向整体\n\n![](http://static.open-open.com/lib/uploadImg/20120201/20120201092741_278.gif)\n\n+ **【依赖关系】**：是一种使用的关系，即一个类的实现需要另一个类的协助，所以要尽量不使用双向的互相依赖.\n\n【代码表现】：局部变量、方法的参数或者对静态方法的调用\n【箭头及指向】：带箭头的虚线，指向被使用者\n\n![](http://static.open-open.com/lib/uploadImg/20120201/20120201092741_129.gif)\n\n+  各种关系的强弱顺序：\n\n        泛化 = 实现 &gt; 组合 &gt; 聚合 &gt; 关联 &gt; 依赖 \n\n下面这张UML图，比较形象地展示了各种类图关系：\n\n\n![](http://static.open-open.com/lib/uploadImg/20120201/20120201092742_482.png)\n\n\n简单工厂模式\n工厂模式介绍\n\n工厂模式专门负责将大量有共同接口的类实例化，工厂模式可以动态决定将哪一个类实例化，不必事先知道要实例化那一个类。\n\n\n工厂模式的几种形态：\n\n简单工厂模式：又称静态工厂方法模式。\n工厂方法模式：又称多态性工厂模式。\n抽象工厂模式：又称 工具箱模式。\n\n\n简单工厂模式的举例  \n       //抽象产品角色  \n      public interface Car&#123;  \n            public void drive();  \n      &#125;  \n      //具体产品角色  \n      public class Benz implements Car&#123;  \n            public void drive() &#123;  \n               System.out.println(&quot;Driving Benz &quot;);  \n            &#125;  \n      &#125;  \n      public class Bmw implements Car&#123;  \n            public void drive() &#123;  \n             System.out.println(&quot;Driving Bmw &quot;);  \n            &#125;  \n      &#125;  \n      //工厂类角色  \n      public class Driver&#123;  \n              //工厂方法.注意 返回类型为抽象产品角色  \n               public static Car driverCar(String s)throws Exception&#123;  \n                     //判断逻辑，返回具体的产品角色给Client  \n                     if(s.equalsIgnoreCase(&quot;Benz&quot;))  \n                          return new Benz();  \n                     else if(s.equalsIgnoreCase(&quot;Bmw&quot;))  \n                              return new Bmw();  \n                       else throw new Exception();  \n             &#125;  \n      &#125;  \n\n\n策略模式\n定义：它定义了算法家族，分别封装起来，让他们之间可以可以互相替换，此模式让算法的变化，不会影响到使用算法的客户。\n\n![](http://i.imgur.com/RPI01tP.png)\n\nStrategy类，定义了所有的支持的算法的公共接口。\n          abstract class Strategy&#123;\n              //算法方法\n              public void AlgorithmInterface();\n          &#125;\n\nConcreteStrategy类封装了具体的算法或行为，继承Strategy类。\n      public class ConcreteStrategyA extend Strategy&#123;\n          //算法A实现方法\n          public void AlgorithmInterface()&#123;\n                  //算法A实现方法\n          &#125;\n      &#125;\n      public class ConcreteStrategyB extend Strategy&#123;\n          //算法B实现方法\n          public void AlgorithmInterface()&#123;\n                  //算法B实现方法\n          &#125;\n      &#125;\n\nContext类，用一个ConcreteStrategy来配置，维护一个对Strategy对象的引用。\n      public class Context&#123;\n          Strategy strategy;\n          public Context(Strategy strategy)&#123;  //初始化时，传入具体的策略对象\n              this.strategy = strategy;\n          &#125;\n          //上下文接口\n          public void ContextInterface()&#123;    //根据具体的策略对象调用其算法方法\n              strategy.AlgorithmInterface();\n          &#125;\n      &#125; \n      //主函数代码：\n      public static void main(String[] args) &#123;\n          Context context；\n          //由于实例化不同的策略，在调用context.AlgorithmInterface();时，所获得的结果也不同。\n          context = new Context(new ConcreteStrategyA());\n          context.AlgorithmInterface();\n          context = new Context(new ConcreteStrategyB());\n          context.AlgorithmInterface();\n      &#125;\n\n\n策略与工厂结合\n修改Context类\n      public class Context&#123;\n          Strategy strategy = null;  //声明一个接口对象\n          public Context(String type)&#123;  //初始化时，在Context类中实现简单工厂的应用。\n              switch(type)&#123;\n              case &quot;需求一&quot;：\n                  Strategy s1 = new ConcreteStrategyA();\n                  strategy = s1;\n                  break;\n              case &quot;需求二&quot;：\n                  Strategy s2 = new ConcreteStrategyB();\n                  strategy = s2;\n                  break;\n              &#125;\n          &#125;\n          public double GetResult()&#123;\n              return strategy..AlgorithmInterface();\n          &#125;\n      &#125;\n\n简单工厂模式与策略与工厂结合的客户端代码对比\n      //工厂模式用法\n      Strategy s = StrategyFactory.createStrategy(type);\n      ... = s.GetResult();\n      //策略与工厂结合\n      Context c = Context(type);\n      ... = c.GetResult();\n\n总结：简单工厂模式，客户端需要两个类，Strategy和StrategyFactory，而策略与工厂结合只需要一个类，Context类。降低了耦合性。\n策略模式解析\n策略模式是一种定义一系列算法的方法，所有这些算法完成的都是相同的工作，只是实现不同，它可以以相同的方式调用所有的算法，减少了各种算法类与使用算法类之间的耦合。\n\n优点：\n\n简化单元测试，因为每个算法都有自己的类，可以通过自己的接口单独测试，\n将一系列行为封装到一个个类中时，可以在这些行为的类中消除条件语句。\n\n\n只要在分析过程中听到需要在不同时间应用不同的业务规则，就可以考虑运用策略模式处理这种可能性变化。\n\n\n","categories":["大话设计模式"],"tags":[]},{"title":"园区网络的管理","url":"http://tanqingbo.cn/2016/05/17/网络工程期末考试/","content":"园区网络的管理以太网的工作特点\n广播的管理\nVLAN划分\n设备上实现\n\n\n路由技术\n静态路由\n动态路由\n\n\n网络访问控制技术\n标准访问控制\n扩展访问控制\n\n\n网络地址转换技术\n\n配置VLAN和路由\n配置产生新的VLAN\n     Switch#vlan database\n     Switch(vlan)#vlan 2 name xxx\n     Switch(vlan)#exit\n\n分配端口给新创建的VLAN\n\n考虑中继VLAN\n     Switch(config)#int fax/x\n     Switch(config-if)#switch mode trunk\n\n\n配置路由指令\n配置rip路由选择协议\n配置OSPF\n\n三层交换机的基本原理\n一个具有三层交换功能的设备，实际上是一个带有第三层路由功能的交换机，是二者的有机结合。\n发送方A将自己的IP地址与接收方B的IP地址比较，判断B是否与自己在同一子网内：\n若B与A在同一子网，则进行二层转发。\n若不在，A要向“默认网关”发出ARP分组，而“默认网关”的IP地址其实是三层交换机的第三层交换模块。\n\n\n如果三层交换模块已知B的MAC地址，则向A回复之，否则它向B广播一个ARP请求，B回复其MAC地址，三层交换机模块保存此地址并回复A，同时将B的MAC地址发送到二层交换机引擎的MAC地址表中。\n此后，当A与B间的数据分组全部由二层交换机高速处理，实现一次路由多次实现。\n\n虚拟Vlan\n在LAN交换机基础上，采用网络管理软件构建的可以跨越不同网段，不同技术的端到端逻辑网络。\n只有构成VLAN的站点直接与支持VLAN的LAN交换机端口相连，才能实现VLAN功能。\n优点包括：\n限制广播，提高交换机性能\n简化网络管理\n简化网络结构，保护网络投资\n提高网络的数据安全性\n\n\n实现方式：\n基于端口的VLAN\n基于MAC地址的VLAN\n基于协议的VLAN\n基于网络地址的VALN \n\n\n\n机房的总体设计\n对机房要求主要考虑面积、地面、墙壁、顶棚、门窗和照明等。\n机房位置选址：\n通常选择在高层大楼的中层为宜\n\n\n机房面积的确定\n通常网络系统机房面积设计应为设备占用面积的5~7倍的关系。\n\n\n计算机网络系统机房装饰设计\n机房地面、机房墙面、机房顶棚、机房门窗、机房照明\n\n\n\n机房的环境设计\n由于网络系统设备的高精密和系统的接插件多，所以机房环境的设计较高。\n通常要考虑的因素有：电源、灰尘、温度与湿度、腐蚀和电磁干扰等，这些也是造成计算机网络系统故障的主要环境因素\n机房温度与湿度的环境：开机时的机房温度通常要求在1530℃，停机时的机房温度要求在535℃；一般湿度保持在20%~80%\n\n配电系统及供电方式\n计算机网络系统设备间或中心机房的供电系统，通常要求不间断第供电。\n也可以采用两路供电系统，一旦一路停电，立即自动切换到另一路供电系统。\n市电直接供电方式\n适应于电网系统运行稳定，质量又有保证，周围没有大型负载以及电磁干扰。\n\n\nUPS系统供电：\n在线型UPS即指其机内的逆变器串联在供电回路上，持续不间断第工作着的UPS\n后备型UPS是指其机内逆变器通过转换开关并联在供电回路上，只有当市电中断以后才受控工作的UPS。\n\n\n综合供电方式：\n机房内，电源插座应有两种。一种有UPS电源供电，另一种市电直接供电。\n\n\n\n机房供电设计\n电力供应有以下要求\n电网电压要稳定，通常要求在任何情况下，其偏差不得超过额定值的+-5%\n要求电网电压杂波少，干扰少\n防止工业控制系统交变电磁场的辐射干扰\n电网必须在一定的时间内不间断地连续供电\n最好不要与大容器的感性负载电网并联运行，以防止高压涌流\n电网的频率漂移要小，提供计算机网络系统设备的电源频率偏差不得大于+-1%\n计算机网络系统所用的电源要有良好的接地\n\n\n\n供电系统的负荷计算\n一个机房或一个用电系统，分为照明用电、空调用电和设备用电\n\n负载功率有实测法和估算法两种\n\n实测法即指在通电的情况下，测量负载电流。如果负载为单相时，则为相电流与电压乘积的2倍作为负载功率；如果负载为三相时，则用电电流与相电压乘积的3倍作为负载功率\n估算法则是将各个单项负载功率加起来，所得的和再乘以一个保险系数（可取1.3）作为总的负载功率。\n\n\n上述计算仅作为总负载功率的基数，还要考虑为以后扩容设备留余量。\n机房电源容量估算\n设计要点：\n\n每个计算机网络机房都需要有一个完善的供电系统，为了保障供电安全，需要对机房中所有机器的总功率进行估算。\n电功率估算方法：每台PC机计300-350W，每台交换机计1000W-1500W，每台路由器计1500-3000W，每台服务器计3000-5000W，照明电一般与动力电路分路供电，可分开按灯具功率计算。附加一个保险系数。机房空调容量的设计\n\n\n机房都主要是靠空调机进行温度和湿度的调节\n\n空调容量的设计，通常需要考虑设备发热、机房照明的发热、机房人员的热量、机房外围结构和空气流通等因素\n\n计算方法：\n      K = (100~300)*∑S(大卡)\n      其中K为空调容量，∑S为机房面积。\n\n\n","categories":["网络原理"],"tags":["网络"]},{"title":"计算机专业相关的夏令营汇总","url":"http://tanqingbo.cn/2016/05/11/夏令营汇总/","content":" 计算机专业相关的夏令营汇总\n\n\n序号学校申请截止时间开营时间结营时间链接\n1华科国光6月12日7月4日7月8日[夏令营官方链接](http://gu.wnlo.cn/index.php?a=shows&catid=35&id=227#rd)\n2华东师范[夏令营官方链接](http://www.eeban.com/forum.php?mod=viewthread&tid=36408&extra=page%3D1&_dsign=836d890e)\n3南京大学6月12日7月14日7月16日[夏令营官方链接](http://www.eeban.com/thread-41222-1-1.html)\n4复旦大学6月10日7月4日7月8日[夏令营官方链接](http://yz.kaoyan.com/fudan/tuimian/591701bbddef5.html)\n5中科院自动化所6月21日7月10日7月15日[夏令营官方链接](http://www.eeban.com/forum.php?mod=viewthread&tid=38705&page=1&extra=#pid791088)\n6北航7月5日7月11日7月12日[夏令营官方链接](http://scse.buaa.edu.cn/info/1099/3694.htm)\n7西安交大5月15日6月4日6月5日[夏令营官方链接](http://www.eeban.com/forum.php?mod=viewthread&tid=34917&highlight=%E8%A5%BF%E5%AE%89%E4%BA%A4%E9%80%9A%E5%A4%A7%E5%AD%A6%E7%94%B5%E5%AD%90%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%AD%A6%E9%99%A2&_dsign=e42fb12e)\n\n8北交6月10日7月20日7月23日[夏令营官方链接](http://www.eeban.com/forum.php?mod=viewthread&tid=42321&page=1&extra=#pid804294)\n\n9南开直博5月31日6月中旬6月中旬[夏令营官方链接](http://cc.nankai.edu.cn/Infomation/NewsDetails.aspx?id=14889&cid=1)\n\n10清华大学信息国家实验室5月31日7月5日7月7日[夏令营官方链接](http://bioinfo.au.tsinghua.edu.cn/admissions/)\n11长安大学7月5日7月10日7月13日[夏令营官方链接](http://it.chd.edu.cn/info/1064/6751.htm)\n12东华大学大数据夏令营7月3日7月15日7月17日[夏令营官方链接](http://yjszs.dhu.edu.cn/3a/bb/c7129a146107/page.htm)\n13清华大学计算机系未知7月16日7月18日[夏令营官方链接](http://www.eeban.com/forum.php?mod=viewthread&tid=40580&extra=page%3D1&_dsign=b69affbf)\n14北大信息科学技术学院未知7月13日7月15日[夏令营官方链接](http://www.eeban.com/forum.php?mod=viewthread&tid=40538&extra=page%3D1&_dsign=96a77407)\n15中科大计算机系未知[夏令营官方链接](http://cs.ustc.edu.cn/xwxx/jxxx/201605/t20160504_244403.html)\n16中科院计算所6月23日7月17日7月23日[夏令营官方链接](http://www.ict.ac.cn/shye/tzgg/201605/t20160513_4601562.html)\n17中科院软件所未知[夏令营官方链接](http://www.is.cas.cn/yjsjy2016/zsxx2016/201705/t20170510_4786426.html)\n18中科院计算机网络中心未知[夏令营官方链接](http://zxsq.ucas.ac.cn/home/index_SC)\n19电子科大信息工程学院6月6号7月4号7月8号[夏令营官方链接](http://yz.uestc.edu.cn/xialingying/2018/05/11/496.html)\n20湖南大学7个学院6月12号[夏令营官方链接](http://yjs.hnu.cn/zsxt/xlygl/)\n21中山大学计算机6月12号7月15号7月22号[夏令营官方链接](http://yz.kaoyan.com/zsu/tuimian/592030a830d9d.html)\n22厦门大学软件6月15号7月18号7月22号[夏令营官方链接](http://yz.kaoyan.com/xmu/tuimian/5920f2cc3ec5a.html)\n23浙大6月26号7月11号7月15号[夏令营官方链接](http://www.eeban.com/forum.php?mod=viewthread&tid=40892&extra=page%3D1&_dsign=2343bdf0)\n24夏门大学计算机6月15号7月15号7月15号[夏令营官方链接](http://information.xmu.edu.cn/portal/node/7583)\n25西南大学6月23号7月21号7月22号[夏令营官方链接](http://www.eeban.com/forum.php?mod=viewthread&tid=35696&extra=page%3D1&_dsign=f797c4b2)\n26南开软件6月23号7月21号7月22号[夏令营官方链接](http://www.eeban.com/forum.php?mod=viewthread&tid=42944&extra=page%3D1&page=1&_dsign=377b0978)\n27川大6月30号7月18号7月23号[夏令营官方链接](http://www.eeban.com/forum.php?mod=viewthread&tid=42944&extra=page%3D1&page=1&_dsign=377b0978)\n28北京师范大学信息科学技术学院7月8号7月10号[夏令营官方链接](http://cist.bnu.edu.cn/tzgg/14065.html)\n29武汉大学计算机6月20号7月11号7月13号[夏令营官方链接](http://cs.whu.edu.cn/a/bangongdianhuafabu/2016/0527/6449.html)\n\n\n\n\n\n为节省大家宝贵的时间\n更快的从海量的各个学校的夏令营信息中找到有用的信息\n我特意将信息整理了一下，并做了这个网页，方便大家查找。\n以上所有学校的夏令营信息只和计算机专业有关。\n上面的信息会随着各个学校夏令营信息的更新而随时更新，方便大家查看。\n\n","categories":["技术博客"],"tags":[]},{"title":"Map使用多个映射","url":"http://tanqingbo.cn/2016/05/03/Map使用多个映射/","content":"Map使用多个映射问题描述\n许多单词和另外一些单词相似，例如，通过改变第一个字母，单词wine可以变成，dine fine line mine nine pine vine 改变第3个字母，wide wife wipe wire…….\n\n他们仅仅通过改变一个字母，可以得到很多个单词，假设有一个词典，89000个单词，将单词长度相同，且只有一个字母不同的单词放到一组。\n思路\n使用一个MAP对象，其中key是单词，value是用一个字母替换能从key变换得到的一系列单词。\n\n主要问题是如何从包含89000个单词的数组中构造MAP对象。\n方法一：暴力解决\n先判断除一个字母不同外，两个单词是否相等。代码如下：\n  private static Boolean oneCharOff(String word1,String word2)&#123;\n      if(word1.length()!=word2.length()) return false;\n      int diffs = 0;\n      for(int i=0;i&lt;word1.length();i++)&#123;\n          if(word1.charAt(i)!=word2.charAt(i))\n              if(++diffs&gt;1)\n                  return false;\n      &#125;\n      return true;\n  &#125;\n\n计算一个MAP对象，该对象以一些单词作为关键字而以只在一个字母处不同的一列单词作为关键字的值，该函数对一个89000单词的词典运行96秒。\n      public static Map&lt;String, List&lt;String&gt;&gt; computeAdjacentWord(List&lt;String&gt; theWords)&#123;\n          //单词映射，单词作为关键字，而只有一个单词和该单词不同的一系列单词作为值。\n          Map&lt;String, List&lt;String&gt;&gt; adjWords = new TreeMap&lt;String, List&lt;String&gt;&gt;();\n          String[] words = new String[theWords.size()];\n          theWords.toArray(words);\n          for(int i=0;i&lt;words.length;i++)&#123;\n              for(int j = i+1;j&lt;words.length;j++)&#123;\n                  if(oneCharOff(words[i], words[j]))&#123;\n                      update(adjWords,words[i], words[j]);\n                      update(adjWords,words[j], words[i]);\n                  &#125;\n              &#125;\n          &#125;\n          return adjWords;\n      &#125;\n\n      private static &lt;KeyType&gt; void update(Map&lt;KeyType, List&lt;String&gt;&gt; adjWords, KeyType string, String string2) &#123;\n          List&lt;String&gt; lst = adjWords.get(string);\n          if(lst == null)&#123;\n              lst = new ArrayList&lt;String&gt;();\n              adjWords.put(string, lst);\n          &#125;\n          lst.add(string2);\n      &#125;\n\n该算法的问题在于速度慢，一个明显的改进就是避免比较不同长度的单词。可以把单词按照长度分组，然后对各分组进行上述程序。\n方法二：避免比较单词长度\n可以把单词按照长度分组，然后对各分组进行上述程序。为此可以使用第二个映射，此时关键字是整数，代表单词长度，而值是该长度对应的单词集合。\n  public static Map&lt;String, List&lt;String&gt;&gt; computeAdjacentWord(List&lt;String&gt; theWords)&#123;\n      Map&lt;String, List&lt;String&gt;&gt; adjWords = new TreeMap&lt;String, List&lt;String&gt;&gt;();\n      Map&lt;Integer, List&lt;String&gt;&gt; wordsByLength = new TreeMap&lt;Integer, List&lt;String&gt;&gt;();\n      for(String w:theWords)&#123;\n          //根据长度对单词分组\n          update(wordsByLength,w.length(),w);\n      &#125;\n      for(List&lt;String&gt; list:wordsByLength.values())&#123;\n\n          String[] words = new String[list.size()];\n          list.toArray(words);\n          for(int i=0;i&lt;words.length;i++)&#123;\n              for(int j = i+1;j&lt;words.length;j++)&#123;\n                  if(oneCharOff(words[i], words[j]))&#123;\n                      update(adjWords,words[i], words[j]);\n                      update(adjWords,words[j], words[i]);\n                  &#125;\n              &#125;\n          &#125;\n      &#125;\n      return adjWords;\n  &#125;\n\n引入第二个集合后，可以使words.length的值成倍减少，也就可以使双重循环的次数减少，从而缩短运行时间。\n\n与第一个方法比较，第二个方法只是在边际上编程困难，其运行时间为51秒，大约快了一倍。\n\n方法二中的update方法和oneCharOff方法参考方法一。\n\n\n方法三：\n另外有附加了一些映射，先和方法二一样，将单词按长度分组，然后分别对每组运算。\n\n假设对长度为4的单词操作，这是首先要找出像wine和nine这样的单词，他们除第一个外单词完全相同，对于这种单词，可以删除第一个字母，留下3个单词做代表，这样就形成一个Map，其中关键字为这个代表，而其值是所有包含同一代表的单词的一个List。\n\n每一个Map中的list对象都形成单词的一个集团，其中任何一个单词均可以通过单个字母替换变成另一个单词，因此在这个最后的Map构成之后，很容易遍历它以及添加一些项到正在计算的原始Map中。\n\n然后我们使用一个新的Map再处理4个字母单词组的第二个字母。此后第三个字母，最后是第四个字母。\n      public static Map&lt;String, List&lt;String&gt;&gt; computeAdjacentWord(List&lt;String&gt; theWords)&#123;\n          Map&lt;String, List&lt;String&gt;&gt; adjWords = new TreeMap&lt;String, List&lt;String&gt;&gt;();\n          Map&lt;Integer, List&lt;String&gt;&gt; wordsByLength = new TreeMap&lt;Integer, List&lt;String&gt;&gt;();\n          for(String w:theWords)&#123;\n              //根据长度对单词分组\n              update(wordsByLength,w.length(),w);\n          &#125;\n          //每一组单词按去掉一个字母后是否相同再次分组映射\n          for(Map.Entry&lt;Integer, List&lt;String&gt;&gt; entry : wordsByLength.entrySet())&#123;\n              List&lt;String&gt; groupsWords = entry.getValue();\n              int groupNum = entry.getKey();\n              //从第一个字母开始，依次处理每个字母，映射到Map中。\n              for(int i=0;i&lt;groupNum;i++)&#123;\n                  Map&lt;String, List&lt;String&gt;&gt; repToWord = new TreeMap&lt;String, List&lt;String&gt;&gt;();\n                  //从第一个字母开始，依次处理每个字母，映射到Map中。\n                  for(String str:groupsWords)&#123;\n                      String rep = str.substring(0,i) + str.substring(i+1);\n                      update(repToWord, rep, str);\n                  &#125;\n                  //放到最终的Map映射中。\n                  for(List&lt;String&gt; wordClique : repToWord.values())&#123;\n                      if(wordClique.size()&gt;2)\n                          for(String s1 : wordClique)\n                              for(String s2 : wordClique)\n                                  if(s1 != s2)\n                                      update(adjWords, s1, s2);\n                  &#125;\n              &#125;\n          &#125;\n          return adjWords;\n      &#125;\n\n      private static &lt;KeyType&gt; void update(Map&lt;KeyType, List&lt;String&gt;&gt; adjWords, KeyType string, String string2) &#123;\n          List&lt;String&gt; lst = adjWords.get(string);\n          if(lst == null)&#123;\n              lst = new ArrayList&lt;String&gt;();\n              adjWords.put(string, lst);\n          &#125;\n          lst.add(string2);\n      &#125;\n\n该算法对89000个单词处理改进到了4秒，大大提升了效率。\n\n\n","categories":["Java"],"tags":["数据结构，Map"]},{"title":"加密算法复习","url":"http://tanqingbo.cn/2016/05/02/加密算法复习/","content":"加密算法复习\nDES算法\nDES全称为Data Encryption Standard，即数据加密标准，是一种使用密钥加密的块算法。\nDES算法入口参数\nDES算法的入口参数有三个:Key、Data、Mode。其中Key为7个字节共56位,是DES算法的工作密钥;Data为8个字节64位,是要被加密或被解密的数据;Mode为DES的工作方式,有两种:加密或解密。\n算法步骤：\nDES算法把64位的明文输入块变为64位的密文输出块,它所使用的密钥也是56位，其算法主要分为两步：\n\n初始置换 其功能是把输入的64位数据块按位重新组合,并把输出分为L0、R0两部分,每部分各长32位,其置换规则为将输入的第58位换到第一位,第50位换到第2位……依此类推,最后一位是原来的第7位。L0、R0则是换位输出后的两部分，L0是输出的左32位,R0是右32位,例:设置换前的输入值为D1D2D3……D64,则经过初始置换后的结果为:L0=D58D50……D8;R0=D57D49……D7。\n 其置换规则见下表：\n 58,50,42,34,26,18,10,2,60,52,44,36,28,20,12,4,\n 62,54,46,38,30,22,14,6,64,56,48,40,32,24,16,8,\n 57,49,41,33,25,17,9,1,59,51,43,35,27,19,11,3,\n 61,53,45,37,29,21,13,5,63,55,47,39,31,23,15,7,\n\n逆置换 经过16次迭代运算后,得到L16、R16,将此作为输入,进行逆置换,逆置换正好是初始置换的逆运算，由此即得到密文输出。 此算法是对称加密算法体系中的代表,在计算机网络系统中广泛使用.\nIDEA算法原理：\n\n\nIDEA 它也是对64bit大小的数据块加密的分组加密算法密钥长度为128位它基于”相异代数群上的混合运算”设计思想。\n\n产生密钥：\n\n算法用了52个子密钥(8轮中的每一轮需要6个，其他4个用与输出变换)。\n将128-位密钥分成8个16-位子密钥。这些是算法的第一批8个子密钥（第一轮六个，第二轮的头两个）。然后，密钥向左环移25位后再分成8个子密钥。开始4个用在第二轮，后面4个用在第三轮。密钥再次向左环移25位产生另外8个子密钥，如此进行直到算法结束。具体是：IDEA总共进行8轮迭代操作，每轮需要6个子密钥,另外还需要4个额外子密钥,所以总共需要52个子密钥，这个52个子密钥都是从128位密钥中扩展出来的。\n\n\n加密过程：\n\n输入的64-位数据分组被分成4个16-位子分组：xl，X2，x3和x4。\n\n这4个子分组成为算法的第一轮的输入，总共有8轮。在每一轮中，这4个子分组相互相异或，相加，相乘，且与6个16-位子密钥相异或，相加，相乘。\n         在每一轮中，执行的顺序如下：\n     　　(1)X1和第一个子密钥相乘。\n     　　(2)x2和第二个子密钥相加。\n     　　(3)X3和第三个子密钥相加。\n     　　(4)x4和第四个子密钥相乘。\n     　　(5)将第(1)步和第(3)步的结果相异或。 .\n     　　(6)将第(2)步和第(4)步的结果相异或。\n     　　(7)将第(5)步的结果与第五个子密钥相乘。\n     　　(8)将第(6)步和第(7)步的结果相加。\n     　　(9)将第(8)步的结果与第六个子密钥相乘。\n     　　(10)将第(7)步和第(9)步的结果相加。\n     　　(11)将第(1)步和第(9)步的结果相异或。\n     　　(12)将第(3)步和第(9)步的结果相异或。\n     　　(13)将第(2)步和第(10)步的结果相异或。\n     　　(14)将第(4)步和第(10)步的结果相异或。\n     　　每一轮的输出是第(11)、(12)、(13)和(14) 步的结果形成的4个子分组。\n                 将中间两个分组分组交换(最后一轮除外)后，即为下一轮的输入。\n     　　经过8轮运算之后，有一个最终的输出变换：\n     　　(1) X1和第一个子密钥相乘。\n     　　(2) x2和第二个子密钥相加。\n     　　(3) x3和第三个子密钥相加。\n     　　(4) x4和第四个子密钥相乘。\n\n\n\nIDEA算法的密钥长度为128位。设计者尽最大努力使该算法不受差分密码分析的影响。\nMD5加密算法\nMD5加密是一种不可逆的加密算法。\nMd5加密算法原理\nMD5加密算法以512位分组来处理输入的信息，且每一分组又被划分为16个32位子分组，经过了一系列的处理后，算法的输出由四个32位分组组成，将这四个32位分组级联后将生成一个128位散列值。\n\n在MD5加密算法中，首先需要对信息进行填充，使其字节长度对512求余数的结果等于448。因此，信息的字节长度（Bits Length）将被扩展至N512+448，即N64+56个字节（Bytes），N为一个正整数。\n\n填充的方法如下：在信息的后面填充一个1和无数个0，直到满足上面的条件时才停止用0对信息的填充。然后再在这个结果后面附加一个以64位二进制表示的填充前的信息长度。经过这两步的处理，现在的信息字节长度=N*512+448+64=(N+1)*512，即长度恰好是512的整数倍数。这样做的原因是为满足后面处理中对信息长度的要求。\n\nMD5中有四个32位被称作链接变量（Chaining Variable）的整数参数，他们分别为：\n  A=0x01234567\n\n  B=0x89abcdef\n\n  C=0xfedcba98\n\n  D=0x76543210\n\n当设置好这四个链接变量后，就开始进入算法的四轮循环运算，循环的次数是信息中512位信息分组的数目。\n\n将上面四个链接变量复制到另外四个变量中：A到a，B到b，C到c，D到d。 主循环有四轮（MD4只有三轮），每轮循环都很相似。第一轮进行16次操作。每次操作对a、b、c和d中的其中三个作一次非线性函数运算，然后将所得结果加上第四个变量（文本中的一个子分组和一个常数）。\n\n再将所得结果向右环移一个不定的数，并加上a、b、c或d中之一。最后用该结果取代a、b、c或d中之一。 以一下是每次操作中用到的四个非线性函数（每轮一个）。\n  F(X,Y,Z)=(X∧Y)∨(( X)∧Z)\n  G(X,Y,Z)=(X∧Z)∨(Y∧( Z))\n  H(X,Y,Z)=X?Y?Z\n  I(X,Y,Z)=Y?(X∨( Z))\n  其中，?是异或，∧是与，∨是或， 是反符号。\n\n如果X、Y和Z的对应位是独立和均匀的，那么结果的每一位也应是独立和均匀的。F是一个逐位运算的函数。即，如果X，那么Y，否则Z。函数H是逐位奇偶操作符。所有这些完成之后，将A，B，C，D分别加上a，b，c，d。然后用下一分组数据继续运行算法，最后的输出是A，B，C和D的级联。最后得到的A，B，C，D就是输出结果，A是低位，D为高位，DCBA组成128位输出结果。\n\n\nMd5加密算法的应用\nMD5加密算法由于其具有较好的安全性，加之商业也可以免费使用该算法，因此该加密算法被广泛使用，md5加密算法主要运用在数字签名、文件完整性验证以及口令加密等方面。\n\n","categories":["技术博客"],"tags":["项目","java"]},{"title":"我的项目---林业百科","url":"http://tanqingbo.cn/2016/05/02/我的项目---林业百科/","content":"我的项目—林业百科数据库森林资源非空间数据标准\n地类代码表\n\n\n林种代码表\n林分因子代码表\n单株林木因子代码表\n森林环境因子代码表\n人工造林措施数据代码表\n森林经营数据代码表\n资源动态变化数据代码表\n森林权属数据代码表\n森林主要植物种代码表\n植被类型代码表\n森林类型代码表\n森林灾害数据代码表\n其他数据代码表\n\nother\n地形图要素分类与代码\n国土基础信息数据分类与代码\n荒漠化信息分类与代码\n陆生野生动物疫病分类与代码\n木材产品物资分类与代码\n森林火灾信息分类与代码1\n森林火灾信息分类与代码2\n森林生态工程信息分类与代码\n森林植物害虫分类与代码\n森林资源分类与代码–国营林场分类与代码\n森林资源分类与代码–林木病害\n森林资源分类与代码–陆栖脊椎野生动物\n森林资源分类与代码–森林类型\n森林资源分类与代码–森林资源\n森林资源分类与代码–自然保护区\n野生种植物保护信息分类与代码1\n野生种植物保护信息分类与代码2\n湿地信息分类与代码\n营林产品分类与代码\n中国土壤分类与代码\n专题地图信息分类与代码\n\n遇到的困难\n数据加密：数据加密采用的是IDEA加密算法，这种算法是在DES算法的基础上发展出来的，类似于三重DES，弥补了DES密钥太短的缺点。IDEA密钥为128位。\n原理：\nIDEA 它也是对64bit大小的数据块加密的分组加密算法密钥长度为128位它基于”相异代数群上的混合运算”设计思想。\n\n产生密钥：\n\n算法用了52个子密钥(8轮中的每一轮需要6个，其他4个用与输出变换)。\n将128-位密钥分成8个16-位子密钥。这些是算法的第一批8个子密钥（第一轮六个，第二轮的头两个）。然后，密钥向左环移25位后再分成8个子密钥。开始4个用在第二轮，后面4个用在第三轮。密钥再次向左环移25位产生另外8个子密钥，如此进行直到算法结束。具体是：IDEA总共进行8轮迭代操作，每轮需要6个子密钥,另外还需要4个额外子密钥,所以总共需要52个子密钥，这个52个子密钥都是从128位密钥中扩展出来的。\n\n\n加密过程：\n\n输入的64-位数据分组被分成4个16-位子分组：xl，X2，x3和x4。\n\n这4个子分组成为算法的第一轮的输入，总共有8轮。在每一轮中，这4个子分组相互相异或，相加，相乘，且与6个16-位子密钥相异或，相加，相乘。\n         在每一轮中，执行的顺序如下：\n     　　(1)X1和第一个子密钥相乘。\n     　　(2)x2和第二个子密钥相加。\n     　　(3)X3和第三个子密钥相加。\n     　　(4)x4和第四个子密钥相乘。\n     　　(5)将第(1)步和第(3)步的结果相异或。 .\n     　　(6)将第(2)步和第(4)步的结果相异或。\n     　　(7)将第(5)步的结果与第五个子密钥相乘。\n     　　(8)将第(6)步和第(7)步的结果相加。\n     　　(9)将第(8)步的结果与第六个子密钥相乘。\n     　　(10)将第(7)步和第(9)步的结果相加。\n     　　(11)将第(1)步和第(9)步的结果相异或。\n     　　(12)将第(3)步和第(9)步的结果相异或。\n     　　(13)将第(2)步和第(10)步的结果相异或。\n     　　(14)将第(4)步和第(10)步的结果相异或。\n     　　每一轮的输出是第(11)、(12)、(13)和(14) 步的结果形成的4个子分组。\n                 将中间两个分组分组交换(最后一轮除外)后，即为下一轮的输入。\n     　　经过8轮运算之后，有一个最终的输出变换：\n     　　(1) X1和第一个子密钥相乘。\n     　　(2) x2和第二个子密钥相加。\n     　　(3) x3和第三个子密钥相加。\n     　　(4) x4和第四个子密钥相乘。\n\n\n\nIDEA算法的密钥长度为128位。设计者尽最大努力使该算法不受差分密码分析的影响。\n对数据库加密遇到的问题：\n因为加密算法是用Java写的，idea算法只能对byte数组加密，但是从数据库中读出来的数据是string类型的，这中间需要string到byte的转换，一开始直接用string.getByte()方法，加完密在利用string的构造方法将byte转化为string存到数据库，然后再从数据库读密文加密的时候就全乱码了。\n\n这个问题捣鼓了很久，不断测试过程发现肯定不是算法问题，因为直接把加完密的byte解密输出的时候，不是乱码，而是明文，所有应该是在加密和解密的过程中，string转byte出现了问题，后来找了一个Base64提供的接口：\n      //string转byte            \n      new sun.misc.BASE64Decoder().decodeBuffer(js.getCode())\n      //byte转string\n      new sun.misc.BASE64Encoder().encodeBuffer(decryptdata[k]);\n      加完密之后，密文byte转string的时候用new sun.misc.BASE64Encoder().encodeBuffer(decryptdata[k])，\n      解密之前，密文string转byte时候用new sun.misc.BASE64Decoder().decodeBuffer(js.getCode())，\n      整个加密 解密过程只是使用这两次，其它情况正常转换即可。\nBase64是网络上最常见的用于传输8Bit字节代码的编码方式之一\n\n\n数据录入数据库的问题\n如何把书中的数据录入数据库中？\n手动录入肯定不可能，因为数据量很大\n解决办法是，扫描仪扫描整本书，得到PDF文件\n然后测试了多个文档识别软件，最终选用了Abbyy FineReader\n通过它消除了不必要的水印，数据出错率也低。\n转换成Excel后，通过Java程序读取Excel内容存入了相应的数据库\n\n\n\n","categories":["技术博客"],"tags":["项目","java"]},{"title":"我的项目---博客","url":"http://tanqingbo.cn/2016/05/01/我的项目---博客/","content":"我的项目—博客数据库\n总共建了6个表\nblog表:存放博客的各种内容\nbiduse_uidtextsmaincontentviewedreleasedatecommentcountstitleauthortid\n主键user表的外建博客内容摘要访问量发表日期评论次数标题作者btypes表的外建\n\nbtypes表：博客的类型表\ntidname\n主键类型名\ncomments表：评论表\npidbiduidptextpdatereplyreplydate\n主键blog表的外建用户表的外建评论内容评论日期回复回复日期\n\nresource表：资源表，存放可以下载的所有资源信息\nridrnameuploaderuploaddatertid\n主键资源名上传者上传日期resourcetype表的外建\nresourcetype表：资源类型\nrtidrtname\n主键资源类型名\nuser表：用户表\nuidnamepasswordauthor\n主键用户名密码真实名\n\n\n\n持久层+控制层\n所用技术：hibernate连接数据库\n\n\nboke.dao和boke.dao.impl是一类，boke.dao提供操作数据库的借口，boke.dao.impl实现boke.dao中的借口，即具体如何操作数据库。\nBoke.dao.service和boke.service.impl是一类，跟boke.dao和boke.dao.impl的关系差不多，Boke.dao.service提供接口，boke.service.impl实现借口，不同的是boke.service.impl中的函数是给前台调用，而boke.dao.impl中的函数是给boke.service.impl调用。\nBoke.service.util包中只有一个类ManagerTemplate.java，它里面包含了boke.dao中所有类的声明和提取器，它的作用是service和dao的桥梁，boke.service.impl中的类继承了ManagerTemplate类，boke.service.impl通过ManagerTemplate调用boke.dao.impl为前台提供服务。\n\n\n前台DWR\nDWR介绍:是一个用于改善web页面与Java类交互的远程服务器端Ajax开源框架，可以帮助开发人员开发包含AJAX技术的网站。它可以允许在浏览器里的代码使用运行在WEB服务器上的JAVA函数，就像它就在浏览器里一样。\nDWR使用：\ndwr.xml的配置文件\n\n\n\n\n   &lt;dwr&gt;\n    &lt;allow&gt;\n    &lt;create creator=&quot;new&quot; javascript=&quot;testClass&quot; &gt;\n    &lt;include method=&quot;testMethod1&quot;/&gt;\n    &lt;/create&gt;\n    &lt;/allow&gt;\n    &lt;/dwr&gt;\n\n    &lt;allow&gt;标签中包括可以暴露给javascript访问的东西。\n    &lt;create&gt;标签中指定javascript中可以访问的java类名，并定义DWR应当如何获得要进行远程的类的实例。\n    creator=&quot;new&quot;属性指定java类实例的生成方式，new意味着DWR应当调用类的默认构造函数来获得实例，\n    其他的还有spring方式，通过与IOC容器Spring进行集成来获得实例等等。javascript=&quot; testClass &quot;属性\n    指定javascript代码访问对象时使用的名称。\n    标签指定要公开给javascript的java类名。\n    &lt;include&gt;标签指定要公开给javascript的方法。不指定的话就公开所有方法。\n    &lt;exclude&gt;标签指定要防止被访问的方法。\n    注意：include和exclude不能同时存在\n2.DWR的前台调用：在web前台页面需要引入engine.js这个类库。然后再引入需要调用的那个java类的js类库，例如：\n     &lt;script type=&#39;text/javascript&#39; src=&#39;/Boke/dwr/interface/UserManager.js&#39;&gt;&lt;/script&gt;\n加完之后就可以在该页面对应的js中使用UserManager类提供的函数了。注：DWR框架会自动生成两个核心JavaScript函数库：1, engine.js文件，这个文件是DWR的核心库，只要需要使用DWR就不能缺少该文件； 2, util.js，这个文件是DWR的工具类库，使用它可以简化客户端DOM元素的操作，可以不引用。\nBootstrap\nBootstrap，来自 Twitter，是目前很受欢迎的前端框架。\nBootstrap 是基于 HTML、CSS、JAVASCRIPT 的,是一个CSS/HTML框架。Bootstrap提供了优雅的HTML和CSS规范.\nBootstrap Less:Less 是一个 CSS 预处理器，让 CSS 具有动态性.\n\n\n项目中遇到的困难\n数据库结构的设计，由于没有经验，最开始设计的表没有严格按照3大范式，在user表和resource表中都加了author这个字段，后来在敲代码实现的时候才发现了这个严重的弊端，要修改的时候，得同时修改user表和resource表中的author，增加了很多不必要的代码量，也降低了系统的性能。\n\n博客检索的时候用的是暴力检索，就是取回用户输入的信息直接上blog表里去检索，因为随着用户量的增加，blog内容就越多，直接检索的速度会很慢，用了一段时间之后才想起来，应该为blog表建一个索引表，只存id和标题，检索的时候上索引表中去找，这样可以大大的提升效率。\n\nhibernate的懒加载问题，在hibernate配置文件中，表的一对多，多对多，一对一中，都得让lazy=”false” ，但是将lazy改成false:每次代码执行时，自动将数据库所有数据加载到对象，不管需不需要使用，效率慢。但是如果将lazy=”true”，程序一运行就抛出一个错误，这个问题困扰了我很久，后来在视频学习的过程中，发现可以用spring延迟session的关闭时间的方法解决懒加载问题。实现方法如下：\n 通过OpenSessionInView的过滤器来实现,在web.xml中配置，配置时，应该放在第一个Filter的位置上；\n  &lt;filter&gt;\n      &lt;filter-name&gt;openSession&lt;/filter-name&gt;\n &lt;filter-class&gt;org.springframework.orm.hibernate4.support.OpenSessionInViewFilter&lt;/filter-class&gt;\n  &lt;/filter&gt;\n  &lt;filter-mapping&gt;\n      &lt;filter-name&gt;openSession&lt;/filter-name&gt;\n      &lt;url-pattern&gt;/*&lt;/url-pattern&gt;\n  &lt;/filter-mapping&gt;\n\n没有考虑到数据结构的优化，博客全部遍历显示的时候，由于应该没有两片完全一样的博客，应该用hashset来存，这样速度更快一些，但我全部都用的是ArrayList。\n\n输入提示，在检索的时候，用来bootstrap2的输入提示样式，但是好像和bootstrap3有点冲突，有时页面会alert一个错误提示。\n\n\n","categories":["技术博客"],"tags":["项目","java"]},{"title":"二叉树的遍历","url":"http://tanqingbo.cn/2016/04/29/二叉树的遍历/","content":"二叉树的遍历\n我用下图的树为例，做树的遍历：\n\n\n树节点的定义：\n  public class TreeNode &#123;\n      int val = 0;\n      TreeNode left = null;\n      TreeNode right = null;\n      public TreeNode(int val) &#123;\n          this.val = val;\n      &#125;\n      public TreeNode(int val, TreeNode left, TreeNode right) &#123;\n          super();\n          this.val = val;\n          this.left = left;\n          this.right = right;\n      &#125;\n  &#125;\n\n树的结构的代码实现：\n      public static void main(String[] args) &#123;\n             TreeNode e = new TreeNode(1);\n             TreeNode g = new TreeNode(2);\n             TreeNode h = new TreeNode(3);\n             TreeNode i = new TreeNode(4);\n             TreeNode d = new TreeNode(5,null,g);\n             TreeNode f = new TreeNode(6,h,i); \n             TreeNode b = new TreeNode(7,d,e);\n             TreeNode c = new TreeNode(8,f,null);\n             TreeNode root = new TreeNode(9,b,c);\n      &#125;\n\n\n中序遍历\n先处理左子树，然后处理当前节点，再处理右子树。\n\n对于一颗二叉查找树，所有的信息都是有序排列的，中序遍历可以是信息有序输出，且运行时间为O（n）。\n\n递归实现中序遍历：\n   public static void printTree(TreeNode t)&#123;\n          if(t!=null)&#123;\n              printTree(t.left);\n              System.out.print(t.val+&quot; &quot;);\n              printTree(t.right);\n          &#125;\n      &#125;\n\n输出结果：\n      5 2 7 1 9 3 6 4 8 \n\n\n后序遍历\n先处理左右子树，然后再处理当前节点，运行时间为O（n）。\n\n递归实现后序遍历：\n     public static void printTree(TreeNode t)&#123;\n             if(t!=null)&#123;\n                 printTree(t.left);\n                 printTree(t.right);\n                 System.out.print(t.val+&quot; &quot;);\n             &#125;\n         &#125;\n\n输出结果：\n      2 5 1 7 3 4 6 8 9 \n\n\n先序遍历\n先处理当前节点，在处理左右子树。\n\n递归实现先序遍历：\n      public static void printTree(TreeNode t)&#123;\n              if(t!=null)&#123;\n                  System.out.print(t.val+&quot; &quot;);\n                  printTree(t.left);\n                  printTree(t.right);\n              &#125;\n          &#125;\n\n输出结果：\n      9 7 5 2 1 8 6 3 4 \n\n有没有觉得树的先序，中序，后序遍历都非常简单，递归三行代码就搞定了。好吧，下边厉害的要来了\n\n\n层序遍历\n层序遍历:所有深度为D的节点要在深度为D+1的节点之前进行处理，层序遍历与其他类型的遍历不同的地方在于它不是递归地执行的，它用到队列，而不使用递归所默示的栈。\n\n算法思想：\n\n定义节点 TreeNode lastNode指向当前行最有节点，TreeNode nlastNode指向下一行最右节点。\n利用队列，首先将根节点入队,再循环里出队,并将其子节点入队,定义TreeNode tmpNode节点指向当前出队列的节点，当tmpNode==lastNode时，代表当前行遍历结束，输出换行，再令lastNode=nlastNode，nlastNode在子节点入队列时指向下一行最右节点。循环直到对列为空就行。 \n\n\n层序遍历代码：\n  package Tree;\n  import java.util.ArrayList;\n  import java.util.LinkedList;\n  import java.util.List;\n  import java.util.Queue;\n  /*\n   * 层序遍历\n   * \n   */\n  public class TreePrinter1 &#123;\n       public static int[][] printTree(TreeNode root) &#123;\n           List&lt; List&lt;Integer&gt; &gt; list = new ArrayList&lt; List&lt;Integer&gt; &gt;();\n           list.add(new ArrayList&lt;Integer&gt;());\n           Queue&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;();\n              queue.add(root);\n              TreeNode lastNode = root;    // 当前行最右节点\n              TreeNode nlastNode = root;    // 下一行最右节点\n              TreeNode tmpNode = null; \n              int hight = 0;                // 树的高度\n              while(!queue.isEmpty())&#123;\n                  tmpNode = queue.poll();\n                  if(tmpNode!=null)&#123;\n                      list.get(hight).add(tmpNode.val);\n                  &#125;\n                  if(tmpNode.left!=null)&#123;\n                      queue.add(tmpNode.left);\n                      nlastNode = tmpNode.left;\n                  &#125;\n                  if(tmpNode.right!=null)&#123;\n                      queue.add(tmpNode.right);\n                      nlastNode = tmpNode.right;\n                  &#125;\n                  if(tmpNode == lastNode)&#123;\n                      lastNode = nlastNode;\n                      hight++;\n                      list.add(new ArrayList&lt;Integer&gt;());\n                  &#125;\n              &#125;\n              int[][] data = new int[list.size()][];\n              for(int i=0;i&lt;list.size();i++)&#123;\n                  for(int j=0;j&lt;list.get(i).size();j++)&#123;\n                      data[i][j] = list.get(i).get(j);\n                  &#125;\n              &#125;\n\n          return data;\n       &#125;\n       public static void main(String[] args) &#123;\n             TreeNode e = new TreeNode(1);\n             TreeNode g = new TreeNode(2);\n             TreeNode h = new TreeNode(3);\n             TreeNode i = new TreeNode(4);\n             TreeNode d = new TreeNode(5,null,g);\n             TreeNode f = new TreeNode(6,h,i);\n             TreeNode b = new TreeNode(7,d,e);\n             TreeNode c = new TreeNode(8,f,null);\n             TreeNode root = new TreeNode(9,b,c);\n             int[][] data  =TreePrinter.printTree(root);\n             for(int s=0;s&lt;data.length;s++)&#123;\n                 for(int j=0;j&lt;data[s].length;j++)&#123;\n                     System.out.print(data[s][j]+&quot; &quot;);\n                 &#125;\n                 System.out.println();\n             &#125;\n      &#125;\n  &#125;\n\n\n\n输出结果：\n  9 \n  7 8 \n  5 1 6 \n  2 3 4 \n\n\n","categories":["Java"],"tags":["算法","树"]},{"title":"Java多线程学习","url":"http://tanqingbo.cn/2016/04/28/Java多线程学习/","content":"Java多线程学习进程和线程的区别：\n进程：每个进程都有独立的代码和数据空间（进程上下文），进程间的切换会有较大的开销，一个进程包含1–n个线程。\n线程：同一类线程共享代码和数据空间，每个线程有独立的运行栈和程序计数器(PC)，线程切换开销小。\n线程和进程一样分为五个阶段：创建、就绪、运行、阻塞、终止。\n多进程是指操作系统能同时运行多个任务（程序）。\n多线程是指在同一程序中有多个顺序流在执行。\n\n\n在java中要想实现多线程，有两种手段，一种是继续Thread类，另外一种是实现Runable接口。\n扩展java.lang.Thread类              class Thread1 extends Thread&#123;\n                  private String name;\n                  public Thread1(String name) &#123;\n                     this.name=name;\n                  &#125;\n                  public void run() &#123;\n                      for (int i = 0; i &lt; 5; i++) &#123;\n                          System.out.println(name + &quot;运行  :  &quot; + i);\n                          try &#123;\n                              sleep((int) Math.random() * 10);\n                          &#125; catch (InterruptedException e) &#123;\n                              e.printStackTrace();\n                          &#125;\n                      &#125;\n\n                  &#125;\n              &#125;\n              public class Main &#123;\n\n                  public static void main(String[] args) &#123;\n                      Thread1 mTh1=new Thread1(&quot;A&quot;);\n                      Thread1 mTh2=new Thread1(&quot;B&quot;);\n                      mTh1.start();\n                      mTh2.start();\n\n                  &#125;\n\n              &#125;\n\nstart()方法的调用后并不是立即执行多线程代码，而是使得该线程变为可运行态（Runnable），什么时候运行是由操作系统决定的。\n\n从程序运行的结果可以发现，多线程程序是乱序执行。因此，只有乱序执行的代码才有必要设计为多线程。Thread.sleep()方法调用目的是不让当前线程独自霸占该进程所获取的CPU资源，以留出一定时间给其他线程执行的机会。\n\n实际上所有的多线程代码执行顺序都是不确定的，每次执行的结果都是随机的。\n\n但是start方法重复调用的话，会出现java.lang.IllegalThreadStateException异常。\n  Thread1 mTh1=new Thread1(&quot;A&quot;);\n  Thread1 mTh2=mTh1;\n  mTh1.start();\n  mTh2.start();\n\n\n实现java.lang.Runnable接口    class Thread2 implements Runnable&#123;\n        private String name;\n\n        public Thread2(String name) &#123;\n            this.name=name;\n        &#125;\n        @Override\n        public void run() &#123;\n              for (int i = 0; i &lt; 5; i++) &#123;\n                    System.out.println(name + &quot;运行  :  &quot; + i);\n                    try &#123;\n                        Thread.sleep((int) Math.random() * 10);\n                    &#125; catch (InterruptedException e) &#123;\n                        e.printStackTrace();\n                    &#125;\n                &#125;\n        &#125;\n    &#125;\n    public class Main &#123;\n        public static void main(String[] args) &#123;\n            new Thread(new Thread2(&quot;C&quot;)).start();\n            new Thread(new Thread2(&quot;D&quot;)).start();\n        &#125;\n\n    &#125;\n\n注：Thread类实际上也是实现了Runnable接口的类。\n\n在启动的多线程的时候，需要先通过Thread类的构造方法Thread(Runnable target) 构造出对象，然后调用Thread对象的start()方法来运行多线程代码。\n\n实际上所有的多线程代码都是通过运行Thread的start()方法来运行的。因此，不管是扩展Thread类还是实现Runnable接口来实现多线程，最终还是通过Thread的对象的API来控制线程的，熟悉Thread类的API是进行多线程编程的基础。\nThread和Runnable的区别  class Thread2 implements Runnable&#123;\n      private int count=15;\n      @Override\n      public void run() &#123;\n            for (int i = 0; i &lt; 5; i++) &#123;\n                System.out.println(Thread.currentThread().getName() + &quot;运行  count= &quot; + count--);\n                  try &#123;\n                      Thread.sleep((int) Math.random() * 10);\n                  &#125; catch (InterruptedException e) &#123;\n                      e.printStackTrace();\n                  &#125;\n              &#125;\n\n      &#125;\n\n  &#125;\n  public class Main &#123;\n\n      public static void main(String[] args) &#123;\n\n          Thread2 my = new Thread2();\n              new Thread(my, &quot;C&quot;).start();//同一个mt，但是在Thread中就不可以，如果用同一个实例化对象mt，就会出现异常   \n              new Thread(my, &quot;D&quot;).start();\n              new Thread(my, &quot;E&quot;).start();\n      &#125;\n\n  &#125;\n\n注：这里要注意每个线程都是用同一个实例化对象，如果不是同一个，效果就和上面的Thread一样了！\n\n实现Runnable接口比继承Thread类所具有的优势：\n\n\n适合多个相同的程序代码的线程去处理同一个资源.\n可以避免java中的单继承的限制\n增加程序的健壮性，代码可以被多个线程共享，代码和数据独立\n\n\n\n\n\n\n提醒一下大家：main方法其实也是一个线程。在java中所以的线程都是同时启动的，至于什么时候，哪个先执行，完全看谁先得到CPU的资源。\n在java中，每次程序运行至少启动2个线程。一个是main线程，一个是垃圾收集线程。因为每当使用java命令执行一个类的时候，实际上都会启动一个ＪＶＭ，每一个ｊＶＭ实习在就是在操作系统中启动了一个进程。\n线程状态转换![线程状态转换图](http://img.blog.csdn.net/20150309140927553)\n\n\n新建状态（New）：新创建了一个线程对象。\n就绪状态（Runnable）：线程对象创建后，其他线程调用了该对象的start()方法。该状态的线程位于可运行线程池中，变得可运行，等待获取CPU的使用权。\n运行状态（Running）：就绪状态的线程获取了CPU，执行程序代码。\n阻塞状态（Blocked）：阻塞状态是线程因为某种原因放弃CPU使用权，暂时停止运行。直到线程进入就绪状态，才有机会转到运行状态。阻塞的情况分三种：\n（一）、等待阻塞：运行的线程执行wait()方法，JVM会把该线程放入等待池中。（二）、同步阻塞：运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池中。（三）、其他阻塞：运行的线程执行sleep()或join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态。\n\n\n\n5.死亡状态（Dead）：线程执行完了或者因异常退出了run()方法，该线程结束生命周期。\n线程调度\n调整线程优先级：Java线程有优先级，优先级高的线程会获得较多的运行机会。\n\n\njava线程的优先级用整数表示，取值是1~10，Thread类有一下三个静态常量：static int MAX_PRIORITY线程可以具有的最高优先级，取值为10。\nstatic int MIN_PRIORITY线程可以具有的最高优先级，取值为1。\nstatic int NORM_PRIORITY分配给线程的默认优先级，取值为5。\n2.Thread类的setPriority()和getPriority()方法分别用来设置和获取线程的优先级。3.线程的优先级有继承关系，比如A线程中创建了B线程，那么B将和A具有相同的优先级。\n\n\n\n线程睡眠：Thread.sleep(long millis)方法，使线程转到阻塞状态。millis参数设定睡眠的时间，以毫秒为单位。当睡眠结束后，就转为就绪（Runnable）状态。sleep()平台移植性好。\n\n线程等待：Object类中的wait()方法，导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 唤醒方法。这个两个唤醒方法也是Object类中的方法，行为等价于调用 wait(0) 一样。\n\n线程让步：Thread.yield() 方法，暂停当前正在执行的线程对象，把执行机会让给相同或者更高优先级的线程。\n\n线程加入：join()方法，等待其他线程终止。在当前线程中调用另一个线程的join()方法，则当前线程转入阻塞状态，直到另一个进程运行结束，当前线程再由阻塞转为就绪状态。\n\n线程唤醒：Object类中的notify()方法，唤醒在此对象监视器上等待的单个线程。如果所有线程都在此对象上等待，则会选择唤醒其中一个线程。选择是任意性的，并在对实现做出决定时发生。线程通过调用其中一个 wait 方法，在对象的监视器上等待。 直到当前的线程放弃此对象上的锁定，才能继续执行被唤醒的线程。被唤醒的线程将以常规方式与在该对象上主动同步的其他所有线程进行竞争；例如，唤醒的线程在作为锁定此对象的下一个线程方面没有可靠的特权或劣势。类似的方法还有一个notifyAll()，唤醒在此对象监视器上等待的所有线程。\n\n\n常用函数说明\nsleep(long millis): 在指定的毫秒数内让当前正在执行的线程休眠（暂停执行）\n\njoin():指等待t线程终止。\njoin:\n\n这里需要理解的就是该线程是指的主线程等待子线程的终止。也就是在子线程调用了join()方法后面的代码，只有等到子线程结束了才能执行。\nThread t = new AThread(); t.start(); t.join();\n\n\n\n\n在很多情况下，主线程生成并起动了子线程，如果子线程里要进行大量的耗时的运算，主线程往往将于子线程之前结束，但是如果主线程处理完其他的事务后，需要用到子线程的处理结果，也就是主线程需要等待子线程执行完成之后再结束，这个时候就要用到join()方法了。\n  class Thread1 extends Thread&#123;\n      private String name;\n      public Thread1(String name) &#123;\n          super(name);\n         this.name=name;\n      &#125;\n      public void run() &#123;\n          System.out.println(Thread.currentThread().getName() + &quot; 线程运行开始!&quot;);\n          for (int i = 0; i &lt; 5; i++) &#123;\n              System.out.println(&quot;子线程&quot;+name + &quot;运行 : &quot; + i);\n              try &#123;\n                  sleep((int) Math.random() * 10);\n              &#125; catch (InterruptedException e) &#123;\n                  e.printStackTrace();\n              &#125;\n          &#125;\n          System.out.println(Thread.currentThread().getName() + &quot; 线程运行结束!&quot;);\n      &#125;\n  &#125;\n\n  public class Main &#123;\n\n      public static void main(String[] args) &#123;\n          System.out.println(Thread.currentThread().getName()+&quot;主线程运行开始!&quot;);\n          Thread1 mTh1=new Thread1(&quot;A&quot;);\n          Thread1 mTh2=new Thread1(&quot;B&quot;);\n          mTh1.start();\n          mTh2.start();\n          System.out.println(Thread.currentThread().getName()+ &quot;主线程运行结束!&quot;);\n\n      &#125;\n\n  &#125;\n\n运行结果：\n  main主线程运行开始!\n  main主线程运行结束!\n  A 线程运行开始!\n  B 线程运行开始!\n  子线程A运行 : 0\n  子线程B运行 : 0\n  子线程A运行 : 1\n  子线程A运行 : 2\n  子线程A运行 : 3\n  子线程A运行 : 4\n  子线程B运行 : 1\n  子线程B运行 : 2\n  子线程B运行 : 3\n  子线程B运行 : 4\n  B 线程运行结束!\n  A 线程运行结束!\n\n发现主线程比子线程早结束。\n\n加join：\n\n\n    public class Main &#123;\n        public static void main(String[] args) &#123;\n            System.out.println(Thread.currentThread().getName()+&quot;主线程运行开始!&quot;);\n            Thread1 mTh1=new Thread1(&quot;A&quot;);\n            Thread1 mTh2=new Thread1(&quot;B&quot;);\n            mTh1.start();\n            mTh2.start();\n            try &#123;\n                mTh1.join();\n            &#125; catch (InterruptedException e) &#123;\n                e.printStackTrace();\n            &#125;\n            try &#123;\n                mTh2.join();\n            &#125; catch (InterruptedException e) &#123;\n                e.printStackTrace();\n            &#125;\n            System.out.println(Thread.currentThread().getName()+ &quot;主线程运行结束!&quot;);\n        &#125;\n    &#125;\n\n运行结果：\n  main主线程运行开始!\n  A 线程运行开始!\n  B 线程运行开始!\n  子线程B运行 : 0\n  子线程A运行 : 0\n  子线程B运行 : 1\n  子线程B运行 : 2\n  子线程B运行 : 3\n  子线程B运行 : 4\n  B 线程运行结束!\n  子线程A运行 : 1\n  子线程A运行 : 2\n  子线程A运行 : 3\n  子线程A运行 : 4\n  A 线程运行结束!\n  main主线程运行结束!\n\n主线程一定会等子线程都结束了再结束。\nyield():暂停当前正在执行的线程对象，并执行其他线程。\nyield()应该做的是让当前运行线程回到可运行状态，以允许具有相同优先级的其他线程获得运行机会。因此，使用yield()的目的是让相同优先级的线程之间能适当的轮转执行。但是，实际中无法保证yield()达到让步目的，因为让步的线程还有可能被线程调度程序再次选中。\n class ThreadYield extends Thread&#123;\n     public ThreadYield(String name) &#123;\n         super(name);\n     &#125;\n\n     @Override\n     public void run() &#123;\n         for (int i = 1; i &lt;= 50; i++) &#123;\n             System.out.println(&quot;&quot; + this.getName() + &quot;-----&quot; + i);\n             // 当i为30时，该线程就会把CPU时间让掉，让其他或者自己的线程执行（也就是谁先抢到谁执行）\n             if (i ==30) &#123;\n                 this.yield();\n             &#125;\n         &#125;\n &#125;\n &#125;\n public class Main &#123;\n     public static void main(String[] args) &#123;\n         ThreadYield yt1 = new ThreadYield(&quot;张三&quot;);\n         ThreadYield yt2 = new ThreadYield(&quot;李四&quot;);\n         yt1.start();\n         yt2.start();\n     &#125;\n &#125;\n\n运行结果：\n\n第一种情况：李四（线程）当执行到30时会CPU时间让掉，这时张三（线程）抢到CPU时间并执行。第二种情况：李四（线程）当执行到30时会CPU时间让掉，这时李四（线程）抢到CPU时间并执行。\n\n\n\nsleep()和yield()的区别\nsleep()和yield()的区别):sleep()使当前线程进入停滞状态，所以执行sleep()的线程在指定的时间内肯定不会被执行；yield()只是使当前线程重新回到可执行状态，所以执行yield()的线程有可能在进入到可执行状态后马上又被执行。\nyield()方法称为“退让”，它把运行机会让给了同等优先级的其他线程\nsleep 方法允许较低优先级的线程获得运行机会，但 yield()  方法执行时，当前线程仍处在可运行状态，所以，不可能让出较低优先级的线程些时获得 CPU 占有权。\n\nsetPriority(): 更改线程的优先级。\n用法：\n  Thread4 t1 = new Thread4(&quot;t1&quot;);\n  Thread4 t2 = new Thread4(&quot;t2&quot;);\n  t1.setPriority(Thread.MAX_PRIORITY);\n  t2.setPriority(Thread.MIN_PRIORITY);\n\n\ninterrupt():\n中断某个线程，这种结束方式比较粗暴，如果t线程打开了某个资源还没来得及关闭也就是run方法还没有执行完就强制结束线程，会导致资源无法关闭 \n\n要想结束进程最好的办法就是用sleep()函数的例子程序里那样，在线程类里面用以个boolean型变量来控制run()方法什么时候结束，run()方法一结束，该线程也就结束了。\nwait()\nObj.wait()，与Obj.notify()必须要与synchronized(Obj)一起使用，也就是wait,与notify是针对已经获取了Obj锁进行操作，从语法角度来说就是Obj.wait(),Obj.notify必须在synchronized(Obj){…}语句块内。从功能上来说wait就是说线程在获取对象锁后，主动释放对象锁，同时本线程休眠。直到有其它线程调用对象的notify()唤醒该线程，才能继续获取对象锁，并继续执行。相应的notify()就是对对象锁的唤醒操作。但有一点需要注意的是notify()调用后，并不是马上就释放对象锁的，而是在相应的synchronized(){}语句块执行结束，自动释放锁后，JVM会在wait()对象锁的线程中随机选取一线程，赋予其对象锁，唤醒线程，继续执行。这样就提供了在线程间同步、唤醒的操作。Thread.sleep()与Object.wait()二者都可以暂停当前线程，释放CPU控制权，主要的区别在于Object.wait()在释放CPU同时，释放了对象锁的控制。\n\n经典的面试题，题目要求如下：  建立三个线程，A线程打印10次A，B线程打印10次B,C线程打印10次C，要求线程同时运行，交替打印10次ABC。这个问题用Object的wait()，notify()就可以很方便的解决。代码如下：\n  public class MyThreadPrinter2 implements Runnable &#123;     \n      private String name;   \n      private Object prev;   \n      private Object self;   \n      private MyThreadPrinter2(String name, Object prev, Object self) &#123;   \n          this.name = name;   \n          this.prev = prev;   \n          this.self = self;   \n      &#125;   \n      public void run() &#123;   \n          int count = 10;   \n          while (count &gt; 0) &#123;   \n              synchronized (prev) &#123;   \n                  synchronized (self) &#123;   \n                      System.out.print(name);   \n                      count--;  \n                      self.notify();   \n                  &#125;   \n                  try &#123;   \n                      prev.wait();   \n                  &#125; catch (InterruptedException e) &#123;   \n                      e.printStackTrace();   \n                  &#125;   \n              &#125;   \n          &#125;   \n      &#125;   \n      public static void main(String[] args) throws Exception &#123;   \n          Object a = new Object();   \n          Object b = new Object();   \n          Object c = new Object();   \n          MyThreadPrinter2 pa = new MyThreadPrinter2(&quot;A&quot;, c, a);   \n          MyThreadPrinter2 pb = new MyThreadPrinter2(&quot;B&quot;, a, b);   \n          MyThreadPrinter2 pc = new MyThreadPrinter2(&quot;C&quot;, b, c);   \n          new Thread(pa).start();\n          Thread.sleep(100);  //确保按顺序A、B、C执行\n          new Thread(pb).start();\n          Thread.sleep(100);  \n          new Thread(pc).start();   \n          Thread.sleep(100);  \n          &#125;   \n  &#125;\n\n输出结果：\n\nABCABCABCABCABCABCABCABCABCABC\n\n\n\nwait和sleep区别\n共同点：\n他们都是在多线程的环境下，都可以在程序的调用处阻塞指定的毫秒数，并返回。 \nwait()和sleep()都可以通过interrupt()方法 打断线程的暂停状态 ，从而使线程立刻抛出InterruptedException。 \n\n\n不同点：\nThread类的方法：sleep(),yield()等 \nObject的方法：wait()和notify()等 \n每个对象都有一个锁来控制同步访问。Synchronized关键字可以和对象的锁交互，来实现线程的同步。 sleep方法没有释放锁，而wait方法释放了锁，使得其他线程可以使用同步控制块或者方法。\nwait，notify和notifyAll只能在同步控制方法或者同步控制块里面使用，而sleep可以在任何地方使用 \nsleep必须捕获异常，而wait，notify和notifyAll不需要捕获异常\n\n\n\n常见线程名词解释\n主线程：JVM调用程序main()所产生的线程。\n当前线程：这个是容易混淆的概念。一般指通过Thread.currentThread()来获取的进程。\n后台线程：指为其他线程提供服务的线程，也称为守护线程。JVM的垃圾回收线程就是一个后台线程。用户线程和守护线程的区别在于，是否等待主线程依赖于主线程结束而结束\n前台线程：是指接受后台线程服务的线程，其实前台后台线程是联系在一起，就像傀儡和幕后操纵者一样的关系。傀儡是前台线程、幕后操纵者是后台线程。由前台线程创建的线程默认也是前台线程。\n可以通过isDaemon()和setDaemon()方法来判断和设置一个线程是否为后台线程。\n\n线程同步\nsynchronized关键字的作用域有二种： \n\n是某个对象实例内，synchronized aMethod(){}可以防止多个线程同时访问这个对象的synchronized方法（如果一个对象有多个synchronized方法，只要一个线程访问了其中的一个synchronized方法，其它线程不能同时访问这个对象中任何一个synchronized方法）。这时，不同的对象实例的synchronized方法是不相干扰的。也就是说，其它线程照样可以同时访问相同类的另一个对象实例中的synchronized方法；\n是某个类的范围，synchronized static aStaticMethod{}防止多个线程同时访问这个类中的synchronized static 方法。它可以对类的所有对象实例起作用。 \n\n\n除了方法前用synchronized关键字，synchronized关键字还可以用于方法中的某个区块中，表示只对这个区块的资源实行互斥访问。用法是: synchronized(this){/区块/}，它的作用域是当前对象； \n\nsynchronized关键字是不能继承的，也就是说，基类的方法synchronized f(){} 在继承类中并不自动是synchronized f(){}，而是变成了f(){}。继承类需要你显式的指定它的某个方法为synchronized方法；\n\n总结：\n\nsynchronized关键字可以作为函数的修饰符，也可作为函数内的语句，也就是平时说的同步方法和同步语句块。\n\n无论synchronized关键字加在方法上还是对象上，它取得的锁都是对象，而不是把一段代码或函数当作锁――而且同步方法很可能还会被其他线程的对象访问。\n\n每个对象只有一个锁（lock）与之相关联。\n\n实现同步是要很大的系统开销作为代价的，甚至可能造成死锁，所以尽量避免无谓的同步控制。\n  Class Foo\n\n&#123;\n\npublic synchronized static void methodAAA()   // 同步的static 函数\n\n&#123;\n\n//….\n\n&#125;\n\npublic void methodBBB()\n\n&#123;\n\n       synchronized(Foo.class)   //  class literal(类名称字面常量)\n\n&#125;\n\n       &#125;\n\n\n\n代码中的methodBBB()方法是把class literal作为锁的情况，它和同步的static函数产生的效果是一样的，取得的锁很特别，是当前调用这个方法的对象所属的类。\n      1. 线程同步的目的是为了保护多个线程反问一个资源时对资源的破坏。\n      2. 线程同步方法是通过锁来实现，每个对象都有切仅有一个锁，这个锁与一个特定的对象关联。\n      3. 对于静态同步方法，锁是针对这个类的，锁对象是该类的Class对象。静态和非静态方法的锁互不干预。\n      4. 对于同步，要时刻清醒在哪个对象上同步，这是关键。\n      5. 编写线程安全的类，需要时刻注意对多个线程竞争访问资源的逻辑和安全做出正确的判断\n      6. 当多个线程等待一个对象锁时，没有获取到锁的线程将发生阻塞。\n      7. 死锁是线程间相互等待锁锁造成的，在实际中发生的概率非常的小。\n\n\n线程数据传递\n在传统的同步开发模式下，当我们调用一个函数时，通过这个函数的参数将数据传入，并通过这个函数的返回值来返回最终的计算结果。但在多线程的异步开发模式下，数据的传递和返回和同步开发模式有很大的区别。由于线程的运行和结束是不可预料的，因此，在传递和返回数据时就无法象函数一样通过函数参数和return语句来返回数据。\n\n通过构造方法传递数据 \n\n在创建线程时，必须要建立一个Thread类的或其子类的实例。因此，我们不难想到在调用start方法之前通过线程类的构造方法将数据传入线程。并将传入的数据使用类变量保存起来，以便线程使用(其实就是在run方法中使用)。\n\n\n通过变量和方法传递数据 \n\n向对象中传入数据一般有两次机会，第一次机会是在建立对象时通过构造方法将数据传入，另外一次机会就是在类中定义一系列的public的方法或变量（也可称之为字段）。然后在建立完对象后，通过对象实例逐个赋值。\n\n\n\n\n通过回调函数传递数据 \n      class Data \n      &#123; \n      public int value = 0; \n      &#125; \n      class Work \n      &#123; \n      public void process(Data data, Integer numbers) \n      &#123; \n      for (int n : numbers) \n      &#123; \n      data.value += n; \n      &#125; \n      &#125; \n      &#125; \n      public class MyThread3 extends Thread \n      &#123; \n      private Work work; \n      public MyThread3(Work work) \n      &#123; \n      this.work = work; \n      &#125; \n      public void run() \n      &#123; \n      java.util.Random random = new java.util.Random(); \n      Data data = new Data(); \n      int n1 = random.nextInt(1000); \n      int n2 = random.nextInt(2000); \n      int n3 = random.nextInt(3000); \n      work.process(data, n1, n2, n3); // 使用回调函数 \n      System.out.println(String.valueOf(n1) + &quot;+&quot; + String.valueOf(n2) + &quot;+&quot; \n      + String.valueOf(n3) + &quot;=&quot; + data.value); \n      &#125; \n      public static void main(String[] args) \n      &#123; \n      Thread thread = new MyThread3(new Work()); \n      thread.start(); \n      &#125; \n      &#125; \n\n\n","categories":["Java"],"tags":["java","线程"]},{"title":"Linux下编译C语言","url":"http://tanqingbo.cn/2016/04/26/Linux下编译C语言/","content":"Linux下编译C语言安装vim编辑器\n在命令行敲入“vi”后按”tab”键，可以看到目前系统中只安装了vi和vim.tiny。\n\nubuntu系统：普通用户下输入命令：sudo apt-get install vim-gtk\n\ncentos系统：普通用户下输入命令：yum -y install vim*\nvim的配置\n刚安装的VIM，可能界面并不是十分友好，这就需要我们去更改vim的配置文件，按照我们的需求去修改它。\n\n在命令行下，输入命令：sudo vim /etc/vim/vimrc必须加上sudo，否则你是没有权限编辑vimrc的。\n\n在这个文件中，会有这么一句：syntax on意思是语法高亮，如果您的被注释掉了，请“让它出来”。\n      请在您的VIM的最后一行，输入他们，可以让您的VIM变得更漂亮、舒服。\n      set nu                           // 在左侧行号\n      set tabstop                  //tab 长度设置为 4\n      set nobackup               //覆盖文件时不备份\n      set cursorline               //突出显示当前行\n      set ruler                       //在右下角显示光标位置的状态行\n      set autoindent             //自动缩进\n\n      保存之后，配置完毕。\n      上面的配置，其实是非常简单的，比如一些配色方案等，小编并没有写入，如果您还有其他需求的话，建议百度。\n\n\n\n编译C\nGCC编译器（GNU C Compiler ）：经过了这么多年的发展，GCC 已经不仅仅能支持 C 语言；它现在还支持 Ada 语言、C++ 语言、Java 语言、Objective C 语言、Pascal 语言、COBOL语言。\n简单编译\n\n示例程序如下：\n    //test.c\n    #include &lt;stdio.h&gt;\n    int main(void)\n    &#123;\n        printf(&quot;Hello World!\\n&quot;);\n        return 0;\n    &#125;\n这个程序，一步到位的编译指令是:\n    gcc test.c -o test\n    ./test\n实质上，上述编译过程是分为四个阶段进行的，即预处理(也称预编译，Preprocessing)、编译(Compilation)、汇编 (Assembly)和连接(Linking)。\n\n预处理\ngcc -E test.c -o test.i 或 gcc -E test.c\n可以输出test.i文件中存放着test.c经预处理之后的代码。预处理结果就是将stdio.h 文件中的内容插入到test.c中了。\n\n编译为汇编代码(Compilation)\n预处理之后，可直接对生成的test.i文件编译，生成汇编代码：\n   gcc -S test.i -o test.s\n\n\ngcc的-S选项，表示在程序编译期间，在生成汇编代码后，停止，-o输出汇编代码文件。  3. 汇编(Assembly)\n对于上一小节中生成的汇编代码文件test.s，gas汇编器负责将其编译为目标文件，如下：\n  gcc -c test.s -o test.o\n\n连接(Linking)\n gcc test.o -o test\n\n\n最后在命令行窗口中，执行./test, 让它说HelloWorld吧！\n","categories":["Linux"],"tags":["Linux","C语言"]},{"title":"微信远程：Python控制电脑的两种方法","url":"http://tanqingbo.cn/2016/04/26/微信远程：Python控制电脑的两种方法/","content":"微信远程：Python控制电脑的两种方法微信控制电脑流程图\n命令提示符CMD入门\n基本的cmd命令介绍\n\n使用cmd运行文件\n\ncmd命令关机\n\n常用命令：\n\ndir  //显示当前目录\ntime  //显示当前时间\nsysteminfo  //显示系统信息\ntree 文件名   //显示文件结构\nnotepad  //打开记事本\ncalc    //打开计算器\nshutdown -s -t 定时关机的时间（秒为单位） -c &quot;关机时打印的信息&quot;  //定时关机命令\nshutdown -a //取消定时关机的命令\n\n\ncmd打开文件\n\n在目标文件夹中按“shift”键，同时鼠标右键，单击“在此处打开命令窗口”，然后输入要打开的文件名（有tab键补全功能），再回车就能打开。\n在高级环境变量的path下添加你要打开的文件的路径，就能在任意位置打开该文件了。Python执行CMD命令\n\n\nos.system(‘xxx’)\n\nsubprocess.Popen(‘xxx’,shell=true,stdout=subprocess.PIPE,stderr=subprocess.STDOUT)\n\n\nPython调用Win API\n安装pywin32-219.win32-py2.7.exe，下载链接为：\n\n https://sourceforge.net/projects/pywin32/files/pywin32/\n\n\nwinAPI的文档链接\n\n http://docs.activestate.com/activepython/2.7/pywin32/win32api.html\n\n\n函数使用\n\n WIN32API .Beep\n 1. Beep(freq, dur)\n  生成扬声器简单的音调。\n  参数\n  频率：INT\n  指定频率，以赫兹的声音。此参数必须通过32,767（0x25通过0x7FFF的）在范围37。\n  DUR：INT\n  指定时间，以毫秒为单位的声音〜一个价值有着特殊的意义：如果dwDuration为 - 1，功能异步操作并产生声音，直到再次调用。\n  win32api.Beep(5000,1000)\n\n\n\n\n2. int = MessageBox(hwnd, message , title , style , language )\nHWND：PyHANDLE\n    hwnd:父窗口的句柄。见注释部分。一般为0\n    message:消息：字符串\n    要被显示在消息框中的消息。\n    title:标题：串/无\n    标题消息框。如果没有，应用程序标题将被使用。\n    style和language均有默认值，可以不填\n\n\n 3. int = ShellExecute(hwnd, op , file , params , dir , bShow )\n 功能是打开某个文件，file填打开文件的目录。\n win32api.ShellExecute(0,&#39;open&#39;,r&#39;C:\\Users\\tqb\\Desktop\\MCC\\NothingInTheWorld.mp3&#39;,&#39;&#39;,&#39;&#39;,1)\n\n","categories":["技术博客"],"tags":["Python"]},{"title":"局域网搭建","url":"http://tanqingbo.cn/2016/04/18/局域网搭建/","content":"局域网搭建配置以太网交换机的主机名、Console口令、远程登录口令、超级密码\n准备的内容：\n\n我们得知道交换机所在的位置？—-为交换机准备一个IP地址。1.1 交换机IP地址的配置在哪里？—-配置在虚拟端口VLAN1上需要访问交换机的端口：\n switch&gt;enable  ---&gt;  switch#  (config terminal---&gt;)\n switch(config)# (interface ID---&gt;) switch(config-if)#\n switch(config-if)#ip address 10.0.0.1 255.0.0.0\n\n配置本地主机，让其与交换机在同一个网段上。\n\n继续回到交换机做准备工作3.1 开放远程telnet访问：–&gt;配置虚拟终端访问协议,虚拟终端访问在交换机上通过虚拟终端线路设置来完成的要在line模式下完成\n\n\n\n\n\n        switch（config）#line vty 0 5\n       switch（config-line）#password xxx\n       switch（config-line）#login\n\n  3.2 继续设置我们的交换机     3.2.1开放交换机的特权命令\n\n 要求为enable命令设置一个密码\n        switch(config)enable password yyyy\n\nvlan划分\n观察当前交换机的划分形式，特权模式用show命令观察。\n Switch&gt;enable\n Switch#show vlan\n\n\n\n\n VLAN Name                             &gt;      Status    Ports\n ---- -------------------------------- --------- -------------------------------\n1    default                          active    Fa0/2, Fa0/3, Fa0/4, Fa0/5\n                                            Fa0/6, Fa0/7, Fa0/8, Fa0/9\n                                            Fa0/10, Fa0/11, Fa0/12, Fa0/13\n                                            Fa0/14, Fa0/15, Fa0/16, Fa0/17\n                                            Fa0/18, Fa0/19, Fa0/20, Fa0/21\n                                            Fa0/22, Fa0/23, Fa0/24, Gig1/1\n                                            Gig1/2\n100  VLAN0100                         active    Fa0/1\n1002 fddi-default                     act/unsup \n1003 token-ring-default               act/unsup \n1004 fddinet-default                  act/unsup \n1005 trnet-default                    act/unsup \n\n用特权模式打开vlan表\n   Switch#vlan database\n   #创建新的vlan端口\n   Switch(vlan)#vlan 100、\n   #为vlan添加成员端口\n   Switch(vlan)#exit\n   #进入全局模式\n   Switch#configure terminal\n   #设置端口\n   Switch(config)#interface Fa0/1\n   Switch(config-if)#\n   #也可以批量设置端口\n   Switch(config)#interface range fa0/1 - 4\n   Switch(config-if-range)#\n   #下面以单个端口演示，批量端口是一样的,将端口放在vlan 100下面\n   Switch(config-if)#switchport access vlan 100\n\n上面的命令就可以将端口放到指定vlan下面，广播信号只能在同一个vlan下发送，能有效缩小广播范围\n删除vlan：先归还成员，在删除vlan\n  Switch#vlan database\n  no vlan 100\n\n跨交换机vlan划分\n必须保证相同vlan ID的端口间才可以通信\n公共端口必须工作在中继模式下\n Switch(config-if)#switchport mode trunk \n #公共的两个端口都要这样设置\n\n\n\n访问控制列表（1~99）\n全局模式建立如下规则列表\n Router(config)#access-list 1 deny 192.168.1.0 0.0.0.255\n Router(config)#access-list 1 permit any\n\n\n\n该规则含义为：拒绝IP地址前缀为192.168.1.的访问，然后允许除此之外的所有IP地址访问。接下来将此规则应用到某个接口上。\n\n  Router(config)#int fa1/0\n  Router(config-if)#ip access-group 1 out\n  注：进入路由器是 in    出路由器是  out\n\n扩展访问控制列表（100~199）\n全局模式建立如下规则列表\n Router(config)#access-list 100 deny tcp host 192.168.1.2 host 200.11.180.2 eq 80\n Router(config)#access-list 100 permit tcp host 192.168.1.2 host 200.11.180.2 eq 21\n Router(config)#access-list 100 permit any any\n\n\n\n该规则含义为:不允许IP地址为192.168.1.2的主机通过http协议访问IP地址为200.11.180.2的主机，但是可以通过ftp的协议方式访问。\n\n将该规则应用到某端口的方法同上。DNS域名解析\n\n\n想要通过域名访问外网某个web页面，得先在本网段建一个域名解析服务器。\n\n\n在域名服务器中-&gt;config-&gt;DNS中添加域名对应的IP地址。\n在发送请求的电脑的DNS Server 中填上域名服务器的IP地址。注：请求电脑和域名解析服务器得在同一个Vlan下。\n\nNAT网络地址转换","categories":["网络原理"],"tags":["互联网"]},{"title":"字符串匹配之kmp算法","url":"http://tanqingbo.cn/2016/04/09/kmp算法的原理/","content":"字符串匹配之kmp算法原理\n字符串匹配是计算机的基本任务之一。\n\n举例来说，有一个字符串”BBC ABCDAB ABCDABCDABDE”，我想知道，里面是否包含另一个字符串”ABCDABD” \n\n首先，字符串”BBC ABCDAB ABCDABCDABDE”的第一个字符与搜索词”ABCDABD”的第一个字符，进行比较。因为B与A不匹配，所以搜索词后移一位。\n\n因为B与A不匹配，搜索词再往后移。\n\n就这样，直到字符串有一个字符，与搜索词的第一个字符相同为止。\n\n接着比较字符串和搜索词的下一个字符，还是相同。\n\n直到字符串有一个字符，与搜索词对应的字符不相同为止。\n\n这时，最自然的反应是，将搜索词整个后移一位，再从头逐个比较。这样做虽然可行，但是效率很差，因为你要把”搜索位置”移到已经比较过的位置，重比一遍。\n\n一个基本事实是，当空格与D不匹配时，你其实知道前面六个字符是”ABCDAB”。KMP算法的想法是，设法利用这个已知信息，不要把”搜索位置”移回已经比较过的位置，继续把它向后移，这样就提高了效率。\n\n怎么做到这一点呢？可以针对搜索词，算出一张《部分匹配表》（Partial Match Table）。这张表是如何产生的，后面再介绍，这里只要会用就可以了。\n\n已知空格与D不匹配时，前面六个字符”ABCDAB”是匹配的。查表可知，最后一个匹配字符B对应的”部分匹配值”为2，因此按照下面的公式算出向后移动的位数：\n                       移动位数 = 已匹配的字符数 - 对应的部分匹配值\n因为 6 - 2 等于4，所以将搜索词向后移动4位。\n\n\n10.因为空格与Ｃ不匹配，搜索词还要继续往后移。这时，已匹配的字符数为2（”AB”），对应的”部分匹配值”为0。所以，移动位数 = 2 - 0，结果为 2，于是将搜索词向后移2位。\n11.因为空格与A不匹配，继续后移一位。\n12.逐位比较，直到发现C与D不匹配。于是，移动位数 = 6 - 2，继续将搜索词向后移动4位。\n13.逐位比较，直到搜索词的最后一位，发现完全匹配，于是搜索完成。如果还要继续搜索（即找出全部匹配），移动位数 = 7 - 0，再将搜索词向后移动7位，这里就不再重复了。\n14.下面介绍《部分匹配表》是如何产生的。首先，要了解两个概念：”前缀”和”后缀”。 “前缀”指除了最后一个字符以外，一个字符串的全部头部组合；”后缀”指除了第一个字符以外，一个字符串的全部尾部组合。\n15.“部分匹配值”就是”前缀”和”后缀”的最长的共有元素的长度。以”ABCDABD”为例:\n     －　&quot;A&quot;的前缀和后缀都为空集，共有元素 的长度为0；\n   　   　－　“AB”的前缀为[A]，后缀为[B]，共有元素的长度为0；\n   　   　－　“ABC”的前缀为[A, AB]，后缀为[BC, C]，共有元素的长度0；\n   　   　－　“ABCD”的前缀为[A, AB, ABC]，后缀为[BCD, CD, D]，共有元素的长度为0；\n   　   　－　“ABCDA”的前缀为[A, AB, ABC, ABCD]，后缀为[BCDA, CDA, DA, A]，共有元素为”A”，长度为1；\n   　　   －　“ABCDAB”的前缀为[A, AB, ABC, ABCD, ABCDA]，后缀为[BCDAB, CDAB, DAB, AB, B]，共有元素为”AB”，长度为2；\n   　    　－　“ABCDABD”的前缀为[A, AB, ABC, ABCD, ABCDA, ABCDAB]，后缀为[BCDABD, CDABD, DABD, ABD, BD, D]，共有元素的长度为0。\n16.“部分匹配”的实质是，有时候，字符串头部和尾部会有重复。比如，”ABCDAB”之中有两个”AB”，那么它的”部分匹配值”就是2（”AB”的长度）。搜索词移动的时候，第一个”AB”向后移动4位（字符串长度-部分匹配值），就可以来到第二个”AB”的位置。\n\n\n\n\nnext数组的求解思路\n通过上文完全可以对kmp算法的原理有个清晰的了解，那么下一步就是编程实现了，其中最重要的就是如何根据待匹配的模版字符串求出对应每一位的最大相同前后缀的长度。我先给出我的代码：\n\n\n     void makeNext(const char P[],int next[])\n      &#123;\n          int q,k;//q:模版字符串下标；k:最大前后缀长度\n          int m = strlen(P);//模版字符串长度\n          next[0] = 0;//模版字符串的第一个字符的最大前后缀长度为0\n          for (q = 1,k = 0; q &lt; m; ++q)//for循环，从第二个字符开始，依次计算每一个字符对应的next值\n          &#123;\n              while(k &gt; 0 &amp;&amp; P[q] != P[k])//递归的求出P[0]···P[q]的最大的相同的前后缀长度k\n                  k = next[k-1];          //不理解没关系看下面的分析，这个while循环是整段代码的精髓所在，确实不好理解  \n             if (P[q] == P[k])//如果相等，那么最大相同前后缀长度加1\n             &#123;\n                 k++;\n             &#125;\n             next[q] = k;\n         &#125;\n     &#125; \n\n\n附代码：\n\n\n       #include&lt;stdio.h&gt;\n          #include&lt;string.h&gt;\n          void makeNext(const char P[],int next[])\n          &#123;\n              int q,k;\n              int m = strlen(P);\n              next[0] = 0;\n              for (q = 1,k = 0; q &lt; m; ++q)\n              &#123;\n                 while(k &gt; 0 &amp;&amp; P[q] != P[k])\n                     k = next[k-1];\n                if (P[q] == P[k])\n                 &#123;\n                     k++;\n                 &#125;\n                 next[q] = k;\n             &#125;\n         &#125;\n         int kmp(const char T[],const char P[],int next[])\n         &#123;\n             int n,m;\n             int i,q;\n             n = strlen(T);\n             m = strlen(P);\n             makeNext(P,next);\n             for (i = 0,q = 0; i &lt; n; ++i)\n             &#123;\n                 while(q &gt; 0 &amp;&amp; P[q] != T[i])\n                     q = next[q-1];\n                 if (P[q] == T[i])\n                 &#123;\n                     q++;\n                 &#125;\n                 if (q == m)\n                 &#123;\n                     printf(&quot;Pattern occurs with shift:%d\\n&quot;,(i-m+1));\n                 &#125;\n             &#125;    \n         &#125;\n         int main()\n         &#123;\n             int i;     int next[20]=&#123;0&#125;;\n             char T[] = &quot;ababxbababcadfdsss&quot;;\n             char P[] = &quot;abcdabd&quot;;\n             printf(&quot;%s\\n&quot;,T);\n             printf(&quot;%s\\n&quot;,P );\n             // makeNext(P,next);\n             kmp(T,P,next);\n             for (i = 0; i &lt; strlen(P); ++i)\n             &#123;\n                 printf(&quot;%d &quot;,next[i]);\n             &#125;\n             printf(&quot;\\n&quot;);\n             return 0;\n         &#125;\n\n","categories":["C语言"],"tags":["算法","字符串"]},{"title":"数组与集合的排序","url":"http://tanqingbo.cn/2016/04/07/数组与集合的排序/","content":"数组与集合的排序数组排序\n先实现Comparable接口\n重写compareTo函数\n           public class Main implements Comparable&#123;\n              long sid;\n              int dgra;\n              int cgra;\n              int sum;\n         public int compareTo(Object o) &#123;\n                  Main p=(Main)o;\n                   int n= sum&lt;p.sum?1:(sum==p.sum?0:-1);\n                   if(n==0)\n                   &#123;\n                    n=dgra&lt;p.dgra?1:(dgra==p.dgra?0:-1);\n                    if(n==0)\n                        n=sid&gt;p.sid?1:-1;\n                   &#125;\n                   return n;\n             &#125;\n             public static void main(String[] args) &#123;\n                 Main[] stu2 = new Main[k];\n                 Arrays.sort(stu1);\n             &#125;\n         &#125;\n\n\n\n集合排序\n先实现Comparable接口\n重写compareTo函数\n   public class Main implements Comparable&lt;Main&gt;&#123;\n  long sid;\n      int dgra;\n      int cgra;\n      int sum;\n @Override\n     public int compareTo(Main o) &#123;\n         Main p=o;\n           int n= sum&lt;p.sum?1:(sum==p.sum?0:-1);\n           if(n==0)\n           &#123;\n            n=dgra&lt;p.dgra?1:(dgra==p.dgra?0:-1);\n            if(n==0)\n                n=sid&gt;p.sid?1:-1;\n           &#125;\n           return n;\n     &#125;\n     public static void main(String[] args) &#123;\n                         List&lt;Main&gt; stu1 = new ArrayList&lt;Main&gt;();\n                         Collections.sort(stu1);\n                     &#125;\n &#125;    \n\n\n\n","categories":["Java"],"tags":["排序"]},{"title":"itext制作pdf表格","url":"http://tanqingbo.cn/2016/04/04/itext制作pdf表格/","content":"itext制作pdf表格添加单元格\n把下面这几项顺次的加入到表格中，当一行充满时候自动换行到下一行  \n\n      PdfPTable table = new PdfPTable(3);  \n      table.addCell(&quot;1.1&quot;);  \n      table.addCell(&quot;1.2&quot;);  \n      table.addCell(&quot;1.3&quot;);  \n      table.addCell(&quot;2.1&quot;);  \n      table.addCell(&quot;2.2&quot;);  \n      table.addCell(&quot;2.3&quot;);\n\n\n以上程序运行结果将显示三行二列的表格。\n\n添加单元格的内容还可以是以下几种形式。\n\n\n\n        public void addCell(PdfPCell cell);\n        public void addCell(PdfPTable table);\n        public void addCell(Phrase phrase);\n        public void addCell(String text);\n        public void addCell(Paragraph paragraph); \n\n\n本文用的是最后一种。 \n\n合并单元格\niText合并单元格的过程如下，首先创建一个cell，设置这个单元格的跨度，\n\n如果是横向合并，则通过\n  cell.setColspan(n);  //n代表从当前单元格的位置开始，合并的单元格数\n\n如果是纵向合并，\n cell.setRowspan(n);//n代表从当前单元格的位置开始，合并的单元格数\n\n\n\n代码举例：（一开始是用数组添加单元格的，后来改成直接添加了，更简洁了）\n  package com.pdf;\n\n  import java.io.FileOutputStream;\n\n  import com.itextpdf.text.Document;\n  import com.itextpdf.text.Element;\n  import com.itextpdf.text.Font;\n  import com.itextpdf.text.Image;\n  import com.itextpdf.text.Paragraph;\n  import com.itextpdf.text.Phrase;\n  import com.itextpdf.text.pdf.BaseFont;\n  import com.itextpdf.text.pdf.PdfPCell;\n  import com.itextpdf.text.pdf.PdfPTable;\n  import com.itextpdf.text.pdf.PdfWriter;\n\n  public class pdf_Table &#123;\n  public static void main(String[] args) &#123;\n   Document document = new Document();\n   try &#123;\n       BaseFont bfChinese = BaseFont.createFont(&quot;C:\\\\Windows\\\\Fonts\\\\simkai.ttf&quot;,\n           BaseFont.IDENTITY_H,false); // 中文处理 \n   Font titleChinese = new Font(bfChinese, 20, Font.BOLD);\n   Font font = new Font(bfChinese, 20, Font.ITALIC);// 模板抬头的字体   \n   Font moneyFontChinese = new Font(bfChinese, 11, Font.ITALIC); // 币种和租金金额的小一号字体    \n   PdfWriter.getInstance(document,\n           new FileOutputStream(&quot;text1.pdf&quot;));\n   document.open();\n   PdfPTable table = new PdfPTable(1);//创建一个有1列的表格 \n   table.setTotalWidth(15);//设置表格的各列宽度\n   PdfPCell cell1 = new PdfPCell(new Paragraph(&quot;招聘人员登记表&quot;, titleChinese));\n   cell1.setHorizontalAlignment(Element.ALIGN_CENTER);\n   table.addCell(cell1);\n   document.add(table);\n   float f[] = &#123;2,3,2,3,2&#125;;\n   PdfPTable table1 = new PdfPTable(5);\n   table1.setTotalWidth(f);\n\n   String str1[] = &#123;&quot;姓名&quot;,&quot;出生年月&quot;,&quot;婚否&quot;,&quot;专业&quot;,&quot;健康状况&quot;,&quot;政治面貌&quot;,&quot;家庭住址&quot;,&quot;简历&quot;,&quot;家庭情况&quot;&#125;;\n   String str2[] = &#123;&quot;性别&quot;,&quot;学历&quot;,&quot;名族&quot;,&quot;毕业学校&quot;,&quot;户籍所在地&quot;,&quot;身份证号&quot;,&quot;姓名&quot;,&quot;亲属关系&quot;,&quot;年龄&quot;,&quot;健康状况&quot;&#125;;\n   PdfPCell ce1 = null;\n   PdfPCell ce2 = null;\n   PdfPCell ce3 = null;\n\n   ce1 = new PdfPCell(new Paragraph(str1[0],moneyFontChinese));\n   ce1.setHorizontalAlignment(Element.ALIGN_CENTER);\n   table1.addCell(ce1);\n   table1.addCell(&quot;&quot;);\n   ce2 = new PdfPCell(new Paragraph(str2[0],moneyFontChinese));\n   ce2.setHorizontalAlignment(Element.ALIGN_CENTER);\n   table1.addCell(ce2);\n   table1.addCell(&quot;&quot;);\n   ce3 = new PdfPCell(new Paragraph(&quot;照片&quot;,moneyFontChinese));\n   ce3.setHorizontalAlignment(Element.ALIGN_CENTER);//水平居中\n   ce3.setUseAscender(true);//垂直居中\n   ce3.setVerticalAlignment(ce3.ALIGN_MIDDLE);//垂直居中\n   ce3.setRowspan(4); //合并同一行的四个格\n   Image img = Image.getInstance(&quot;E:\\\\我的电脑备份\\\\照片\\\\照片素材\\\\旅行\\\\长城\\\\IMG_20140727_095516.jpg&quot;);//选择图片\n    //   img.setAlignment(1);\n     //  img.scaleAbsolute(110,150);//控制图片大小\n   ce3.setImage(img);\n   table1.addCell(ce3);\n\n\n         for(int i=1;i&lt;4;i++)&#123;\n         ce1 = new PdfPCell(new Paragraph(str1[i],moneyFontChinese));\n         ce1.setHorizontalAlignment(Element.ALIGN_CENTER);\n         table1.addCell(ce1);\n         table1.addCell(&quot;&quot;);\n         ce2 = new PdfPCell(new Paragraph(str2[i],moneyFontChinese));\n         ce2.setHorizontalAlignment(Element.ALIGN_CENTER);\n         table1.addCell(ce2);\n         table1.addCell(&quot;&quot;);\n     &#125;\n    for(int i=4;i&lt;6;i++)&#123;\n         ce1 = new PdfPCell(new Paragraph(str1[i],moneyFontChinese));\n         ce1.setHorizontalAlignment(Element.ALIGN_CENTER);\n         table1.addCell(ce1);\n         table1.addCell(&quot;&quot;);\n         ce2 = new PdfPCell(new Paragraph(str2[i],moneyFontChinese));\n         ce2.setHorizontalAlignment(Element.ALIGN_CENTER);\n         table1.addCell(ce2);\n         ce3 = new PdfPCell(new Paragraph(&quot;&quot;));\n         ce3.setColspan(2); //合并同一行的2个格\n         table1.addCell(ce3);\n    &#125;\n    ce1 = new PdfPCell(new Paragraph(str1[6],moneyFontChinese));\n    ce1.setHorizontalAlignment(Element.ALIGN_CENTER);\n    table1.addCell(ce1);\n    ce3 = new PdfPCell(new Paragraph(&quot;&quot;));\n    ce3.setColspan(4); //合并同一行的2个格\n    table1.addCell(ce3);\n\n\n\n    ce1 = new PdfPCell(new Paragraph(str1[8],moneyFontChinese));\n    ce1.setHorizontalAlignment(Element.ALIGN_CENTER);\n    ce1.setUseAscender(true);//垂直居中\n    ce1.setVerticalAlignment(ce1.ALIGN_MIDDLE);//垂直居中\n    ce1.setRowspan(5); //合并同一行的四个格\n    table1.addCell(ce1);\n\n    for(int i=0;i&lt;4;i++)&#123;\n        ce2 = new PdfPCell(new Paragraph(str2[i+6],moneyFontChinese));\n        ce2.setHorizontalAlignment(Element.ALIGN_CENTER);\n        table1.addCell(ce2);\n    &#125;\n    for(int i=0;i&lt;16;i++)&#123;\n          table1.addCell(&quot; &quot;);\n    &#125;\n    ce1 = new PdfPCell(new Paragraph(str1[7],moneyFontChinese));\n    ce1.setMinimumHeight(90);\n    ce1.setHorizontalAlignment(Element.ALIGN_CENTER);\n    ce1.setUseAscender(true);//垂直居中\n    ce1.setVerticalAlignment(ce1.ALIGN_MIDDLE);//垂直居中\n    table1.addCell(ce1);\n    ce2 = new PdfPCell(new Paragraph(&quot; &quot;));\n    ce2.setColspan(4);\n    table1.addCell(ce2);\n  String str = &quot;1.多说几句话身份和空间分割法与人文u影的交付该雕。&quot;\n          +&quot;2.活动官方发布没办法长三角和环境事故。&quot;\n                  + &quot;3,白癜风是快捷方便和技术快递费&quot;;\n    ce1 = new PdfPCell(new Paragraph(&quot;注意事项&quot;,moneyFontChinese));\n    ce1.setMinimumHeight(90);\n    ce1.setHorizontalAlignment(Element.ALIGN_CENTER);\n    ce1.setUseAscender(true);//垂直居中\n    ce1.setVerticalAlignment(ce1.ALIGN_MIDDLE);//垂直居中\n    table1.addCell(ce1);\n    ce2 = new PdfPCell(new Paragraph(str,moneyFontChinese));\n    ce2.setHorizontalAlignment(Element.ALIGN_CENTER);\n    ce2.setUseAscender(true);//垂直居中\n    ce2.setVerticalAlignment(ce2.ALIGN_MIDDLE);//垂直居中\n    ce2.setColspan(4);\n    table1.addCell(ce2);\n\n    //        Image img = Image.getInstance(&quot;E:\\\\我的电脑备份\\\\照片\\\\照片素材\\\\旅行\\\\长城\\\\IMG_20140727_095516.jpg&quot;);//选择图片\n    //        img.setAlignment(1);\n    //        img.scaleAbsolute(100,100);//控制图片大小\n    //        img.setAbsolutePosition(0,200);//控制图片位置\n    //        table1.addCell(img);\n\n    //        ce3 = new PdfPCell(new Paragraph(&quot;&quot;));\n    //        ce3.setColspan(4); //合并同一行的2个格\n    //        table1.addCell(ce3);\n    //         for(int i=1;i&lt;9;i++)&#123;\n    //             if(i&lt;6)&#123;\n    //         ce1[i] = new PdfPCell(new Paragraph(str1[i],moneyFontChinese));\n    //         ce1[i].setHorizontalAlignment(Element.ALIGN_CENTER);\n    //         ce2[i] = new PdfPCell(new Paragraph(&quot;&quot;));\n    //          ce3[i] = new PdfPCell(new Paragraph(str2[i],moneyFontChinese));\n    //          ce3[i].setHorizontalAlignment(Element.ALIGN_CENTER);\n    //         ce4[i] = new PdfPCell(new Paragraph(&quot;&quot;));\n    //          ce5[i] = new PdfPCell(new Paragraph(&quot;  &quot;));\n    //             &#125;\n    //             else &#123;\n    //                 ce1[i] = new PdfPCell(new Paragraph(str1[i],font));\n    //                 ce1[i].setHorizontalAlignment(Element.ALIGN_CENTER);\n    //                 ce2[i] = new PdfPCell(new Paragraph(&quot;&quot;));\n    //                  ce3[i] = new PdfPCell(new Paragraph(str2[i],font));\n    //                  ce3[i].setHorizontalAlignment(Element.ALIGN_CENTER);\n    //                 ce4[i] = new PdfPCell(new Paragraph(&quot;&quot;));\n    //                  ce5[i] = new PdfPCell(new Paragraph(&quot;&quot;));\n    //             &#125;\n    //       //  document.add(table1[i]);\n    //         &#125;\n    //         \n    //      //   ce5[0].setRowspan(4);\n    //         ce4[4].setColspan(2);  //合并同一行的两个格\n    //         ce4[5].setColspan(2);\n    //         ce2[6].setColspan(4);  //合并同一行的四个格\n    //         ce2[7].setColspan(4);\n    //         ce2[8].setColspan(4);\n    //         for(int i=0;i&lt;9;i++)&#123;\n    //              table1[i].addCell(ce1[i]);\n    //              table1[i].addCell(ce2[i]);\n    //              table1[i].addCell(ce3[i]);\n    //              table1[i].addCell(ce4[i]);\n    //              if(i&gt;0)\n    //              table1[i].addCell(ce5[i]);\n    //             document.add(table1[i]);\n    //         &#125;\n             document.add(table1);\n              document.close();\n         &#125; catch (Exception e) &#123;\n             e.printStackTrace();\n         &#125; \n    &#125;\n    &#125;\n\n效果如下：\n\n\n","categories":["Java"],"tags":["itext"]},{"title":"Java内存模型及GC原理","url":"http://tanqingbo.cn/2016/04/04/Java 内存模型及GC原理/","content":"Java 内存模型及GC原理Java内存模型\n按照官方的说法：Java 虚拟机具有一个堆，堆是运行时数据区域，所有类实例和数组的内存均从此处分配。\n\nJVM主要管理两种类型内存：堆和非堆，堆内存（Heap Memory）是在 Java 虚拟机启动时创建，非堆内存(Non-heap Memory)是在JVM堆之外的内存。\n\n堆是Java代码可及的内存，留给开发人员使用的；非堆是JVM留给自己用的，包含方法区、JVM内部处理或优化所需的内存（如 JIT Compiler，Just-in-time Compiler，即时编译后的代码缓存）、每个类结构（如运行时常数池、字段和方法数据）以及方法和构造方法的代码。\n\n\nJVM 内存包含如下几个部分：\n\n堆内存（Heap Memory）： 存放Java对象\n非堆内存（Non-Heap Memory）： 存放类加载信息和其它meta-data\n其它（Other）： 存放JVM 自身代码等\n\n\n\n\n\n在JVM启动时，就已经保留了固定的内存空间给Heap内存，这部分内存并不一定都会被JVM使用，但是可以确定的是这部分保留的内存不会被其他进程使用，这部分内存大小由-Xmx 参数指定。而另一部分内存在JVM启动时就分配给JVM，作为JVM的初始Heap内存使用，这部分内存是由 -Xms 参数指定。\n详细配置文件目录：eclipse/eclipse.ini\n\nJava内存分配\nJava的内存管理实际上就是变量和对象的管理，其中包括对象的分配和释放。\n\nJVM内存申请过程如下：\n\nJVM 会试图为相关Java对象在Eden中初始化一块内存区域\n当Eden空间足够时，内存申请结束；否则到下一步\nJVM 试图释放在Eden中所有不活跃的对象（这属于1或更高级的垃圾回收）,释放后若Eden空间仍然不足以放入新对象，则试图将部分Eden中活跃对象放入Survivor区\nSurvivor区被用来作为Eden及OLD的中间交换区域，当OLD区空间足够时，Survivor区的对象会被移到Old区，否则会被保留在Survivor区\n当OLD区空间不够时，JVM 会在OLD区进行完全的垃圾收集（0级）\n完全垃圾收集后，若Survivor及OLD区仍然无法存放从Eden复制过来的部分对象，导致JVM无法在Eden区为新对象创建内存区域，则出现”out of memory”错误\n\n\n\nGC基本原理\nGC（Garbage Collection)，是JAVA/.NET中的垃圾收集器。\n\n编程人员容易出现问题的地方，忘记或者错误的内存回收会导致程序或系统的不稳定甚至崩溃，Java提供的GC功能可以自动监测对象是否超过作用域从而达到自动回收内存的目的，Java语言没有提供释放已分配内存的显示操作方法。所以，Java的内存管理实际上就是对象的管理，其中包括对象的分配和释放。\n\n\n对于程序员来说，分配对象使用new关键字；释放对象时，只要将对象所有引用赋值为null，让程序不能够再访问到这个对象，我们称该对象为”不可达的”.GC将负责回收所有”不可达”对象的内存空间。\n\n对于GC来说，当程序员创建对象时，GC就开始监控这个对象的地址、大小以及使用情况。通常，GC采用有向图的方式记录和管理堆（heap）中的所有对象。通过这种方式确定哪些对象是”可达的”，哪些对象是”不可达的”.当GC确定一些对象为”不可达”时，GC就有责任回收这些内存空间。\n\n为了保证 GC能够在不同平台实现的问题，Java规范对GC的很多行为都没有进行严格的规定。例如，对于采用什么类型的回收算法、什么时候进行回收等重要问题都没有明确的规定。\n\n\nGC分代划分\nJVM内存模型中Heap区分两大块，一块是 Young Generation，另一块是Old Generation\n在Young Generation中，有一个叫Eden Space的空间，主要是用来存放新生的对象，还有两个Survivor Spaces（from、to），它们的大小总是一样，它们用来存放每次垃圾回收后存活下来的对象。\n在Old Generation中，主要存放应用程序中生命周期长的内存对象。\n在Young Generation块中，垃圾回收一般用Copying的算法，速度快。每次GC的时候，存活下来的对象首先由Eden拷贝到某个SurvivorSpace，当Survivor Space空间满了后，剩下的live对象就被直接拷贝到OldGeneration中去。因此，每次GC后，Eden内存块会被清空。\n在Old Generation块中，垃圾回收一般用mark-compact的算法，速度慢些，但减少内存要求。\n垃圾回收分多级，0级为全部(Full)的垃圾回收，会回收OLD段中的垃圾；1级或以上为部分垃圾回收，只会回收Young中的垃圾，内存溢出通常发生于OLD段或Perm段垃圾回收后，仍然无内存空间容纳新的Java对象的情况。增量式GC\n增量式GC（Incremental GC），是GC在JVM中通常是由一个或一组进程来实现的，它本身也和用户程序一样占用heap空间，运行时也占用CPU。\n当GC进程运行时，应用程序停止运行。当GC运行时间较长时，用户能够感到Java程序的停顿，另外一方面，如果GC运行时间太短，则可能对象回收率太低.\n增量式GC就是通过一定的回收算法，把一个长时间的中断，划分为很多个小的中断，通过这种方式减少GC对用户程序的影响。\nSun JDK提供的HotSpot JVM就能支持增量式GC。HotSpot JVM缺省GC方式为不使用增量GC，为了启动增量GC，我们必须在运行Java程序时增加-Xincgc的参数。\nHotSpot JVM增量式GC的实现是采用Train GC算法，它的基本想法就是：将堆中的所有对象按照创建和使用情况进行分组（分层），将使用频繁高和具有相关性的对象放在一队中，随着程序的运行，不断对组进行调整。当GC运行时，它总是先回收最老的（最近很少访问的）的对象，如果整组都为可回收对象，GC将整组回收。这样，每次GC运行只回收一定比例的不可达对象，保证程序的顺畅运行。\n\n详解函数finalize\nfinalize 是位于Object类的一个方法，详见我的开源项目：src-jdk1.7.0_02\n\n      protected void finalize() throws Throwable &#123; &#125;\n\n该方法的访问修饰符为protected，由于所有类为Object的子类，因此用户类很容易访问到这个方法。\n\n由于，finalize函数没有自动实现链式调用，我们必须手动的实现，因此finalize函数的最后一个语句通常是 super.finalize（）。通过这种方式，我们可以实现从下到上实现finalize的调用，即先释放自己的资源，然后再释放父类的资源。根据Java语言规范，JVM保证调用finalize函数之前，这个对象是不可达的，但是JVM不保证这个函数一定会被调用。另外，规范还保证finalize函数最多运行一次。\n\n很多Java初学者会认为这个方法类似与C++中的析构函数，将很多对象、资源的释放都放在这一函数里面。其实，这不是一种很好的方式，原因有三：\n\n其一、GC为了能够支持finalize函数，要对覆盖这个函数的对象作很多附加的工作。\n其二、在finalize运行完成之后，该对象可能变成可达的，GC还要再检查一次该对象是否是可达的。因此，使用 finalize会降低GC的运行性能。\n其三、由于GC调用finalize的时间是不确定的，因此通过这种方式释放资源也是不确定的。\n\n\n通常，finalize用于一些不容易控制、并且非常重要资源的释放，例如一些I/O的操作，数据的连接。\n\n\nGC程序交互\n序如何与GC进行交互呢？ Java2增强了内存管理功能，增加了一个java.lang.ref包，详见我的开源项目：src-jdk1.7.0_02\n其中定义了三种引用类。这三种引用类分别为：SoftReference、 WeakReference、 PhantomReference\n通过使用这些引用类，程序员可以在一定程度与GC进行交互，以便改善GC的工作效率，这些引用类的引用强度介于可达对象和不可达对象之间。\nSoft Reference的主要特点是据有较强的引用功能。只有当内存不够的时候，才进行回收这类内存，因此在内存足够的时候，它们通常不被回收。另外，这些引用对象还能保证在Java抛出OutOfMemory 异常之前，被设置为null。它可以用于实现一些常用图片的缓存，实现Cache的功能，保证最大限度的使用内存而不引起OutOfMemory。以下给出这种引用类型的使用伪代码：\n\n\n          // 申请一个图像对象  \n        　Image image=new Image();       // 创建Image对象  \n        　…  \n        　// 使用 image  \n        　…  \n        　// 使用完了image，将它设置为soft 引用类型，并且释放强引用；  \n        　SoftReference sr=new SoftReference(image);  \n        　image=null;  \n        　…  \n        　// 下次使用时  \n        　if (sr!=null)   \n            image=sr.get();  \n        　else&#123;  \n            //由于GC由于低内存，已释放image，因此需要重新装载；  \n        　       image=new Image();  //由于GC由于低内存，已释放image，因此需要重新装载；  \n        　       sr=new SoftReference(image);  \n        　&#125;  \n\n\nWeak引用对象与Soft引用对象的最大不同就在于：GC在进行回收时，需要通过算法检查是否回收Soft引用对象，而对于Weak引用对象，GC总是进行回收。Weak引用对象更容易、更快被GC回收。\nPhantom引用的用途较少，主要用于辅助finalize函数的使用。\n\nJava编程建议\n最基本的建议就是尽早释放无用对象的引用。大多数程序员在使用临时变量的时候，都是让引用变量在退出活动域（scope）后，自动设置为 null.我们在使用这种方式时候，必须特别注意一些复杂的对象图，例如数组，队列，树，图等，这些对象之间有相互引用关系较为复杂。对于这类对象，GC 回收它们一般效率较低。如果程序允许，尽早将不用的引用对象赋为null，这样可以加速GC的工作。\n尽量少用finalize函数。finalize函数是Java提供给程序员一个释放对象或资源的机会。但是，它会加大GC的工作量，因此尽量少采用finalize方式回收资源。\n如果需要使用经常使用的图片，可以使用soft应用类型。它可以尽可能将图片保存在内存中，供程序调用，而不引起OutOfMemory.\n注意集合数据类型，包括数组，树，图，链表等数据结构，这些数据结构对GC来说，回收更为复杂。另外，注意一些全局的变量，以及一些静态变量。这些变量往往容易引起悬挂对象（dangling reference），造成内存浪费。\n当程序有一定的等待时间，程序员可以手动执行System.gc()，通知GC运行，但是Java语言规范并不保证GC一定会执行。使用增量式GC可以缩短Java程序的暂停时间。\n\n","categories":["Java"],"tags":["JVM"]},{"title":"操作系统之进程与线程","url":"http://tanqingbo.cn/2016/04/03/操作系统之进程与线程/","content":"操作系统之进程与线程任务调度大部分操作系统(如Windows、Linux)的任务调度是采用时间片轮转的抢占式调度方式，也就是说一个任务执行一小段时间后强制暂停去执行下一个任务，每个任务轮流执行。任务执行的一小段时间叫做时间片，任务正在执行时的状态叫运行状态，任务执行一段时间后强制暂停去执行下一个任务，被暂停的任务就处于就绪状态等待下一个属于它的时间片的到来。这样每个任务都能得到执行，由于CPU的执行效率非常高，时间片非常短，在各个任务之间快速地切换，给人的感觉就是多个任务在“同时进行”，这也就是我们所说的并发。\n进程\n应用程序是具有某种功能的程序，程序是运行于操作系统之上的。\n\n进程是一个具有一定独立功能的程序在一个数据集上的一次动态执行的过程，是操作系统进行资源分配和调度的一个独立单位，是应用程序运行的载体。\n\n进程一般由程序、数据集合和进程控制块三部分组成。\n\n程序用于描述进程要完成的功能，是控制进程执行的指令集；数据集合是程序在执行时所需要的数据和工作区；程序控制块(Program Control Block，简称PCB)，包含进程的描述信息和控制信息，是进程存在的唯一标志。\n\n\n进程具有的特征：\n\n\n动态性：进程是程序的一次执行过程，是临时的，有生命期的，是动态产生，动态消亡的；\n并发性：任何进程都可以同其他进程一起并发执行；\n独立性：进程是系统进行资源分配和调度的一个独立单位；\n结构性：进程由程序、数据和进程控制块三部分组成。\n\n\n\n\n线程\n线程是程序执行中一个单一的顺序控制流程，是程序执行流的最小单元，是处理器调度和分派的基本单位。一个进程可以有一个或多个线程，各个线程之间共享程序的内存空间\n线程组成：\n\n线程ID\n当前指令指针(PC)\n寄存器和堆栈。\n\n而进程由内存空间(代码、数据、进程空间、打开的文件)和一个或多个线程组成。\n\n\n\n进程与线程的区别\n线程是程序执行的最小单位，而进程是操作系统分配资源的最小单位；\n一个进程由一个或多个线程组成，线程是一个进程中代码的不同执行路线；\n进程之间相互独立，但同一进程下的各个线程之间共享程序的内存空间(包括代码段、数据集、堆等)及一些进程级的资源(如打开文件和信号)，某进程内的线程在其它进程不可见；\n调度和切换：线程上下文切换比进程上下文切换要快得多。\n\n![进程与线程的资源共享关系](http://ww3.sinaimg.cn/large/e40462dbgw1f2jjw366f4j20k90e6tar.jpg)\n![线程与多线程的关系](http://ww3.sinaimg.cn/large/e40462dbgw1f2jjx9yh2jj20na0ejwh6.jpg)\n\n\n总之，线程和进程都是一种抽象的概念，线程是一种比进程更小的抽象，线程和进程都可用于实现并发。\n在早期的操作系统中并没有线程的概念，进程是能拥有资源和独立运行的最小单位，也是程序执行的最小单位。它相当于一个进程里只有一个线程，进程本身就是线程。所以线程有时被称为轻量级进程\n\n多线程与多核\n多核(心)处理器是指在一个处理器上集成多个运算核心从而提高计算能力，也就是有多个真正并行计算的处理核心，每一个处理核心对应一个内核线程.\n内核线程（Kernel Thread， KLT）就是直接由操作系统内核支持的线程，这种线程由内核来完成线程切换，内核通过操作调度器对线程进行调度，并负责将线程的任务映射到各个处理器上。\n\n进程与线程的生命周期\n当线程的数量小于处理器的数量时，线程的并发是真正的并发，不同的线程运行在不同的处理器上。但当线程的数量大于处理器的数量时，线程的并发会受到一些阻碍，此时并不是真正的并发，因为此时至少有一个处理器会运行多个线程。\n\n在单个处理器运行多个线程时，并发是一种模拟出来的状态。\n\n在早期只有进程的操作系统中，进程有五种状态，创建、就绪、运行、阻塞(等待)、退出。早期的进程相当于现在的只有单个线程的进程，那么现在的多线程也有五种状态，现在的多线程的生命周期与早期进程的生命周期类似。\n\n进程在运行过程有三种状态：就绪、运行、阻塞，创建和退出状态描述的是进程的创建过程和退出过程。\n\n创建：进程正在创建，还不能运行。操作系统在创建进程时要进行的工作包括分配和建立进程控制块表项、建立资源表格并分配资源、加载程序并建立地址空间；就绪：时间片已用完，此线程被强制暂停，等待下一个属于他的时间片到来；运行：此线程正在执行，正在占用时间片；阻塞：也叫等待状态，等待某一事件(如IO或另一个线程)执行完；退出：进程已结束，所以也称结束状态，释放操作系统分配的资源。\n\n\n线程的生命周期\n\n\n\n\n创建：一个新的线程被创建，等待该线程被调用执行；就绪：时间片已用完，此线程被强制暂停，等待下一个属于他的时间片到来；运行：此线程正在执行，正在占用时间片；阻塞：也叫等待状态，等待某一事件(如IO或另一个线程)执行完；退出：一个线程完成任务或者其他终止条件发生，该线程终止进入退出状态，退出状态释放该线程所分配的资源。\n\n","categories":["操作系统"],"tags":["操作系统"]},{"title":"计算机网络五层协议中的第一层--物理层","url":"http://tanqingbo.cn/2016/04/03/计算机网络五层协议中的第一层--物理层/","content":"计算机网络五层协议中的第一层–物理层物理层一般有三种传输介质：有线（铜线和光纤）、无线（陆地无线电）和卫星。\n这里要说的是信号在物理层存在的两种方式，数字信号（电脑可以识别的0和1即比特），模拟信号是铜线和光纤等可以传输的电信号或者无线信号，在现实中模拟信号的存在方式诸如连续变化的电压，而在无线传输中类似光照强度或者声音强度。\n\n电话调制解调器：要在本地回路或任何其他物理信道上发送比特，必须把比特转换为可在信道上传输的模拟信号。执行数字比特流和模拟信号流（代表这些数字比特）之间转换的设备成为调制解调器（也就是传说中的mdoem，猫），调制解调器是调制器（modulator）和解调器（demodulator）的缩写。调制解调器分为许多类型：电话调制解调器、DSL调制解调器、有线电视调制解调器和无线调制解调器等。\n\n数据交换：电话系统中用到了两种不同的交换技术：电路交换和数据包交换。传统的电话系统基于电路交换技术，但随着IP技术之上的语音通信兴起，数据包交换已经取得了长足的进步。\n\n电路交换的一个重要特点是在发送数据之前需要建立一条端到端的路径。从拨完号码到开始响铃，这段时间可能需要10秒钟，长途电话和国际长途电话所需要的时间更长。数据包交换是电路交换的一个替代方案，它无须像电路交换那样要事先设立一条专门的路径。路由器使用存储-转发传输技术，把经由它的每个数据包发送到通往该包目的地的路径上。这个转发过程与电路交换不同，在电路交换中，连接的建立过程预留了从发送端到接收端一条路上的带路资源，该条电路上的所有数据将走相同的路径。另一方面，让所有的数据遵循同样的路径意味着它们到达接收端的顺序不可能出现混乱。而在数据包交换中，没有固定的路径，不同的数据包可以走不同的路径，路径的选择取决于它们被传输时的网络状况，所以它们到达接收端的顺序可能是混乱的。\n\n\n电路交换和数据包交换的区别：\n\n\n数据包和电路交换在其他方面也有所不同。因为数据包交换中没有为传输数据预留带宽，数据包可能不得不等待一段时间才能被转发。这样就引入了排队延迟（queuing delay），如果许多包要在同一时间被发送出去还会引入拥塞。在电话交换中拥塞发生在建立电路时，而在数据包交换中拥塞发生在转发数据包时。\n对于电路交换如果一条电路已经预留给了某一个特定的用户，但是并没有流量通过这条电路，那么这条电路的带宽就会浪费，类似电话两端的人都接通的了电话但是彼此都没有说话，那么用电路交换这种方式，无疑是对当前链路的一种浪费。数据包交换就不会浪费带宽，因此从整个系统角度来看数据包交换的效率更高。我们要做的权衡是：要么保证服务质量但是可能浪费资源，要么不保证服务质量，也不浪费资源。\n其次数据包交换比电路交换的容错性更好。事实上，这也是为什么数据包交换会被发明出来，并且最终替代电路交换的主要原因。在电路交换中，如果链路中间的一个交换机出现故障，那么经过这个交换机的所有链路都将被终止，而数据包交换，数据可以绕过死掉的交换机通过其他好的交换机转发出去。对于数据包交换，数据的走向是不确定的，它会选择合适的路径最终到达我们希望它去到的地方。\n最后电路交换和数据包交换使用的收费方式不同，电路交换是按时间收费，而数据包交换是按流量计费。\n 项目    电路交换    包交换\n\n\n\n呼叫建立    需要    不需要\n专用的物理路径    需要    不需要\n每个包遵循相同的路由    是    不是\n包按顺序到达    是    不是\n交换机崩溃是否致命    是    不是\n可用带宽    固定    动态\n可能拥塞的时间    呼叫建立时    在每个包排队时\n潜在浪费带宽    是    不是\n存储-转发传输    不是    是\n收费    按分钟就计费    按包计费\n\n通过上面的表格我们很容易发现包交换和电路交换相比还是有很多优势的。\n\nADSL和有线电视电缆\n\n有线电视使用了同轴电缆，而ADSL使用了双绞线\n\n\n\n注： ADSL:ADSL属于DSL技术的一种，全称Asymmetric Digital Subscriber Line（ 非对称数字用户线路），亦可称作非对称数字用户环路。是一种新的数据传输方式。ADSL技术采用频分复用技术把普通的电话线分成了电话、上行和下行三个相对独立的信道，从而避免了相互之间的干扰。用户可以边打电话边上网，不用担心上网速率和通话质量下降的情况。理论上，ADSL 可在5 km 的范围内，在一对铜缆双绞线上提供最高1 Mbps的的上行速率和最高8Mbps的下行速率（也就是我们通常说的带宽），能同时提供话音和数据业务。一般来说，ADSL 速率完全取决于线路的距离，线路越长，速率越低。\n","categories":["网络原理"],"tags":["网络"]},{"title":"Servlet开发","url":"http://tanqingbo.cn/2016/04/03/Servlet开发/","content":"Servlet开发Servlet简介\nServlet是sun公司提供的一门用于开发动态web资源的技术。\n\nSun公司在其API中提供了一个servlet接口，用户若想用发一个动态web资源(即开发一个Java程序向浏览器输出数据)，需要完成以下2个步骤：\n\n编写一个Java类，实现servlet接口。\n把开发好的Java类部署到web服务器中。\n\n\n\nServlet的运行过程\nServlet程序是由WEB服务器调用，web服务器收到客户端的Servlet访问请求后：\n①Web服务器首先检查是否已经装载并创建了该Servlet的实例对象。如果是，则直接执行第④步，否则，执行第②步。\n②装载并创建该Servlet的一个实例对象。 \n③调用Servlet实例对象的init()方法。\n④创建一个用于封装HTTP请求消息的HttpServletRequest对象和一个代表HTTP响应消息的HttpServletResponse对象，然后调用Servlet的service()方法并将请求和响应对象作为参数传递进去。\n⑤WEB应用程序被停止或重新启动之前，Servlet引擎将卸载Servlet，并在卸载之前调用Servlet的destroy()方法。 \n\n\n\nServlet接口实现类\nServlet接口SUN公司定义了两个默认实现类，分别为：GenericServlet、HttpServlet。\n\nHttpServlet指能够处理HTTP请求的servlet，它在原有Servlet接口上添加了一些与HTTP协议处理方法，它比Servlet接口的功能更为强大。因此开发人员在编写Servlet时，通常应继承这个类，而避免直接去实现Servlet接口。\n\nHttpServlet在实现Servlet接口时，覆写了service方法，该方法体内的代码会自动判断用户的请求方式，如为GET请求，则调用HttpServlet的doGet方法，如为Post请求，则调用doPost方法。因此，开发人员在编写Servlet时，通常只需要覆写doGet或doPost方法，而不要去覆写service方法。\n通过Eclipse创建和编写Servlet\n在编写Servlet类的时候要继承javax.servlet.http.HttpServlet类。\n\neclipse自动生成代码如下：\n       1 package gacl.servlet.study;\n       2 \n       3 import java.io.IOException;\n       4 import java.io.PrintWriter;\n       5 \n       6 import javax.servlet.ServletException;\n       7 import javax.servlet.http.HttpServlet;\n       8 import javax.servlet.http.HttpServletRequest;\n       9 import javax.servlet.http.HttpServletResponse;\n      10 \n      11 public class ServletDemo1 extends HttpServlet &#123;\n      12 \n      13     /**\n      14      * The doGet method of the servlet. &lt;br&gt;\n      15      *\n      16      * This method is called when a form has its tag value method equals to get.\n      17      * \n      18      * @param request the request send by the client to the server\n      19      * @param response the response send by the server to the client\n      20      * @throws ServletException if an error occurred\n      21      * @throws IOException if an error occurred\n      22      */\n      23     public void doGet(HttpServletRequest request, HttpServletResponse response)\n      24             throws ServletException, IOException &#123;\n      25 \n      26         response.setContentType(&quot;text/html&quot;);\n      27         PrintWriter out = response.getWriter();\n      28         out.println(&quot;&lt;!DOCTYPE HTML PUBLIC \\&quot;-//W3C//DTD HTML 4.01 Transitional//EN\\&quot;&gt;&quot;);\n      29         out.println(&quot;&lt;HTML&gt;&quot;);\n      30         out.println(&quot;  &lt;HEAD&gt;&lt;TITLE&gt;A Servlet&lt;/TITLE&gt;&lt;/HEAD&gt;&quot;);\n      31         out.println(&quot;  &lt;BODY&gt;&quot;);\n      32         out.print(&quot;    This is &quot;);\n      33         out.print(this.getClass());\n      34         out.println(&quot;, using the GET method&quot;);\n      35         out.println(&quot;  &lt;/BODY&gt;&quot;);\n      36         out.println(&quot;&lt;/HTML&gt;&quot;);\n      37         out.flush();\n      38         out.close();\n      39     &#125;\n      40 \n      41     /**\n      42      * The doPost method of the servlet. &lt;br&gt;\n      43      *\n      44      * This method is called when a form has its tag value method equals to post.\n      45      * \n      46      * @param request the request send by the client to the server\n      47      * @param response the response send by the server to the client\n      48      * @throws ServletException if an error occurred\n      49      * @throws IOException if an error occurred\n      50      */\n      51     public void doPost(HttpServletRequest request, HttpServletResponse response)\n      52             throws ServletException, IOException &#123;\n      53 \n      54         response.setContentType(&quot;text/html&quot;);\n      55         PrintWriter out = response.getWriter();\n      56         out.println(&quot;&lt;!DOCTYPE HTML PUBLIC \\&quot;-//W3C//DTD HTML 4.01 Transitional//EN\\&quot;&gt;&quot;);\n      57         out.println(&quot;&lt;HTML&gt;&quot;);\n      58         out.println(&quot;  &lt;HEAD&gt;&lt;TITLE&gt;A Servlet&lt;/TITLE&gt;&lt;/HEAD&gt;&quot;);\n      59         out.println(&quot;  &lt;BODY&gt;&quot;);\n      60         out.print(&quot;    This is &quot;);\n      61         out.print(this.getClass());\n      62         out.println(&quot;, using the POST method&quot;);\n      63         out.println(&quot;  &lt;/BODY&gt;&quot;);\n      64         out.println(&quot;&lt;/HTML&gt;&quot;);\n      65         out.flush();\n      66         out.close();\n      67     &#125;\n      68 \n      69 &#125;\n\n如果是post请求的话则编写dopost函数，是get请求的话就编写doget函数。但此时web服务器还不能调用该servlet类，还需在web.xml文件中配置。 \n\n然后我们就可以通过浏览器访问ServletDemo1这个Servlet。\n\n\nServlet开发注意细节\nServlet访问URL映射配置\n\n由于客户端是通过URL地址访问web服务器中的资源，所以Servlet程序若想被外界访问，必须把servlet程序映射到一个URL地址上，这个工作在web.xml文件中使用元素和元素完成。\\\n\n元素用于注册Servlet，它包含有两个主要的子元素：和，分别用于设置Servlet的注册名称和Servlet的完整类名。 \n\n一个元素用于映射一个已注册的Servlet的一个对外访问路径，它包含有两个子元素：和，分别用于指定Servlet的注册名称和Servlet的对外访问路径。\n\n同一个Servlet可以被映射到多个URL上，即多个元素的子元素的设置值可以是同一个Servlet的注册名。 \n\nServlet访问URL使用*通配符映射　\n\n在Servlet映射到的URL中也可以使用通配符，但是只能有两种固定的格式：一种格式是”.扩展名”，另一种格式是以正斜杠（/）开头并以”/*”结尾。例如：\n       &lt;servlet&gt;\n       &lt;servlet-name&gt;ServletDemo1&lt;/servlet-name&gt;\n       &lt;servlet-class&gt;gacl.servlet.study.ServletDemo1&lt;/servlet-class&gt;\n     &lt;/servlet&gt;\n      &lt;servlet-mapping&gt;\n      &lt;servlet-name&gt;ServletDemo1&lt;/servlet-name&gt;\n      &lt;url-pattern&gt;/*&lt;/url-pattern&gt;\n\n可以匹配任意的字符，所以此时可以用任意的URL去访问ServletDemo1这个Servlet.例如：\n     http://localhost:8080/工程名/nvlkfmndlmd\n\n\n对于如下的一些映射关系：　　Servlet1 映射到 /abc/*　　Servlet2 映射到 /*　　Servlet3 映射到 /abc　　Servlet4 映射到 .do问题：　　当请求URL为“/abc/a.html”，“/abc/*”和“/*”都匹配，哪个servlet响应    　　Servlet引擎将调用Servlet1。　　当请求URL为“/abc”时，“/abc/*”和“/abc”都匹配，哪个servlet响应    　　Servlet引擎将调用Servlet3。　　当请求URL为“/abc/a.do”时，“/abc/*”和“.do”都匹配，哪个servlet响应    　　Servlet引擎将调用Servlet1。　　当请求URL为“/a.do”时，“/”和“.do”都匹配，哪个servlet响应    　　Servlet引擎将调用Servlet2。　　当请求URL为“/xxx/yyy/a.do”时，“/”和“.do”都匹配，哪个servlet响应    　　Servlet引擎将调用Servlet2。　　匹配的原则就是”谁长得更像就找谁”\n\nServlet与普通Java类的区别　\n\nServlet是一个供其他Java程序（Servlet引擎）调用的Java类，它不能独立运行，它的运行完全由Servlet引擎来控制和调度。　　针对客户端的多次Servlet请求，通常情况下，服务器只会创建一个Servlet实例对象，也就是说Servlet实例对象一旦创建，它就会驻留在内存中，为后续的其它请求服务，直至web容器退出，servlet实例对象才会销毁。　　在Servlet的整个生命周期内，Servlet的init方法只被调用一次。而对一个Servlet的每次访问请求都导致Servlet引擎调用一次servlet的service方法。对于每次访问请求，Servlet引擎都会创建一个新的HttpServletRequest请求对象和一个新的HttpServletResponse响应对象，然后将这两个对象作为参数传递给它调用的Servlet的service()方法，service方法再根据请求方式分别调用doXXX方法。　　如果在元素中配置了一个元素，那么WEB应用程序在启动时，就会装载并创建Servlet的实例对象、以及调用Servlet实例对象的init()方法。\n\n\n举例：\n  &lt;servlet&gt;\n      &lt;servlet-name&gt;invoker&lt;/servlet-name&gt;\n      &lt;servlet-class&gt;\n          org.apache.catalina.servlets.InvokerServlet\n      &lt;/servlet-class&gt;\n      &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;\n  &lt;/servlet&gt;\n\n用途：为web应用写一个InitServlet，这个servlet配置为启动时装载，为整个web应用创建必要的数据库表和数据。\n\n缺省Servlet\n\n如果某个Servlet的映射路径仅仅为一个正斜杠（/），那么这个Servlet就成为当前Web应用程序的缺省Servlet。 \n\n凡是在web.xml文件中找不到匹配的元素的URL，它们的访问请求都将交给缺省Servlet处理，也就是说，缺省Servlet用于处理所有其他Servlet都不处理的访问请求。例如：\n &lt;!-- 将ServletDemo2配置成缺省Servlet --&gt;\n  8   &lt;servlet-mapping&gt;\n  9     &lt;servlet-name&gt;ServletDemo2&lt;/servlet-name&gt;\n 10     &lt;url-pattern&gt;/&lt;/url-pattern&gt;\n 11   &lt;/servlet-mapping&gt;\n\n当访问不存在的Servlet时，就使用配置的默认缺省的Servlet进行处理\n\n\n\n\n\n在&lt;tomcat的安装目录&gt;\\conf\\web.xml文件中，注册了一个名称为org.apache.catalina.servlets.DefaultServlet的Servlet，并将这个Servlet设置为了缺省Servlet。\n\n当访问Tomcat服务器中的某个静态HTML文件和图片时，实际上是在访问这个缺省Servlet。\n\n\n\nServlet的线程安全问题\n\n当多个客户端并发访问同一个Servlet时，web服务器会为每一个客户端的访问请求创建一个线程，并在这个线程上调用Servlet的service方法，因此service方法内如果访问了同一个资源的话，就有可能引发线程安全问题。\n\n线程安全的例子：\n    public void doGet(HttpServletRequest request, \n       HttpServletResponse response)\n                throws ServletException, IOException &#123;\n            /**\n     * 当多线程并发访问这个方法里面的代码时，会存在线程安全问题吗？\n     * i变量被多个线程并发访问，但是没有线程安全问题，因为i是doGet方法里面的局部变量，\n     * 当有多个线程并发访问doGet方法时，每一个线程里面都有自己的i变量，\n     * 各个线程操作的都是自己的i变量，所以不存在线程安全问题\n     * 多线程并发访问某一个方法的时候，如果在方法内部定义了一些资源(变量，集合等)\n     * 那么每一个线程都有这些东西，所以就不存在线程安全问题了\n */\nint i=1;\ni++;\nresponse.getWriter().write(i);\n&#125;\npublic void doPost(HttpServletRequest request, HttpServletResponse response)\n        throws ServletException, IOException &#123;\n    doGet(request, response);\n&#125;\n\n\n\n\n\n把i定义成全局变量，当多个线程并发访问变量i时，就会存在线程安全问题了。\n\n线程安全问题只存在多个线程并发操作同一个资源的情况下，所以在编写Servlet的时候，如果并发访问某一个资源(变量，集合等)，就会存在线程安全问题。那么该如何解决这个问题呢？先看下面的代码：\n   public class ServletDemo3 extends HttpServlet &#123;\n  int i=1;\n  public void doGet(HttpServletRequest request, HttpServletResponse response)\n          throws ServletException, IOException &#123;\n  /**\n   * 加了synchronized后，并发访问i时就不存在线程安全问题了，\n   * 为什么加了synchronized后就没有线程安全问题了呢？\n   * 假如现在有一个线程访问Servlet对象，那么它就先拿到了Servlet对象的那把锁\n   * 等到它执行完之后才会把锁还给Servlet对象，由于是它先拿到了Servlet对象的那把锁，\n   * 所以当有别的线程来访问这个Servlet对象时，由于锁已经被之前的线程拿走了，后面的线程只能排队等候了\n   * \n   */\n  synchronized (this) &#123;//在java中，每一个对象都有一把锁，这里的this指的就是Servlet对象\n      i++;\n      try &#123;\n          Thread.sleep(1000*4);\n      &#125; catch (InterruptedException e) &#123;\n          e.printStackTrace();\n      &#125;\n      response.getWriter().write(i+&quot;&quot;);\n  &#125;  \n   }\n\n\n5.现在这种做法是给Servlet对象加了一把锁，保证任何时候都只有一个线程在访问该Servlet对象里面的资源，这样就不存在线程安全问题了.\n这种做法虽然解决了线程安全问题，但是编写Servlet却万万不能用这种方式处理线程安全问题，假如有9999个人同时访问这个Servlet，那么这9999个人必须按先后顺序排队轮流访问。\n　　针对Servlet的线程安全问题，Sun公司是提供有解决方案的：让Servlet去实现一个SingleThreadModel接口，如果某个Servlet实现了SingleThreadModel接口，那么Servlet引擎将以单线程模式来调用其service方法。　　查看Sevlet的API可以看到，SingleThreadModel接口中没有定义任何方法和常量，在Java中，把没有定义任何方法和常量的接口称之为标记接口，经常看到的一个最典型的标记接口就是”Serializable”，这个接口也是没有定义任何方法和常量的，标记接口在Java中有什么用呢？主要作用就是给某个对象打上一个标志，告诉JVM，这个对象可以做什么，比如实现了”Serializable“接口的类的对象就可以被序列化，还有一个”Cloneable“接口，这个也是一个标记接口，在默认情况下，Java中的对象是不允许被克隆的，就像现实生活中的人一样，不允许克隆，但是只要实现了”Cloneable”接口，那么对象就可以被克隆了。\n　　让Servlet实现了SingleThreadModel接口，只要在Servlet类的定义中增加实现SingleThreadModel接口的声明即可。 **　**　对于实现了SingleThreadModel接口的Servlet，Servlet引擎仍然支持对该Servlet的多线程并发访问，其采用的方式是产生多个Servlet实例对象，并发的每个线程分别调用一个独立的Servlet实例对象。　　实现SingleThreadModel接口并不能真正解决Servlet的线程安全问题，因为Servlet引擎会创建多个Servlet实例对象，而真正意义上解决多线程安全问题是指一个Servlet实例对象被多个线程同时调用的问题。事实上，在Servlet API 2.4中，已经将SingleThreadModel标 记为Deprecated（过时的）。  \n\n一般来说，servlet是单例的，同一个实例可以同时有多个用户访问，这个没有任何问题。问题在于servlet是否有状态，对这些状态的访问是否必须是synchronized的。如果是，那么在同一个时间就只有一个用户可以访问这些状态了，这就大大降低了性能。所以一般来说servlet都是无状态的。\n\n","categories":["Java"],"tags":["Java","Servlet"]},{"title":"操作系统的运行环境","url":"http://tanqingbo.cn/2016/04/01/操作系统的运行环境/","content":"操作系统的运行环境操作系统的运行机制\n计算机系统中，通常CPU执行两种不同性质的程序：一种是操作系统内核程序；另一种是用户自编程序或系统外层的应用程序。对操作系统而言，这两种程序的作用不同，前者是后者的管理者，因此“管理程序”要执行一些特权指令，而“被管理程序”出于安全考虑不能执行这些指令。所谓特权指令，是指计算机中不允许用户直接使用的指令，如I/O指令、 置中断指令，存取用于内存保护的寄存器、送程序状态字到程序状态字寄存器等指令。操作系统在具体实现上划分了用户态（目态）和核心态（管态)，以严格区分两类程序。\n\n现代计算机几乎都是层次结构，操作系统的各项功能分别设置在不同层次上，一些与硬件关联较紧密的模块，诸如时钟管理、中断处理、设备驱动等处于最底层。其次是运行频率较髙的程序，诸如进程管理、存储器管理和设备管理等。这两部分内容构成了操作系统的内核。这部分内容的指令操作工作在核心态。\n\n内核一般包括四个方面的内容：\n\n时钟管理：\n\n 在计算机的各种部件中，时钟是最关键的设备。 时钟的第一功能是计时，操作系统需要通过时钟管理，向用户提供标准的系统时间。另外，通过时钟中断的管理，可以实现进程的切换。诸如，在分时操作系统中，釆用时间片轮转调度的实现；在实时系统中，按截止时间控制运行的实现；在批处理系统中，通过时钟管理来衡量一个作业的运行程度等。因此，系统管理的方方面面无不依赖于时钟。\n\n\n中断机制\n\n引入中断技术的初衷是提高多道程序运行环境中CPU的利用率，而且主要是针对外部设备的。\n\n\n原语\n\n按层次结构设计的操作系统，底层必然是一些可被调用的公用小程序，它们各自完成一个规定的操作。其特点是：1.它们处于操作系统的最底层，是最接近硬件的部分。2.这些程序的运行具有原子性——其操作只能一气呵成3.这些程序的运行时间都较短，而且调用频繁。\n\n\n系统控制的数据结构及处理\n\n系统中用来登记状态信息的数据结构很多，比如作业控制块、进程控制块(PCB)、设备控制块、各类链表、消息队列、缓冲区、空闲区登记表、内存分配表等。为了实现有效的管理，系统需要一些基本的操作，常见的操作有以下三种：1.进程管理：进程状态管理、进程调度和分派、创建与撤销进程控制块等。2.存储器管理：存储器的空间分配和回收、内存信息保护程序、代码对换程序等。3.设备管理：缓冲区管理、设备分配和回收等。\n\n\n\n\n\n中断和异常的概念\n当中断或异常发生时，运行用户态的CPU会立即进入核心态，这是通过硬件实现的.\n中断(Interruption)，也称外中断，指来自CPU执行指令以外的事件的发生，如设备发出的I/O结束中断，表示设备输入/输出处理已经完成，希望处理机能够向设备发下一个输入 / 输出请求，同时让完成输入/输出后的程序继续运行。时钟中断，表示一个固定的时间片已到，让处理机处理计时、启动定时运行的任务等。这一类中断通常是与当前程序运行无关的事件，即它们与当前处理机运行的程序无关。\n异常(Exception)，也称内中断、例外或陷入(Trap)，指源自CPU执行指令内部的事件，如程序的非法操作码、 地址越界、算术溢出、虚存系统的缺页以及专门的陷入指令等引起的事件。对异常的处理一般要依赖于当前程序的运行现场，而且异常不能被屏蔽，一旦出现应立即处理。关于内中断和外中断的联系与区别如图1-2所示。\n\n![图1-2 内中断和外中断的联系与区别](http://c.biancheng.net/cpp/uploads/allimg/140629/1-14062Z13353613.png)\n\n系统调用\n所谓系统调用就是用户在程序中调用操作系统所提供的一些子功能，系统调用可以被看做特殊的公共子程序。系统中的各种共享资源都由操作系统统一掌管，因此在用户程序中，凡是与资源有关的操作（如存储分配、进行I/0传输以及管理文件等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。通常，一个操作系统提供的系统调用命令有几十乃至上百条之多。\n\n这些系统调用按功能大致可分为如下几类：\n\n\n设备管理。完成设备的请求或释放，以及设备启动等功能。\n文件管理。完成文件的读、写、创建及删除等功能。\n进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。\n进程通信。完成进程之间的消息传递或信号传递等功能。\n内存管理。完成内存的分配、回收以及获取作业占用内存区大小及始址等功能。\n\n\n\n系统调用运行在系统的核心态。通过系统调用的方式来使用系统功能，可以保证系统的稳定性和安全性，防止用户随意更改或访问系统的数据或命令。系统调用命令是由操作系统提供的一个或多个子程序模块实现的。\n\n操作系统的运行环境可以理解为：用户通过操作系统运行上层程序（如系统提供的命令解释程序或用户自编程序)，而这个上层程序的运行依赖于操作系统的底层管理程序提供服务支持，当需要管理程序服务时，系统则通过硬件中断机制进入核心态，运行管理程序；也可能是程序运行出现异常情况，被动地需要管理程序的服务，这时就通过异常处理来进入核心态。当管理程序运行结束时，用户程序需要继续运行，则通过相应的保存的程序现场退出中断处理程序或异常处理程序，返回断点处继续执行。\n\n由用户态转向核心态的例子：\n\n\n用户程序要求操作系统的服务，即系统调用。\n发生一次中断。\n用户程序中产生了一个错误状态。\n用户程序中企图执行一条特权指令。\n从核心态转向用户态由一条指令实现，这条指令也是特权命令。一般是中断返回指令。\n\n\n\n\n","categories":["操作系统"],"tags":["操作系统"]},{"title":"八大排序算法","url":"http://tanqingbo.cn/2016/03/31/八大排序算法/","content":"八大排序算法–Java实现插入排序\n基本思想：每步将一个待排序的纪录，按其关键码值的大小插入前面已经排序的文件中适当位置上，直到全部插入完为止。\n算法适用于少量数据的排序，时间复杂度为O(n^2)。是稳定的排序方法。\n代码：\n          public static void insertionSort(int[] array)&#123;\n              int tmp;\n              for(int i=1;i&lt;array.length;i++)&#123;\n                  tmp = array[i];  //将当前位置的数给tmp\n                  int j = i;\n                  for(;j&gt;0&amp;&amp;array[j-1]&gt;tmp;j--)&#123;\n                      /*\n                       * 往右移，腾出左边的位置,\n                       * array[j-1]&gt;tmp:大于号是升序排列，小于号是降序排列\n                       */\n                      array[j] = array[j-1];\n                  &#125;\n                  //将当前位置的数插入到合适的位置\n                  array[j] = tmp;\n              &#125;\n          &#125;\n\n\n\n冒泡排序\n基本思想：持续比较相邻的元素。如果第一个比第二个大，就交换他们两个。直到没有任何一对数字需要比较。\n冒泡排序最好的时间复杂度为O(n)。冒泡排序的最坏时间复杂度为O(n^2)。因此冒泡排序总的平均时间复杂度为O(n^2)。\n算法适用于少量数据的排序，是稳定的排序方法。\n代码：\n     public static void bubbleSort(int[] array)&#123;\n          int tmp;\n          boolean flag = false;  //设置是否发生交换的标志\n          for(int i = array.length-1;i &gt;= 0;i--)&#123;\n              for(int j=0;j&lt;i;j++)&#123;          //每一轮都找到一个最大的数放在右边\n                  if(array[j]&gt;array[j+1])&#123;\n                      tmp = array[j];\n                      array[j] = array[j+1];\n                      array[j+1] = tmp;\n                      flag = true;   //发生了交换\n                  &#125;\n              &#125;\n              if(!flag)  break;   //这一轮循环没有发生交换，说明排序已经完成，退出循环\n          &#125;\n      &#125;\n\n\n\n选择排序\n基本思想：每一次从待排序的数据元素中选出最小（或最大）的一个元素，存放在序列的起始位置，直到全部待排序的数据元素排完。\n选择排序是不稳定的排序方法。时间复杂度 O(n^2)。\n代码：\n   public static void selectSort(int[] array)&#123;\n      for(int i = 0;i&lt;array.length-1;i++)&#123;\n          int    min = array[i];\n          int minindex = i;\n          for(int j = i;j&lt;array.length;j++)&#123;\n              if(array[j]&lt;min)&#123;  //选择当前最小的数\n                  min = array[j];\n                  minindex = j;\n              &#125;\n          &#125;\n          if(i != minindex)&#123; //若i不是当前元素最小的，则和找到的那个元素交换\n              array[minindex] = array[i];\n              array[i] = min;\n          &#125;\n      &#125;\n  &#125;\n\n\n\n希尔排序\n基本思想：先取一个小于n的整数d1作为第一个增量，把文件的全部记录分组。所有距离为d1的倍数的记录放在同一个组中。先在各组内进行直接插入排序；然后，取第二个增量d2&lt;d1重复上述的分组和排序，直至所取的增量dt=1(dt&lt;dt-1…&lt;d2&lt;d1)，即所有记录放在同一组中进行直接插入排序为止。\n在使用增量dk的一趟排序之后，对于每一个i，我们都有a[i]&lt;=a[i+dk],即所有相隔dk的元素都被排序。\n如图：增量序列为5，3，1，每一趟排序之后，相隔对应增量的元素都被排序了。当增量为1时，数组元素全部被排序。\n希尔排序不稳定，时间复杂度 平均时间 O(nlogn) 最差时间O(n^2) \n代码：\n      public static void shellSort(int[] array)&#123;\n          int j;\n          for(int gap = array.length/2; gap&gt;0; gap /= 2)&#123;\n              //定义一个增长序列，即分割数组的增量,d1=N/2   dk=(d(k-1))/2\n              for(int i = gap; i&lt;array.length;i++)&#123;\n                  int tmp = array[i];\n                  for( j =i; j&gt;=gap&amp;&amp;tmp&lt;array[j-gap]; j -= gap)&#123;\n                      //将相距为Dk的元素进行排序\n                      array[j] = array[j-gap];\n                  &#125;\n                  array[j] = tmp;\n              &#125;\n          &#125;\n      &#125;\n\n\n\n堆排序\n预备知识：\n\n二叉堆是完全二元树（二叉树）或者是近似完全二元树（二叉树）。二叉堆有两种：最大堆和最小堆。大根堆：父结点的键值总是大于或等于任何一个子节点的键值；小根堆：父结点的键值总是小于或等于任何一个子节点的键值。二叉堆一般用数组来表示。例如，根节点在数组中的位置是0，第n个位置的子节点分别在2n+1和 2n+2。因此，第0个位置的子节点在1和2，1的子节点在3和4。以此类推。这种存储方式便於寻找父节点和子节点。例如初始要排序的数组为：49, 38, 65, 97, 76, 13, 27, 49构造成大根堆之后的数组为：97 76 65 49 49 13 27 38实际树形结构如图（最大堆）：\n\n\n\n堆排序基本思想：在排序过程中，将R[l..n]看成是一棵完全二叉树的顺序存储结构，利用完全二叉树中双亲结点和孩子结点之间的内在关系【参见二叉树的顺序存储结构】，在当前无序区中选择关键字最大(或最小)的记录。堆排序利用了大根堆(或小根堆)堆顶记录的关键字最大(或最小)这一特征，使得在当前无序区中选取最大(或最小)关键字的记录变得简单。\n\n堆排序是一种选择排序,其时间复杂度为O(nlogn)。堆排序是不稳定的\n\n代码：\n\n       /*\n       * 堆排序\n       * 调整最大堆，交换根元素和最后一个元素。\n       * 参数说明：\n       *     a -- 待排序的数组\n       */\n      public static void heapSort(int[] a) &#123;\n          int n = a.length;\n          int i,tmp;\n          // 从(n/2-1) --&gt; 0逐次遍历。遍历之后，得到的数组实际上是一个(最大)二叉堆。\n          for (i = n / 2 - 1; i &gt;= 0; i--)\n              maxHeapDown(a, i, n-1);\n          // 从最后一个元素开始对序列进行调整，不断的缩小调整的范围直到第一个元素\n          for (i = n - 1; i &gt; 0; i--) &#123;\n              // 交换a[0]和a[i]。交换后，a[i]是a[0...i]中最大的。\n              tmp = a[0];\n              a[0] = a[i];\n              a[i] = tmp;\n              // 调整a[0...i-1]，使得a[0...i-1]仍然是一个最大堆。\n              // 即，保证a[i-1]是a[0...i-1]中的最大值。\n              maxHeapDown(a, 0, i-1);\n          &#125;\n      &#125;\n      /*\n       * 注：数组实现的堆中，第N个节点的左孩子的索引值是(2N+1)，右孩子的索引是(2N+2)。\n       *     其中，N为数组下标索引值，如数组中第1个数对应的N为0。\n       *\n       * 参数说明：\n       *     a -- 待排序的数组\n       *     start -- 被下调节点的起始位置(一般为0，表示从第1个开始)\n       *     end   -- 截至范围(一般为数组中最后一个元素的索引)\n       */\n      public static void maxHeapDown(int[] a, int start, int end) &#123;\n          int c = start;            // 当前(current)节点的位置\n          int l = 2*c + 1;        // 左(left)孩子的位置\n          int tmp = a[c];            // 当前(current)节点的大小\n          for (; l &lt;= end; c=l,l=2*l+1) &#123;\n              // &quot;l&quot;是左孩子，&quot;l+1&quot;是右孩子\n              if ( l &lt; end &amp;&amp; a[l] &lt; a[l+1])\n                  l++;        // 左右两孩子中选择较大者，即m_heap[l+1] \n              if (tmp &gt;= a[l])\n                  break;        // 调整结束\n              else &#123;            // 交换值\n                  a[c] = a[l];\n                  a[l]= tmp;\n              &#125;\n          &#125;\n      &#125;\n\n\n\n归并排序\n归并排序的原理\n\n将待排序的数组分成前后两个部分，再递归的将前半部分数据和后半部分的数据各自归并排序，得到的两部分数据，然后使用merge合并算法（算法见代码）将两部分算法合并到一起。例如：如果N=1；那么只有一个数据要排序，N=2，只需要调用merge函数将前后合并，N=4，………..  也就是将一个很多数据的数组分成前后两部分，然后不断递归归并排序，再合并，最后返回有序的数组。\n\n\n归并排序的时间复杂度\n\n归并排序的最好、最坏和平均时间复杂度都是O(nlogn)，而空间复杂度是O(n)，比较次数介于(nlogn)/2和(nlogn)-n+1，赋值操作的次数是(2nlogn)。因此可以看出，归并排序算法比较占用内存，但却是效率高且稳定的排序算法。\n\n\n代码：\n\n    public class MergeSort &#123;\n      private static void mergeSort(int[] array,int[] tmp,int left,int right)&#123;\n          if(left&lt;right)&#123;\n              int center = ( left + right ) / 2;//取数组的中点\n              mergeSort(array,tmp,left,center);//归并排序数组的前半部分\n              mergeSort(array,tmp,center+1,right);//归并排序数组的后半部分\n              merge(array,tmp,left,center+1,right);//将数组的前后半部分合并\n          &#125;\n      &#125;\n      /*\n       * 超简单的合并函数\n       */\n      private static void merge(int[] array, int[] tmp, int leftPos, int rightPos, int rightEnd) &#123;\n          // TODO Auto-generated method stub\n          int leftEnd = rightPos - 1;\n          int tmpPos = leftPos;\n          int numElements = rightEnd - leftPos + 1;\n          while(leftPos &lt;= leftEnd &amp;&amp; rightPos &lt;= rightEnd)&#123;\n              if(array[leftPos]&lt;=array[rightPos])&#123;\n                  tmp[tmpPos++] = array[leftPos++];\n              &#125;else&#123;\n                  tmp[tmpPos++] = array[rightPos++];\n              &#125;\n          &#125;\n          while(leftPos &lt;= leftEnd)&#123;\n              tmp[tmpPos++] = array[leftPos++];\n          &#125;\n          while(rightPos &lt;= rightEnd)&#123;\n              tmp[tmpPos++] = array[rightPos++];\n          &#125;\n          for(int i=0;i&lt;numElements;i++,rightEnd--)&#123;\n              array[rightEnd] = tmp[rightEnd];\n          &#125;\n      &#125;\n      public static void mergeSort(int[] array)&#123;\n          int[] tmp = new int[array.length];//声明一个用来合并的数组\n          mergeSort(array,tmp,0,array.length-1);//调用排序函数，传入数字的起点和终点\n      &#125;\n  &#125;\n\n\n\n快速排序\n快速排序原理：\n\n\n如果数组S中元素是0或者1，则返回；\n区数组S中任一元素v，称之为枢纽元；\n将S-{v}（S中剩余的元素）划分成连个不相交的集合：S1={S-{v}|x&lt;=v}和S2={S-{v}|x&gt;=v};\n返回{quicksort(s1)}后跟v，继而返回{quicksort(S2)}。\n\n\n\n选取枢纽元（三数中值分割法）\n\n一般的做法是使用左端、右端和中心位置上的三个元素的中值作为基元。分割策略：在分割阶段吧所有小元素移到数组的左边，大元素移到数组右边。，大小是相对于枢纽元素而言的。当i在j的左边时，将i右移，移过哪些小于枢纽元的元素，并将j左移，已过那些大于枢纽元的元素，当i和j停止时，i指向一个大元素，而j指向一个小元素，如果i在j的左边，那么将这两个元素交换，其效果是把一个大元素推向右边，而把小元素推向左边。效果如图：\n\n\n\n快速排序平均时间复杂度为O(nlogn)，最坏情况为O(n^2)，n越大，速度越快。不是稳定的排序算法。\n\n代码：\n\n    /*\n   * 快速排序\n   * 两个方向，左边的i下标一直往右走，当a[i] &lt;= a[center_index]，\n   * 其中center_index是中枢元素的数组下标，而右边的j下标一直往左走，当a[j] &gt; a[center_index]\n   * 如果i和j都走不动了，i &lt;= j, 交换a[i]和a[j],重复上面的过程，直到i&gt;j\n   * 交换a[j]和a[center_index]，完成一趟快速排序\n   * 枢轴采用三数中值分割法可以优化\n   */\n  //递归快速排序\n  public static void quickSort(int a[])&#123;\n      qSort(a, 0, a.length - 1);\n  &#125;\n  //递归排序，利用两路划分\n  public static void qSort(int a[],int low,int high)&#123;\n      int pivot = 0;\n      if(low &lt; high)&#123;\n          //将数组一分为二\n          pivot = partition(a,low,high);\n          //对第一部分进行递归排序\n          qSort(a,low,pivot);\n          //对第二部分进行递归排序\n          qSort(a,pivot + 1,high);\n      &#125;\n  &#125;\n  //partition函数，实现三数中值分割法\n  public static int partition(int a[],int low,int high)&#123;\n      int pivotkey = a[low];   //选取第一个元素为枢轴记录\n      while(low &lt; high)&#123;\n          //将比枢轴记录小的交换到低端\n          while(low &lt; high &amp;&amp; a[high] &gt;= pivotkey)&#123;\n              high--;\n          &#125;\n          //采用替换而不是交换的方式操作\n          a[low] = a[high];\n          //将比枢轴记录大的交换到高端\n          while(low &lt; high &amp;&amp; a[low] &lt;= pivotkey)&#123;\n              low++;\n          &#125;\n          a[high] = a[low];\n      &#125;\n      //枢纽所在位置赋值\n      a[low] = pivotkey;\n      //返回枢纽所在的位置\n      return low;\n  &#125;\n\n\n\n桶式排序\n桶式排序不再是一种基于比较的排序方法，它是一种比较巧妙的排序方式，但这种排序方式需要待排序的序列满足以下两个特征：待排序列所有的值处于一个可枚举的范围之类；待排序列所在的这个可枚举的范围不应该太大，否则排序开销太大。\n\n排序的具体步骤如下：\n\n(1)对于这个可枚举范围构建一个buckets数组，用于记录“落入”每个桶中元素的个数；(2)将（1）中得到的buckets数组重新进行计算，按如下公式重新计算：\n      buckets[i] = buckets[i] +buckets[i-1] (其中1&lt;=i&lt;buckets.length);\n\n\n桶式排序是一种非常优秀的排序算法，时间效率极高，它只要通过2轮遍历：第1轮遍历待排数据，统计每个待排数据“落入”各桶中的个数，第2轮遍历buckets用于重新计算buckets中元素的值，2轮遍历后就可以得到每个待排数据在有序序列中的位置，然后将各个数据项依次放入指定位置即可。\n\n桶式排序的空间开销较大，它需要两个数组，第1个buckets数组用于记录“落入”各桶中元素的个数，进而保存各元素在有序序列中的位置，第2个数组用于缓存待排数据.\n\n桶式排序是稳定的。如果待排序数据的范围在0~k之间，那么它的时间复杂度是O(k+n)的.\n\n但是它的限制多，比如它只能排整形数组。而且当k较大，而数组长度n较小，即k&gt;&gt;n时，辅助数组C[k+1]的空间消耗较大。当数组为整形，且k和n接近时, 可以用此方法排序。 \n\n代码实现：\n\n        //min的值为0，max的值为待排序数组中最大值+1\n        public static void bucketSort(int[] data, int min, int max) &#123;  \n          // 缓存数组  \n          int[] tmp = new int[data.length];  \n          // buckets用于记录待排序元素的信息  \n          // buckets数组定义了max-min个桶  \n          int[] buckets = new int[max - min];  \n          // 计算每个元素在序列出现的次数  \n          for (int i = 0; i &lt; data.length; i++) &#123;  \n              buckets[data[i] - min]++;  \n          &#125;  \n          // 计算“落入”各桶内的元素在有序序列中的位置  \n          for (int i = 1; i &lt; max - min; i++) &#123;  \n              buckets[i] = buckets[i] + buckets[i - 1];  \n          &#125;  \n          // 将data中的元素完全复制到tmp数组中  \n          System.arraycopy(data, 0, tmp, 0, data.length);  \n          // 根据buckets数组中的信息将待排序列的各元素放入相应位置  \n          for (int k = data.length - 1; k &gt;= 0; k--) &#123;  \n              data[--buckets[tmp[k] - min]] = tmp[k];  \n          &#125;  \n      &#125;  \n\n\n\n总结\n下面是一个总的表格，大致总结了我们常见的所有的排序算法的特点。\n\n排序法平均时间最差情形稳定度额外空间备注\n冒泡O(n2)  O(n2) 稳定O(1)n小时较好\n选择O(n2)  O(n2) 不稳定O(1)n小时较好\n插入O(n2)  O(n2) 稳定O(1)大部分已排序时较好\nShell(希尔)O(nlogn)O(ns) 不稳定O(1)    s是所选分组\n快速O(nlogn)  O(n2) 不稳定O(nlogn)n大时较好\n归并O(nlogn)  O(nlogn) 稳定O(1)n大时较好\n堆O(nlogn)  O(nlogn) 不稳定O(1)n大时较好\n桶式O(k+n)  O(k+n) 稳定O(1)只能排整形数组\n\n性能测试\n  \n\n\n","categories":["Java"],"tags":["算法","排序"]},{"title":"计算机网络体系与参考模型","url":"http://tanqingbo.cn/2016/03/31/计算机网络体系与参考模型/","content":"计算机网络体系与参考模型计算机网络分层结构\n计算机网络为什么要采用分层结构？\n\n分层是为了更好的管理，当网络大时，就必须采取分层，并且每一层都要实现对应的功能，这样才会更好的发展。但是分层不能太多，否则会资源浪费。\n\n\n分层的好处：\n\n易于更新，易于调试。易于交流，易于抽象。易于标准化。\n\n\n实体：任何可以发送或接受消息的硬件或者软件。通常是一个特定的软件模块。\n\n对等层：不同机器上的同一层。\n\n对等实体：同一层上的实体。\n\n\n协议\n协议是一种规则，并且控制两个对等实体的通信，协议是水平的。\n\n协议组成：\n\n语义：对构成协议元素的含义的解释，即讲什么。\n语法：数据与控制信息的结构和格式。即怎么讲。\n同步：规定事件执行的顺序。接口\n\n\n接口又被称为服务访问点，从物理层开始。每一层都向上提供服务访问点（接口），所以没有接口就不能提供服务。\n\n服务数据单元（SDU）：第n层的服务数据单元记作 n-SDU。\n协议控制信息（PCI）:第n的协议控制信息，记作 n-PIC。\n接口控制信息（ICI）:第n层的接口控制信息，记作 n-ICI。\n协议数据单元（PDU）:第n层的服务数据单元（SDU）+第n层的协议控制信息（PCI）=第n层的协议数据单元（PDU）。表示的是同等层对等实体间传送的数据单元。接口数据单元（IDU）：第n层的服务数据单元（SDU）+第n层的接口控制信息(ICI)=第n层的接口数据单元（IDU）。表示的是在相邻层接口之间传送的数据单元。服务\n\n\n服务指下层为相邻上层提供的功能调用。协议是水平的，而服务是垂直的。即下层向上层通过接口提供服务。\n\n服务分3类：\n\n.面向连接的服务和面向无连接的服务：\n面向连接的服务：当通信双方通信时，要事先建立一条通信线路，该通信线路包括建立连接，使用连接、释放连接三个过程。（TCP协议）\n\n\n\n\n面向无连接的服务：通信双方不需要事先建立通信线路，而是把每个带有目的地址的包传送到线路上，由系统选择线路进行传输，（IP协议、UDP协议）\n\n\n\n面向连接的服务与面向无连接的服务对照：2.有应答服务与无应答服务：\n\n有应答服务：指接收方在收到数据后向发送方给出相应的应答。无应答服务：指接收方在收到数据后不自动给出应答。\n\n3.可靠服务与不可靠服务：\n\n可靠服务：指网络具有检错，纠错，应答机制。能保证数据正确。可靠地传送到达目的地。不可靠服务：指网络不能保证数据正确、可靠地传送到达目的地，网络只能尽量正确，可靠，是一种“尽力而为”的服务.\n\niso/osi参考模型和TCP/IP参考模型：\n五层结构的总结：\nOSI参考模型具有7层结构，而TCP/IP参考模型只有4层结构（一般看成5层结构）。在OSI参考模型中表示层和会话层不是重点，只需掌握5层结构。\n\n\n\n5层结构参考模型各层的总结如下表：\n\nOSI参考模型和TCP/IP参考模型的区别：\n\n会话层与表示层的基本功能：\n\n会话层：在两个结点之间建立，维护和释放面向用户的连接，并对会话进行管理控制，保证会话数据可靠传送。表示层：负责处理在两个内部数据表示结构不同的通信系统交换信息的表示格式。为数据加密解密以及提高数据的传输速率提供必要的数据压缩和解压等功能。\n\n\n\n计算机网络的性能指标\n.时延：指数据从网络或链路的一端传送到另外一端所需要的时间。（也称延迟或迟延）\n(1)发送时延（传输时延）：主机或路由器发送数据帧所需要的时间，即从发送数据帧的第一位算起到该帧的最后一位发送完毕所需要的时间，因此。发送时延也被称为传输时延。公式为：\n                  发送时延=数据帧长度（bit）/发送速率（bit/s)\n\n\n\n\n(2)传播时延：是指电磁波在信道通信中传播一定距离所需要的时间。公式为：\n  传播时延=信道长度（m）/电磁波在信道上传播的速度（m/s）\n\n\n(3)处理时延：是指主机或路由器在接收到分组时进行处理所需要的时间。\n\n\n(4)排队时延： 分组在进行网络传输时，要经过许多的路由器，但分组在进入路由器后要先在输入队列中排队等待处理，在路由器确定了转发接口后，还需要在输出队列中排队等待转发，这就产生了排队时延。\n\n     总时延=发送时延+传播时延+处理时延+排队时延\n2.时延带宽积：时延带宽积又称为以比特为单位的链路长度。        时延带宽积=传布时延  x  带宽\n3..往返时间：从发送方发送数据开始，到发送方收到来自接收方的确认消息总共经历的时间。4.利用率：包括信道利用率和网络利用率两种；\n\n信道利用率：指某个信道有百分之几的时间是被利用的（有数据通过），完全空闲时利用率为0.网络利用率：是指全网络的信道利用率的加权平均值，注意：不是信道利用率与网络利用率越高越好。因为利用率越高，会导致数据在路由器中转发延时越长。\n\n","categories":["网络原理"],"tags":["网络"]},{"title":"归并排序的原理及时间复杂度","url":"http://tanqingbo.cn/2016/03/30/归并排序的原理及时间复杂度/","content":"归并排序的原理及时间复杂度\n归并排序的定义：\n\n归并排序算法采用的是分治算法,即先把要排序的数组分成两个(或两个以上)有序表，然后再合并成一个新的有序表,即把待排序的序列分成若干个子序列,每个子序列都是有序的,然后把有序子序列合并成整体有序序列,这个过程也称为2-路归并.注意:归并排序的一种稳定排序,即相等元素的顺序不会改变.\n\n\n归并排序的原理\n\n将待排序的数组分成前后两个部分，再递归的将前半部分数据和后半部分的数据各自归并排序，得到的两部分数据，然后使用merge合并算法（算法见代码）将两部分算法合并到一起。例如：如果N=1；那么只有一个数据要排序，N=2，只需要调用merge函数将前后合并，N=4，………..  也就是将一个很多数据的数组分成前后两部分，然后不断递归归并排序，再合并，最后返回有序的数组。\n\n\n归并排序的时间复杂度\n\n归并排序的最好、最坏和平均时间复杂度都是O(nlogn)，而空间复杂度是O(n)，比较次数介于(nlogn)/2和(nlogn)-n+1，赋值操作的次数是(2nlogn)。因此可以看出，归并排序算法比较占用内存，但却是效率高且稳定的排序算法。\n\n\n代码：\n\n    public class MergeSort &#123;\n      private static void mergeSort(int[] array,int[] tmp,int left,int right)&#123;\n          if(left&lt;right)&#123;\n              int center = ( left + right ) / 2;//取数组的中点\n              mergeSort(array,tmp,left,center);//归并排序数组的前半部分\n              mergeSort(array,tmp,center+1,right);//归并排序数组的后半部分\n              merge(array,tmp,left,center+1,right);//将数组的前后半部分合并\n          &#125;\n      &#125;\n      /*\n       * 超简单的合并函数\n       */\n      private static void merge(int[] array, int[] tmp, int leftPos, int rightPos, int rightEnd) &#123;\n          // TODO Auto-generated method stub\n          int leftEnd = rightPos - 1;\n          int tmpPos = leftPos;\n          int numElements = rightEnd - leftPos + 1;\n          while(leftPos &lt;= leftEnd &amp;&amp; rightPos &lt;= rightEnd)&#123;\n              if(array[leftPos]&lt;=array[rightPos])&#123;\n                  tmp[tmpPos++] = array[leftPos++];\n              &#125;else&#123;\n                  tmp[tmpPos++] = array[rightPos++];\n              &#125;\n          &#125;\n          while(leftPos &lt;= leftEnd)&#123;\n              tmp[tmpPos++] = array[leftPos++];\n          &#125;\n          while(rightPos &lt;= rightEnd)&#123;\n              tmp[tmpPos++] = array[rightPos++];\n          &#125;\n          for(int i=0;i&lt;numElements;i++,rightEnd--)&#123;\n              array[rightEnd] = tmp[rightEnd];\n          &#125;\n      &#125;\n      public static void mergeSort(int[] array)&#123;\n          int[] tmp = new int[array.length];//声明一个用来合并的数组\n          mergeSort(array,tmp,0,array.length-1);//调用排序函数，传入数字的起点和终点\n      &#125;\n  &#125;\n\n\n\n","categories":["Java"],"tags":["算法","排序"]},{"title":"Mysql数据库","url":"http://tanqingbo.cn/2016/03/27/Mysql数据库/","content":"Mysql数据库mysql数据库优化\n\n利用LIMIT 1取得唯一行,这样数据库引擎发现只有1后将停止扫描，而不是去扫描整个表或索引。\n保证连接的索引是相同的类型\n不要使用BY RAND()命令,MySQL可能会为表中每一个独立的行执行BY RAND()命令（这会消耗处理器的处理能力），然后给你仅仅返回一行。\n尽量避免SELECT *命令:从表中读取越多的数据，查询会变得更慢。\n准备好的sql语句\n视情况确定存储类型\n永远为每张表设置一个ID\n使用ENUM而不是VARCHAR，ENUM类型是非常快和紧凑的。\n无缓冲的查询\n固定长度的表会更快,表中没有如下类型的字段： VARCHAR，TEXT，BLOB,则为固定长度的表\n垂直分割，垂直分割是一种把数据库中的表按列变成几张表的方法，这样可以降低表的复杂度和字段的数目，从而达到优化的目的。\n\n\nMySQL数据引擎\nInnoDB和MyISAM是在使用MySQL最常用的两个表类型，各有优缺点，视具体应用而定。\n\n基本差别：\n\nMyISAM类型不支持事务处理等高级处理，而InnoDB类型支持。MyISAM类型的表强调的是性能，其执行数度比InnoDB类型更快，但是不提供事务支持，而InnoDB提供事务支持以及外部键等高级数据库功能。\n\n\nMyIASM是IASM表的新版本，有如下扩展：\n      二进制层次的可移植性。 \n      NULL列索引。 \n      对变长行比ISAM表有更少的碎片。 \n      支持大文件。\n      更好的索引压缩。\n      更好的键吗统计分布。\n      更好和更快的auto_increment处理。\n\n\nSQL注入攻击\n程序员在编写代码的时候，没有对用户输入数据的合法性进行判断，使应用程序存在安全隐患。用户可以提交一段数据库查询代码，根据程序返回的结果，获得某些他想得知的数据，这就是所谓的SQL Injection，即SQL注入。\n\n例子：\n      某个网站的登录验证的SQL查询代码为：\n      1\n      strSQL = &quot;SELECT * FROM users WHERE (name = &#39;&quot; + userName + &quot;&#39;)\n       and (pw = &#39;&quot;+ passWord +&quot;&#39;);&quot; \n      恶意填入\n      1\n      userName = &quot;1&#39; OR &#39;1&#39;=&#39;1&quot;;\n      与\n      1\n      passWord = &quot;1&#39; OR &#39;1&#39;=&#39;1&quot;;\n      时，将导致原本的SQL字符串被填为\n      1\n      strSQL = &quot;SELECT * FROM users WHERE (name = &#39;1&#39; OR &#39;1&#39;=&#39;1&#39;) and\n       (pw = &#39;1&#39; OR &#39;1&#39;=&#39;1&#39;);&quot;\n      也就是实际上运行的SQL命令会变成下面这样的\n      1\n      strSQL = &quot;SELECT * FROM users;&quot;\n      因此达到无账号密码，亦可登录网站。所以SQL注入攻击被俗称为黑客的填空游戏。\n\n应对办法(数据库防火墙,虚拟补丁技术)\n\n从安全技术手段上来说，可以通过数据库防火墙实现对SQL注入攻击的防范，因为SQL注入攻击往往是通过应用程序来进攻，可以使用虚拟补丁技术实现对注入攻击的SQL特征识别，实现实时攻击阻断。\n\n\n\n","categories":["Java"],"tags":["数据库","MYSQL"]},{"title":"Web 服务器错误代码","url":"http://tanqingbo.cn/2016/03/27/Web 服务器错误代码/","content":"Web 服务器错误代码1xx(临时响应)： 表示临时响应并需要请求者继续执行操作的状态码。\n100(继续)请求者应当继续提出请求。服务器返回此代码表示已收到请求的第一部分，正在等待其余部分。\n101(切换协议)请求者已要求服务器切换协议，服务器已确认并准备切换。2xx (成功)：表示成功处理了请求的状态码。\n200(成功)服务器已成功处理了请求。通常，这表示服务器提供了请求的网页。如果是对您的 robots.txt 文件显示此状态码，则表示 Googlebot 已成功检索到该文件。\n201(已创建)请求成功并且服务器创建了新的资源。\n201(已创建)请求成功并且服务器创建了新的资源。\n202(已接受)服务器已接受请求，但尚未处理。\n203(非授权信息)服务器已成功处理了请求，但返回的信息可能来自另一来源。\n204(无内容)服务器成功处理了请求，但没有返回任何内容。\n205(重置内容)服务器成功处理了请求，但没有返回任何内容。与 204 响应不同，此响应要求请求者重置文档视图(例如，清除表单内容以输入新内容)。\n206(部分内容)服务器成功处理了部分 GET 请求。4xx(请求错误)： 这些状态码表示请求可能出错，妨碍了服务器的处理。\n400(错误请求)服务器不理解请求的语法。\n401(未授权)请求要求身份验证。对于登录后请求的网页，服务器可能返回此响应。\n403(禁止)服务器拒绝请求。\n404(未找到)服务器找不到请求的网页。例如，对于服务器上不存在的网页经常会返回此代码。\n405(方法禁用)禁用请求中指定的方法。\n406(不接受)无法使用请求的内容特性响应请求的网页。\n407(需要代理授权)此状态码与 401(未授权)类似，但指定请求者应当授权使用代理。如果服务器返回此响应，还表示请求者应当使用代理。\n408(请求超时)服务器等候请求时发生超时。\n409(冲突)服务器在完成请求时发生冲突。服务器必须在响应中包含有关冲突的信息。服务器在响应与前一个请求相冲突的 PUT 请求时可能会返回此代码，以及两个请求的差异列表。\n410(已删除)如果请求的资源已永久删除，服务器就会返回此响应。\n411(需要有效长度)服务器不接受不含有效内容长度标头字段的请求。\n412(未满足前提条件)服务器未满足请求者在请求中设置的其中一个前提条件。\n413(请求实体过大)服务器无法处理请求，因为请求实体过大，超出服务器的处理能力。\n414(请求的 URI 过长)请求的 URI(通常为网址)过长，服务器无法处理。\n415(不支持的媒体类型)请求的格式不受请求页面的支持。\n416(请求范围不符合要求)如果页面无法提供请求的范围，则服务器会返回此状态码。 \n417(未满足期望值)服务器未满足”期望”请求标头字段的要求。5xx(服务器错误)：这些状态码表示服务器在处理请求时发生内部错误。这些错误可能是服务器本身的错误，而不是请求出错。\n500(服务器内部错误)服务器遇到错误，无法完成请求。\n501(尚未实施)服务器不具备完成请求的功能。例如，服务器无法识别请求方法时可能会返回此代码。\n502(错误网关)服务器作为网关或代理，从上游服务器收到无效响应。\n503(服务不可用)服务器目前无法使用(由于超载或停机维护)。通常，这只是暂时状态。\n504(网关超时)服务器作为网关或代理，但是没有及时从上游服务器收到请求。\n505(HTTP 版本不受支持)服务器不支持请求中所用的 HTTP 协议版本。\n\n","categories":["Java"],"tags":["web"]},{"title":"Spring整合hibernate和Struts","url":"http://tanqingbo.cn/2016/03/27/Spring整合hibernate和Struts/","content":"Spring整合hibernate整合hibernate的思想\ndao\nservice:控制事务整合的步骤\n\n\n加入Spring的支持\n\n加入hibernate的支持，最好是将hibernate的配置信息放在applicationContext.xml中\n\n如果使用的是myeclipse2014，生成的数据源中缺少driverClassName的配置，自己加上即可\n\n在配置文件中，生成了四个bean，分别是：数据库连接池 　　 Session工厂  　　 定义事物管理器对象   　　　 使用事物驱动的Annotation注解\n\n注：在数据库连接池的数据库连接字符串后面记得加上字符转码\n   &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/test?characterEncoding=utf-8&quot;&gt;&lt;/property&gt;\n\n\n编写PO，HBM及DAO；如果使用生成的DAO，将@TRANSACTION去掉，不要在DAO中控制事务\n\n编写Service接口，在接口中控制事务，可以在接口或接口的方法中增加@Transtraction\n\n编写service实现类；在service实现类中注入dao；\n事务：transaction\n\n\n事务是用户自定义的一个操作序列，是一个最小的执行单元，不能再分自定义Dao(推荐使用的方法)\nBaseDao：所有Dao中实现的方法，是个接口\nBaseDaoImpl：具体实现\nXXXDaoImp：具体实体类的dao；整合struts2\n\n\n在web.xml中增加一个监听器，这个监听器再启动工程时加载applicationContext.xml配置文件;\n并将此BeanFactory存储到Application作用于对象中；\n增加一个struts-spring-plugin.jar的插件；\n在struts.xml配置文件中配置action时，class属性的值应该是由spring创建的Action实例解决hibernate的懒加载\n\n\n将lazy改成false:每次代码执行时，自动将数据库所有数据加载到对象，不管需不需要使用，效率慢。\n可以采用迫切左外连语句\n延迟session的关闭时间（jsp显示完毕后才关闭）\n通过OpenSessionInView的过滤器来实现,在web.xml中配置，配置时，应该放在第一个Filter的位置上；\n      &lt;filter&gt;\n          &lt;filter-name&gt;openSession&lt;/filter-name&gt;\n     &lt;filter-class&gt;org.springframework.orm.hibernate4.support.OpenSessionInViewFilter&lt;/filter-class&gt;\n      &lt;/filter&gt;\n      &lt;filter-mapping&gt;\n          &lt;filter-name&gt;openSession&lt;/filter-name&gt;\n          &lt;url-pattern&gt;/*&lt;/url-pattern&gt;\n      &lt;/filter-mapping&gt;\n\n\n\n分页实现\n      1.sql语句；\n            查询当前页的数据库的分页sql;在hibernate中可以使用setMaxResult,setFristResult两个方法来进行设置；\n            查询总记录数；\n        //分页\n        @Override\n        public void getAll(Class&lt;T&gt; clazz, PageInfo info) &#123;\n            //设置总记录数\n            info.setRecordCount(this.getCount(clazz));\n            //设置总页数\n            info.setPageCount( info.getRecordCount()%info.getPageSize()==0 ? \n            info.getRecordCount()/info.getPageSize() : info.getRecordCount()/info.getPageSize()+1 );\n            Criteria c =  this.getSession().createCriteria(clazz);\n            //每页的记录数\n            c.setMaxResults(info.getPageSize());\n            c.setFirstResult((info.getCurrentPage()-1)*info.getPageSize());\n            //查询，并将查询结果赋给info\n            info.setList(c.list());\n        &#125;\n        2.封装分页信息；\n            PageInfo;\n                action;总记录数，总页数；当前页号，当页的数据；等\n        3.将页面封装起来；\n            @include\n            @自定义标记；\n        eg:&lt;%@ include file=&quot;subPage.jsp&quot; %&gt;\n\n实例代码下载","categories":["Java"],"tags":["Java","Sping","框架","hibernate","Struts"]},{"title":"深入理解List、Set与Map","url":"http://tanqingbo.cn/2016/03/27/Set与Map/","content":"List、Set与Map\nList 、Set、 Map有什么区别和联系\nlist 和set 有共同的父类 它们的用法也是一样的 唯一的不太就是set中不能有相同的元素 list中可以\nlist和set的用途非常广泛 list可以完全代替数组来使用\nmap 是独立的合集 它使用键值对的方式来储存数据 键不能有重复的 值可以用 \nmap不像上边两种集合那个用的广泛 不过在servlet 和jsp中 map可是绝对的重中之重 页面之间传值全靠map\n\n\n\n\nList 、Set、 Map都有哪些子类\n      Collection\n      ├List\n      │├LinkedList\n      │├ArrayList\n      │└Vector\n      │　└Stack\n      └Set\n       |-HashSet\n       └TreeSet        \n      Map\n      ├Hashtable\n      ├HashMap\n      └WeakHashMap\n\n注意：Map没有继承Collection接口，Map提供key到value的映射。\n\n\nList\nLinkedList类\nLinkedList实现了List接口，允许null元素。此外LinkedList提供额外的get，remove，insert方法在 LinkedList的首部或尾部。这些操作使LinkedList可被用作堆栈（stack），队列（queue）或双向队列（deque）。\n注意LinkedList没有同步方法。如果多个线程同时访问一个List，则必须自己实现访问同步。一种解决方法是在创建List时构造一个同步的List：\n\n\n\n　　    　            　List list = Collections.synchronizedList(new LinkedList(…));\n+ 特点：寻址困难，插入和删除容易。\n\nArrayList类\n\nArrayList实现了可变大小的数组。它允许所有元素，包括null。ArrayList没有同步。\nsize，isEmpty，get，set方法运行时间为常数。但是add方法开销为分摊的常数，添加n个元素需要O(n)的时间。其他的方法运行时间为线性。\n每个ArrayList实例都有一个容量（Capacity），即用于存储元素的数组的大小。这个容量可随着不断添加新元素而自动增加，但是增长算法并 没有定义。当需要插入大量元素时，在插入前可以调用ensureCapacity方法来增加ArrayList的容量以提高插入效率。\n和LinkedList一样，ArrayList也是非同步的（unsynchronized）。\n特点是：寻址容易，插入和删除困难；\n\n\nVector类\n\nVector非常类似ArrayList，但是Vector是同步的。由Vector创建的Iterator，虽然和ArrayList创建的 Iterator是同一接口，但是，因为Vector是同步的，当一个Iterator被创建而且正在被使用，另一个线程改变了Vector的状态（例 如，添加或删除了一些元素），这时调用Iterator的方法时将抛出ConcurrentModificationException，因此必须捕获该 异常。\n\n\nStack 类\n\nStack继承自Vector，实现一个后进先出的堆栈。Stack提供5个额外的方法使得 Vector得以被当作堆栈使用。基本的push和pop 方法，还有peek方法得到栈顶的元素，empty方法测试堆栈是否为空，search方法检测一个元素在堆栈中的位置。Stack刚创建后是空栈。\n\n\n\nSet\nHashSet类\n\n它不允许出现重复元素；\n不保证集合中元素的顺序\n允许包含值为null的元素，但最多只能有一个null元素。\nHashSet的实现是不同步的。\n\n\nTreeSet类\n\nreeSet类实现 Set 接口，该接口由 TreeMap 实例支持。此类保证排序后的 set 按照升序排列元素，根据使用的构造方法不同，可能会按照元素的自然顺序 进行排序，或按照在创建 set 时所提供的比较器进行排序。\n\nTreeSet描述的是Set的一种变体——可以实现排序等功能的集合，它在讲对象元素添加到集合中时会自动按照某种比较规则将其插入到有序的对象序列中.\n\n\nHashSet是基于Hash算法实现的,其性能通常优于TreeSet,我们通常都应该使用HashSet,在我们需要排序的功能时,我门才使用TreeSet;\n\n\n\n\nMap接口\nHashtable类\n\nHashtable继承Map接口，实现一个key-value映射的哈希表。任何非空（non-null）的对象都可作为key或者value。　　添加数据使用put(key, value)，取出数据使用get(key)，这两个基本操作的时间开销为常数。\n\nHashtable 通过initial capacity和load factor两个参数调整性能。通常缺省的load factor 0.75较好地实现了时间和空间的均衡。增大load factor可以节省空间但相应的查找时间将增大，这会影响像get和put这样的操作。\n\n作为key的对象将通过计算其散列函数来确定与之对应的value的位置，因此任何作为key的对象都必须实现hashCode和equals方法。\n\n　Hashtable是同步的。\n\n\n\nHashMap类\n\nHashMap和Hashtable类似，不同之处在于HashMap是非同步的，并且允许null，即null value和null key。其迭代子操作时间开销和HashMap 的容量成比例,因此，不要将HashMap的初始化容量设得过高，或者load factor过低。\n\n\nWeakHashMap类\n\nWeakHashMap是一种改进的HashMap，它对key实行“弱引用”，如果一个key不再被外部所引用，那么该key可以被GC回收。\n\n\nhashmap遍历的两种方式\n\nHashMap的遍历有两种常用的方法，那就是使用keyset及entryset来进行遍历\n\n方法一：\nMap map = new HashMap();　　Iterator iter = map.entrySet().iterator();　　while (iter.hasNext()) {　　Map.Entry entry = (Map.Entry) iter.next();　　Object key = entry.getKey();　　Object val = entry.getValue();　　}\n\n效率高,以后尽量要使用此种方式！\n\n方法二：\n     Map map = new HashMap();\n  　　Iterator iter = map.keySet().iterator();\n  　　while (iter.hasNext()) &#123;\n  　　Object key = iter.next();\n  　　Object val = map.get(key);\n  　　&#125;\n\n效率低,以后尽量少使用！\n\n\n\nHashMap的数据结构\n\nHashMap里面实现一个静态内部类Entry，其重要的属性有 key , value, next.数据\n\nvalue的值是元素的key的哈希值对数组长度取模得到。如下面第二幅图中，12%16=12,28%16=12,108%16=12,140%16=12。所以12、28、108以及140都存储在数组下标为12的位置。\n\n结构如图所示：\n\n\n\n\nHashMap的存取实现\n     // 存储时:\n      int hash = key.hashCode(); // 这个hashCode方法这里不详述,只要理解每个key的hash是一个固定的int值\n      int index = hash % Entry[].length;\n      Entry[index] = value;    &lt;br/&gt;        \n      // 取值时:\n      int hash = key.hashCode();\n      int index = hash % Entry[].length;\n      return Entry[index];\n\n解决hash冲突的办法\n\n开放定址法（线性探测再散列，二次探测再散列，伪随机探测再散列）再哈希法链地址法建立一个公共溢出区Java中hashmap的解决办法就是采用的链地址法。\n\n\n再散列rehash过程\n\n当哈希表的容量超过默认容量时，必须调整table的大小。当容量已经达到最大可能值时，那么该方法就将容量调整到Integer.MAX_VALUE返回，这时，需要创建一张新表，将原表的映射到新表中。\n\n\n\n","categories":["Java"],"tags":["Java","数据结构"]},{"title":"Java面试基础(三)","url":"http://tanqingbo.cn/2016/03/25/Java面试基础（三）/","content":"Java面试基础（三）多态：\n同一个对象，在程序不同时刻的多种运行状态。举例：动物，狗是狗，狗是动物。水(气态，液态，固态)\n\n多态前提\n\nA:存在着继承或者实现关系B:有方法的重写C:父类(接口)引用指向子类(实现)对象\n\n\n多态的好处和弊端：\n\n好处：多态的存在提高了程序的扩展性和后期可维护性弊端：虽然可以预先使用，但是只能访问父类中已有的功能，运行的是后期子类的功能内容。不能预先使用子类中定义的特有功能。\n\n\n多态中对象调用成员的特点\n\nFu f = new Zi();\nA:成员变量编译看左边，运行看左边B:成员方法编译看左边，运行看右边C:静态方法编译看左边，运行看左边\n\n\n多态的思想\n\n指挥同一批对象做事情。举例：带兵打仗，下课等。\n\n\ninstanceof关键字\n\nA:用于判断某个对象是否是某种类型。B:格式对象名 instanceof 子类(实现)名\n\n\nObject类：\n\n(1)是所有类的根类，超类。java中提供的类以及我们自定义的类都直接或者间接的继承自Object类。(2)Object类中的方法A:void finalize()当垃圾回收器确定不存在对该对象的更多引用时，由对象的垃圾回收器调用此方法。B:Class getClass()获取对象的字节码文件的描述类，后面再讲反射的时候还会在说这个类。String name = s.getClass().getName();C:int hashCode()获取对象的哈希值。其实就是对象的内存地址值十进制表示D:String toString()返回对象的字符串表示。表示格式：getClass().getName()+”@”+Integer.toHexString(hashCode());一般我们输出对象名的时候，其实底层调用的就是该对象的toString()方法。这种返回没有意义，所以，我们会重写这个方法，显示类的成员变量信息。E:boolean equals(Object obj)用于比较两个对象的地址值是否相同。我们获取对象后，比较它的地址值意义不大。所以也会对这个方法进行重写。重写要完成什么功能，是根据需求定的。(3)==和equals的用法：A:==怎么用？可以用于比较基本数据类型，比较的就是基本数据类型的值是否相等。可以用于比较引用数据类型，比较的是对象的地址值是否相等。B:equals怎么用？equals只能用于比较引用数据类型的。Object提供的equals是用于比较对象地址值是否相同。自定义类中，如果重写了equals方法，那么就是按照你自己的需求来比较的。\n\n\npackage关键字\n\n(1)包：其实就是文件夹。用于区分不同包下相同的类名。(2)好处：A：对类文件进行分类管理。B：给类提供了多层命名空间aaa.Demobbb.DemoC：写在程序文件的第一行。D：包也是一种封装形式。\n\n\nimport关键字(1)导入包的关键字(2)格式：import 包名;(3)注意：A:一个程序文件中只有一个package，可以有多个import。B:用来导包中的类，不导入包中的包。C:通常写import  mypack.Demo，明确自己使用的类。 \n\n关键字的顺序\n\n类，包，导包这些关键的顺序。包 – &gt;  导包 – &gt; 类\n\n\n不同修饰符的访问权限\n\n      　      本类中       同一个包中       不同包中的子类中        不同包中\nprivate       OK\n默认          OK             Ok\nprotected    OK             Ok                  OK\npublic       OK             Ok                  OK              OK\n\n\n不同修饰符可以修饰哪些内容\n\n                 类            构造方法          成员变量              成员方法\n  private (能修饰内部类)        OK              OK                   OK\n  默认         Ok              Ok              Ok                   OK\n  protected(能修饰内部类)       OK              OK                   Ok\n  public       Ok             Ok              OK                   OK\n  static                                      OK                   Ok\n  final        Ok                             OK                   OK\n  abstract     Ok                                                  OK\n\n\n一般格式：\n\n成员变量：权限修饰符+static/final+数据类型+成员变量名public static final int NUM = 10;成员方法：权限修饰符+static/final/abstract+返回类型+方法名\n\n\n内部类(次重点)\n\n(1)把一个类定义在某个类中的，这个类就被称为内部类，内置类，嵌套类。(2)访问特点：A:内部类可以直接访问外部类中的成员，因为内部类持有外部类的引用，格式为：外部类名.thisB:外部类要想访问内部类的成员，必须创建对象访问。(3)内部类的访问格式：A:当内部类定义在外部类的成员位置，而且非私有，则可以在其他外部类中直接建立内部类对象格式：外部类名.内部类名  变量名 = new 外部类对象.内部类对象如：Outer.Inner in = new Outer().new Inner()B:当内部类在外部类成员位置，且被static修饰时外部其他类可直接访问静态内部类的非静态成员格式：new 外部类名.内部类名().内部类成员如：new Outer.Inner().function();外部其他类可直接访问静态内部类的静态成员格式：new 外部类名.内部类名.内部类成员如：new Outer.Inner.function();(4)什么使用时候内部类呢？假如有A类和B类，A类想直接访问B类的成员，B类访问A类成员的时候，需要创建A类对象进行访问，这个时候，就可以把A类定义为B类的内部类。(5)内部类的位置A:成员位置可以被private修饰(Body，Heart)可以被static修饰。(它访问的外部类的成员必须是静态的)B:局部位置可以直接访问外部类中的成员，因为还持有外部类的持用也可以直接访问局部成员，但是局部成员要用final修饰。注意：局部内部类不能用private和static修饰(6)通过class文件我们就可以区分是否带有内部类，以及内部类的位置Outer$Inner:成员内部类Outer$1Inner:局部内部类\n\n\n匿名内部类(局部内部类的简写) (重点)\n\n(1)前提：继承一个类或者实现一个接口(注意不要弄混匿名内部类的前提和多态的前提)(2)格式：\n       new 父类名或者接口名()\n       &#123;\n        重写父类方法或者实现接口中的方法。\n        也可以自定义其他方法。\n       &#125;;\n(3)什么时候定义匿名内部类？匿名内部类只是为了简化书写，匿名内部类有局限，通常定义匿名内部类时，该类方法不超过3个(4)匿名内部类的好处和弊端：好处：简化代码书写弊端：不能直接调用自己的特有方法不能执行强转换动作如果该类里面方法较多，不允许使用匿名内部类\n\n\n模板设计模式：\n\n在定义功能时，功能的一部分是确定的，有一部分是不确定的，而且确定的部分在使用不确定的部分，可将不确定的部分暴露出去，由该类的子类去完成。如：求一段程序的运行时间例子。\n\n\n异常\n\n(1)程序运行过程中的不正常现象就叫异常。(2)导致程序运行不正常的现象有很多，所以，就有很多的异常对象。而这些异常对象存在着共性的内容，所以，可以不断的进行抽取。最终形成了异常的体系结构。异常体系的根类是:Throwable   Throwable：\n|--Error:重大的问题，我们处理不了。也不需要编写代码处理。比如说内存溢出。\n|--Exception:一般性的错误，是需要我们编写代码进行处理的。\n|--RuntimeException:运行时异常，这个我们也不需要处理。\n   其实就是为了让他在运行时出问题，然后我们回来修改代码。\n(3)异常的分类异常有两种：编译时被检测异常：该异常在编译时，如果没有处理(没有抛也没有try)，编译失败。该异常被标识，代表这可以被处理。运行时异常(编译时不检测)在编译时，不需要处理，编译器不检查。该异常的发生，建议不处理，让程序停止。需要对代码进行修正。(4)异常体系的特点：异常体系中的所有类及其子类对象都具备可抛性。也就是说可以被throw和throws关键字所操作。(5)main方法是如何处理异常的。A:在main里面编写代码进行处理B:交给jvm自己进行处理。采用的是jvm的默认处理方式。其实就是相当于调用了异常对象的printStackTrace()方法。(6)Throwable类的学习getMessage():获取异常信息，返回字符串。toString():获取异常类名和异常信息，返回字符串。printStackTrace():获取异常类名和异常信息，以及异常出现在程序中的位置。返回值void。(7)异常的处理·\n      A:try...catch...finally\n基本格式：\n      try\n      &#123;\n      可能出现异常的代码\n      &#125;\n      catch(异常对象)\n      &#123;\n      异常处理代码\n      &#125;\n      finally\n      &#123;\n      释放资源\n      &#125;\n变形格式：\n      try...catch\n      try...catch...catch...\n      try...catch...catch...finally\n多个异常同时被捕获的时候，记住一个原则：先逮小的，再逮大的。finally:永远被执行，除非退出jvm。System.exit(0);\n\n\n面试题2个。\n\nfinal,finally,finalize区别。final是最终的意思。它可以用于修饰类，成员变量，成员方法。它修饰的类不能被继承，它修饰的变量时常量，它修饰的方法不能被重写。finally:是异常处理里面的关键字。它其中的代码永远被执行。特殊情况：在执行它之前jvm退出。System.exit(0);finalize:是Object类中的一个方法。它是于垃圾回收器调用的方式。\n\n\n\n\n：假如catch中有return语句， finally里中的代码会执行吗？  是在return前，还是在return后呢？  会，在return前执行finally里面的代码。(8)Exception和RuntimeException的区别A:Exception:一般性的错误，是需要我们编写代码进行处理的。B:RuntimeException:运行时异常，这个我们也不需要处理。  其实就是为了让他在运行时出问题，然后我们回来修改代码。在用throws抛出一个的时候，如果这个异常是属于RuntimeException的体系的时候，我们在调用的地方可以不用处理。(RuntimeException和RuntimeException的子类)在用throws抛出一个的时候，如果这个异常是属于Exception的体系的时候，我们在调用的地方必须进行处理或者继续抛出。\n\n\n自定义异常\n定义类继承Exception或者RuntimeException\n\n\n\n\n为了让该自定义类具备可抛性。\n让该类具备操作异常的共性方法。     class MyExcepiton extends Exception  &#123;   \n          MyExcepiton()&#123;&#125;   \n          MyExcepiton(String message)  \n         &#123;    super(message);    &#125; \n     &#125; \n     class MyException extends RuntimeException  &#123;\n         MyExcepiton()&#123;&#125;  \n       MyExcepiton(String message) \n        &#123;    super(message);    &#125; \n      &#125;\n\n\n\nthrows和throw的区别\nA：有throws的时候可以没有throw。有throw的时候，如果throw抛的异常是Exception体系，那么必须有throws在方法上声明。B：throws用于方法的声明上，其后跟的是异常类名，后面可以跟多个异常类，之间用逗号隔开throw用于方法体中，其后跟的是一个异常对象名\n\n\n\n","categories":["Java"],"tags":["Java","面试"]},{"title":"Java面试基础(二)","url":"http://tanqingbo.cn/2016/03/25/Java面试基础（二）/","content":"Java面试基础（二）+ 单例设计模式：(1)设计模式：解决某类问题行之有效的方法，是一种思想，是规律的总结(2)用来保证某个类在内存中只有一个对象(3)保证唯一性的思想及步骤:\n\n为了避免其他程序建立该类对象，先禁止其他程序建立该类对象，即将构造函数私有化\n为了其他程序访问到该类对象，须在本类中创建一个该类私有对象\n为了方便其他程序访问到该类对象，可对外提供一个公共访问方式。比如API中的Runtime类就是单例设计模式。\n\n\n单例设计模式的两种方式A:饿汉式 当类加载的时候，就创建对象。\n  class Student\n  &#123;\n      private Student()&#123;&#125;\n\n      private static final Student s = new Student();\n\n      public static Student getInstance()\n      &#123;\n          return s;\n      &#125;\n  &#125;\nB:懒汉式 当使用的使用，才去创建对象。\n     class Student\n  &#123;\n      private Student()&#123;&#125;\n      private static final Student s = null;    \n      public static Student getInstance()\n      &#123;\n          if(s==null) \n          &#123;\n              //线程1就进来了，线程2就进来了。\n              s = new Student();\n          &#125;\n          return s;\n      &#125;\n  &#125;\n\n饿汉式和懒汉式的区别：\n\n饿汉式是类一加载进内存就创建好了对象；\n懒汉式则是类才加载进内存的时候，对象还没有存在，只有调用了getInstance()方法时，对象才开始创建。\n懒汉式是延迟加载，如果多个线程同时操作懒汉式时就有可能出现线程安全问题，解决线程安全问题,可以加同步来解决。但是加了同步之后，每一次都要比较锁，效率就变慢了，所以可以加双重判断来提高程序效率。\n注：开发常用饿汉式，因为饿汉式简单安全。懒汉式多线程的时候容易发生问题\n\n\n\nMath类的使用(重点)\n**数学操作类:**该类没有构造函数，方法均为静态的\n\n成员变量：\n\nE：比任何其他值都更接近e（即自然对数的底数）的double值。\nPI：比任何其他值都更接近pi（即圆的周长与直径之比）的double值。\n\n\n成员方法：\n         static double abs(double a) \n\n返回 double 值的绝对值。返回绝对值 static double ceil(double a)\n\n返回最小的（最接近负无穷大）double 值，该值大于等于参数，并等于某个整数。\n static double floor(double a) \n\n返回最大的（最接近正无穷大）double 值，该值小于等于参数，并等于某个整数。 \n   max：返回两个值中较大的那个   min：返回两个值中较小的那个   static long round(double a) 返回最接近参数的 long。   static int round(float a) 返回最接近参数的 int。 \n     static double random() \n  返回带正号的 double 值，该值大于等于 0.0 且小于 1.0 static double pow(double a, double b)  返回第一个参数的第二个参数次幂的值 static double sqrt(double a)  返回正确舍入的 double 值的正平方根\n\n\n\nRandom类的使用(重点)\n\n产生随机数的类\n\n构造方法:\n\n        Random() 创建一个新的随机数生成器。  \n        Random(long seed) 使用单个 long 种子创建一个新的随机数生成器 \n\n成员方法:\n\n    int nextInt() 返回下一个伪随机数，它是此随机数生成器的序列中均匀分布的 int 值 \n    int nextInt(int n) 返回一个伪随机数，它是取自此随机数生成器序列的、在 0（包括）和指定值（不包括）之间均匀分布的 int 值 \n\n\nScanner类的使用\n可以获取从键盘的输入数据\n\n构造方法：\n  Scanner(InputStream source) 构造一个新的 Scanner，它生成的值是从指定的输入流扫描的。&lt;br/&gt;\n        如：Scanner sc = new Scanner(System.in);\n  sc.nextInt();获取整型数据\n  sc.nextLine();获取字符串数据\n\n\n继承(重点)\n把很多类的相同特征和行为进行抽取，用一个类来描述。让多个类和这个类产生一个关系。这样的话，多个类就可以省略很多代码。这个关系就是继承。java中用extends关键字表示。\n\n继承的体系结构:\n\n多个具体的对象，不断的向上抽取共享的内容，最终形成了一个体系。这个体系叫做继承体系。\n\n\n继承的特点:\n\njava中只能单继承，没有多继承 \njava可以有多重(层)继承 \n\n\n继承的好处：\n\n继承的出现提高了代码的复用性 \n继承的出现让类与类之间产生了关系，提供了多态的前提。 \n\n\n子父类中的成员关系\n\n成员变量:在子类方法中使用一个变量时,首先，在方法的局部变量中找这个变量，有则使用。否则，在本类中找成员变量，有则使用。否则，在父类中找成员变量，有则使用。否则，报错。\n成员方法:用子类对象使用一个方法时。首先，在子类中找这个方法，有则使用。否则，在父类中找这个方法，有则使用。否则，报错。\n\n\n\n重写和重载的区别？\n重载：在同一类中。方法名相同，参数列表不同。重载可以改变返回类型。\n重写：在不同类中(子父类中)。方法声明相同(返回类型，方法名，参数列表均相同)。\n重写需要注意：\n子类方法的访问权限要大于等于父类方法的访问权限。 \n静态只能重写静态。但是这种情况一般不会出现。\n\n\n\n构造方法\n子类的实例化过程,子类创建对象时，会先去创建父类的对象。默认是去调用父类的无参构造方法。子类构造方法中，第一行默认是super()\n为什么子类中第一行会默认有super()?\n因为他继承父类的成员使用，使用前这些成员必须初始化，而他们是父类的成员，所以，必须通过父类进行初始化。所以，会先创建一个父类的对象。当父类没有无参构造方法时,必须使用this或者super调用其他的构造方法。\n\n\n\nthis和super的区别\nthis:代表本类对象的引用。\n\nsuper:代表父类的存储空间。\nfinal关键字(重点)\n最终的意思，可以用于修饰类，方法，变量。\n\nfinal修饰的类不能被继承。\n\nfinal修饰的方法不能被重写。\n\nfinal修饰的变量是一个常量。只能被赋值一次。\n\n内部类只能访问被final修饰的局部变量。\n抽象类(重点)\n多个类有相同的方法声明，但是方法体不一样。这个时候，我们考虑把方法声明进行抽取。让子类继承后，自己去实现方法体。没有方法体的方法，我们需要用抽象标志下。\n\n抽象的关键字是：abstract。\n\n抽象类：该方法称为抽象方法，包含抽象方法的类就是抽象类。\n\n抽象类的特点：\n\n抽象类和抽象方法都要用abstract进行修饰\n抽象类不能被实例化\n抽象类中不一定有抽象方法，但是，有抽象方法的类一定是抽象类。\n\n\n抽象类中数据的特点\n\n抽象类中可以有变量，也可以有常量。 \n抽象类中可以有抽象方法，也可以有非抽象方法。 \n抽象类是一个类，所以，它有构造方法。 \n虽然本身不能实例化。但是可以给子类实例化使用。 \n\n\n抽象类中的问题\n\nA:抽象类中是否有构造方法？能不能被实例化？如果不能，为什么有构造方法？\n\n抽象类有构造方法。抽象类不能被实例化。抽象类中的构造方法供子类实例化调用。  \n\n\n抽象关键字abstract不可以和哪些关键字共存？ \n\nprivate:私有内容子类继承不到，所以，不能重写。但是abstract修饰的方法，要求被重写。两者冲突。 \n\nfinal:final修饰的方法不能被重写。而abstract修饰的方法，要求被重写。两者冲突。 \n\nstatic:假如一个抽象方法能通过static修饰，那么这个方法，就可以直接通过类名调用。而抽象方法是没有方法体的，这样的调用无意义。所以，不能用static修饰。 \n\n\n\n抽象类中可不可以没有抽象方法？如果可以，这样的类有什么用吗？ \n\n抽象类可以没有抽象方法。\n抽象类中没有抽象方法的作用，只是为了不让别的类建立该抽象类对象。这个在awt中有体现。\n\n\n\n接口interface\n当一个类中的方法都是抽象的时候，java提供了另一种表示方式，叫接口。\n\n用interface关键字表示。类与接口关系用implements表示。\n\n接口的成员特点\n      成员变量 \n      是常量，默认修饰 public static final \n      成员方法 \n      都是抽象的，默认修饰 public abstract \n\n\n    A:类与类的关系 \n    是继承关系。类与类只能单继承，可以多重继承。 \n    B:类和接口的关系&lt;br/&gt;\n    是实现关系。类可以多实现接口。 \n    类在继承一个类的同时，可以实现多个接口。 \n    C:接口和接口的关系 \n    是继承关系。接口可以多继承接口。 \n\n接口的特点:\n      是对外暴露的规则 \n      是功能的扩展 \n      接口的出现降低耦合性。 \n      耦合(类与类之间的关系 )\n      内聚(类完成功能的能力) \n      编程规范：低耦合，高内聚。 \n      接口可以多实现。如：CPU和主板、笔记本的USB插口、插座 \n\n接口和抽象类的区别\n\n抽象类只能被单继承接口可以多实现,接口的出现避免了多继承的局限性。 \n\n\n抽象类中的数据特点： \n\n成员变量：可以是变量，也可以是常量 \n成员方法：可以是抽象方法，也可以是非抽象方法 \n构造方法：有构造方法 \n\n\n接口中的数据特点： \n\n成员变量：是常量。默认修饰 public static final \n成员方法：都是抽象方法。都有默认修饰 public abstract \n构造方法：没有构造方法 \n抽象类中定义的是继承体系中的共性功能。接口中定义的是继承体系中的扩展功能。 \n抽象类被继承是”is a”关系:xx是yy的一种,接口被实现是”like a”关系:xx像yy的一种.\n\n\n\n","categories":["Java"],"tags":["Java","面试"]},{"title":"Java面试基础(一)","url":"http://tanqingbo.cn/2016/03/25/Java面试基础（一）/","content":"Java面试基础(一)面向对象\n面向对象思想：面向对象是相对于面向过程而言的，面向过程强调的是功能，面向对象强调的是将功能封装进对象，强调具备功能的对象；\n思想特点：A.是符合人们思考习惯的一种思想；B:将复杂的事情简单化了；C:将程序员从执行者变成了指挥者\n特征：封装：隐藏对象的属性和实现细节，仅对外提供公共访问方式继承: 多个类中存在相同属性和行为时，将这些内容抽取到单独一个类中，那么多个类无需再定义   这些属性和行为，只要继承那个类即可。多态: 一个对象在程序不同运行时刻代表的多种状态，父类或者接口的引用指向子类对象类和对象：\n类：对现实世界中某类事物的描述,是抽象的，概念上的定义。\n对象：事物具体存在的个体。成员变量和局部变量的区别(重点)(1)作用域 成员变量：针对整个类有效。局部变量：只在某个范围内有效。(一般指的就是方法,语句体内)(2)存储位置成员变量：随着对象的创建而存在，随着对象的消失而消失，存储在堆内存中。局部变量：在方法被调用，或者语句被执行的时候存在，存储在栈内存中。当方法调用完，或者语句结束后，就自动释放。(3)初始值成员变量：有默认初始值。局部变量：没有默认初始值，使用前必须赋值。匿名对象(1)匿名对象就是没有名字的对象。是对象的一种简写形式。(2)应用场景A:只调用一次类中的方法。B:可以作为实际参数在方法传递中使用封装：\n指隐藏对象的属性和实现细节，仅对外提供公共访问方式；比如电脑机箱、笔记本等\n好处：将变化隔离；方便使用；提高复用性；提高安全性\n关键字private：封装在代码中的体现(1)私有的意思，权限修饰符(2)用来修饰成员变量和成员函数(3)用private修饰的成员只在本类中有效(4)私有是封装的一种体现构造方法：\n\n\n特点：方法名与类名相同没有返回类型没有返回值\n作用：构造函数是用于创建对象，并对其进行初始化赋值，对象一建立就自动调用相对应的构造函数，\n构造方法的注意事项:A:如果一个自定义类没有构造方法，系统会默认给出一个无参构造方法。B:如果一个自定义类提供了构造方法，那么，系统将不再给出无参构造方法。这个时候，你可以不使用无参构造方法。如果你想使用，那么，就必须手动给出无参构造方法。\n\n建议：一般情况下，我们的自定义类都要手动给出无参构造方法。 4. 构造方法和成员方法的区别A:格式区别构造方法和类名相同，并且没有返回类型，也没有返回值。普通成员方法可以任意起名，必须有返回类型，可以没有返回值。B:作用区别构造方法用于创建对象，并进行初始化值。普通成员方法是用于完成特定功能的。C:调用区别构造方法是在创建对象时被调用的，一个对象建立，只调用一次相应构造函数,普通成员方法是由创建好的对象调用，可以调用多次\n构造代码块：\n作用：给对象进行初始化，对象一建立就执行，而且优先于构造函数执行\n\n构造代码块和构造函数的区别：(1)构造代码块是给所有不同对象的共性进行统一初始化(2)构造函数是给对应的对象进行初始化\nthis关键字\nthis关键字代表本类对象的一个引用，谁调用this所在的方法，this就代表谁  \n\nthis的使用场景A:用于区分同名成员变量和局部变量；B:在定义函数时，该函数内部要用到调用该函数的对象时，因为此时对象还没建立，故this代表此对象C:构造函数间调用这个时候，this(参数)必须作为第一条语句存在。\nPerson p = new Person();在内存中做了哪些事情。\n\n\n将Person.class文件加载进内存中。\n如果p定义在主方法中，那么，就会在栈空间开辟一个变量空间p。\n在堆内存给对象分配空间。\n对对象中的成员进行默认初始化。\n对对象中的成员进行显示初始化。\n调用构造代码块对对象进行初始化。(如果没有就不执行)\n调用构造方法对对象进行初始化。对象初始化完毕。\n将对象的内存地址赋值给p变量，让p变量指向该对象。static关键字：\n\n\n静态的意思，用来修饰成员变量和成员函数\n静态的特点:\n随着类的加载而加载优先于对象存在对所有对象共享可以被类名直接调用\n\n\n\n静态的注意事项\n为什么静态方法只能访问静态成员：因为静态的内容是随着类的加载而加载，它是先进内存的。\n静态方法中不能使用this,super关键字\n主方法是静态的\npublic static void main(String[] args)\npublic:公共的意思，是最大权限修饰符。static:由于jvm调用main方法的时候，没有创建对象。只能通过类名调用。所以，main必须用static修饰。void:由于main方法是被jvm调用，不需要返回值。用void修饰。main:main是主要的意思，所以jvm采用了这个名字。是程序的入口。String[]:字符串数组args:数组名在运行的时候，通过java命令给args数组赋值。格式：java MainTest hello world itcast\n\n\n\n静态变量和成员变量的区别A：调用方式静态变量也称为类变量，可以直接通过类名调用。也可以通过对象名调用。这个变量属于类。成员变量也称为实例变量，只能通过对象名调用。这个变量属于对象。B：存储位置静态变量存储在方法区中的静态区。成员变量存储在堆内存。C：生命周期静态变量随着类的加载而存在，随着类的消失而消失。生命周期长。成员变量随着对象的创建而存在，随着对象的消失而消失。D：与对象的相关性静态变量是所有对象共享的数据。成员变量是每个对象所特有的数据。\n\n静态的优点和弊端\n\n 优点：对对象的共享数据进行单独空间的存储，节省内存，没有必要每个对象都存储一份可直接被类名调用弊端：生命周期过长，随着类的消失而消失访问出现权限，即静态虽好但只能访问静态\n\n\n什么使用使用静态呢？\n\n 1.当所有对象共享某个数据的时候，就把这个成员变量定义为静态修饰的。 2.当某个方法没有访问该类中的非静态成员，就可以把这个方法定义为静态修饰。 3.静态的生命周期比较长，所以一般不推荐使用。\n\n\n静态代码块\n\n A:它只执行一次，它比main还先执行。 B:执行顺序 静态代码块–构造代码块–构造方法\n\n\n\n制作API(次重点)\nAPI(全拼):Application Program Interface 应用程序编程接口。\n (1)类中的内容需要用文档注释。 (2)使用JDK\\bin目录下的javadoc工具。 格式:javadoc -d 目录 -author -version ArrayTool.java\n\n\n\n","categories":["Java"],"tags":["Java","面试"]},{"title":"Sping入门","url":"http://tanqingbo.cn/2016/03/23/Spring入门基础/","content":"Sping入门一些资源\nsping.io\nprojects.spring.io/spring-framework\n其他Spring是什么\nSpring是一个开源框架，为了解决企业应用开发的复杂性而创建的，但是现在已经不止于应用于企业应用\n是一个轻量级的控制反转（IoC）和面向切面的容器框架\n在Spring上开发应用更简单、方便、快捷，Spring带来了复杂的javaee开发的春天\n\nSpring作用\n容器\n提供了多种技术支持（JMS   MQ支持  UnitTest）\nAOP(事务管理、日志等)\n提供了众多方便应用的辅助类（JDBC Template等）\n对主流应用框架（Hibernate等）提供了良好的支持\nspring是一个一站式的框架；\nspring主要有两个思想：IOC和AOP；\nspring的主要的功能是整合其它框架；适应范围\n构建企业应用（SpringMVC+Spring+Hibernate/mybatis）\n单独使用Bean容器（Bean管理）\n单独使用AOP进行切面处理\n其他的Spring功能，如：对消息的支持等\n在互联网中应用\n抽象类代表一个概念（例如：飞机），接口代表一种能力（会飞的）ioc是反转控制；\n指的就是组件和组件之间的关系并不是由任意一端来进行维护的，而有由第三方来维护的；第一个Spring程序\n创建工程，增加spring支持\n在applicationContext.xml文件中定义bean\n创建工厂\n创建一个Spring工厂\nBeanFactory factory=new ClassPathXmlApplicationContext(&quot;aplicationContxt.xml&quot;);\n在工厂重获对象,默认bean是单例模式\nfactory.getBean(&quot;name&quot;);\n\n\n\n关于bean的配置\n默认bean是单例的（scope=”singleton”），但可以通过 scope属性修改成prototype;\nspring工厂赋值在init方法之前装配方式\n\n\n属性装配\n构造方法装配装配的内容\n\n\nbean\nnull\n集合\nmap\nref\nvalue自动装配的方式(四种)\n案例代码下载\n default-autowire = byName\n          byType\n          constructor\n          autoDetect\n\n\n\nAnnotation的配置方法\n案例代码下载\n\n控制层 　　　业务层      　　　　    持久层\n\naction     　　　  service   　　　　  dao\nannotation的配置步骤\n在配置文件中增加一个schema ，名子是context;\n\n使用&lt;context:componet-scan &gt;标记来扫描包；\n\n#这个配置可以自动扫描com.dao,service,com.action三个包中的类，并且实例化\n&lt;context:component-scan base-package=&quot;com.dao,service,com.action&quot;&gt;&lt;/context:component-scan&gt;\n\n用于创建bean的注解      @Component    三层都可以  \n      @Repository   写dao  （持久层）\n\n      eg:\n      @Repository(&quot;DeptDao&quot;)（如果只是@Repository，\n      则factory.getBean(&quot;deptDaoImpl&quot;);中的&quot;deptDaoImpl&quot;和源类名不一样，第一个字母是小写）\n      public class DeptDaoImpl implements DeptDao &#123;\n          ......\n      &#125;\n      这样就可以在主函数里获得DeptDaoImpl类的实例：\n      DeptDao dao =  (DeptDao) factory.getBean(&quot;DeptDao&quot;);\n\n      @Service      写service （业务层 ） \n      @Controller   写action（控制层）\n用于控制bean的作用域注解，可将单例变成非单例      @Scope(&quot;prototype&quot;)\n      eg：\n      @Controller\n      @Scope(&quot;prototype&quot;)\n      public class DeptAction &#123;...&#125;\n用于装配的注解，为类中的其他类属性实例化          @Autowired  :建议使用\n          @Resource\n          @Inject\n\n          eg:\n          @Autowired   //实例化类DeptServise\n          DeptServise deptService;\n\n\n","categories":["Java"],"tags":["Java","Sping","框架"]},{"title":"JavaEE介绍","url":"http://tanqingbo.cn/2016/03/22/JavaEE介绍/","content":"JavaEE介绍JavaEE\nHTTP:Tomcat\nServlet  JSP  JSTL  EL\nMVC设计模式\nxml\nAJAX:JS\nJQuery：js框架软件的架构C/S:Client/Server(胖客户端)\n  优点：可以发挥客户端计算机的硬件，功能更强大，缓存；  缺点：维护性差\n\nB/S：Browser/Server(瘦客户端)\n  优点：维护性特别好，  缺点：服务器压力比较大\n\nRIA：rich internet application(富客户端)\n  ajax  jquery  extjs  javaFx  Flex  html5\n\nHTTP协议：\nhyper text  transfer protocal  ：80    超文本传输协议，是TCP协议的高层协议  \n特点：无状态  无连接  基于请求/响应模式的协议\nURL：统一资源定位器\n 格式：协议://ip地址:端口号/应用名/资源？参数(http://www.taobao.com    )\n\nHTTP1.0与HTTP1.1的区别\n如果在一个页面中包含其它资源（图片，js，css等），http1.0会创建多个连接，每个连接发送一个请求，而http1.1只会创建一个连接，在一个连接中发送多个请求，性能更好。HTTP协议的结构：\n 三部分：\n        1.请求行\n         2.消息头\n         3.内容体（可选）\n    响应的三部分\n    1.状态行\n    2.消息行\n    3.实体内容\n   状态行中有状态码，状态码常用的数值是\n         200：服务器正常处理\n         404：客户端错误，找不到页面\n         500：服务器内容错误，通常是程序错误\n\n\n\nGET与POST的区别\n get通过请求行发送数据               当直接在地址栏上写URL      使用A标签    使用js的location，open  或者form表单中method的属性值位get时，发送时get请求          post通过请求体发送数据          post更好，对长度没有限制               form表单中method的属性值位post时，发送post请求，尽量使用post请求\n\n","categories":["Java"],"tags":["Java"]},{"title":"hibernate介绍","url":"http://tanqingbo.cn/2016/03/22/hibernate介绍/","content":"hibernate框架\nhibernate是一个持久层框架\n什么是orm（关系对象映射）\n object relationship mapping\n编程语言：oop\n   数据库：rdbms\n\n第一个hibernate应用程序\n\n\n新建立一个工程，并加入hibernate支持（4.1）\n创建PO及配置文件\n使用API来操作PO 对象\n获取session\n   开启事务&lt;br/&gt;\n   执行操作&lt;br/&gt;\n   提交事务&lt;br/&gt;\n   关闭连接\n\n核心配置文件\n\n\n一个数据源只包含一个核心配置文件，这个文件包含三类内容：\n 数据源配置\n   hibernate的属性配置&lt;br/&gt;\n   加载映射文件\n\n映射文件常用标记\n&lt;class name= &quot;com.oracle.po.Book&quot; table= &quot;BOOK&quot; schema= &quot;SCOTT&quot; &gt;\n &lt;id name= &quot;bid&quot; type= &quot;java.lang.Integer&quot; &gt;:oid属性映射\n\n\n\n","categories":["Java"],"tags":["Java","框架","hibernate"]},{"title":"hibernate应用","url":"http://tanqingbo.cn/2016/03/22/hibernate应用/","content":"hibernate应用如何创建session?\nConfigguration:配置文件\nSessionFactory:session工厂\nSession：核心接口什么是session？\n\n\nJava运行程序与hibernate之间的会话。主要功能是对经过映射的实体类提供创建，读取，删除操作；同时session也是一个容器，它可以临时保存着po对象的引用。\n也就是说session可以缓存数据库的数据。可以减少对数据库的操作次数。po对象的三个状态（po对象的生命周期）\n\n\n瞬时态：从来没有持久化，也没有纳入到session的管理。\n持久态：纳入到了session的管理。\n游离态：曾经是持久化对象，当前不与session关联。常用的方法：\nflush：刷新（与数据库同步），刷新不等于提交，rollback可以回退。\nsave：插入\npersist：插入（不能忽略主键的值）\nget：根据oid获得对应的po 对象\nevict：从session移除一个实体\nclear：从session中移除所有对象\nclose：关闭session，并从session中移除所有对象\nupdate：修改游离态的对象（将游离态对象转成持久化对象）\ndelete：删除\n\nget与load的区别？\n\n\n作用：都是根据oid获取对应的实体。\n区别：\n 1.get会立即执行查询语句，得到真实对象，如果找不到，则返回null； 2.load不会立即查询语句，返回一个代理对象，当需要访问这个实体时才会发送SQL语句，如果实体不存在，则抛出ObjectNotFoundException异常。 相同点：查询时，先查询缓存，如找到，无论找到的是真实对象还是代理对象，都不会再发SQL语句。\n\n主键的设计事项\n每个表都应该有主键，与之对应的实体也应该有一个oid；\n主键的设置应该是无意义的，最好是数字，不应该与业务关联\nhibernate的主键生成方式主要有：\n     increment：自增长（最大值+1）；只是应用于测试，不适用并发访问，支持int long short类型。\n     identity：支持mysql  db2  ms  sqlserver支持，数据库自身的自增长。\n     sequence：序列\n     hilo：高低算法；\n     native：先identity，sequence，hilo\n     assigned：手动分配\n     uuid：生成128位的码，返回的是字符串；\n     foreign：外键（一对一）\n\n\n\n","categories":["Java"],"tags":["Java","框架","hibernate"]},{"title":"Dll","url":"http://tanqingbo.cn/2016/03/22/Dll/","content":"Dll\n链接库分为动态和静态两种，后缀分别是.dll和.lib\n使用GetProcAddress获取Dll中导出函数的指针\n使用FreeLibrary卸载指定dllVS下,Dll分为3类\n\n\n非MFC的Dll  即使用SDK API进行编程，能被其他所有语言调用\nMFC规则DLL   可以使用MFC进行编程，能被其他语言调用\nMFC扩展DLL  可以使用MFC进行编程，但只能被MFC编写的程序调用。学第一种。DLL的编写\n\n\nDLL的导出, DLL的导出函数使用\nextern &quot;C&quot;_declspec(dllexport)\n\n而导入函数使用\nextern &quot;C&quot; _declspec (dllimport )\n extern &quot;C&quot;：作为一种编译约定\n #pragma once：表示制备编译一次，而不会因重复包含而重复编译\n\n线程注入：\n目标进程-&gt;传入DLL地址-&gt;开启远程线程-&gt;加载DLL-&gt;实现DLL注入\n实现线程注入，依次使用以下函数：\n OpenProcess  //获取已知进程的句柄\n VirtualAllocEx  //在进程中申请空间\n WriteProcessMemory //向进程中写入东西\n GetProcAddress  //取得函数在DLL中地址\n  CreateRemoteThreadEx //在其他进程中创建新进程\n\n\n\n","categories":["C语言"],"tags":["技术","VS"]},{"title":"Python爬虫","url":"http://tanqingbo.cn/2016/03/20/Python爬虫/","content":"Python爬虫作者：谭庆波\n爬虫：一段自动抓取互联网信息的程序\n价值：互联网数据，为我所用。爬虫运行原理\n\n\nURL管理器：管理待抓取的URL集合和已抓取URL，防止重复和循环抓取。URL管理器实现：\n\n\n用ｓｅｔ（）集合存放待爬取和已爬取得ＵＲＬ。\nmysql数据库存放待爬取和已爬取得ＵＲＬ，url（url,is_crewled）\n缓存数据库存放待爬取和已爬取得ＵＲＬ。网页下载器\n\n\n网页下载器是将互联网上的url对应的网页下载到本地的工具。\nPython的网页下载器：urllib2urllib2下载网页方法1：最简洁方法\n   import urillb2 \n   response=urilb2.urlopen(&#39;http:www.baidu.com&#39;)//直接请求 \n   printf response.getcode()//获取状态码(如果是200，表示获取成功) \n   cont = response.read()//读取内容\n\nurllib2下载网页方法2：添加data  http  header\n   import urillb2 \n   request=urilb2.Request(url)//创建request对象\n   request.add_data(&#39;a&#39;,&#39;1&#39;)//添加数据\n   request.add_header(&#39;User-Agent&#39;,&#39;Mozilla/5.0&#39;)//添加http的header\n  response = urllib2.urlopen(request)//发送获取结果\n\nurllib2下载网页方法3:添加特俗情景的处理器  \nimport urllib2,cookielib\ncj=cookielib.CookieJar()//创建cookie容器\nopener=urllib2.build_opener(urllib2.HTTPCookieProcessor(cj))//创建一个opener\nurllib2.install_opener(opener)//给urllib2安装opener\nres=urllib2.urlopen(&quot;http://www.baidu.com&quot;)//使用带有cookie的urllib2访问网页\n\n\n在Eclipse中安装PyDev\n\n\n在Eclipse中：Help-&gt;Install New Software\n然后在弹出的Install窗口中，点击Add去添加仓库。\n然后就可以看到Eclipse去搜索了，很快，就可以找到PyDev了\n取消掉那个：Contact all update sites during install to find required software\n然后一直next就行哈！\n\n网页解析器\n网页解析器的种类：正则表达式   html.parser    Beautiful Soup插件（最强大）     lxml插件（除正则表达式外，其他都是结构化解析）安装Beautiful Soup\nBeautiful Soup是Python的第三方库，用于从HTML和xml中提取数据\n官网：http://www.crummy.com/software/BeautifulSoup/bs4/doc/从cmd中进入到Python的安装目录下的Scripts，执行：\n  pip install beautifulsoup4\n\n\n安装好之后，eclipse执行：\n  #coding:utf-8\n  import bs4\n  print bs4\n\n\n结果不报错，则安装成功Beautiful Soup语法\n由html网页内容创建Beautiful Soup对象，有两个方法：find_all(寻找所有满足要求的节点)，find（寻找第一个满足要求的节点），两个方法的参数一模一样。\n通过节点在访问节点名称、属性、文字。###创建Beautiful Soup对象\n from bs4 import BeautifulSoup\n #根据网页内容创建BeautifulSoup对象\n  soup =BeautifulSoup(\n           html_doc,             # html文档字符\n           &#39;html.parser&#39;,         # HTML解析器\n           from_encoding=&#39;utf8&#39;  # HTML文档编码\n               )\n\n搜索节点\nfind_all(name,attrs,string)访问节点信息\n node.name    #获取节点标签名\n node[&#39;href&#39;]  #获取节点href属性\n node.get_text()  #获取节点文字\n\n\n\nBeautiful Soup实例\n#coding:utf-8\nfrom bs4 import BeautifulSoup\nfrom setuptools.package_index import HREF\nimport re\n\nhtml_doc = &quot;&quot;&quot;\n&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&#39;s story&lt;/title&gt;&lt;/head&gt;\n&lt;body&gt;\n&lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;\n\n&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were&gt;\n&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,\n&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and\n&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;\nand they lived at the bottom of a well.&lt;/p&gt;\n\n&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;\n&quot;&quot;&quot;\n\n\n    soup =BeautifulSoup(\n           html_doc,             # html文档字符\n           &#39;html.parser&#39;,         # HTML解析器\n          from_encoding=&#39;utf8&#39;  # HTML文档编码\n               )\nprint &#39;获取所有链接&#39;\nlinks = soup.find_all(&#39;a&#39;)\nfor link in links:\n    print link.name,link[&#39;href&#39;],link.get_text()\n\n\nprint &#39;获取lacie的链接&#39;\nlink_node = soup.find(&#39;a&#39;,href=&#39;http://example.com/lacie&#39;)\nprint link_node.name,link_node[&#39;href&#39;],link_node.get_text()\n\n\nprint &quot;正则匹配&quot;\nlink1 = soup.find(&#39;a&#39;,href=re.compile(r&quot;ill&quot;))\nprint link1.name,link1[&#39;href&#39;],link1.get_text()\n\n\nprint &quot;获取P段落文字&quot;\np_node = soup.find(&#39;p&#39;,class_=&quot;title&quot;)\nprint p_node.name,p_node.get_text()       \n\n实例爬虫\n#coding:utf-8\nimport urllib2\nimport cookielib\n\n\nurl = &quot;http://www.baidu.com&quot;\n\n\nprint &quot;第一种方法&quot;\nresponse1 = urllib2.urlopen(url)\nprint &quot;打印状态码，200即为请求成功&quot;\nprint response1.getcode()\nprint &quot;打印网页内容的长度&quot;\nprint len(response1.read())\n\n\nprint &#39;第二种方法&#39;\nrequest = urllib2.Request(url)\nrequest.add_header(&quot;user-agent&quot;,&quot;Mozilla/5.0&quot;)\nresponse2 = urllib2.urlopen(request)\nprint response2.getcode()\nprint len(response2.read())\n\n\nprint &#39;第三种方法&#39;\ncj = cookielib.CookieJar()\nopener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cj))\nurllib2.install_opener(opener)\nresponse3 = urllib2.urlopen(url)\nprint response3.getcode()\nprint cj\nprint &quot;打印网页内容&quot;\nprint response3.read()  \n\n目标：百度百科Python词条相关词条网页入口页：http://baike.baidu.com/view/21087.htmlURL格式：\n词条页面URL：/view/125370.htm\n数据格式：\n标题：\n\n    &lt;dd class=&quot;lemmaWgt-lemmaTitle-title&quot;&gt;&lt;h1&gt;****&lt;/h1&gt;&lt;/dd&gt;\n\n\n简介：\n\n&quot;&lt;div class=&quot;lemma-summary&quot; label-module=&quot;lemmaSummary&quot;&gt;***&lt;/div&gt;&quot;\n\n页面编码：UTF-8实例代码：爬取百度百科Python词条相关1000个页面数据\n代码下载链接：github下载\n\n\n","categories":["Java"],"tags":["Python","算法","博客"]},{"title":"搭建hexo博客","url":"http://tanqingbo.cn/2016/03/17/搭建hexo博客/","content":"作者：谭庆波安装Git\n下载 msysgit 并执行即可完成安装。安装Node.js\n在 Windows 环境下安装 Node.js 非常简单，仅须下载安装文件并执行即可完成安装。安装hexo\n利用 npm 命令即可安装。（在任意位置点击鼠标右键，选择Git bash）\n npm install -g hexo  \n\n创建hexo文件夹\n安装完成后，在你喜爱的文件夹下（如H:\\hexo），执行以下指令(在H:\\hexo内点击鼠标右键，选择Git bash)，Hexo 即会自动在目标文件夹建立网站所需要的所有文件。\n hexo init \n npm install\n\n本地查看\n现在我们已经搭建起本地的hexo博客了，执行以下命令(在H:\\hexo)，然后到浏览器输入localhost:4000看看。\n hexo generate\n hexo server\n\n\n好了，至此，本地博客已经搭建起来了，只是本地哦，别人看不到的。下面，我们要部署到Github。创建repository\n在自己Github主页右下角，创建一个新的repository。比如我的Github账号是tqb4342，那么我应该创建的repository名字应该是tqb4342.github.io。部署\n编辑_config.yml(在H:\\hexo下)。你在部署时，要把下面的zippera都换成你的账号名。\ndeploy:\ntype: git\nrepository: https://github.com/zippera/zippera.github.io.git\nbranch: master\n\n执行下列指令即可完成部署。\n npm install hexo-deployer-git --save \n hexo generate \n hexo deploy\n\n\n记住：每次修改本地文件后，需要hexo generate才能保存。每次使用命令时，都要在H:\\hexo目录下。 \nOkay,我们的博客已经完全搭建起来了，在浏览器访问tqb4342.github.io就能看到你的成就了！ 导航栏添加自定义页面\n\n\n命令手动生成自定义页面\n\n  hexo n page &quot;about&quot;\n\n\n编辑 hexo/source/about/index.md 内容\n\n修改 themes/jacman/_config.yml 文件\n\n\n\n    menu:\n    关于: /about\n\n","categories":["技术博客"],"tags":["技术","博客","hexo"]}]