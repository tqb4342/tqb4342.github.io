<!DOCTYPE html>
<html>
<meta  lang="zh-CN" >
<head>
  <meta charset="UTF-8">
  <meta name="viewport"
    content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <meta name="theme-color" content="#fff" id="theme-color">
  <link rel="icon" href="/img/logo.jpg">
  <title>机器学习必读经典书籍与论文下载&nbsp; | &nbsp;IT码农</title>
  
  
  <meta property="title" content="机器学习必读经典书籍与论文下载">
  
  
  <meta property="url" content="https://tanqingbo.cn/ML-EBook-paper/index.html">
  
  
  <meta property="og:img" content="https://cdn.jsdelivr.net/gh/tqb4342/BlogPhoto@master/20201214150346.png">
  
  
  <meta property="description" content="部分经典机器学习书籍已经整理好了，在公众号【轮子工厂】后台回复“机器学习”可以领取，另外还配套有视频教程、课件和项目练习！">
  
  <meta property="keywords" content="机器学习,论文">
  
  <meta property="og:type" content="article">
  <meta property="og:article:published_time" content="2020-12-14">
  <meta property="og:article:modified_time" content="2020-12-14">
  <meta property="og:article:author" content="IT&amp;nbsp; 码&amp;nbsp; 农">
  
  
  <meta property="og:article:tag" content="机器学习">
  
  
  
  
  
 <meta name="yandex-verification" content="6b899e6f05914428" /> 
 <link rel="canonical" href="https://tanqingbo.cn/ML-EBook-paper/index.html" />
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-178024758-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-178024758-1');
</script>

<!-- 百度自动推送 -->
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>

<!-- 360自动推送 -->
<script>
(function(){
var src = "https://jspassport.ssl.qhimg.com/11.0.1.js?d182b3f28525f2db83acfaaf6e696dba";
document.write('<script src="' + src + '" id="sozz"><\/script>');
})();
</script>

  
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?d87293651eefff721c898f38338ea3a8";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>


  
  <script>
    // control reverse button
    var reverseDarkList = {
      dark: 'light',
      light: 'dark'
    };
    var themeColor = {
      dark: '#1c1c1e',
      light: '#fff'
    }
    // get the data of css prefers-color-scheme
    var getCssMediaQuery = function() {
      return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
    };
    // reverse current darkmode setting function
    var reverseDarkModeSetting = function() {
      var setting = localStorage.getItem('user-color-scheme');
      if(reverseDarkList[setting]) {
        setting = reverseDarkList[setting];
      } else if(setting === null) {
        setting = reverseDarkList[getCssMediaQuery()];
      } else {
        return;
      }
      localStorage.setItem('user-color-scheme', setting);
      return setting;
    };
    // apply current darkmode setting
    var setDarkmode = function(mode) {
      var setting = mode || localStorage.getItem('user-color-scheme');
      if(setting === getCssMediaQuery()) {
        document.documentElement.removeAttribute('data-user-color-scheme');
        localStorage.removeItem('user-color-scheme');
        document.getElementById('theme-color').content = themeColor[setting];
      } else if(reverseDarkList[setting]) {
        document.documentElement.setAttribute('data-user-color-scheme', setting);
        document.getElementById('theme-color').content = themeColor[setting];
      } else {
        document.documentElement.removeAttribute('data-user-color-scheme');
        localStorage.removeItem('user-color-scheme');
        document.getElementById('theme-color').content = themeColor[getCssMediaQuery()];
      }
    };
    setDarkmode();
  </script>
  <script>
    function loadScript(url, cb) {
      var script = document.createElement('script');
      script.src = url;
      if (cb) script.onload = cb;
      script.async = true;
      document.body.appendChild(script);
    }
  </script>
  
  <link rel="preload" href="//at.alicdn.com/t/font_1946621_f7g5jnuftcf.css" as="style" >
  <link rel="preload" href="//at.alicdn.com/t/font_1952792_89b4ac4k4up.css" as="style" >
  
  <link rel="preload" href="//cdn.jsdelivr.net/npm/fslightbox@3.1.0/index.min.js" as="script">
  
  
  <link rel="preload" href="/js/lib/lozad.min.js" as="script">
  
  
  
  
  
  <link rel="prefetch" href="//cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-svg.js" as="script">
  
  
  
  <link rel="prefetch" href="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js" as="script">
  
  
  
  
<link rel="stylesheet" href="/css/main.css">

  
  
<link rel="stylesheet" href="//at.alicdn.com/t/font_1946621_f7g5jnuftcf.css">

  
  
<link rel="stylesheet" href="//at.alicdn.com/t/font_1952792_89b4ac4k4up.css">

  
  
  
<meta name="generator" content="Hexo 5.1.1">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>


<body>
  <div class="wrapper">
    
    <nav class="navbar">
  <div class="navbar-logo">
    <span class="navbar-logo-main">
      
      <img class="navbar-logo-img" src="/img/logo.jpg">
      
      <span class="navbar-logo-dsc">IT&nbsp; 码&nbsp; 农</span>
    </span>
  </div>
  <div class="navbar-menu">
    
    <a href="/" class="navbar-menu-item">
    
    首页
    
    </a>
    
    <a href="/CSBook001" class="navbar-menu-item">
    
    电子书下载
    
    </a>
    
    <a href="/categories" class="navbar-menu-item">
    
    分类
    
    </a>
    
    <a href="/links" class="navbar-menu-item">
    
    友链
    
    </a>
    
    <a class="navbar-menu-item darknavbar" id="dark"><i class="iconfont icon-weather"></i></a>
    <a class="navbar-menu-item searchnavbar" id="search"><i class="iconfont icon-search" style="font-size: 1.2rem; font-weight: 400;"></i></a>
  </div>
</nav>
    
    <div id="local-search" style="display: none;">
      <input class="navbar-menu-item" id="search-input" placeholder="请输入搜索内容...">
      <div id="search-content"></div>
    </div>
    
    <div class="section-wrap">
      <div class="container">
        <div class="columns">
          <main class="main-column">
<div class="image-wrapper">
  <img src="https://cdn.jsdelivr.net/gh/tqb4342/BlogPhoto@master/20201214150346.png" data-src="https://cdn.jsdelivr.net/gh/tqb4342/BlogPhoto@master/20201214150346.png"
    srcset="data:image/svg+xml,%3Csvg%20xmlns=&#39;http://www.w3.org/2000/svg&#39;%20viewBox=&#39;0%200%20300%20300&#39;%3E%3C/svg%3E"
    class="image lozad">
</div>

<article class="card card-content">
  <header>
    <h1 class="post-title">
      机器学习必读经典书籍与论文下载
    </h1>
  </header>
  <div class="post-meta post-show-meta">
    <time datetime="2020-12-14T07:01:18.000Z" style="display: flex; align-items: center;">
      <i class="iconfont icon-calendar" style="margin-right: 2px;"></i>
      <span>2020-12-14</span>
    </time>
    
    <span class="dot"></span>
    
    <a href="/categories/图像处理与机器学习/" class="post-meta-link">图像处理与机器学习</a>
    
    
    
    <span class="dot"></span>
    <span>5.2k 字</span>
    
	&nbsp;&nbsp;
	  <!-- id 将作为查询条件 -->
    <div style="display: flex; align-items: center;">
      <i class="iconfont icon-wodebaobiao" style="margin-right: 2px; font-size: 1.15rem;"></i>
		<span id="/ML-EBook-paper/" class="leancloud_visitors" data-flag-title="机器学习必读经典书籍与论文下载">
			<em class="post-meta-item-text">阅读量 </em>
			<i class="leancloud-visitors-count">loading</i>
		</span>
	</div>
	
  </div>
  
  
  
  <div class="post-meta post-show-meta" style="margin-top: -10px;">
    <div style="display: flex; align-items: center;">
      <i class="iconfont icon-biaoqian" style="margin-right: 2px; font-size: 1.15rem;"></i>
      
      
        <a href="/tags/机器学习/" class="post-meta-link">机器学习</a>
      
    </div>
  </div>
  
  


		
  
  <meta name="description" content="部分经典机器学习书籍已经整理好了，在公众号【轮子工厂】后台回复“机器学习”可以领取，另外还配套有视频教程、课件和项目练习！">
  
  <meta name="keywords" content="机器学习,论文">
  </header>
  

  
  <div id="section" class="post-content">
	<!--
		<p>最近整理了一些计算专业必读的经典专业书，可以点击下面的链接查看和下载高清pdf电子版：</p>
		<ul>
		<li><a href="https://tanqingbo.cn/computer-book/">计算机专业几本必看的几本经典书籍！</a></li>
		</ul>
	-->
    <p>部分经典机器学习书籍已经整理好了，在公众号【<strong>轮子工厂</strong>】后台回复“<strong>机器学习</strong>”可以领取，另外还配套有视频教程、课件和项目练习！</p>
<h2 id="入门书单"><a href="#入门书单" class="headerlink" title="入门书单"></a>入门书单</h2><h5 id="1-《数学之美》"><a href="#1-《数学之美》" class="headerlink" title="1.《数学之美》"></a>1.《数学之美》</h5><p>作者吴军博士是我特备喜欢的以为人工智能专家，他的大部分我都看过，在本书中以极为通俗的语言讲述了数学在机器学习和自然语言处理等领域的应用。</p>
<h5 id="2-《集体智慧编程》"><a href="#2-《集体智慧编程》" class="headerlink" title="2.《集体智慧编程》"></a>2.《集体智慧编程》</h5><p>作者Toby Segaran也是《数据之美：解密优雅数据解决方案背后的故事》的作者。这本书最大的优势就是里面没有理论推导和复杂的数学公式，是很不错的入门书。目前中文版已经脱销，对于有志于这个领域的人来说，英文的pdf是个不错的选择，因为后面有很多经典书的翻译都较差，只能看英文版，不如从这个入手。还有，这本书适合于快速看完，因为据评论，看完一些经典的带有数学推导的书后会发现这本书什么都没讲，只是举了很多例子而已。</p>
<h5 id="3-《智能web算法》"><a href="#3-《智能web算法》" class="headerlink" title="3.《智能web算法》"></a>3.《智能web算法》</h5><p>作者Haralambos Marmanis、Dmitry Babenko。这本书中的公式比《集体智慧编程》要略多一点，里面的例子多是互联网上的应用，看名字就知道。不足的地方在于里面的配套代码是BeanShell而不是python或其他。总起来说，这本书还是适合初学者，与上一本一样需要快速读完，如果读完上一本的话，这一本可以不必细看代码，了解算法主要思想就行了。</p>
<h5 id="4-《统计学习方法》"><a href="#4-《统计学习方法》" class="headerlink" title="4.《统计学习方法》"></a>4.《统计学习方法》</h5><p>作者李航，是国内机器学习领域的几个大家之一，曾在MSRA任高级研究员，现在华为诺亚方舟实验室。书中写了十个算法，每个算法的介绍都很干脆，直接上公式，是彻头彻尾的“干货书”。每章末尾的参考文献也方便了想深入理解算法的童鞋直接查到经典论文；本书可以与上面两本书互为辅助阅读。</p>
<h5 id="5-《Machine-Learning》（《机器学习》）"><a href="#5-《Machine-Learning》（《机器学习》）" class="headerlink" title="5.《Machine Learning》（《机器学习》）"></a>5.《Machine Learning》（《机器学习》）</h5><p>作者Tom Mitchell是CMU的大师，有机器学习和半监督学习的网络课程视频。这本书是领域内翻译的较好的书籍，讲述的算法也比《统计学习方法》的范围要大很多。据评论这本书主要在于启发，讲述公式为什么成立而不是推导；不足的地方在于出版年限较早，时效性不如PRML。但有些基础的经典还是不会过时的，所以这本书现在几乎是机器学习的必读书目。</p>
<h5 id="6-《Mining-of-Massive-Datasets》（《大数据》）"><a href="#6-《Mining-of-Massive-Datasets》（《大数据》）" class="headerlink" title="6.《Mining of Massive Datasets》（《大数据》）"></a>6.《Mining of Massive Datasets》（《大数据》）</h5><p>作者Anand Rajaraman[3]、Jeffrey David Ullman，Anand是Stanford的PhD。这本书介绍了很多算法，也介绍了这些算法在数据规模比较大的时候的变形。但是限于篇幅，每种算法都没有展开讲的感觉，如果想深入了解需要查其他的资料，不过这样的话对算法进行了解也足够了。还有一点不足的地方就是本书原文和翻译都有许多错误，勘误表比较长，读者要用心了。</p>
<h5 id="7-《数据挖掘：实用机器学习技术》"><a href="#7-《数据挖掘：实用机器学习技术》" class="headerlink" title="7.《数据挖掘：实用机器学习技术》"></a>7.《数据挖掘：实用机器学习技术》</h5><p>作者Ian H. Witten 、Eibe Frank是weka的作者、新西兰怀卡托大学教授。他们的《ManagingGigabytes》[4]也是信息检索方面的经典书籍。这本书最大的特点是对weka的使用进行了介绍，但是其理论部分太单薄，作为入门书籍还可，但是，经典的入门书籍如《集体智慧编程》、《智能web算法》已经很经典，学习的话不宜读太多的入门书籍，建议只看一些上述两本书没讲到的算法。</p>
<h5 id="8-《机器学习及其应用》"><a href="#8-《机器学习及其应用》" class="headerlink" title="8.《机器学习及其应用》"></a>8.《机器学习及其应用》</h5><p>周志华、杨强主编。来源于“机器学习及其应用研讨会”的文集。该研讨会由复旦大学智能信息处理实验室发起，目前已举办了十届，国内的大牛如李航、项亮、王海峰、刘铁岩、余凯等都曾在该会议上做过讲座。这本书讲了很多机器学习前沿的具体的应用，需要有基础的才能看懂。如果想了解机器学习研究趋势的可以浏览一下这本书。关注领域内的学术会议是发现研究趋势的方法嘛。</p>
<hr>
<h2 id="进阶书单"><a href="#进阶书单" class="headerlink" title="进阶书单"></a>进阶书单</h2><h5 id="1-《Pattern-Classification》（《模式分类》第二版）"><a href="#1-《Pattern-Classification》（《模式分类》第二版）" class="headerlink" title="1.《Pattern Classification》（《模式分类》第二版）"></a>1.《Pattern Classification》（《模式分类》第二版）</h5><p>作者Richard O. Duda[5]、Peter E. Hart、David。模式识别的奠基之作，但对最近呈主导地位的较好的方法SVM、Boosting方法没有介绍，被评“挂一漏万之嫌”。</p>
<h5 id="2-《Pattern-Recognition-And-Machine-Learning》"><a href="#2-《Pattern-Recognition-And-Machine-Learning》" class="headerlink" title="2.《Pattern Recognition And Machine Learning》"></a>2.《Pattern Recognition And Machine Learning》</h5><p>作者Christopher M. Bishop[6]；简称PRML，侧重于概率模型，是贝叶斯方法的扛鼎之作，据评“具有强烈的工程气息，可以配合stanford 大学 Andrew Ng 教授的 Machine Learning 视频教程一起来学，效果翻倍。”</p>
<h5 id="3-《统计学习基础：数据挖掘、推理与预测》第二版"><a href="#3-《统计学习基础：数据挖掘、推理与预测》第二版" class="headerlink" title="3.《统计学习基础：数据挖掘、推理与预测》第二版"></a>3.《统计学习基础：数据挖掘、推理与预测》第二版</h5><p>作者RobertTibshirani、Trevor Hastie、Jerome Friedman。“这本书的作者是Boosting方法最活跃的几个研究人员，发明的Gradient Boosting提出了理解Boosting方法的新角度，极大扩展了Boosting方法的应用范围。这本书对当前最为流行的方法有比较全面深入的介绍，对工程人员参考价值也许要更大一点。另一方面，它不仅总结了已经成熟了的一些技术，而且对尚在发展中的一些议题也有简明扼要的论述。让读者充分体会到机器学习是一个仍然非常活跃的研究领域，应该会让学术研究人员也有常读常新的感受。”</p>
<h5 id="4-《数据挖掘：概念与技术》第三版"><a href="#4-《数据挖掘：概念与技术》第三版" class="headerlink" title="4.《数据挖掘：概念与技术》第三版"></a>4.《数据挖掘：概念与技术》第三版</h5><p>作者（美）Jiawei Han[8]、（加）Micheline Kamber、（加）Jian Pei，其中第一作者是华裔。本书毫无疑问是数据挖掘方面的的经典之作，不过翻译版总是被喷，没办法，大部分翻译过来的书籍都被喷，想要不吃别人嚼过的东西，就好好学习英文吧。</p>
<h5 id="5-《AI-Modern-Approach-2nd》"><a href="#5-《AI-Modern-Approach-2nd》" class="headerlink" title="5.《AI, Modern Approach 2nd》"></a>5.《AI, Modern Approach 2nd》</h5><p>Peter Norvig，无争议的领域经典。</p>
<h5 id="6-《Foundations-of-Statistical-Natural-Language-Processing》"><a href="#6-《Foundations-of-Statistical-Natural-Language-Processing》" class="headerlink" title="6.《Foundations of Statistical Natural Language Processing》"></a>6.《Foundations of Statistical Natural Language Processing》</h5><p>自然语言处理领域公认经典。</p>
<h5 id="7-《Statistical-Learning-Theory》"><a href="#7-《Statistical-Learning-Theory》" class="headerlink" title="7.《Statistical Learning Theory》"></a>7.《Statistical Learning Theory》</h5><p>Vapnik的大作，统计学界的权威，本书将理论上升到了哲学层面，他的另一本书《The Nature ofStatistical Learning Theory》也是统计学习研究不可多得的好书，但是这两本书都比较深入，适合有一定基础的读者。</p>
<hr>
<h2 id="数学基础书单"><a href="#数学基础书单" class="headerlink" title="数学基础书单"></a>数学基础书单</h2><h5 id="1-《矩阵分析》"><a href="#1-《矩阵分析》" class="headerlink" title="1.《矩阵分析》"></a>1.《矩阵分析》</h5><p>Roger Horn。矩阵分析领域无争议的经典</p>
<h5 id="2-《概率论及其应用》"><a href="#2-《概率论及其应用》" class="headerlink" title="2.《概率论及其应用》"></a>2.《概率论及其应用》</h5><p>威廉·费勒。极牛的书，可数学味道太重，不适合做机器学习的</p>
<h5 id="3-《All-Of-Statistics》"><a href="#3-《All-Of-Statistics》" class="headerlink" title="3.《All Of Statistics》"></a>3.《All Of Statistics》</h5><p>机器学习这个方向，统计学也一样非常重要。推荐All of statistics，这是CMU的一本很简洁的教科书，注重概念，简化计算，简化与Machine Learning无关的概念和统计内容，可以说是很好的快速入门材料。</p>
<h5 id="4-《Nonlinear-Programming-2nd》"><a href="#4-《Nonlinear-Programming-2nd》" class="headerlink" title="4.《Nonlinear Programming, 2nd》"></a>4.《Nonlinear Programming, 2nd》</h5><p>最优化方法，非线性规划的参考书。</p>
<h5 id="5-《Convex-Optimization》"><a href="#5-《Convex-Optimization》" class="headerlink" title="5.《Convex Optimization》"></a>5.《Convex Optimization》</h5><p>Boyd的经典书籍，被引用次数超过14000次，面向实际应用，并且有配套代码，是一本不可多得的好书。</p>
<h5 id="6-《Numerical-Optimization》"><a href="#6-《Numerical-Optimization》" class="headerlink" title="6.《Numerical Optimization》"></a>6.《Numerical Optimization》</h5><p>第二版，Nocedal著，非常适合非数值专业的学生和工程师参考，算法流程清晰详细，原理清楚。</p>
<h5 id="7-《Introduction-to-Mathematical-Statistics》"><a href="#7-《Introduction-to-Mathematical-Statistics》" class="headerlink" title="7.《Introduction to Mathematical Statistics》"></a>7.《Introduction to Mathematical Statistics》</h5><p>第六版，Hogg著，本书介绍了概率统计的基本概念以及各种分布，以及ML，Bayesian方法等内容。</p>
<h5 id="8-《An-Introduction-to-Probabilistic-Graphical-Models》"><a href="#8-《An-Introduction-to-Probabilistic-Graphical-Models》" class="headerlink" title="8.《An Introduction to Probabilistic Graphical Models》"></a>8.《An Introduction to Probabilistic Graphical Models》</h5><p>Jordan著，本书介绍了条件独立、分解、混合、条件混合等图模型中的基本概念，对隐变量（潜在变量）也做了详细介绍，相信大家在隐马尔科夫链和用Gaussian混合模型来实现EM算法时遇到过这个概念。</p>
<h5 id="9-《Probabilistic-Graphical-Models-Principles-and-Techniques》"><a href="#9-《Probabilistic-Graphical-Models-Principles-and-Techniques》" class="headerlink" title="9.《Probabilistic Graphical Models-Principles and Techniques》"></a>9.《Probabilistic Graphical Models-Principles and Techniques》</h5><p>Koller著，一本很厚很全面的书，理论性很强，可以作为参考书使用。</p>
<h2 id="大家的补充"><a href="#大家的补充" class="headerlink" title="大家的补充"></a>大家的补充</h2><h5 id="1-线性代数-Linear-Algebra-："><a href="#1-线性代数-Linear-Algebra-：" class="headerlink" title="1. 线性代数 (Linear Algebra)："></a>1. 线性代数 (Linear Algebra)：</h5><p>我想国内的大学生都会学过这门课程，但是，未必每一位老师都能贯彻它的精要。这门学科对于Learning是必备的基础，对它的透彻掌握是必不可少的。Introduction to Linear Algebra (3rd Ed.) by Gilbert Strang.</p>
<p>的难度适中，讲解清晰，重要的是对许多核心的概念讨论得比较透彻。我个人觉得，学习线性代数，最重要的不是去熟练矩阵运算和解方程的方法——这些在实际工作中MATLAB可以代劳，关键的是要深入理解几个基础而又重要的概念：子空间(Subspace)，正交(Orthogonality)，特征值和特征向量(Eigenvalues and eigenvectors)，和线性变换(Linear transform)。从我的角度看来，一本线代教科书的质量，就在于它能否给这些根本概念以足够的重视，能否把它们的联系讲清楚。Strang的这本书在这方面是做得很好的。</p>
<p>而且，这本书有个得天独厚的优势。书的作者长期在MIT讲授线性代数课(18.06)，课程的video在MIT的Open courseware网站上有提供。有时间的朋友可以一边看着名师授课的录像，一边对照课本学习或者复习。</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="http://ocw.mit.edu/OcwWeb/Mathematics/18-06Spring-2005/CourseHome/index.htm8">http://ocw.mit.edu/OcwWeb/Mathematics/18-06Spring-2005/CourseHome/index.htm8</a></p>
<h5 id="2-概率和统计-Probability-and-Statistics"><a href="#2-概率和统计-Probability-and-Statistics" class="headerlink" title="2.概率和统计 (Probability and Statistics):"></a>2.概率和统计 (Probability and Statistics):</h5><p>概率论和统计的入门教科书很多，我目前也没有特别的推荐。我在这里想介绍的是一本关于多元统计的基础教科书：</p>
<p>Applied Multivariate Statistical Analysis (5th Ed.) by Richard A. Johnson and Dean W. Wichern</p>
<p>这本书是我在刚接触向量统计的时候用于学习的，我在香港时做研究的基础就是从此打下了。实验室的一些同学也借用这本书学习向量统计。这本书没有特别追求数学上的深度，而是以通俗易懂的方式讲述主要的基本概念，读起来很舒服，内容也很实用。对于Linear regression, factor analysis, principal component analysis (PCA), and canonical component analysis (CCA)这些Learning中的基本方法也展开了初步的论述。</p>
<p>之后就可以进一步深入学习贝叶斯统计和Graphical models。一本理想的书是</p>
<p>Introduction to Graphical Models (draft version). by M. Jordan and C. Bishop.</p>
<p>我不知道这本书是不是已经出版了（不要和Learning in Graphical Models混淆，那是个论文集，不适合初学）。这本书从基本的贝叶斯统计模型出发一直深入到复杂的统计网络的估计和推断，深入浅出，statistical learning的许多重要方面都在此书有清楚论述和详细讲解。MIT内部可以access，至于外面，好像也是有电子版的。</p>
<h5 id="3-分析-Analysis-："><a href="#3-分析-Analysis-：" class="headerlink" title="3.分析 (Analysis)："></a>3.分析 (Analysis)：</h5><p>我想大家基本都在大学就学过微积分或者数学分析，深度和广度则随各个学校而异了。这个领域是很多学科的基础，值得推荐的教科书莫过于</p>
<p>Principles of Mathematical Analysis, by Walter Rudin</p>
<p>有点老，但是绝对经典，深入透彻。缺点就是比较艰深——这是Rudin的书的一贯风格，适合于有一定基础后回头去看。</p>
<p>在分析这个方向，接下来就是泛函分析(Functional Analysis)。</p>
<p>Introductory Functional Analysis with Applications, by Erwin Kreyszig.</p>
<p>适合作为泛函的基础教材，容易切入而不失全面。我特别喜欢它对于谱论和算子理论的特别关注，这对于做learning的研究是特别重要的。Rudin也有一本关于functional analysis的书，那本书在数学上可能更为深刻，但是不易于上手，所讲内容和learning的切合度不如此书。</p>
<p>在分析这个方向，还有一个重要的学科是测度理论(Measure theory)，但是我看过的书里面目前还没有感觉有特别值得介绍的。</p>
<h5 id="4-拓扑-Topology-："><a href="#4-拓扑-Topology-：" class="headerlink" title="4.拓扑 (Topology)："></a>4.拓扑 (Topology)：</h5><p>在我读过的基本拓扑书各有特色，但是综合而言，我最推崇：</p>
<p>Topology (2nd Ed.) by James Munkres</p>
<p>这本书是Munkres教授长期执教MIT拓扑课的心血所凝。对于一般拓扑学(General topology)有全面介绍，而对于代数拓扑(Algebraic topology)也有适度的探讨。此书不需要特别的数学知识就可以开始学习，由浅入深，从最基本的集合论概念（很多书不屑讲这个）到Nagata-Smirnov Theorem和Tychonoff theorem等较深的定理（很多书避开了这个）都覆盖了。讲述方式思想性很强，对于很多定理，除了给出证明过程和引导你思考其背后的原理脉络，很多令人赞叹的亮点——我常读得忘却饥饿，不愿释手。很多习题很有水平。</p>
<h5 id="5-流形理论-Manifold-theory-："><a href="#5-流形理论-Manifold-theory-：" class="headerlink" title="5.流形理论 (Manifold theory)："></a>5.流形理论 (Manifold theory)：</h5><p>对于拓扑和分析有一定把握时，方可开始学习流形理论，否则所学只能流于浮浅。我所使用的书是</p>
<p>Introduction to Smooth Manifolds. by John M. Lee</p>
<p>虽然书名有introduction这个单词，但是实际上此书涉入很深，除了讲授了基本的manifold, tangent space, bundle, sub-manifold等，还探讨了诸如纲理论(Category theory)，德拉姆上同调(De Rham cohomology)和积分流形等一些比较高级的专题。对于李群和李代数也有相当多的讨论。行文通俗而又不失严谨，不过对某些记号方式需要熟悉一下。</p>
<p>虽然李群论是建基于平滑流形的概念之上，不过，也可能从矩阵出发直接学习李群和李代数——这种方法对于急需使用李群论解决问题的朋友可能更加实用。而且，对于一个问题从不同角度看待也利于加深理解。下面一本书就是这个方向的典范：</p>
<p>Lie Groups, Lie Algebras, and Representations: An Elementary Introduction. by Brian C. Hall</p>
<p>此书从开始即从矩阵切入，从代数而非几何角度引入矩阵李群的概念。并通过定义运算的方式建立exponential mapping，并就此引入李代数。这种方式比起传统的通过“左不变向量场(Left-invariant vector field)“的方式定义李代数更容易为人所接受，也更容易揭示李代数的意义。最后，也有专门的论述把这种新的定义方式和传统方式联系起来。</p>
<h2 id="机器学习领域经典论文"><a href="#机器学习领域经典论文" class="headerlink" title="机器学习领域经典论文"></a><strong>机器学习领域经典论文</strong></h2><p>除了以上推荐的书以外，出版在Foundations and Trends in Machine Learning上面的survey文章都值得一看。</p>
<p><strong>入门</strong>：</p>
<p>Pattern Recognition And Machine Learning</p>
<p>Christopher M. Bishop</p>
<p>Machine Learning : A Probabilistic Perspective</p>
<p>Kevin P. Murphy</p>
<p>The Elements of Statistical Learning : Data Mining, Inference, and Predictio<br>n</p>
<p>Trevor Hastie, Robert Tibshirani, Jerome Friedman</p>
<p>Information Theory, Inference and Learning Algorithms</p>
<p>David J. C. MacKay</p>
<p>All of Statistics : A Concise Course in Statistical Inference</p>
<p>Larry Wasserman</p>
<p><strong>优化</strong>：</p>
<p>Convex Optimization</p>
<p>Stephen Boyd, Lieven Vandenberghe</p>
<p>Numerical Optimization</p>
<p>Jorge Nocedal, Stephen Wright</p>
<p>Optimization for Machine Learning</p>
<p>Suvrit Sra, Sebastian Nowozin, Stephen J. Wright</p>
<p><strong>核方法</strong>：</p>
<p>Kernel Methods for Pattern Analysis</p>
<p>John Shawe-Taylor, Nello Cristianini</p>
<p>Learning with Kernels : Support Vector Machines, Regularization, Optimizatio<br>n, and Beyond</p>
<p>Bernhard Schlkopf, Alexander J. Smola</p>
<p><strong>半监督</strong>：</p>
<p>Semi-Supervised Learning</p>
<p>Olivier Chapelle</p>
<p><strong>高斯过程</strong>：</p>
<p>Gaussian Processes for Machine Learning (Adaptive Computation and Machine Le<br>arning)</p>
<p>Carl Edward Rasmussen, Christopher K. I. Williams</p>
<p><strong>概率图模型</strong>：</p>
<p>Graphical Models, Exponential Families, and Variational Inference</p>
<p>Martin J Wainwright, Michael I Jordan</p>
<p>Boosting:</p>
<p>Boosting : Foundations and Algorithms</p>
<p>Schapire, Robert E.; Freund, Yoav</p>
<p><strong>贝叶斯</strong>:</p>
<p>Statistical Decision Theory and Bayesian Analysis</p>
<p>James O. Berger</p>
<p>The Bayesian Choice : From Decision-Theoretic Foundations to Computational I<br>mplementation</p>
<p>Christian P. Robert</p>
<p>Bayesian Nonparametrics</p>
<p>Nils Lid Hjort, Chris Holmes, Peter Müller, Stephen G. Walker</p>
<p>Principles of Uncertainty</p>
<p>Joseph B. Kadane</p>
<p>Decision Theory : Principles and Approaches</p>
<p>Giovanni Parmigiani, Lurdes Inoue</p>
<p><strong>蒙特卡洛</strong>：</p>
<p>Monte Carlo Strategies in Scientific Computing</p>
<p>Jun S. Liu</p>
<p>Monte Carlo Statistical Methods</p>
<p>Christian P.Robert, George Casella</p>
<p><strong>信息几何</strong>：</p>
<p>Methods of Information Geometry</p>
<p>Shun-Ichi Amari, Hiroshi Nagaoka</p>
<p>Algebraic Geometry and Statistical Learning Theory</p>
<p>Watanabe, Sumio</p>
<p>Differential Geometry and Statistics</p>
<p>M.K. Murray, J.W. Rice</p>
<p><strong>渐进收敛</strong>：</p>
<p>Asymptotic Statistics</p>
<p>A. W. van der Vaart</p>
<p>Empirical Processes in M-estimation</p>
<p>Geer, Sara A. van de</p>
<p><strong>不推荐</strong>：</p>
<p>Statistical Learning Theory</p>
<p>Vladimir N. Vapnik</p>
<p>Bayesian Data Analysis, Second Edition</p>
<p>Andrew Gelman, John B. Carlin, Hal S. Stern, Donald B. Rubin</p>
<p>Probabilistic Graphical Models : Principles and Techniques</p>
<p>Daphne Koller, Nir Friedman</p>
<h2 id="机器学习经典论文-survey合集"><a href="#机器学习经典论文-survey合集" class="headerlink" title="机器学习经典论文/survey合集"></a><strong>机器学习经典论文/survey合集</strong></h2><p><strong>Active Learning</strong></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/106.pdf">Two Faces of Active Learning50</a>, Dasgupta, 2011</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/104.pdf">Active Learning Literature Survey8</a>, Settles, 2010</p>
<p><strong>Applications</strong></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/100.pdf">A Survey of Emerging Approaches to Spam Filtering9</a>, Caruana, 2012</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/83.pdf">Ambient Intelligence: A Survey3</a>, Sadri, 2011</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/88.pdf">A Survey of Online Failure Prediction Methods2</a>, Salfner, 2010</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/23.pdf">Anomaly Detection: A Survey3</a>, Chandola, 2009</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/81.pdf">Mining Data Streams: A Review4</a>, Gaber, 2005</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/37.pdf">Workflow Mining: A Survey of Issues and Approaches2</a>, Aalst, 2003</p>
<p><strong>Biology</strong></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/125.pdf">Support Vector Machines in Bioinformatics: a Survey12</a>, Chicco, 2012</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/63.pdf">Computational Epigenetics: The New Scientific Paradigm 3</a>, Lim, 2010</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/2.pdf">Automated Protein Structure Classification: A Survey4</a>, Hassanzadeh, 2009</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/62.pdf">Chemoinformatics - An Introduction for Computer Scientists3</a>, Brown, 2009</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/77.pdf">Computational Challenges in Systems Biology2</a>, Heath, 2009</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/64.pdf">Computational Epigenetics 3</a>, Bock, 2008</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/68.pdf">Progress and Challenges in Protein Structure Prediction3</a>, Zhang, 2008</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/58.pdf">A Review of Feature Selection in Bioinformatics4</a>, Saeys, 2007</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/57.pdf">Machine Learning in Bioinformatics: A Brief Survey and Recommendations for Practitioners6</a>, Bhaskar, 2006</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/3.pdf">Bioinformatics - An Introduction for Computer Scientists1</a>, Cohen, 2004</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/66.pdf">Computational Systems Biology2</a>, Kitano, 2002</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/69.pdf">Protein Structure Prediction and Structural Genomics2</a>, Baker, 2001</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/70.pdf">Recent Developments and Future Directions in Computational Genomics1</a>, Tsoka, 2000</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/14.pdf">Molecular Biology for Computer Scientists1</a>, Hunter, 1993</p>
<p><strong>Classification</strong></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/54.pdf">Supervised Machine Learning: A Review of Classification Techniques22</a>, Kotsiantis, 2007</p>
<p><strong>Clustering</strong></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/84.pdf">XML Data Clustering: An Overview4</a>, Algergawy, 2011</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/45.pdf">Data Clustering: 50 Years Beyond K-Means6</a>, Jain, 2010</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/105.pdf">Clustering Stability: An Overview5</a>, Luxburg, 2010</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/46.pdf">Parallel Clustering Algorithms: A Survey4</a>, Kim, 2009</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/47.pdf">A Survey: Clustering Ensembles Techniques2</a>, Ghaemi, 2009</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/25.pdf">A Tutorial on Spectral Clustering4</a>, Luxburg, 2007</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/15.pdf">Survey of Clustering Data Mining Techniques4</a>, Berkhin, 2006</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/16.pdf">Survey of Clustering Algorithms4</a>, Xu, 2005</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/22.pdf">Clustering of Time Series Data - A Survey3</a>, Liao, 2005</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/51.pdf">Clustering Methods4</a>, Rokach, 2005</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/24.pdf">Recent Advances in Clustering: A Brief Survey2</a>, Kotsiantis, 2004</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/28.pdf">Subspace Clustering for High Dimensional Data: A Review2</a>, Parsons, 2004</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/48.pdf">Unsupervised and Semi-supervised Clustering: a Brief Survey3</a>, Grira, 2004</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/40.pdf">Clustering in Life Sciences3</a>, Zhao, 2002</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/26.pdf">On Clustering Validation Techniques2</a>, Halkidi, 2001</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/18.pdf">Data Clustering: A Review3</a>, Jain, 1999</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/21.pdf">A Survey of Fuzzy Clustering4</a>, Yang, 1993</p>
<p><strong>Computer Vision</strong></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/97.pdf">Pedestrian Detection: An Evaluation of the State of the Art7</a>, Dollar, 2012</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/101.pdf">A Comparative Study of Palmprint Recognition Algorithms3</a>, Zhang, 2012</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/85.pdf">Human Activity Analysis: A Review2</a>, Aggarwal, 2011</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/79.pdf">Subspace Methods for Face Recognition2</a>, Rao, 2010</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/136.pdf">Context Based Object Categorization: A Critical Survey2</a>, Galleguillos, 2010</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/29.pdf">Object tracking: A Survey3</a>, Yilmaz, 2006</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/35.pdf">Detecting Faces in Images: A Survey2</a>, Yang, 2002</p>
<p><strong>Databases</strong></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/7.pdf">Data Fusion3</a>, Bleiholder, 2008</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/8.pdf">Duplicate Record Detection: A Survey2</a>, Elmagarmid, 2007</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/72.pdf">Overview of Record Linkage and Current Research Directions2</a>, Winkler, 2006</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/32.pdf">A Survey of Schema-based Matching Approaches3</a>, Shvaiko, 2005</p>
<p><strong>Deep Learning</strong></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/110.pdf">Representation Learning: A Review and New Perspectives17</a>, Bengio, 2012</p>
<p><strong>Dimension Reduction</strong></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/9.pdf">Dimensionality Reduction: A Comparative Review6</a>, Maaten, 2009</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/132.pdf">Dimension Reduction: A Guided Tour4</a>, Burges, 2009</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/129.pdf">A Survey of Manifold-Based Learning Methods2</a>, Huo, 2007</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/12.pdf">Toward Integrating Feature Selection Algorithms for Classification and Clustering3</a>, Liu, 2005</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/11.pdf">An Introduction to Variable and Feature Selection3</a>, Guyon, 2003</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/10.pdf">A Survey of Dimension Reduction Techniques2</a>, Fodor, 2002</p>
<p><strong>Economics</strong></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/67.pdf">Auctions and Bidding: A Guide for Computer Scientists1</a>, Parsons, 2011</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/65.pdf">Computational Sustainability1</a>, Gomes, 2009</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/71.pdf">Computational Finance1</a>, Tsang, 2004</p>
<p><strong>Game Theory</strong></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/76.pdf">Computer Poker: A Review4</a>, Rubin, 2011</p>
<p><strong>Graphical Models</strong></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/123.pdf">An Introduction to Variational Methods for Graphical Models5</a>, Jordan, 1999</p>
<p><strong>Kernel Methods</strong></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/131.pdf">Kernels for Vector-Valued Functions: a Review4</a>, Alvarez, 2012</p>
<p><strong>Learning Theory</strong></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/118.pdf">Introduction to Statistical Learning Theory7</a>, Bousquet, 2004</p>
<p><strong>Machine Learning</strong></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/124.pdf">A Few Useful Things to Know about Machine Learning7</a>, Domingos, 2012</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/109.pdf">A Tutorial on Bayesian Nonparametric Models4</a>, Blei, 2011</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/119.pdf">Decision Forests for Classification, Regression, Density Estimation, Manifold Learning and Semi-Supervised Learning2</a>, Criminisi, 2011</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/121.pdf">Top 10 Algorithms in Data Mining4</a>, Wu, 2008</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/17.pdf">Semi-Supervised Learning Literature Survey</a>, Zhu, 2007</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/42.pdf">Interestingness Measures for Data Mining: A Survey</a>, Geng, 2006</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/43.pdf">A Survey of Interestingness Measures for Knowledge Discovery1</a>, McGarry, 2005</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/115.pdf">A Tutorial on the Cross-Entropy Method</a>, Boer, 2005</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/30.pdf">A Survey of Kernels for Structured Data</a>, Gartner, 2003</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/44.pdf">Survey on Frequent Pattern Mining</a>, Goethals, 2003</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/122.pdf">The Boosting Approach to Machine Learning: An Overview1</a>, Schapire, 2003</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/86.pdf">A Survey on Wavelet Applications in Data Mining</a>, Li, 2002</p>
<p><strong>Mathematics</strong></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/126.pdf">Topology and Data3</a>, Carlsson, 2009</p>
<p><strong>Multi-armed Bandit</strong></p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://s3-us-west-2.amazonaws.com/mlsurveys/133.pdf">Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems3</a>, Bubeck, 2012</p>
<p><strong>Natural Computing</strong></p>
<p>Reservoir Computing Approaches to Recurrent Neural Network Training, Jaeger, 2009</p>
<p>Artificial Immune Systems, Aickelin, 2005</p>
<p>A Survey of Evolutionary Algorithms for Data Mining and Knowledge Discovery, Freitas?? , 2003</p>
<p>Data Mining in Soft Computing Framework: A Survey, Mitra, 2002</p>
<p>Neural Networks for Classification: A Survey1, Zhang, 2000</p>
<p><strong>Natural Language Processing</strong></p>
<p>Probabilistic Topic Models2, Blei, 2012</p>
<p>Ontology Learning From Text: A Look Back And Into The Future1, Wong, 2012</p>
<p>Machine Transliteration Survey, Karimi, 2011</p>
<p>Translation Techniques in Cross-Language Information Retrieval, Zhou, 2011</p>
<p>Comprehensive Review of Opinion Summarization, Kim, 2011</p>
<p>A Survey on Sentiment Detection of Reviews, Tang, 2009</p>
<p>Word Sense Desambiguation: A Survey, Navigli, 2009</p>
<p>Topic Models, Blei, 2009</p>
<p>Opinion Mining and Sentiment Analysis, Pang, 2008</p>
<p>Information Extraction, Sarawagi, 2008</p>
<p>Statistical Machine Translation, Lopez, 2008</p>
<p>A Survey of Named Entity Recognition and Classification, Nadeau, 2007</p>
<p>Adaptive Information Extraction, Turmo, 2006</p>
<p>Survey of Text Clustering, Jing, 2005</p>
<p>Machine Learning in Automated Text Categorization, Sebastiani, 2002</p>
<p>Web Mining Research: A Survey, Kosala, 2000</p>
<p><strong>Networks</strong></p>
<p>Community Detection in Graphs1, Fortunato, 2010</p>
<p>A Survey of Statistical Network Models, Goldenberg, 2010</p>
<p>Communities in Networks, Porter, 2009</p>
<p>Graph Clustering, Schaeffer, 2007</p>
<p>Graph Mining: Laws, Generators, and Algorithms, Chakrabarti, 2006</p>
<p>Comparing Community Structure Identification, Danon, 2005</p>
<p>Link Mining: A Survey1, Getoor, 2005</p>
<p>Detecting Community Structure in Networks, Newman, 2004</p>
<p>Link Mining: A New Data Mining Challenge, Getoor, 2003</p>
<p><strong>On-Line Learning</strong></p>
<p>On-Line Algorithms in Machine Learning1, Blum, 1998</p>
<p><strong>Others</strong></p>
<p>A Survey of Very Large-Scale Neighborhood Search Techniques, Ahuja, 2001</p>
<p><strong>Planning and Scheduling</strong></p>
<p>A Review of Machine Learning for Automated Planning1, Jimenez, 2009</p>
<p><strong>Probabilistic</strong></p>
<p>Approximate Policy Iteration: A Survey and Some New Methods, Bertsekas, 2011</p>
<p>An Introduction to MCMC for Machine Learning1, Andrieu, 2003</p>
<p><strong>Probabilistic Models</strong></p>
<p>An Introduction to Conditional Random Fields1, Sutton, 2010</p>
<p><strong>Randomized Algorithms</strong></p>
<p>Randomized Algorithms for Matrices and Data1, Mahoney, 2011</p>
<p><strong>Recommender Systems</strong></p>
<p>Recent advances in Personalized Recommender Systems1, Liu, 2009</p>
<p>Matrix Factorization Techniques for Recommender Systems1, Koren, 2009</p>
<p>A Survey of Collaborative Filtering Techniques1, Su, 2009</p>
<p><strong>Regression</strong></p>
<p>Ensemble Approaches for Regression: a Survey4, Moreira, 2012</p>
<p><strong>Reinforcement Learning</strong></p>
<p>A Survey of Reinforcement Learning in Relational Domains1, Otterlo, 2005</p>
<p>Reinforcement Learning: A Survey, Kaelbling, 1996</p>
<p><strong>Rule Learning</strong></p>
<p>Association Mining, Ceglar, 2006</p>
<p>Algorithms for Association Rule Mining - A General Survey and Comparison, Hipp, 2000</p>
<p><strong>Testing</strong></p>
<p>Controlled Experiments on the Web: Survey and Practical Guide, Kohavi, 2009</p>
<p><strong>Time Series</strong></p>
<p>Time-Series Data Mining2, Esling, 2012</p>
<p>A Review on Time Series Data Mining1, Fu, 2011</p>
<p>Discrete Wavelet Transform-Based Time Series Analysis and Mining, Chaovalit, 2011</p>
<p><strong>Transfer Learning</strong></p>
<p>A Survey on Transfer Learning, Pan, 2010</p>
<p><strong>Web Mining</strong></p>
<p>A Taxonomy of Sequential Pattern Mining Algorithms, Mabroukeh, 2010</p>
<p>A Survey of Web Clustering Engines, Carpineto, 2009</p>
<p>Web Page Classification: Features and Algorithms, Qi, 2009</p>
<p>Mining Interesting Knowledge from Weblogs: A Survey, Facca, 2005</p>
<p>An Overview of Web Data Clustering Practices, Vakali, 2005</p>
<p>A Survey of Web Metrics, Dhyani, 2002</p>
<p>Data Mining for Hypertext: A Tutorial Survey3, Chakrabarti, 2000</p>
		
  </div>	
<div>
  	  <br>
	<div style="height:20px;border:none;border-top:1px solid #000;"></div>  
	<!--
    <div style="margin-left: 125px;">
    <div style="float: left; width: 200px; height: 200px;">
        <img class="adv" style="width: 100%; height: 100%; border: solid 1px #ddd;" src="https://pic4.zhimg.com/80/v2-6f4153925b20af12b17837b531302695_720w.jpeg">
    </div>
	
    <div style="float: left; margin-left: 35px;">
        <div style="font-size: 28px; margin-bottom: 12px;margin-left: 4px;">关注我的公众号</div>
        <small style="font-size: 1.2em;">
            →「技术干货」每日推送<br><br>
            →「免费资料」随时领取<br><br>
            →「签到活动」每周福利<br><br>
        </small>
    </div>
    <div style="clear: both;"></div>	
	</div>	
	-->
  	<p align="center" style="margin-top: 15px; font-size: 16px;color: #337ab7;">
       <strong><a href="https://tanqingbo.cn/CSBook001/" target="_blank" style="unicode-bidi: isolate;font-variant-numeric: tabular-nums;text-transform: none;text-decoration-line: underline;">点击下载：计算机专业最全PDF高清电子书！</a></strong>
    </p>
  
<div>
  
  <div class="post-note note-warning copyright" style="margin-top: 42px">
    <p><span style="font-weight: bold;">作者：</span><a target="_blank" rel="nofollow noopener noreferrer" href="https://tanqingbo.cn/about">IT码农</a></p>
    <p><span style="font-weight: bold;">文章链接：</span><a target="_blank" rel="nofollow noopener noreferrer" href="https://tanqingbo.cn/ML-EBook-paper/">https://tanqingbo.cn/ML-EBook-paper/</a></p>
    <p><span style="font-weight: bold;">版权声明：</span>本博客所有文章除特别声明外，均采用<a target="_blank" rel="noopener external nofollow noreferrer" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">CC BY-NC-SA 4.0 协议</a>。转载请注明出处！</p>
  </div>
  
  </div>
</article>
<div class="nav">
  
  <div class="nav-item-prev">
    <a href="/CS-Classic-Books/" class="nav-link">
      <i class="iconfont icon-left nav-prev-icon"></i>
      <div>
        <div class="nav-label">上一篇</div>
        
        <div class="nav-title">计算机专业必读哪些经典书籍？ </div>
        
      </div>
    </a>
  </div>
  
  
  <div class="nav-item-next">
    <a href="/10-website/" class="nav-link">
      <div>
        <div class="nav-label">下一篇</div>
        
        <div class="nav-title">推荐10个堪称神器的网站 </div>
        
      </div>
      <i class="iconfont icon-right nav-next-icon"></i>
    </a>
  </div>
  
</div>

<div class="card card-content comment-card" style="margin-top: 16px;">
  <div class="comment-card-title">评论</div>
  
  <div id="vcomments"></div>
  
  <script>
    loadScript("https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js");
    var oldLoadVa = window.onload;
    window.onload = function () {
      oldLoadVa && oldLoadVa();
      new Valine({
        el: '#vcomments',
        appId: 'RtYsYDbddUcoEbJrbQcpPgP2-gzGzoHsz',
        appKey: 'M8e7BRAbupxzxRVSoj9JkJ5E',
        placeholder: 'Just go go',
        path: window.location.pathname,
        avatar: 'mp',
        meta: ["nick","mail","link"],
        pageSize: '10',
        lang: '',
        visitor: 'true',
        highlight: true,
        recordIP: false,
        
        
        
        enableQQ: 'false',
        requiredFields: [],
      });
    };
  </script>

</div>

<div class="card card-content toc-card" id="mobiletoc">
  <div class="toc-header"><i class="iconfont icon-menu" style="padding-right: 2px;"></i>目录</div>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%A5%E9%97%A8%E4%B9%A6%E5%8D%95"><span class="toc-text">入门书单</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E3%80%8A%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E%E3%80%8B"><span class="toc-text">1.《数学之美》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E3%80%8A%E9%9B%86%E4%BD%93%E6%99%BA%E6%85%A7%E7%BC%96%E7%A8%8B%E3%80%8B"><span class="toc-text">2.《集体智慧编程》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E3%80%8A%E6%99%BA%E8%83%BDweb%E7%AE%97%E6%B3%95%E3%80%8B"><span class="toc-text">3.《智能web算法》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B"><span class="toc-text">4.《统计学习方法》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5-%E3%80%8AMachine-Learning%E3%80%8B%EF%BC%88%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%89"><span class="toc-text">5.《Machine Learning》（《机器学习》）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#6-%E3%80%8AMining-of-Massive-Datasets%E3%80%8B%EF%BC%88%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E3%80%8B%EF%BC%89"><span class="toc-text">6.《Mining of Massive Datasets》（《大数据》）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7-%E3%80%8A%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%9A%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%9C%AF%E3%80%8B"><span class="toc-text">7.《数据挖掘：实用机器学习技术》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#8-%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E3%80%8B"><span class="toc-text">8.《机器学习及其应用》</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%9B%E9%98%B6%E4%B9%A6%E5%8D%95"><span class="toc-text">进阶书单</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E3%80%8APattern-Classification%E3%80%8B%EF%BC%88%E3%80%8A%E6%A8%A1%E5%BC%8F%E5%88%86%E7%B1%BB%E3%80%8B%E7%AC%AC%E4%BA%8C%E7%89%88%EF%BC%89"><span class="toc-text">1.《Pattern Classification》（《模式分类》第二版）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E3%80%8APattern-Recognition-And-Machine-Learning%E3%80%8B"><span class="toc-text">2.《Pattern Recognition And Machine Learning》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E3%80%81%E6%8E%A8%E7%90%86%E4%B8%8E%E9%A2%84%E6%B5%8B%E3%80%8B%E7%AC%AC%E4%BA%8C%E7%89%88"><span class="toc-text">3.《统计学习基础：数据挖掘、推理与预测》第二版</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-%E3%80%8A%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%9A%E6%A6%82%E5%BF%B5%E4%B8%8E%E6%8A%80%E6%9C%AF%E3%80%8B%E7%AC%AC%E4%B8%89%E7%89%88"><span class="toc-text">4.《数据挖掘：概念与技术》第三版</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5-%E3%80%8AAI-Modern-Approach-2nd%E3%80%8B"><span class="toc-text">5.《AI, Modern Approach 2nd》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#6-%E3%80%8AFoundations-of-Statistical-Natural-Language-Processing%E3%80%8B"><span class="toc-text">6.《Foundations of Statistical Natural Language Processing》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7-%E3%80%8AStatistical-Learning-Theory%E3%80%8B"><span class="toc-text">7.《Statistical Learning Theory》</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E4%B9%A6%E5%8D%95"><span class="toc-text">数学基础书单</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E3%80%8A%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90%E3%80%8B"><span class="toc-text">1.《矩阵分析》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E3%80%8A%E6%A6%82%E7%8E%87%E8%AE%BA%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E3%80%8B"><span class="toc-text">2.《概率论及其应用》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E3%80%8AAll-Of-Statistics%E3%80%8B"><span class="toc-text">3.《All Of Statistics》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-%E3%80%8ANonlinear-Programming-2nd%E3%80%8B"><span class="toc-text">4.《Nonlinear Programming, 2nd》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5-%E3%80%8AConvex-Optimization%E3%80%8B"><span class="toc-text">5.《Convex Optimization》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#6-%E3%80%8ANumerical-Optimization%E3%80%8B"><span class="toc-text">6.《Numerical Optimization》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7-%E3%80%8AIntroduction-to-Mathematical-Statistics%E3%80%8B"><span class="toc-text">7.《Introduction to Mathematical Statistics》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#8-%E3%80%8AAn-Introduction-to-Probabilistic-Graphical-Models%E3%80%8B"><span class="toc-text">8.《An Introduction to Probabilistic Graphical Models》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#9-%E3%80%8AProbabilistic-Graphical-Models-Principles-and-Techniques%E3%80%8B"><span class="toc-text">9.《Probabilistic Graphical Models-Principles and Techniques》</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E5%AE%B6%E7%9A%84%E8%A1%A5%E5%85%85"><span class="toc-text">大家的补充</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-Linear-Algebra-%EF%BC%9A"><span class="toc-text">1. 线性代数 (Linear Algebra)：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E6%A6%82%E7%8E%87%E5%92%8C%E7%BB%9F%E8%AE%A1-Probability-and-Statistics"><span class="toc-text">2.概率和统计 (Probability and Statistics):</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E5%88%86%E6%9E%90-Analysis-%EF%BC%9A"><span class="toc-text">3.分析 (Analysis)：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-%E6%8B%93%E6%89%91-Topology-%EF%BC%9A"><span class="toc-text">4.拓扑 (Topology)：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5-%E6%B5%81%E5%BD%A2%E7%90%86%E8%AE%BA-Manifold-theory-%EF%BC%9A"><span class="toc-text">5.流形理论 (Manifold theory)：</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A2%86%E5%9F%9F%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87"><span class="toc-text">机器学习领域经典论文</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87-survey%E5%90%88%E9%9B%86"><span class="toc-text">机器学习经典论文&#x2F;survey合集</span></a></li></ol>
</div></main>
          <aside class="left-column">
            
            <div class="card card-author">
              
<img src="/img/logo.jpg" class="author-img">

<p class="author-name">IT&nbsp; 码&nbsp; 农</p>
<p class="author-description">一个专注于程序员成长的网站</p>
<div class="author-message">
  <a class="author-posts-count" href="/archives">
    <span>204</span>
    <span>文章</span>
  </a>
  <a class="author-categories-count" href="/categories">
    <span>13</span>
    <span>分类</span>
  </a>
  <a class="author-tags-count" href="/tags">
    <span>114</span>
    <span>标签</span>
  </a>
</div>

<div class="author-card-society">
  
    <div class="author-card-society-icon">
      <a target="_blank" rel="noopener external nofollow noreferrer" href="https://cdn.jsdelivr.net/gh/tqb4342/BlogPhoto@master/20201215143241.png">
        <i class="iconfont icon-wechat society-icon"></i>
      </a>
    </div>
  
    <div class="author-card-society-icon">
      <a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/tqb4342">
        <i class="iconfont icon-github society-icon"></i>
      </a>
    </div>
  
    <div class="author-card-society-icon">
      <a target="_blank" rel="noopener external nofollow noreferrer" href="https://weibo.com/tqb4342">
        <i class="iconfont icon-sina society-icon"></i>
      </a>
    </div>
  
</div>

            </div>
            
            <div class="sticky-tablet">
  
  
  <article class="display-when-two-columns spacer">
    <div class="card card-content toc-card">
      <div class="toc-header"><i class="iconfont icon-menu" style="padding-right: 2px;"></i>目录</div>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%A5%E9%97%A8%E4%B9%A6%E5%8D%95"><span class="toc-text">入门书单</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E3%80%8A%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E%E3%80%8B"><span class="toc-text">1.《数学之美》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E3%80%8A%E9%9B%86%E4%BD%93%E6%99%BA%E6%85%A7%E7%BC%96%E7%A8%8B%E3%80%8B"><span class="toc-text">2.《集体智慧编程》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E3%80%8A%E6%99%BA%E8%83%BDweb%E7%AE%97%E6%B3%95%E3%80%8B"><span class="toc-text">3.《智能web算法》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B"><span class="toc-text">4.《统计学习方法》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5-%E3%80%8AMachine-Learning%E3%80%8B%EF%BC%88%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%89"><span class="toc-text">5.《Machine Learning》（《机器学习》）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#6-%E3%80%8AMining-of-Massive-Datasets%E3%80%8B%EF%BC%88%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E3%80%8B%EF%BC%89"><span class="toc-text">6.《Mining of Massive Datasets》（《大数据》）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7-%E3%80%8A%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%9A%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%9C%AF%E3%80%8B"><span class="toc-text">7.《数据挖掘：实用机器学习技术》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#8-%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E3%80%8B"><span class="toc-text">8.《机器学习及其应用》</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%9B%E9%98%B6%E4%B9%A6%E5%8D%95"><span class="toc-text">进阶书单</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E3%80%8APattern-Classification%E3%80%8B%EF%BC%88%E3%80%8A%E6%A8%A1%E5%BC%8F%E5%88%86%E7%B1%BB%E3%80%8B%E7%AC%AC%E4%BA%8C%E7%89%88%EF%BC%89"><span class="toc-text">1.《Pattern Classification》（《模式分类》第二版）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E3%80%8APattern-Recognition-And-Machine-Learning%E3%80%8B"><span class="toc-text">2.《Pattern Recognition And Machine Learning》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E3%80%81%E6%8E%A8%E7%90%86%E4%B8%8E%E9%A2%84%E6%B5%8B%E3%80%8B%E7%AC%AC%E4%BA%8C%E7%89%88"><span class="toc-text">3.《统计学习基础：数据挖掘、推理与预测》第二版</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-%E3%80%8A%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%9A%E6%A6%82%E5%BF%B5%E4%B8%8E%E6%8A%80%E6%9C%AF%E3%80%8B%E7%AC%AC%E4%B8%89%E7%89%88"><span class="toc-text">4.《数据挖掘：概念与技术》第三版</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5-%E3%80%8AAI-Modern-Approach-2nd%E3%80%8B"><span class="toc-text">5.《AI, Modern Approach 2nd》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#6-%E3%80%8AFoundations-of-Statistical-Natural-Language-Processing%E3%80%8B"><span class="toc-text">6.《Foundations of Statistical Natural Language Processing》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7-%E3%80%8AStatistical-Learning-Theory%E3%80%8B"><span class="toc-text">7.《Statistical Learning Theory》</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E4%B9%A6%E5%8D%95"><span class="toc-text">数学基础书单</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E3%80%8A%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90%E3%80%8B"><span class="toc-text">1.《矩阵分析》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E3%80%8A%E6%A6%82%E7%8E%87%E8%AE%BA%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E3%80%8B"><span class="toc-text">2.《概率论及其应用》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E3%80%8AAll-Of-Statistics%E3%80%8B"><span class="toc-text">3.《All Of Statistics》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-%E3%80%8ANonlinear-Programming-2nd%E3%80%8B"><span class="toc-text">4.《Nonlinear Programming, 2nd》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5-%E3%80%8AConvex-Optimization%E3%80%8B"><span class="toc-text">5.《Convex Optimization》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#6-%E3%80%8ANumerical-Optimization%E3%80%8B"><span class="toc-text">6.《Numerical Optimization》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7-%E3%80%8AIntroduction-to-Mathematical-Statistics%E3%80%8B"><span class="toc-text">7.《Introduction to Mathematical Statistics》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#8-%E3%80%8AAn-Introduction-to-Probabilistic-Graphical-Models%E3%80%8B"><span class="toc-text">8.《An Introduction to Probabilistic Graphical Models》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#9-%E3%80%8AProbabilistic-Graphical-Models-Principles-and-Techniques%E3%80%8B"><span class="toc-text">9.《Probabilistic Graphical Models-Principles and Techniques》</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E5%AE%B6%E7%9A%84%E8%A1%A5%E5%85%85"><span class="toc-text">大家的补充</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-Linear-Algebra-%EF%BC%9A"><span class="toc-text">1. 线性代数 (Linear Algebra)：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E6%A6%82%E7%8E%87%E5%92%8C%E7%BB%9F%E8%AE%A1-Probability-and-Statistics"><span class="toc-text">2.概率和统计 (Probability and Statistics):</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E5%88%86%E6%9E%90-Analysis-%EF%BC%9A"><span class="toc-text">3.分析 (Analysis)：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-%E6%8B%93%E6%89%91-Topology-%EF%BC%9A"><span class="toc-text">4.拓扑 (Topology)：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5-%E6%B5%81%E5%BD%A2%E7%90%86%E8%AE%BA-Manifold-theory-%EF%BC%9A"><span class="toc-text">5.流形理论 (Manifold theory)：</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A2%86%E5%9F%9F%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87"><span class="toc-text">机器学习领域经典论文</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87-survey%E5%90%88%E9%9B%86"><span class="toc-text">机器学习经典论文&#x2F;survey合集</span></a></li></ol>
    </div>
  </article>
  
  
  <article class="card card-content categories-widget">
    <div class="categories-card">
  <div class="categories-header"><i class="iconfont icon-fenlei" style="padding-right: 2px;"></i>分类</div>
  <div class="categories-list">
    
      <a href="/categories/工具">
        <div class="categories-list-item">
          工具
          <span class="categories-list-item-badge">15</span>
        </div>
      </a>
    
      <a href="/categories/设计模式">
        <div class="categories-list-item">
          设计模式
          <span class="categories-list-item-badge">5</span>
        </div>
      </a>
    
      <a href="/categories/数据结构与算法">
        <div class="categories-list-item">
          数据结构与算法
          <span class="categories-list-item-badge">13</span>
        </div>
      </a>
    
      <a href="/categories/C与C✙✙">
        <div class="categories-list-item">
          C与C✙✙
          <span class="categories-list-item-badge">2</span>
        </div>
      </a>
    
      <a href="/categories/编程资料">
        <div class="categories-list-item">
          编程资料
          <span class="categories-list-item-badge">28</span>
        </div>
      </a>
    
      <a href="/categories/Python">
        <div class="categories-list-item">
          Python
          <span class="categories-list-item-badge">7</span>
        </div>
      </a>
    
      <a href="/categories/ITK与VTK">
        <div class="categories-list-item">
          ITK与VTK
          <span class="categories-list-item-badge">7</span>
        </div>
      </a>
    
      <a href="/categories/Java">
        <div class="categories-list-item">
          Java
          <span class="categories-list-item-badge">23</span>
        </div>
      </a>
    
      <a href="/categories/Linux">
        <div class="categories-list-item">
          Linux
          <span class="categories-list-item-badge">5</span>
        </div>
      </a>
    
      <a href="/categories/SEO教程">
        <div class="categories-list-item">
          SEO教程
          <span class="categories-list-item-badge">2</span>
        </div>
      </a>
    
      <a href="/categories/图像处理与机器学习">
        <div class="categories-list-item">
          图像处理与机器学习
          <span class="categories-list-item-badge">57</span>
        </div>
      </a>
    
      <a href="/categories/计算机基础知识">
        <div class="categories-list-item">
          计算机基础知识
          <span class="categories-list-item-badge">11</span>
        </div>
      </a>
    
      <a href="/categories/技术以外">
        <div class="categories-list-item">
          技术以外
          <span class="categories-list-item-badge">29</span>
        </div>
      </a>
    
  </div>
</div>
  </article>
  
  <article class="card card-content tags-widget">
    <div class="tags-card">
  <div class="tags-header"><i class="iconfont icon-biaoqian" style="padding-right: 2px;"></i>热门标签</div>
  <div class="tags-list">
    
    <a href="\tags\机器学习" title="机器学习"><div class="tags-list-item">机器学习</div></a>
    
    <a href="\tags\算法" title="算法"><div class="tags-list-item">算法</div></a>
    
    <a href="\tags\深度学习" title="深度学习"><div class="tags-list-item">深度学习</div></a>
    
    <a href="\tags\Java" title="Java"><div class="tags-list-item">Java</div></a>
    
    <a href="\tags\工具" title="工具"><div class="tags-list-item">工具</div></a>
    
    <a href="\tags\网站" title="网站"><div class="tags-list-item">网站</div></a>
    
    <a href="\tags\电子书下载" title="电子书下载"><div class="tags-list-item">电子书下载</div></a>
    
    <a href="\tags\ITK" title="ITK"><div class="tags-list-item">ITK</div></a>
    
    <a href="\tags\Python" title="Python"><div class="tags-list-item">Python</div></a>
    
    <a href="\tags\VTK" title="VTK"><div class="tags-list-item">VTK</div></a>
    
    <a href="\tags\设计模式" title="设计模式"><div class="tags-list-item">设计模式</div></a>
    
    <a href="\tags\Linux" title="Linux"><div class="tags-list-item">Linux</div></a>
    
    <a href="\tags\Keras" title="Keras"><div class="tags-list-item">Keras</div></a>
    
    <a href="\tags\图谱分割" title="图谱分割"><div class="tags-list-item">图谱分割</div></a>
    
    <a href="\tags\操作系统" title="操作系统"><div class="tags-list-item">操作系统</div></a>
    
    <a href="\tags\医疗图像" title="医疗图像"><div class="tags-list-item">医疗图像</div></a>
    
  </div>
</div>
  </article>
  
  
</div>
          </aside>
          <aside class="right-column">
            <div class="sticky-widescreen">


<article class="card card-content toc-card">
<div style="">
    <div style="float: left; width: 125px; height: 125px;">
        <img class="adv" style="width: 100%; height: 100%; border: solid 1px #ddd;" src="https://cdn.jsdelivr.net/gh/tqb4342/BlogPhoto@master/20210112103119.jpg">
    </div>
    <div style="float: left; margin-left: 17px; margin-top: 12px;">
        <div style="font-size: 18px; margin-bottom: 12px;margin-left: 4px;">关注我的公众号</div>
        <small style="font-size: 0.8em;">
            →「技术干货」每日推送<br>
            →「免费资料」随时领取<br>
            →「签到活动」每周福利<br>
        </small>
    </div>
    <div style="clear: both;"></div>
	<div style="font-size: 0.8em; margin: 15px 0 10px 0;">
    <a href="https://tanqingbo.cn/coder-source/" target="_blank" style="color:orange;font-size: 14px;" rel="noopener noreferrer">扫描上方二维码，关注我的公众号</a>
    <br>
    <div style="height: 8px;"></div>
    更多干货，等你来看，我在微信上等你！
</div>
</div>
</article>


<article class="card card-content toc-card">
<div class="xingqiu-img"> <a href="https://tanqingbo.cn/msb-source/" target="_blank"><img src="https://cdn.jsdelivr.net/gh/tqb4342/BlogPhoto@master/20210104122757.png"></a></div>
<!--
<div style="clear: both;"></div>
<div style="font-size: 0.8em; margin: 15px 0 10px 0;">
	<strong><span style="caret-color: red;font-size: 15px;color: rgb(77, 168, 238);"><a href="https://tanqingbo.cn/about/" title="计算机专业经典书籍下载">扫码加入星球你将收获：</a></span></strong>
    <div style="height: 8px;"></div>
    1、主流互联网中找不到的副业赚钱方法，帮助你闷声赚钱；
	<div style="height: 5px;"></div>
	2、分享我的投资理财方法以及互联网中各种流量陷阱和套路；
	<div style="height: 5px;"></div>
	3、无限次向我提问，咨询成长方法、求学困惑、副业赚钱等问题。
</div>
-->
</article>


  
  
  <article class="card card-content toc-card">
    <div class="toc-header"><i class="iconfont icon-menu" style="padding-right: 2px;"></i>目录</div>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%A5%E9%97%A8%E4%B9%A6%E5%8D%95"><span class="toc-text">入门书单</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E3%80%8A%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E%E3%80%8B"><span class="toc-text">1.《数学之美》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E3%80%8A%E9%9B%86%E4%BD%93%E6%99%BA%E6%85%A7%E7%BC%96%E7%A8%8B%E3%80%8B"><span class="toc-text">2.《集体智慧编程》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E3%80%8A%E6%99%BA%E8%83%BDweb%E7%AE%97%E6%B3%95%E3%80%8B"><span class="toc-text">3.《智能web算法》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E3%80%8B"><span class="toc-text">4.《统计学习方法》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5-%E3%80%8AMachine-Learning%E3%80%8B%EF%BC%88%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%8B%EF%BC%89"><span class="toc-text">5.《Machine Learning》（《机器学习》）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#6-%E3%80%8AMining-of-Massive-Datasets%E3%80%8B%EF%BC%88%E3%80%8A%E5%A4%A7%E6%95%B0%E6%8D%AE%E3%80%8B%EF%BC%89"><span class="toc-text">6.《Mining of Massive Datasets》（《大数据》）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7-%E3%80%8A%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%9A%E5%AE%9E%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%9C%AF%E3%80%8B"><span class="toc-text">7.《数据挖掘：实用机器学习技术》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#8-%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E3%80%8B"><span class="toc-text">8.《机器学习及其应用》</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%9B%E9%98%B6%E4%B9%A6%E5%8D%95"><span class="toc-text">进阶书单</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E3%80%8APattern-Classification%E3%80%8B%EF%BC%88%E3%80%8A%E6%A8%A1%E5%BC%8F%E5%88%86%E7%B1%BB%E3%80%8B%E7%AC%AC%E4%BA%8C%E7%89%88%EF%BC%89"><span class="toc-text">1.《Pattern Classification》（《模式分类》第二版）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E3%80%8APattern-Recognition-And-Machine-Learning%E3%80%8B"><span class="toc-text">2.《Pattern Recognition And Machine Learning》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E3%80%8A%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E3%80%81%E6%8E%A8%E7%90%86%E4%B8%8E%E9%A2%84%E6%B5%8B%E3%80%8B%E7%AC%AC%E4%BA%8C%E7%89%88"><span class="toc-text">3.《统计学习基础：数据挖掘、推理与预测》第二版</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-%E3%80%8A%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%EF%BC%9A%E6%A6%82%E5%BF%B5%E4%B8%8E%E6%8A%80%E6%9C%AF%E3%80%8B%E7%AC%AC%E4%B8%89%E7%89%88"><span class="toc-text">4.《数据挖掘：概念与技术》第三版</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5-%E3%80%8AAI-Modern-Approach-2nd%E3%80%8B"><span class="toc-text">5.《AI, Modern Approach 2nd》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#6-%E3%80%8AFoundations-of-Statistical-Natural-Language-Processing%E3%80%8B"><span class="toc-text">6.《Foundations of Statistical Natural Language Processing》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7-%E3%80%8AStatistical-Learning-Theory%E3%80%8B"><span class="toc-text">7.《Statistical Learning Theory》</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E4%B9%A6%E5%8D%95"><span class="toc-text">数学基础书单</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E3%80%8A%E7%9F%A9%E9%98%B5%E5%88%86%E6%9E%90%E3%80%8B"><span class="toc-text">1.《矩阵分析》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E3%80%8A%E6%A6%82%E7%8E%87%E8%AE%BA%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E3%80%8B"><span class="toc-text">2.《概率论及其应用》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E3%80%8AAll-Of-Statistics%E3%80%8B"><span class="toc-text">3.《All Of Statistics》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-%E3%80%8ANonlinear-Programming-2nd%E3%80%8B"><span class="toc-text">4.《Nonlinear Programming, 2nd》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5-%E3%80%8AConvex-Optimization%E3%80%8B"><span class="toc-text">5.《Convex Optimization》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#6-%E3%80%8ANumerical-Optimization%E3%80%8B"><span class="toc-text">6.《Numerical Optimization》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#7-%E3%80%8AIntroduction-to-Mathematical-Statistics%E3%80%8B"><span class="toc-text">7.《Introduction to Mathematical Statistics》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#8-%E3%80%8AAn-Introduction-to-Probabilistic-Graphical-Models%E3%80%8B"><span class="toc-text">8.《An Introduction to Probabilistic Graphical Models》</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#9-%E3%80%8AProbabilistic-Graphical-Models-Principles-and-Techniques%E3%80%8B"><span class="toc-text">9.《Probabilistic Graphical Models-Principles and Techniques》</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E5%AE%B6%E7%9A%84%E8%A1%A5%E5%85%85"><span class="toc-text">大家的补充</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0-Linear-Algebra-%EF%BC%9A"><span class="toc-text">1. 线性代数 (Linear Algebra)：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E6%A6%82%E7%8E%87%E5%92%8C%E7%BB%9F%E8%AE%A1-Probability-and-Statistics"><span class="toc-text">2.概率和统计 (Probability and Statistics):</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E5%88%86%E6%9E%90-Analysis-%EF%BC%9A"><span class="toc-text">3.分析 (Analysis)：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-%E6%8B%93%E6%89%91-Topology-%EF%BC%9A"><span class="toc-text">4.拓扑 (Topology)：</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5-%E6%B5%81%E5%BD%A2%E7%90%86%E8%AE%BA-Manifold-theory-%EF%BC%9A"><span class="toc-text">5.流形理论 (Manifold theory)：</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A2%86%E5%9F%9F%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87"><span class="toc-text">机器学习领域经典论文</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87-survey%E5%90%88%E9%9B%86"><span class="toc-text">机器学习经典论文&#x2F;survey合集</span></a></li></ol>
  </article>
  
  
  <article class="card card-content">
    <div class="recent-posts-card">
  <div class="recent-posts-header"><i class="iconfont icon-wenzhang_huaban" style="padding-right: 2px;"></i>最近文章</div>
  <div class="recent-posts-list">
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2021-05-18</div>
        <a href="/暴跌30心态崩了/"><div class="recent-posts-item-content">暴跌30%，心态崩了</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2021-05-15</div>
        <a href="/哪本入门级的学习数据库的书最值得推荐？/"><div class="recent-posts-item-content">哪本入门级的学习数据库的书最值得推荐？</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2021-05-08</div>
        <a href="/蔚来，牛逼！/"><div class="recent-posts-item-content">蔚来，牛逼！</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2021-05-06</div>
        <a href="/微信PC版3.3.0内测更新，电脑可以刷朋友圈了/"><div class="recent-posts-item-content">微信Windows 3.3.0内测更新，电脑可以刷朋友圈了</div></a>
      </div>
    
  </div>
</div>
  </article>

  
  
  
</div>
          </aside>
        </div>
      </div>
    </div>
  </div>
  
  <footer class="footer">
  <div class="footer-container">
    <div>
      <div class="footer-dsc">
        <span>Copyright ©
          
          2020 -
          
          2021
        </span>
        &nbsp;
        <a href="/" class="footer-link">IT&nbsp; 码&nbsp; 农 </a>
      </div>
		<div class="footer-dsc">
			<center><span>
			<a href="https://tanqingbo.cn/CSBook001/" target="_blank">计算机专业最全电子书PDF下载</a> - <a href="https://tanqingbo.cn/links/" target="_blank">友情链接</a>
			</span></center>
		</div>
    </div>

    
    
    
	
    
	

	<div class="footer-dsc">
	<script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
	</script>
	<span id="busuanzi_container_site_pv">
		本站总访问量<span id="busuanzi_value_site_pv"></span>次
	</span> &nbsp;|&nbsp
	<span id="busuanzi_container_site_uv">
		本站总访客数<span id="busuanzi_value_site_uv"></span>次
	</span>
	</div>
	
	
	
</footer>
  <a role="button" id="scrollbutton" class="basebutton" >
  <i class="iconfont icon-arrowleft button-icon"></i>
</a>
<a role="button" id="menubutton" class="basebutton">
  <i class="iconfont icon-menu button-icon"></i>
</a>
<a role="button" id="popbutton" class="basebutton">
  <i class="iconfont icon-expand button-icon"></i>
</a>
<a role="button" id="darkbutton" class="basebutton darkwidget">
  <i class="iconfont icon-weather button-icon"></i>
</a>
<a role="button" id="searchbutton" class="basebutton searchwidget">
  <i class="iconfont icon-search button-icon"></i>
</a>

  
  
  

  
  
  <script>
  var addImgLayout = function () {
    var img = document.querySelectorAll('.post-content img');
    var i;
    for (i = 0; i < img.length; i++) {
      var wrapper = document.createElement('a');
      wrapper.setAttribute('data-fslightbox', 'gallery');
      wrapper.setAttribute('href', img[i].getAttribute('data-src'));
      wrapper.style.cssText = 'width: 100%; display: flex; justify-content: center;';
      img[i].before(wrapper);
      wrapper.append(img[i]);
    }
    refreshFsLightbox();
  }
</script>
<script>loadScript("//cdn.jsdelivr.net/npm/fslightbox@3.1.0/index.min.js", addImgLayout)</script>
  
  
  
<script src="/js/main.js"></script>

  
  
  <script>
    var addLazyload = function () {
      var observer = lozad('.lozad', {
        load: function (el) {
          el.srcset = el.getAttribute('data-src');
        },
        loaded: function (el) {
          el.classList.add('loaded');
        }
      });
      observer.observe();
    }
  </script>
  <script>loadScript("/js/lib/lozad.min.js", addLazyload)</script>
  
  
  <script>
    var googleAnalytics = function() {
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-178024758-1');
    }
  </script>
  <script>loadScript("https://www.googletagmanager.com/gtag/js?id=" + "UA-178024758-1", googleAnalytics)</script>
  
</body>

</html>